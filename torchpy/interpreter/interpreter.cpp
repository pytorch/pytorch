#include <dlfcn.h>

#define PY_SSIZE_T_CLEAN
#include <Python.h>
#include <iostream>
#include "interpreter_impl.h"

#include <assert.h>
#include <pybind11/embed.h>
#include <stdio.h>
#include <torch/csrc/autograd/generated/variable_factories.h>
#include <torch/csrc/jit/python/pybind_utils.h>
#include <iostream>
#include <map>
#include <thread>

namespace py = pybind11;
using namespace py::literals;

// TODO this should come from cmake
#define DEBUG 1

#if (DEBUG == 1)
#define PYOBJ_ASSERT(obj) \
  if (NULL == obj) {      \
    PyErr_Print();        \
  }                       \
  assert(NULL != obj);
#elif (DEBUG == 0)
#define PYOBJ_ASSERT(obj) assert(NULL != obj);
#endif

// This is generated by cmake with the path to the compiled cpython
#include "python_path.h"

static wchar_t* program;

#define FOREACH_LIBRARY(_) \
  _(array)                 \
  _(_asyncio)              \
  _(audioop)               \
  _(binascii)              \
  _(_bisect)               \
  _(_blake2)               \
  _(_bz2)                  \
  _(cmath)                 \
  _(_codecs_cn)            \
  _(_codecs_hk)            \
  _(_codecs_iso2022)       \
  _(_codecs_jp)            \
  _(_codecs_kr)            \
  _(_codecs_tw)            \
  _(_contextvars)          \
  _(_crypt)                \
  _(_csv)                  \
  _(_ctypes)               \
  _(_ctypes_test)          \
  _(_curses)               \
  _(_curses_panel)         \
  _(_datetime)             \
  _(_decimal)              \
  _(_elementtree)          \
  _(fcntl)                 \
  _(grp)                   \
  _(_hashlib)              \
  _(_heapq)                \
  _(_json)                 \
  _(_lsprof)               \
  _(_lzma)                 \
  _(math)                  \
  _(_md5)                  \
  _(mmap)                  \
  _(_multibytecodec)       \
  _(_multiprocessing)      \
  _(nis)                   \
  _(_opcode)               \
  _(ossaudiodev)           \
  _(parser)                \
  _(_pickle)               \
  _(_posixsubprocess)      \
  _(pyexpat)               \
  _(_queue)                \
  _(_random)               \
  _(readline)              \
  _(resource)              \
  _(select)                \
  _(_sha1)                 \
  _(_sha256)               \
  _(_sha3)                 \
  _(_sha512)               \
  _(_socket)               \
  _(spwd)                  \
  _(_ssl)                  \
  _(_struct)               \
  _(syslog)                \
  _(termios)               \
  _(_testbuffer)           \
  _(_testcapi)             \
  _(_testimportmultiple)   \
  _(_testmultiphase)       \
  _(unicodedata)           \
  _(xxlimited)             \
  _(_xxtestfuzz)           \
  _(zlib)

#define DECLARE_LIBRARY_INIT(name) extern "C" PyObject* PyInit_##name(void);
FOREACH_LIBRARY(DECLARE_LIBRARY_INIT)
#undef DECLARE_LIBRARY_INIT

extern "C" __attribute__((visibility("default"))) void initialize_interface(
    InterpreterImpl* s) {
#define INITIALIZE_MEMBER(func) s->func = func;
  FOREACH_INTERFACE_FUNCTION(INITIALIZE_MEMBER)
#undef INITIALIZE_MEMBER
}

const char* finder = R"RAW(
import sys
class F:
    def find_spec(self, fullname, path, target=None):
        if fullname == 'torch._C':
            return sys.meta_path[1].find_spec('torch._C', None, None)
        return None
sys.meta_path.insert(0, F())

# make loader importable
)RAW";

extern "C" PyObject* initModule(void);

std::map<std::thread::id, PyThreadState*> thread_states;
PyThreadState* mainThreadState = NULL;
PyInterpreterState* interpreterState = NULL;
std::thread::id mainThreadId;
static std::atomic<size_t> s_id;
std::map<size_t, py::object> forwards;

void thread_enter() {
  std::thread::id my_tid = std::this_thread::get_id();
  if (thread_states.find(my_tid) == thread_states.end()) {
    if (my_tid == mainThreadId || thread_states.size() == 0) {
      std::cout << "Bootstrap main tread state for tid " << my_tid << std::endl;
      thread_states[my_tid] = mainThreadState;

    } else {
      std::cout << "Create new thread state for tid " << my_tid << std::endl;
      thread_states[my_tid] = PyThreadState_New(interpreterState);
    }
  } else {
    std::cout << "Found thread state for tid " << my_tid << std::endl;
  }
  PyThreadState* myThreadState = thread_states[my_tid];
  assert(myThreadState != nullptr);
  PyEval_RestoreThread(myThreadState); // Acquires GIL
}

void thread_exit() {
  std::thread::id my_tid = std::this_thread::get_id();
  PyThreadState* myThreadState = thread_states[my_tid];
  PyEval_ReleaseThread(myThreadState); // Releases GIL
}

__attribute__((constructor)) void init() {
  // some dependency in mkl requires this...
  void* result = dlopen("libz.so", RTLD_GLOBAL | RTLD_LAZY);
  assert(result);

  program = Py_DecodeLocale("main", NULL);
  if (program == NULL) {
    fprintf(stderr, "Fatal error: cannot decode argv[0]\n");
    exit(1);
  }
  Py_SetProgramName(program);
#define APPEND_INIT(name) PyImport_AppendInittab(#name, PyInit_##name);
  FOREACH_LIBRARY(APPEND_INIT)
#undef APPEND_INIT
  PyImport_AppendInittab("torch._C", initModule);
  Py_Initialize();
  PyRun_SimpleString(PY_PATH_STRING);
  PyRun_SimpleString(finder);
  // mainThreadState = PyEval_SaveThread(); // save our state, release GIL
  mainThreadState = PyThreadState_Get();
  interpreterState = mainThreadState->interp;
  mainThreadId = std::this_thread::get_id();
  std::cout << "init() tid " << mainThreadId << std::endl;
  assert(interpreterState != nullptr);
  PyEval_ReleaseThread(mainThreadState);
}

static void teardown() {
  std::cout << "teardown!" << std::endl;
  // thread_enter();
  // TODO this function needs to handle being called from a crashed thread of
  // during overall shutdown what should the convention be? should not iterate
  // threadstates here probably. forwards.clear();

  // for (auto it = thread_states.begin(); it != thread_states.end(); it++) {
  // PyThreadState_Clear(it->second);
  // PyThreadState_Delete(it->second);
  // }
  // thread_states.clear();

  if (Py_FinalizeEx() < 0) {
    std::cout << "IT BROKE SO WE ARE EXITING\n";
    exit(120);
  }
  PyMem_RawFree(program);
}

__attribute__((destructor)) void deinit() {}

static void run_some_python(const char* code) {
  thread_enter();

  if (PyRun_SimpleString(code) == -1) {
    throw std::runtime_error("python eval failed\n");
  }

  thread_exit();
}

static void run_python_file(const char* code) {
  thread_enter();

  FILE* f = fopen(code, "r");
  if (PyRun_SimpleFile(f, code) == -1) {
    throw std::runtime_error("python eval failed\n");
  }
  fclose(f);

  thread_exit();
}


static size_t load_model(const char* filename) {
  thread_enter();
  assert(PyGILState_Check() == 1);
  std::thread::id my_tid = std::this_thread::get_id();

  std::string code = std::string("model = torch.jit.load('") +
      std::string(filename) + std::string("')");
  py::exec(code);

  std::cout << "loaded model " << my_tid << std::endl;
  auto id = ++s_id;

  thread_exit();
  return id;
}

static at::Tensor forward_model(size_t model_id, at::Tensor input) {
  at::Tensor output;
  thread_enter();
  {
    std::thread::id my_tid = std::this_thread::get_id();
    assert(PyGILState_Check() == 1);
    std::cout << "forward_model enter " << my_tid << std::endl;
    // auto forward = forwards[model_id];
    py::exec("print('py: calling forward!', model.forward)");
    auto forward = py::globals()["model"].attr("forward");
    std::cout << "found forward! " << my_tid << std::endl;

    py::object py_output = forward(input);
    std::cout << "called forward!!" << std::endl;
    // TODO is this going to leak?
    // added it to prevent crash wehn using 'output' tensor in callee of
    // forward()
    py_output.inc_ref();
    output = py::cast<at::Tensor>(py_output);
    std::cout << "forward_model exit" << std::endl;
  }
  thread_exit();

  return output;
  // return input;
}
