Traceback (most recent call last):
  File "/data/users/tianren/pytorch/test_torch_cond_integration.py", line 134, in test_3_functional_correctness
    result1 = compiled_op(x1, weight)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_dynamo/eval_frame.py", line 934, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/compile_fx.py", line 1016, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/data/users/tianren/pytorch/torch/_inductor/compile_fx.py", line 1000, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
                        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/compile_fx.py", line 1754, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/compile_fx.py", line 1449, in codegen_and_compile
    graph.run(*example_inputs)
  File "/data/users/tianren/pytorch/torch/_inductor/graph.py", line 983, in run
    return super().run(*args)
           ^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/fx/interpreter.py", line 200, in run
    self.env[node] = self.run_node(node)
                     ^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/graph.py", line 1697, in run_node
    result = super().run_node(n)
             ^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/fx/interpreter.py", line 295, in run_node
    return getattr(self, n.op)(n.target, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/graph.py", line 1341, in call_function
    raise LoweringException(e, target, args, kwargs).with_traceback(
  File "/data/users/tianren/pytorch/torch/_inductor/graph.py", line 1331, in call_function
    out = lowerings[target](*args, **kwargs)  # type: ignore[index]
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/kernel/custom_op.py", line 965, in range_based_lowering_wrapper
    return _range_based_lowering_fn(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/kernel/custom_op.py", line 744, in _range_based_lowering_fn
    autotuned_result, winning_choice = autotune_custom_op(
                                       ^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/kernel/custom_op.py", line 581, in autotune_custom_op
    layout=FixedLayout(
           ^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/ir.py", line 3691, in __init__
    assert all(isinstance(s, (Expr, int)) for s in size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch._inductor.exc.InductorError: LoweringException: AssertionError: 
  target: test_cond.dispatch_op.default
  args[0]: TensorBox(StorageBox(
    InputBuffer(name='arg3_1', layout=FixedLayout('cuda:0', torch.float32, size=[s33, s50, s69], stride=[s50*s69, s69, 1]))
  ))
  args[1]: TensorBox(StorageBox(
    InputBuffer(name='arg4_1', layout=FixedLayout('cuda:0', torch.float32, size=[s69], stride=[1]))
  ))

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Traceback (most recent call last):
  File "/data/users/tianren/pytorch/test_torch_cond_integration.py", line 159, in test_3_functional_correctness
    result2 = compiled_op(x2, weight)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_dynamo/eval_frame.py", line 934, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/compile_fx.py", line 1016, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/data/users/tianren/pytorch/torch/_inductor/compile_fx.py", line 1000, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
                        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/compile_fx.py", line 1754, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/compile_fx.py", line 1449, in codegen_and_compile
    graph.run(*example_inputs)
  File "/data/users/tianren/pytorch/torch/_inductor/graph.py", line 983, in run
    return super().run(*args)
           ^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/fx/interpreter.py", line 200, in run
    self.env[node] = self.run_node(node)
                     ^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/graph.py", line 1697, in run_node
    result = super().run_node(n)
             ^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/fx/interpreter.py", line 295, in run_node
    return getattr(self, n.op)(n.target, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/graph.py", line 1341, in call_function
    raise LoweringException(e, target, args, kwargs).with_traceback(
  File "/data/users/tianren/pytorch/torch/_inductor/graph.py", line 1331, in call_function
    out = lowerings[target](*args, **kwargs)  # type: ignore[index]
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/kernel/custom_op.py", line 965, in range_based_lowering_wrapper
    return _range_based_lowering_fn(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/kernel/custom_op.py", line 744, in _range_based_lowering_fn
    autotuned_result, winning_choice = autotune_custom_op(
                                       ^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/kernel/custom_op.py", line 605, in autotune_custom_op
    selected_result, winning_choice = autotune_select_algorithm(
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/select_algorithm.py", line 4006, in autotune_select_algorithm
    return cache(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/select_algorithm.py", line 2808, in __call__
    timings = self.do_autotuning(
              ^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/select_algorithm.py", line 3036, in do_autotuning
    raise NoValidChoicesError
torch._inductor.exc.InductorError: LoweringException: NoValidChoicesError: 
  target: test_cond.dispatch_op.default
  args[0]: TensorBox(StorageBox(
    InputBuffer(name='arg3_1', layout=FixedLayout('cuda:0', torch.float32, size=[s33, s50, s69], stride=[s50*s69, s69, 1]))
  ))
  args[1]: TensorBox(StorageBox(
    InputBuffer(name='arg4_1', layout=FixedLayout('cuda:0', torch.float32, size=[s69], stride=[1]))
  ))

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Traceback (most recent call last):
  File "/data/users/tianren/pytorch/test_torch_cond_integration.py", line 184, in test_3_functional_correctness
    result3 = compiled_op(x3, weight)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_dynamo/eval_frame.py", line 934, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/compile_fx.py", line 1016, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/data/users/tianren/pytorch/torch/_inductor/compile_fx.py", line 1000, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
                        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/compile_fx.py", line 1754, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/compile_fx.py", line 1449, in codegen_and_compile
    graph.run(*example_inputs)
  File "/data/users/tianren/pytorch/torch/_inductor/graph.py", line 983, in run
    return super().run(*args)
           ^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/fx/interpreter.py", line 200, in run
    self.env[node] = self.run_node(node)
                     ^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/graph.py", line 1697, in run_node
    result = super().run_node(n)
             ^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/fx/interpreter.py", line 295, in run_node
    return getattr(self, n.op)(n.target, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/graph.py", line 1341, in call_function
    raise LoweringException(e, target, args, kwargs).with_traceback(
  File "/data/users/tianren/pytorch/torch/_inductor/graph.py", line 1331, in call_function
    out = lowerings[target](*args, **kwargs)  # type: ignore[index]
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/kernel/custom_op.py", line 965, in range_based_lowering_wrapper
    return _range_based_lowering_fn(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/kernel/custom_op.py", line 744, in _range_based_lowering_fn
    autotuned_result, winning_choice = autotune_custom_op(
                                       ^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/kernel/custom_op.py", line 605, in autotune_custom_op
    selected_result, winning_choice = autotune_select_algorithm(
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/select_algorithm.py", line 4006, in autotune_select_algorithm
    return cache(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/select_algorithm.py", line 2808, in __call__
    timings = self.do_autotuning(
              ^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/select_algorithm.py", line 3036, in do_autotuning
    raise NoValidChoicesError
torch._inductor.exc.InductorError: LoweringException: NoValidChoicesError: 
  target: test_cond.dispatch_op.default
  args[0]: TensorBox(StorageBox(
    InputBuffer(name='arg3_1', layout=FixedLayout('cuda:0', torch.float32, size=[s33, s50, s69], stride=[s50*s69, s69, 1]))
  ))
  args[1]: TensorBox(StorageBox(
    InputBuffer(name='arg4_1', layout=FixedLayout('cuda:0', torch.float32, size=[s69], stride=[1]))
  ))

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Traceback (most recent call last):
  File "/data/users/tianren/pytorch/test_torch_cond_integration.py", line 351, in test_8_edge_cases
    result = compiled_single(x, weight)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_dynamo/eval_frame.py", line 934, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/compile_fx.py", line 1016, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/data/users/tianren/pytorch/torch/_inductor/compile_fx.py", line 1000, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
                        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/compile_fx.py", line 1754, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/compile_fx.py", line 1449, in codegen_and_compile
    graph.run(*example_inputs)
  File "/data/users/tianren/pytorch/torch/_inductor/graph.py", line 983, in run
    return super().run(*args)
           ^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/fx/interpreter.py", line 200, in run
    self.env[node] = self.run_node(node)
                     ^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/graph.py", line 1697, in run_node
    result = super().run_node(n)
             ^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/fx/interpreter.py", line 295, in run_node
    return getattr(self, n.op)(n.target, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/graph.py", line 1341, in call_function
    raise LoweringException(e, target, args, kwargs).with_traceback(
  File "/data/users/tianren/pytorch/torch/_inductor/graph.py", line 1331, in call_function
    out = lowerings[target](*args, **kwargs)  # type: ignore[index]
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/kernel/custom_op.py", line 965, in range_based_lowering_wrapper
    return _range_based_lowering_fn(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/kernel/custom_op.py", line 744, in _range_based_lowering_fn
    autotuned_result, winning_choice = autotune_custom_op(
                                       ^^^^^^^^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/kernel/custom_op.py", line 581, in autotune_custom_op
    layout=FixedLayout(
           ^^^^^^^^^^^^
  File "/data/users/tianren/pytorch/torch/_inductor/ir.py", line 3691, in __init__
    assert all(isinstance(s, (Expr, int)) for s in size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch._inductor.exc.InductorError: LoweringException: AssertionError: 
  target: test_cond.single_impl_op.default
  args[0]: TensorBox(StorageBox(
    InputBuffer(name='arg3_1', layout=FixedLayout('cuda:0', torch.float32, size=[s33, s50, s69], stride=[s50*s69, s69, 1]))
  ))
  args[1]: TensorBox(StorageBox(
    InputBuffer(name='arg4_1', layout=FixedLayout('cuda:0', torch.float32, size=[s69], stride=[1]))
  ))

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


ğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ª
torch.cond Dispatch Integration Test Suite
ğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ªğŸ§ª

================================================================================
TEST 1: Registration
================================================================================
âœ… Registration successful

================================================================================
TEST 2: Compilation
================================================================================
âœ… Compilation successful

================================================================================
TEST 3: Functional Correctness
================================================================================

  3a. Short sequence (seq_len=256) - should use SIN
     âŒ ERROR: LoweringException: AssertionError: 
  target: test_cond.dispatch_op.default
  args[0]: TensorBox(StorageBox(
    InputBuffer(name='arg3_1', layout=FixedLayout('cuda:0', torch.float32, size=[s33, s50, s69], stride=[s50*s69, s69, 1]))
  ))
  args[1]: TensorBox(StorageBox(
    InputBuffer(name='arg4_1', layout=FixedLayout('cuda:0', torch.float32, size=[s69], stride=[1]))
  ))

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


  3b. Medium sequence (seq_len=1024) - should use TANH
     âŒ ERROR: LoweringException: NoValidChoicesError: 
  target: test_cond.dispatch_op.default
  args[0]: TensorBox(StorageBox(
    InputBuffer(name='arg3_1', layout=FixedLayout('cuda:0', torch.float32, size=[s33, s50, s69], stride=[s50*s69, s69, 1]))
  ))
  args[1]: TensorBox(StorageBox(
    InputBuffer(name='arg4_1', layout=FixedLayout('cuda:0', torch.float32, size=[s69], stride=[1]))
  ))

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


  3c. Long sequence (seq_len=4096) - should use RELU
     âŒ ERROR: LoweringException: NoValidChoicesError: 
  target: test_cond.dispatch_op.default
  args[0]: TensorBox(StorageBox(
    InputBuffer(name='arg3_1', layout=FixedLayout('cuda:0', torch.float32, size=[s33, s50, s69], stride=[s50*s69, s69, 1]))
  ))
  args[1]: TensorBox(StorageBox(
    InputBuffer(name='arg4_1', layout=FixedLayout('cuda:0', torch.float32, size=[s69], stride=[1]))
  ))

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


  Summary: âŒ Some tests FAILED

================================================================================
TEST 4: Symbolic Shape Preservation
================================================================================

  Checking for symbolic shape indicators in logs...
  Look for log messages like:
    - 'Created fake inputs with symbolic shapes'
    - 'dispatch_dim shape[1] = s<number> (type: SymInt)'
    - 'torch.cond in traced graph: True'

  ğŸ’¡ To verify symbolic shapes:
     Run with: TORCH_LOGS=+inductor python test_torch_cond_integration.py
     Check for 'SymInt' type in debug logs

  âš ï¸  Manual verification required

================================================================================
TEST 5: torch.cond in Traced Graph
================================================================================

  Checking for torch.cond in traced graph...
  Expected pattern:
    %cond = call_function[target=torch.ops.higher_order.cond]

  ğŸ’¡ To verify torch.cond:
     1. Run with: TORCH_LOGS=+output_code,+graph
     2. Look for 'higher_order.cond' in graph output
     3. Check for nested subgraphs (true_graph_0, false_graph_0)

  âš ï¸  Manual verification required

================================================================================
TEST 6: Subgraph Structure
================================================================================

  Expected subgraph structure:
    Main graph
    â”œâ”€ true_graph_0                      (sin implementation)
    â””â”€ false_graph_0                     (nested cond)
        â”œâ”€ false_graph_0.true_graph_0   (tanh implementation)
        â””â”€ false_graph_0.false_graph_0  (relu implementation)

  Expected operators in subgraphs:
    - true_graph_0: torch.ops.aten.sin.default
    - false_graph_0.true_graph_0: torch.ops.aten.tanh.default
    - false_graph_0.false_graph_0: torch.ops.aten.relu.default

  ğŸ’¡ To verify subgraphs:
     Run with: TORCH_LOGS=+graph
     Count number of subgraphs (should be 4 total)

  âš ï¸  Manual verification required

================================================================================
TEST 7: SubgraphBuffer Not Used
================================================================================

  Verifying old SubgraphBuffer approach is NOT used...
  Should NOT see:
    - 'Created SubgraphBuffer with multi-range dispatch'
    - Python runtime if-else dispatch code

  Should see instead:
    - 'Creating torch.cond dispatch'
    - 'Successfully traced torch.cond dispatch'
    - 'Inlining torch.cond dispatch graph'

  ğŸ’¡ To verify:
     Check logs for 'torch.cond' messages, not 'SubgraphBuffer'

  âš ï¸  Manual verification required

================================================================================
TEST 8: Edge Cases
================================================================================

  Testing edge case: All ranges select same implementation
  Expected behavior: Direct inline, no torch.cond dispatch

  âŒ ERROR: LoweringException: AssertionError: 
  target: test_cond.single_impl_op.default
  args[0]: TensorBox(StorageBox(
    InputBuffer(name='arg3_1', layout=FixedLayout('cuda:0', torch.float32, size=[s33, s50, s69], stride=[s50*s69, s69, 1]))
  ))
  args[1]: TensorBox(StorageBox(
    InputBuffer(name='arg4_1', layout=FixedLayout('cuda:0', torch.float32, size=[s69], stride=[1]))
  ))

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


================================================================================
FINAL TEST SUMMARY
================================================================================

Automated Tests:
  âœ“ Registration:    âœ… PASS
  âœ“ Compilation:     âœ… PASS
  âœ“ Functional:      âŒ FAIL
      - short   : âŒ FAIL
      - medium  : âŒ FAIL
      - long    : âŒ FAIL
  âœ“ Edge Cases:      âŒ FAIL

Manual Verification Tests:
  âš ï¸  Symbolic Shapes:    (Check logs with TORCH_LOGS=+inductor)
  âš ï¸  torch.cond Graph:   (Check logs with TORCH_LOGS=+graph)
  âš ï¸  Subgraph Structure: (Check logs with TORCH_LOGS=+graph)
  âš ï¸  No SubgraphBuffer:  (Check logs for 'torch.cond' not 'SubgraphBuffer')

================================================================================
âŒ SOME TESTS FAILED

Failed tests:
  - functional
  - edge_cases
================================================================================
