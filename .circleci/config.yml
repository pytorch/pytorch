# IMPORTANT: To update Docker image version, please search and update ":{previous_version}"
# in this file to the new version number, and **ALSO** update the version number below:
# PyTorchDockerVersion:262
# Caffe2DockerVersion:230

docker_config_defaults: &docker_config_defaults
  user: jenkins
  aws_auth:
    # This IAM user only allows read-write access to ECR
    aws_access_key_id: ${CIRCLECI_AWS_ACCESS_KEY_FOR_ECR_READ_WRITE_V2}
    aws_secret_access_key: ${CIRCLECI_AWS_SECRET_KEY_FOR_ECR_READ_WRITE_V2}

# NOTE: We only perform the merge in build step and not in test step, because
# all source files will be shared from build to test
install_official_git_client: &install_official_git_client
  name: Install Official Git Client
  no_output_timeout: "1h"
  command: |
    set -e
    sudo apt-get -qq update
    sudo apt-get -qq install openssh-client git

setup_ci_environment: &setup_ci_environment
  name: Set Up CI Environment
  no_output_timeout: "1h"
  command: |
    set -e

    curl -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
    echo "deb https://nvidia.github.io/libnvidia-container/ubuntu14.04/amd64 /" | sudo tee -a /etc/apt/sources.list.d/nvidia-docker.list
    echo "deb https://nvidia.github.io/nvidia-container-runtime/ubuntu14.04/amd64 /" | sudo tee -a /etc/apt/sources.list.d/nvidia-docker.list
    echo "deb https://nvidia.github.io/nvidia-docker/ubuntu14.04/amd64 /" | sudo tee -a /etc/apt/sources.list.d/nvidia-docker.list

    sudo apt-get -qq update
    sudo apt-get -qq remove linux-image-generic linux-headers-generic linux-generic
    sudo apt-get -qq install \
      linux-headers-$(uname -r) \
      linux-image-generic \
      moreutils \
      nvidia-docker2 \
      expect-dev

    sudo pkill -SIGHUP dockerd

    sudo pip -q install awscli==1.16.35

    if [[ "${JOB_BASE_NAME}" == *-test* ]]; then
      if [ -n "${CUDA_VERSION}" ]; then
        wget 'https://s3.amazonaws.com/ossci-linux/nvidia_driver/NVIDIA-Linux-x86_64-396.26.run'
        sudo /bin/bash ./NVIDIA-Linux-x86_64-396.26.run -s --no-drm
        nvidia-smi
      fi
    fi

    if [[ "${JOB_BASE_NAME}" == *-build ]]; then
      echo "declare -x IN_CIRCLECI=1" > /home/circleci/project/env
      echo "declare -x COMMIT_SOURCE=${CIRCLE_BRANCH}" >> /home/circleci/project/env
      echo "declare -x PYTHON_VERSION=${PYTHON_VERSION}" >> /home/circleci/project/env
      echo "declare -x SCCACHE_BUCKET=ossci-compiler-cache-circleci-v2" >> /home/circleci/project/env
      if [ -n "${CUDA_VERSION}" ]; then
        echo "declare -x TORCH_CUDA_ARCH_LIST=5.2" >> /home/circleci/project/env
      fi
      export SCCACHE_MAX_JOBS=`expr $(nproc) - 1`
      export MEMORY_LIMIT_MAX_JOBS=8  # the "large" resource class on CircleCI has 32 CPU cores, if we use all of them we'll OOM
      export MAX_JOBS=$(( ${SCCACHE_MAX_JOBS} > ${MEMORY_LIMIT_MAX_JOBS} ? ${MEMORY_LIMIT_MAX_JOBS} : ${SCCACHE_MAX_JOBS} ))
      echo "declare -x MAX_JOBS=${MAX_JOBS}" >> /home/circleci/project/env

      # This IAM user allows write access to S3 bucket for sccache
      echo "declare -x AWS_ACCESS_KEY_ID=${CIRCLECI_AWS_ACCESS_KEY_FOR_SCCACHE_S3_BUCKET_V2}" >> /home/circleci/project/env
      echo "declare -x AWS_SECRET_ACCESS_KEY=${CIRCLECI_AWS_SECRET_KEY_FOR_SCCACHE_S3_BUCKET_V2}" >> /home/circleci/project/env
    fi

    # This IAM user only allows read-write access to ECR
    export AWS_ACCESS_KEY_ID=${CIRCLECI_AWS_ACCESS_KEY_FOR_ECR_READ_WRITE_V2}
    export AWS_SECRET_ACCESS_KEY=${CIRCLECI_AWS_SECRET_KEY_FOR_ECR_READ_WRITE_V2}
    eval $(aws ecr get-login --region us-east-1 --no-include-email)

pytorch_linux_build_defaults: &pytorch_linux_build_defaults
  resource_class: large
  machine:
    image: default
  steps:
  - run:
      <<: *install_official_git_client
  - checkout
  - run:
      <<: *setup_ci_environment
  - run:
      name: Build
      no_output_timeout: "1h"
      command: |
        set -e
        # Pull Docker image and run build
        echo "DOCKER_IMAGE: "${DOCKER_IMAGE}
        docker pull ${DOCKER_IMAGE} >/dev/null
        export id=$(docker run -t -d -w /var/lib/jenkins ${DOCKER_IMAGE})

        git submodule sync && git submodule update -q --init

        docker cp /home/circleci/project/. $id:/var/lib/jenkins/workspace

        export COMMAND='((echo "export JOB_BASE_NAME=${JOB_BASE_NAME}" && echo "source ./workspace/env" && echo "sudo chown -R jenkins workspace && cd workspace && .jenkins/pytorch/build.sh") | docker exec -u jenkins -i "$id" bash) 2>&1'
        echo ${COMMAND} > ./command.sh && unbuffer bash ./command.sh | ts

        # Push intermediate Docker image for next phase to use
        if [ -z "${BUILD_ONLY}" ]; then
          export COMMIT_DOCKER_IMAGE=${DOCKER_IMAGE}-${CIRCLE_SHA1}
          docker commit "$id" ${COMMIT_DOCKER_IMAGE}
          docker push ${COMMIT_DOCKER_IMAGE}
        fi

pytorch_linux_test_defaults: &pytorch_linux_test_defaults
  machine:
    image: default
  steps:
  - run:
      <<: *setup_ci_environment
  - run:
      name: Test
      no_output_timeout: "1h"
      command: |
        set -e
        export COMMIT_DOCKER_IMAGE=${DOCKER_IMAGE}-${CIRCLE_SHA1}
        echo "DOCKER_IMAGE: "${COMMIT_DOCKER_IMAGE}
        docker pull ${COMMIT_DOCKER_IMAGE} >/dev/null
        if [ -n "${CUDA_VERSION}" ]; then
          export id=$(docker run --runtime=nvidia -t -d -w /var/lib/jenkins ${COMMIT_DOCKER_IMAGE})
        else
          export id=$(docker run -t -d -w /var/lib/jenkins ${COMMIT_DOCKER_IMAGE})
        fi
        if [ -n "${MULTI_GPU}" ]; then
          export COMMAND='((echo "export JOB_BASE_NAME=${JOB_BASE_NAME}" && echo "source ./workspace/env" && echo "sudo chown -R jenkins workspace && cd workspace && .jenkins/pytorch/multigpu-test.sh") | docker exec -u jenkins -i "$id" bash) 2>&1'
        else
          export COMMAND='((echo "export JOB_BASE_NAME=${JOB_BASE_NAME}" && echo "source ./workspace/env" && echo "sudo chown -R jenkins workspace && cd workspace && .jenkins/pytorch/test.sh") | docker exec -u jenkins -i "$id" bash) 2>&1'
        fi
        echo ${COMMAND} > ./command.sh && unbuffer bash ./command.sh | ts

caffe2_linux_build_defaults: &caffe2_linux_build_defaults
  resource_class: large
  machine:
    image: default
  steps:
  - run:
      <<: *install_official_git_client
  - checkout
  - run:
      <<: *setup_ci_environment
  - run:
      name: Build
      no_output_timeout: "1h"
      command: |
        set -e
        # TODO: merge this into Caffe2 build.sh
        cat >/home/circleci/project/ci_build_script.sh <<EOL
        # =================== The following code will be executed inside Docker container ===================
        set -ex

        # Reinitialize submodules
        git submodule sync && git submodule update -q --init --recursive

        mkdir -p build

        # Configure additional cmake arguments
        cmake_args=()
        cmake_args+=("$CMAKE_ARGS")

        if [[ $BUILD_ENVIRONMENT == *aten* ]]; then
          cmake_args+=("-DBUILD_ATEN=ON")
        fi

        # conda must be added to the path for Anaconda builds (this location must be
        # the same as that in install_anaconda.sh used to build the docker image)
        if [[ "${BUILD_ENVIRONMENT}" == conda* ]]; then
          export PATH=/opt/conda/bin:$PATH
          sudo chown -R jenkins:jenkins '/opt/conda'
        fi

        # set the env var for onnx build and test
        if [[ "$BUILD_ENVIRONMENT" == *onnx* ]]; then
          export INTEGRATED=1
        fi

        # Build
        if test -x ".jenkins/caffe2/build.sh"; then
          ./.jenkins/caffe2/build.sh ${cmake_args[@]}
        else
          ./.jenkins/build.sh ${cmake_args[@]}
        fi

        # Show sccache stats if it is running
        if pgrep sccache > /dev/null; then
          sccache --show-stats
        fi
        # =================== The above code will be executed inside Docker container ===================
        EOL
        chmod +x /home/circleci/project/ci_build_script.sh

        echo "DOCKER_IMAGE: "${DOCKER_IMAGE}
        docker pull ${DOCKER_IMAGE} >/dev/null
        export id=$(docker run -t -d -w /var/lib/jenkins ${DOCKER_IMAGE})
        docker cp /home/circleci/project/. $id:/var/lib/jenkins/workspace

        export COMMAND='((echo "source ./workspace/env" && echo "sudo chown -R jenkins workspace && cd workspace && ./ci_build_script.sh") | docker exec -u jenkins -i "$id" bash) 2>&1'
        echo ${COMMAND} > ./command.sh && unbuffer bash ./command.sh | ts

        # Push intermediate Docker image for next phase to use
        if [ -z "${BUILD_ONLY}" ]; then
          export COMMIT_DOCKER_IMAGE=${DOCKER_IMAGE}-${CIRCLE_SHA1}
          docker commit "$id" ${COMMIT_DOCKER_IMAGE}
          docker push ${COMMIT_DOCKER_IMAGE}
        fi

caffe2_linux_test_defaults: &caffe2_linux_test_defaults
  machine:
    image: default
  steps:
  - run:
      <<: *setup_ci_environment
  - run:
      name: Test
      no_output_timeout: "1h"
      command: |
        set -e
        # TODO: merge this into Caffe2 test.sh
        cat >/home/circleci/project/ci_test_script.sh <<EOL
        # =================== The following code will be executed inside Docker container ===================
        set -ex

        # libdc1394 (dependency of OpenCV) expects /dev/raw1394 to exist...
        sudo ln /dev/null /dev/raw1394

        # Hotfix, use hypothesis 3.44.6 on Ubuntu 14.04
        # See comments on https://github.com/HypothesisWorks/hypothesis-python/commit/eadd62e467d6cee6216e71b391951ec25b4f5830
        if [[ "$BUILD_ENVIRONMENT" == *ubuntu14.04* ]]; then
          sudo pip -q uninstall -y hypothesis
          # "pip install hypothesis==3.44.6" from official server is unreliable on CircleCI, so we host a copy on S3 instead
          sudo pip -q install attrs==18.1.0 -f https://s3.amazonaws.com/ossci-linux/wheels/attrs-18.1.0-py2.py3-none-any.whl
          sudo pip -q install coverage==4.5.1 -f https://s3.amazonaws.com/ossci-linux/wheels/coverage-4.5.1-cp36-cp36m-macosx_10_12_x86_64.whl
          sudo pip -q install hypothesis==3.44.6 -f https://s3.amazonaws.com/ossci-linux/wheels/hypothesis-3.44.6-py3-none-any.whl
        fi

        # conda must be added to the path for Anaconda builds (this location must be
        # the same as that in install_anaconda.sh used to build the docker image)
        if [[ "${BUILD_ENVIRONMENT}" == conda* ]]; then
          export PATH=/opt/conda/bin:$PATH
        fi

        # set the env var for onnx build and test
        if [[ "$BUILD_ENVIRONMENT" == *onnx* ]]; then
          export INTEGRATED=1
        fi

        # Upgrade SSL module to avoid old SSL warnings
        pip -q install --user --upgrade pyOpenSSL ndg-httpsclient pyasn1

        pip -q install --user -b /tmp/pip_install_onnx "file:///var/lib/jenkins/workspace/third_party/onnx#egg=onnx"
        pip -q install --user future

        # Build
        if test -x ".jenkins/caffe2/test.sh"; then
          ./.jenkins/caffe2/test.sh
        else
          ./.jenkins/test.sh
        fi

        # Remove benign core dumps.
        # These are tests for signal handling (including SIGABRT).
        rm -f ./crash/core.fatal_signal_as.*
        rm -f ./crash/core.logging_test.*
        # =================== The above code will be executed inside Docker container ===================
        EOL
        chmod +x /home/circleci/project/ci_test_script.sh

        export COMMIT_DOCKER_IMAGE=${DOCKER_IMAGE}-${CIRCLE_SHA1}
        echo "DOCKER_IMAGE: "${COMMIT_DOCKER_IMAGE}
        docker pull ${COMMIT_DOCKER_IMAGE} >/dev/null
        if [ -n "${CUDA_VERSION}" ]; then
          export id=$(docker run --runtime=nvidia -t -d -w /var/lib/jenkins ${COMMIT_DOCKER_IMAGE})
        else
          export id=$(docker run -t -d -w /var/lib/jenkins ${COMMIT_DOCKER_IMAGE})
        fi
        docker cp /home/circleci/project/. "$id:/var/lib/jenkins/workspace"

        export COMMAND='((echo "source ./workspace/env" && echo "sudo chown -R jenkins workspace && cd workspace && ./ci_test_script.sh") | docker exec -u jenkins -i "$id" bash) 2>&1'
        echo ${COMMAND} > ./command.sh && unbuffer bash ./command.sh | ts

caffe2_macos_build_defaults: &caffe2_macos_build_defaults
  macos:
    xcode: "9.0"
  steps:
    - checkout
    - run:
        name: Build
        no_output_timeout: "1h"
        command: |
          set -e

          export IN_CIRCLECI=1

          # moreutils installs a `parallel` executable by default, which conflicts with the executable from the `parallel` formulae
          brew install moreutils --without-parallel
          brew install cmake
          brew install expect

          # Reinitialize submodules
          git submodule sync && git submodule update -q --init --recursive

          # Reinitialize path (see man page for path_helper(8))
          eval `/usr/libexec/path_helper -s`

          # Use Homebrew Python if configured to do so
          if [ "${PYTHON_INSTALLATION}" == "homebrew" ]; then
            export PATH=/usr/local/opt/python/libexec/bin:/usr/local/bin:$PATH
          fi

          pip -q install numpy

          # Install Anaconda if we need to
          if [ -n "${CAFFE2_USE_ANACONDA}" ]; then
            rm -rf ${TMPDIR}/anaconda
            curl -o ${TMPDIR}/anaconda.sh https://repo.continuum.io/miniconda/Miniconda${ANACONDA_VERSION}-latest-MacOSX-x86_64.sh
            /bin/bash ${TMPDIR}/anaconda.sh -b -p ${TMPDIR}/anaconda
            rm -f ${TMPDIR}/anaconda.sh
            export PATH="${TMPDIR}/anaconda/bin:${PATH}"
            source ${TMPDIR}/anaconda/bin/activate
          fi

          # Install sccache
          sudo curl https://s3.amazonaws.com/ossci-macos/sccache --output /usr/local/bin/sccache
          sudo chmod +x /usr/local/bin/sccache
          export SCCACHE_BUCKET=ossci-compiler-cache-circleci-v2

          # This IAM user allows write access to S3 bucket for sccache
          export AWS_ACCESS_KEY_ID=${CIRCLECI_AWS_ACCESS_KEY_FOR_SCCACHE_S3_BUCKET_V2}
          export AWS_SECRET_ACCESS_KEY=${CIRCLECI_AWS_SECRET_KEY_FOR_SCCACHE_S3_BUCKET_V2}

          export SCCACHE_BIN=${PWD}/sccache_bin
          mkdir -p ${SCCACHE_BIN}
          if which sccache > /dev/null; then
            printf "#!/bin/sh\nexec sccache $(which clang++) \$*" > "${SCCACHE_BIN}/clang++"
            chmod a+x "${SCCACHE_BIN}/clang++"

            printf "#!/bin/sh\nexec sccache $(which clang) \$*" > "${SCCACHE_BIN}/clang"
            chmod a+x "${SCCACHE_BIN}/clang"

            export PATH="${SCCACHE_BIN}:$PATH"
          fi

          # Build
          if [ "${BUILD_IOS:-0}" -eq 1 ]; then
            unbuffer scripts/build_ios.sh 2>&1 | ts
          elif [ -n "${CAFFE2_USE_ANACONDA}" ]; then
            # All conda build logic should be in scripts/build_anaconda.sh
            unbuffer scripts/build_anaconda.sh 2>&1 | ts
          else
            unbuffer scripts/build_local.sh 2>&1 | ts
          fi

          # Show sccache stats if it is running
          if which sccache > /dev/null; then
            sccache --show-stats
          fi

version: 2
jobs:
  pytorch_linux_trusty_py2_7_9_build:
    environment:
      JOB_BASE_NAME: pytorch-linux-trusty-py2.7.9-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-py2.7.9:262"
    <<: *pytorch_linux_build_defaults

  pytorch_linux_trusty_py2_7_9_test:
    environment:
      JOB_BASE_NAME: pytorch-linux-trusty-py2.7.9-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-py2.7.9:262"
    resource_class: large
    <<: *pytorch_linux_test_defaults

  pytorch_linux_trusty_py2_7_build:
    environment:
      JOB_BASE_NAME: pytorch-linux-trusty-py2.7-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-py2.7:262"
    <<: *pytorch_linux_build_defaults

  pytorch_linux_trusty_py2_7_test:
    environment:
      JOB_BASE_NAME: pytorch-linux-trusty-py2.7-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-py2.7:262"
    resource_class: large
    <<: *pytorch_linux_test_defaults

  pytorch_linux_trusty_py3_5_build:
    environment:
      JOB_BASE_NAME: pytorch-linux-trusty-py3.5-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-py3.5:262"
    <<: *pytorch_linux_build_defaults

  pytorch_linux_trusty_py3_5_test:
    environment:
      JOB_BASE_NAME: pytorch-linux-trusty-py3.5-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-py3.5:262"
    resource_class: large
    <<: *pytorch_linux_test_defaults

  pytorch_linux_trusty_py3_6_gcc4_8_build:
    environment:
      JOB_BASE_NAME: pytorch-linux-trusty-py3.6-gcc4.8-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-py3.6-gcc4.8:262"
    <<: *pytorch_linux_build_defaults

  pytorch_linux_trusty_py3_6_gcc4_8_test:
    environment:
      JOB_BASE_NAME: pytorch-linux-trusty-py3.6-gcc4.8-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-py3.6-gcc4.8:262"
    resource_class: large
    <<: *pytorch_linux_test_defaults

  pytorch_linux_trusty_py3_6_gcc5_4_build:
    environment:
      JOB_BASE_NAME: pytorch-linux-trusty-py3.6-gcc5.4-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-py3.6-gcc5.4:262"
    <<: *pytorch_linux_build_defaults

  pytorch_linux_trusty_py3_6_gcc5_4_test:
    environment:
      JOB_BASE_NAME: pytorch-linux-trusty-py3.6-gcc5.4-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-py3.6-gcc5.4:262"
    resource_class: large
    <<: *pytorch_linux_test_defaults

  pytorch_linux_trusty_py3_6_gcc7_build:
    environment:
      JOB_BASE_NAME: pytorch-linux-trusty-py3.6-gcc7-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-py3.6-gcc7:262"
    <<: *pytorch_linux_build_defaults

  pytorch_linux_trusty_py3_6_gcc7_test:
    environment:
      JOB_BASE_NAME: pytorch-linux-trusty-py3.6-gcc7-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-py3.6-gcc7:262"
    resource_class: large
    <<: *pytorch_linux_test_defaults

  pytorch_linux_trusty_pynightly_build:
    environment:
      JOB_BASE_NAME: pytorch-linux-trusty-pynightly-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-pynightly:262"
    <<: *pytorch_linux_build_defaults

  pytorch_linux_trusty_pynightly_test:
    environment:
      JOB_BASE_NAME: pytorch-linux-trusty-pynightly-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-pynightly:262"
    resource_class: large
    <<: *pytorch_linux_test_defaults

  pytorch_linux_xenial_py3_clang5_asan_build:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-py3-clang5-asan-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-py3-clang5-asan:262"
      PYTHON_VERSION: "3.6"
    <<: *pytorch_linux_build_defaults

  pytorch_linux_xenial_py3_clang5_asan_test:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-py3-clang5-asan-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-py3-clang5-asan:262"
      PYTHON_VERSION: "3.6"
    resource_class: large
    <<: *pytorch_linux_test_defaults

  pytorch_linux_xenial_cuda8_cudnn6_py3_build:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-cuda8-cudnn6-py3-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda8-cudnn6-py3:262"
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "8"
    <<: *pytorch_linux_build_defaults

  pytorch_linux_xenial_cuda8_cudnn6_py3_test:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-cuda8-cudnn6-py3-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda8-cudnn6-py3:262"
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "8"
    resource_class: gpu.medium
    <<: *pytorch_linux_test_defaults

  pytorch_linux_xenial_cuda8_cudnn6_py3_multigpu_test:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-cuda8-cudnn6-py3-multigpu-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda8-cudnn6-py3:262"
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "8"
      MULTI_GPU: "1"
    resource_class: gpu.large
    <<: *pytorch_linux_test_defaults

  pytorch_linux_xenial_cuda8_cudnn6_py3_NO_AVX2_test:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-cuda8-cudnn6-py3-NO_AVX2-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda8-cudnn6-py3:262"
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "8"
    resource_class: gpu.medium
    <<: *pytorch_linux_test_defaults

  pytorch_linux_xenial_cuda8_cudnn6_py3_NO_AVX_NO_AVX2_test:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-cuda8-cudnn6-py3-NO_AVX-NO_AVX2-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda8-cudnn6-py3:262"
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "8"
    resource_class: gpu.medium
    <<: *pytorch_linux_test_defaults

  pytorch_linux_xenial_cuda9_cudnn7_py2_build:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-cuda9-cudnn7-py2-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda9-cudnn7-py2:262"
      PYTHON_VERSION: "2.7"
      CUDA_VERSION: "9"
    <<: *pytorch_linux_build_defaults

  pytorch_linux_xenial_cuda9_cudnn7_py2_test:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-cuda9-cudnn7-py2-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda9-cudnn7-py2:262"
      PYTHON_VERSION: "2.7"
      CUDA_VERSION: "9"
    resource_class: gpu.medium
    <<: *pytorch_linux_test_defaults

  pytorch_linux_xenial_cuda9_cudnn7_py3_build:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-cuda9-cudnn7-py3-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda9-cudnn7-py3:262"
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "9"
    <<: *pytorch_linux_build_defaults

  pytorch_linux_xenial_cuda9_cudnn7_py3_test:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-cuda9-cudnn7-py3-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda9-cudnn7-py3:262"
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "9"
    resource_class: gpu.medium
    <<: *pytorch_linux_test_defaults

  pytorch_linux_xenial_cuda9_2_cudnn7_py3_gcc7_build:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-cuda9.2-cudnn7-py3-gcc7-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda9.2-cudnn7-py3-gcc7:262"
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "9.2"
    <<: *pytorch_linux_build_defaults

  pytorch_linux_xenial_cuda9_2_cudnn7_py3_gcc7_test:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-cuda9.2-cudnn7-py3-gcc7-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda9.2-cudnn7-py3-gcc7:262"
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "9.2"
    resource_class: gpu.medium
    <<: *pytorch_linux_test_defaults

  pytorch_linux_xenial_cuda10_cudnn7_py3_gcc7_build:
    environment:
      JOB_BASE_NAME: pytorch-linux-xenial-cuda10-cudnn7-py3-gcc7-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda10-cudnn7-py3-gcc7:262"
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "10"
    <<: *pytorch_linux_build_defaults

  pytorch_short_perf_test_gpu:
    environment:
      JOB_BASE_NAME: pytorch-short-perf-test-gpu
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda8-cudnn6-py3:262"
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "8"
    resource_class: gpu.medium
    machine:
      image: default
    steps:
    - run:
        <<: *setup_ci_environment
    - run:
        name: Perf Test
        no_output_timeout: "1h"
        command: |
          set -e
          export COMMIT_DOCKER_IMAGE=${DOCKER_IMAGE}-${CIRCLE_SHA1}
          echo "DOCKER_IMAGE: "${COMMIT_DOCKER_IMAGE}
          docker pull ${COMMIT_DOCKER_IMAGE} >/dev/null
          export id=$(docker run --runtime=nvidia -t -d -w /var/lib/jenkins ${COMMIT_DOCKER_IMAGE})

          docker cp $id:/var/lib/jenkins/workspace/env /home/circleci/project/env
          # This IAM user allows write access to S3 bucket for perf test numbers
          echo "declare -x AWS_ACCESS_KEY_ID=${CIRCLECI_AWS_ACCESS_KEY_FOR_PERF_TEST_S3_BUCKET_V2}" >> /home/circleci/project/env
          echo "declare -x AWS_SECRET_ACCESS_KEY=${CIRCLECI_AWS_SECRET_KEY_FOR_PERF_TEST_S3_BUCKET_V2}" >> /home/circleci/project/env
          docker cp /home/circleci/project/env $id:/var/lib/jenkins/workspace/env

          export COMMAND='((echo "export JOB_BASE_NAME=${JOB_BASE_NAME}" && echo "source ./workspace/env" && echo "sudo chown -R jenkins workspace && cd workspace && .jenkins/pytorch/short-perf-test-gpu.sh") | docker exec -u jenkins -i "$id" bash) 2>&1'
          echo ${COMMAND} > ./command.sh && unbuffer bash ./command.sh | ts

  pytorch_doc_push:
    environment:
      JOB_BASE_NAME: pytorch-doc-push
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda8-cudnn6-py3:262"
    resource_class: large
    machine:
      image: default
    steps:
    - run:
        <<: *setup_ci_environment
    - run:
        name: Doc Push
        no_output_timeout: "1h"
        command: |
          set -e
          if [[ "${CIRCLE_BRANCH}" != "master" ]]; then
            echo "Skipping doc push..."
            exit 0
          fi
          export COMMIT_DOCKER_IMAGE=${DOCKER_IMAGE}-${CIRCLE_SHA1}
          echo "DOCKER_IMAGE: "${COMMIT_DOCKER_IMAGE}
          docker pull ${COMMIT_DOCKER_IMAGE} >/dev/null
          export id=$(docker run -t -d -w /var/lib/jenkins ${COMMIT_DOCKER_IMAGE})

          cat >/home/circleci/project/doc_push_script.sh <<EOL
          # =================== The following code will be executed inside Docker container ===================
          git clone https://yf225:${GITHUB_PYTORCHBOT_TOKEN}@github.com/pytorch/pytorch.github.io -b site
          pushd pytorch.github.io

          set -ex

          export LC_ALL=C
          export PATH=/opt/conda/bin:$PATH

          rm -rf pytorch || true

          # Get all the documentation sources, put them in one place
          # TODO: These clones can race
          git clone https://github.com/pytorch/pytorch
          pushd pytorch
          git clone https://github.com/pytorch/vision
          pushd vision
          conda install -q pillow
          time python setup.py install
          popd
          pushd docs
          rm -rf source/torchvision
          cp -r ../vision/docs/source source/torchvision

          # Build the docs
          pip -q install -r requirements.txt || true
          make html

          # Move them into the docs repo
          popd
          popd
          git rm -rf docs/master || true
          mv pytorch/docs/build/html docs/master
          find docs/master -name "*.html" -print0 | xargs -0 sed -i -E 's/master[[:blank:]]\\([[:digit:]]\\.[[:digit:]]\\.[[:xdigit:]]+\\+[[:xdigit:]]+[[:blank:]]\\)/<a href="http:\\/\\/pytorch.org\\/docs\\/versions.html">& \\&#x25BC<\\/a>/g'
          git add docs/master || true
          git status
          git config user.email "soumith+bot@pytorch.org"
          git config user.name "pytorchbot"
          # If there aren't changes, don't make a commit; push is no-op
          git commit -m "auto-generating sphinx docs" || true
          git status
          git push origin site

          popd
          # =================== The above code will be executed inside Docker container ===================
          EOL
          chmod +x /home/circleci/project/doc_push_script.sh
          docker cp /home/circleci/project/doc_push_script.sh $id:/var/lib/jenkins/workspace/doc_push_script.sh

          export COMMAND='((echo "export JOB_BASE_NAME=${JOB_BASE_NAME}" && echo "source ./workspace/env" && echo "sudo chown -R jenkins workspace && cd workspace && ./doc_push_script.sh") | docker exec -u jenkins -i "$id" bash) 2>&1'
          echo ${COMMAND} > ./command.sh && unbuffer bash ./command.sh | ts

  pytorch_macos_10_13_py3_build:
    macos:
      xcode: "9.0"
    steps:
      - checkout
      - run:
          name: Build
          environment:
            JOB_BASE_NAME: pytorch-macos-10.13-py3-build
            BUILD_ENVIRONMENT: pytorch-macos-10.13-py3
          no_output_timeout: "1h"
          command: |
            set -e

            export IN_CIRCLECI=1
            # moreutils installs a `parallel` executable by default, which conflicts with the executable from the `parallel` formulae
            brew install moreutils --without-parallel
            brew install expect

            # Install sccache
            sudo curl https://s3.amazonaws.com/ossci-macos/sccache --output /usr/local/bin/sccache
            sudo chmod +x /usr/local/bin/sccache

            export SCCACHE_BUCKET=ossci-compiler-cache-circleci-v2
            # This IAM user allows write access to S3 bucket for sccache
            export AWS_ACCESS_KEY_ID=${CIRCLECI_AWS_ACCESS_KEY_FOR_SCCACHE_S3_BUCKET_V2}
            export AWS_SECRET_ACCESS_KEY=${CIRCLECI_AWS_SECRET_KEY_FOR_SCCACHE_S3_BUCKET_V2}

            git submodule sync && git submodule update -q --init
            chmod a+x .jenkins/pytorch/macos-build.sh
            unbuffer .jenkins/pytorch/macos-build.sh 2>&1 | ts

            mkdir -p /Users/distiller/pytorch-ci-env/workspace
            cp -r /Users/distiller/project/. /Users/distiller/pytorch-ci-env/workspace
      - persist_to_workspace:
          root: /Users/distiller/pytorch-ci-env
          paths:
            - "*"

  pytorch_macos_10_13_py3_test:
    macos:
      xcode: "9.0"
    steps:
      - run:
          name: Prepare workspace
          command: |
            sudo mkdir -p /Users/distiller/pytorch-ci-env
            sudo chmod -R 777 /Users/distiller/pytorch-ci-env
      - attach_workspace:
          at: /Users/distiller/pytorch-ci-env
      - run:
          name: Test
          environment:
            JOB_BASE_NAME: pytorch-macos-10.13-py3-test
            BUILD_ENVIRONMENT: pytorch-macos-10.13-py3
          no_output_timeout: "1h"
          command: |
            set -e
            export IN_CIRCLECI=1
            # moreutils installs a `parallel` executable by default, which conflicts with the executable from the `parallel` formulae
            brew install moreutils --without-parallel
            brew install expect

            cp -r /Users/distiller/pytorch-ci-env/workspace/. /Users/distiller/project

            chmod a+x .jenkins/pytorch/macos-test.sh
            unbuffer .jenkins/pytorch/macos-test.sh 2>&1 | ts

  pytorch_macos_10_13_cuda9_2_cudnn7_py3_build:
    macos:
      xcode: "9.0"
    steps:
      - checkout
      - run:
          name: Build
          environment:
            JOB_BASE_NAME: pytorch-macos-10.13-cuda9.2-cudnn7-py3-build
            BUILD_ENVIRONMENT: pytorch-macos-10.13-cuda9.2-cudnn7-py3
          no_output_timeout: "1h"
          command: |
            set -e

            export IN_CIRCLECI=1

            # moreutils installs a `parallel` executable by default, which conflicts with the executable from the `parallel` formulae
            brew install moreutils --without-parallel
            brew install expect

            # Install CUDA 9.2
            sudo rm -rf ~/cuda_9.2.64_mac_installer.app || true
            curl https://s3.amazonaws.com/ossci-macos/cuda_9.2.64_mac_installer.zip -o ~/cuda_9.2.64_mac_installer.zip
            unzip ~/cuda_9.2.64_mac_installer.zip -d ~/
            sudo ~/cuda_9.2.64_mac_installer.app/Contents/MacOS/CUDAMacOSXInstaller --accept-eula --no-window
            sudo cp /usr/local/cuda/lib/libcuda.dylib /Developer/NVIDIA/CUDA-9.2/lib/libcuda.dylib
            sudo rm -rf /usr/local/cuda || true

            # Install cuDNN 7.1 for CUDA 9.2
            curl https://s3.amazonaws.com/ossci-macos/cudnn-9.2-osx-x64-v7.1.tgz -o ~/cudnn-9.2-osx-x64-v7.1.tgz
            rm -rf ~/cudnn-9.2-osx-x64-v7.1 && mkdir ~/cudnn-9.2-osx-x64-v7.1
            tar -xzvf ~/cudnn-9.2-osx-x64-v7.1.tgz -C ~/cudnn-9.2-osx-x64-v7.1
            sudo cp ~/cudnn-9.2-osx-x64-v7.1/cuda/include/cudnn.h /Developer/NVIDIA/CUDA-9.2/include/
            sudo cp ~/cudnn-9.2-osx-x64-v7.1/cuda/lib/libcudnn* /Developer/NVIDIA/CUDA-9.2/lib/
            sudo chmod a+r /Developer/NVIDIA/CUDA-9.2/include/cudnn.h /Developer/NVIDIA/CUDA-9.2/lib/libcudnn*

            # Install sccache
            sudo curl https://s3.amazonaws.com/ossci-macos/sccache --output /usr/local/bin/sccache
            sudo chmod +x /usr/local/bin/sccache
            export SCCACHE_BUCKET=ossci-compiler-cache-circleci-v2
            # This IAM user allows write access to S3 bucket for sccache
            export AWS_ACCESS_KEY_ID=${CIRCLECI_AWS_ACCESS_KEY_FOR_SCCACHE_S3_BUCKET_V2}
            export AWS_SECRET_ACCESS_KEY=${CIRCLECI_AWS_SECRET_KEY_FOR_SCCACHE_S3_BUCKET_V2}

            git submodule sync && git submodule update -q --init
            chmod a+x .jenkins/pytorch/macos-build.sh
            unbuffer .jenkins/pytorch/macos-build.sh 2>&1 | ts

  caffe2_py2_cuda8_0_cudnn6_ubuntu16_04_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-cuda8.0-cudnn6-ubuntu16.04-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda8.0-cudnn6-ubuntu16.04:230"
      CUDA_VERSION: "8"
      BUILD_ENVIRONMENT: "py2-cuda8.0-cudnn6-ubuntu16.04"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_cuda8_0_cudnn6_ubuntu16_04_test:
    environment:
      JOB_BASE_NAME: caffe2-py2-cuda8.0-cudnn6-ubuntu16.04-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda8.0-cudnn6-ubuntu16.04:230"
      CUDA_VERSION: "8"
      BUILD_ENVIRONMENT: "py2-cuda8.0-cudnn6-ubuntu16.04"
    resource_class: gpu.medium
    <<: *caffe2_linux_test_defaults

  caffe2_py2_cuda9_0_cudnn7_ubuntu16_04_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-cuda9.0-cudnn7-ubuntu16.04-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda9.0-cudnn7-ubuntu16.04:230"
      CUDA_VERSION: "9"
      BUILD_ENVIRONMENT: "py2-cuda9.0-cudnn7-ubuntu16.04"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_cuda9_0_cudnn7_ubuntu16_04_test:
    environment:
      JOB_BASE_NAME: caffe2-py2-cuda9.0-cudnn7-ubuntu16.04-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda9.0-cudnn7-ubuntu16.04:230"
      CUDA_VERSION: "9"
      BUILD_ENVIRONMENT: "py2-cuda9.0-cudnn7-ubuntu16.04"
    resource_class: gpu.medium
    <<: *caffe2_linux_test_defaults

  caffe2_py2_cuda9_1_cudnn7_ubuntu16_04_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-cuda9.1-cudnn7-ubuntu16.04-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda9.1-cudnn7-ubuntu16.04:230"
      CUDA_VERSION: "9.1"
      BUILD_ENVIRONMENT: "py2-cuda9.1-cudnn7-ubuntu16.04"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_cuda9_1_cudnn7_ubuntu16_04_test:
    environment:
      JOB_BASE_NAME: caffe2-py2-cuda9.1-cudnn7-ubuntu16.04-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda9.1-cudnn7-ubuntu16.04:230"
      CUDA_VERSION: "9.1"
      BUILD_ENVIRONMENT: "py2-cuda9.1-cudnn7-ubuntu16.04"
    resource_class: gpu.medium
    <<: *caffe2_linux_test_defaults

  caffe2_py2_mkl_ubuntu16_04_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-mkl-ubuntu16.04-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-mkl-ubuntu16.04:230"
      BUILD_ENVIRONMENT: "py2-mkl-ubuntu16.04"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_mkl_ubuntu16_04_test:
    environment:
      JOB_BASE_NAME: caffe2-py2-mkl-ubuntu16.04-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-mkl-ubuntu16.04:230"
      BUILD_ENVIRONMENT: "py2-mkl-ubuntu16.04"
    resource_class: large
    <<: *caffe2_linux_test_defaults

  caffe2_py2_gcc4_8_ubuntu14_04_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-gcc4.8-ubuntu14.04-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-gcc4.8-ubuntu14.04:230"
      BUILD_ENVIRONMENT: "py2-gcc4.8-ubuntu14.04"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_gcc4_8_ubuntu14_04_test:
    environment:
      JOB_BASE_NAME: caffe2-py2-gcc4.8-ubuntu14.04-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-gcc4.8-ubuntu14.04:230"
      BUILD_ENVIRONMENT: "py2-gcc4.8-ubuntu14.04"
    resource_class: large
    <<: *caffe2_linux_test_defaults

  caffe2_onnx_py2_gcc5_ubuntu16_04_build:
    environment:
      JOB_BASE_NAME: caffe2-onnx-py2-gcc5-ubuntu16.04-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-gcc5-ubuntu16.04:230"
      BUILD_ENVIRONMENT: "onnx-py2-gcc5-ubuntu16.04"
    <<: *caffe2_linux_build_defaults

  caffe2_onnx_py2_gcc5_ubuntu16_04_test:
    environment:
      JOB_BASE_NAME: caffe2-onnx-py2-gcc5-ubuntu16.04-test
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-gcc5-ubuntu16.04:230"
      BUILD_ENVIRONMENT: "onnx-py2-gcc5-ubuntu16.04"
    resource_class: large
    <<: *caffe2_linux_test_defaults

  caffe2_py2_cuda8_0_cudnn7_ubuntu16_04_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-cuda8.0-cudnn7-ubuntu16.04-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda8.0-cudnn7-ubuntu16.04:230"
      BUILD_ENVIRONMENT: "py2-cuda8.0-cudnn7-ubuntu16.04"
      BUILD_ONLY: "1"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_gcc4_9_ubuntu14_04_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-gcc4.9-ubuntu14.04-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-gcc4.9-ubuntu14.04:230"
      BUILD_ENVIRONMENT: "py2-gcc4.9-ubuntu14.04"
      BUILD_ONLY: "1"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_clang3_8_ubuntu16_04_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-clang3.8-ubuntu16.04-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-clang3.8-ubuntu16.04:230"
      BUILD_ENVIRONMENT: "py2-clang3.8-ubuntu16.04"
      BUILD_ONLY: "1"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_clang3_9_ubuntu16_04_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-clang3.9-ubuntu16.04-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-clang3.9-ubuntu16.04:230"
      BUILD_ENVIRONMENT: "py2-clang3.9-ubuntu16.04"
      BUILD_ONLY: "1"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_android_ubuntu16_04_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-android-ubuntu16.04-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-android-ubuntu16.04:230"
      BUILD_ENVIRONMENT: "py2-android-ubuntu16.04"
      BUILD_ONLY: "1"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_cuda9_0_cudnn7_centos7_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-cuda9.0-cudnn7-centos7-build
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda9.0-cudnn7-centos7:230"
      BUILD_ENVIRONMENT: "py2-cuda9.0-cudnn7-centos7"
      BUILD_ONLY: "1"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_ios_macos10_13_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-ios-macos10.13-build
      BUILD_IOS: "1"
      PYTHON_INSTALLATION: "system"
      PYTHON_VERSION: "2"
    <<: *caffe2_macos_build_defaults

  caffe2_py2_system_macos10_13_build:
    environment:
      JOB_BASE_NAME: caffe2-py2-system-macos10.13-build
      PYTHON_INSTALLATION: "system"
      PYTHON_VERSION: "2"
    <<: *caffe2_macos_build_defaults

workflows:
  version: 2
  build:
    jobs:
      - pytorch_linux_trusty_py2_7_9_build
      - pytorch_linux_trusty_py2_7_9_test:
          requires:
            - pytorch_linux_trusty_py2_7_9_build
      - pytorch_linux_trusty_py2_7_build
      - pytorch_linux_trusty_py2_7_test:
          requires:
            - pytorch_linux_trusty_py2_7_build
      - pytorch_linux_trusty_py3_5_build
      - pytorch_linux_trusty_py3_5_test:
          requires:
            - pytorch_linux_trusty_py3_5_build
      - pytorch_linux_trusty_py3_6_gcc4_8_build
      - pytorch_linux_trusty_py3_6_gcc4_8_test:
          requires:
            - pytorch_linux_trusty_py3_6_gcc4_8_build
      - pytorch_linux_trusty_py3_6_gcc5_4_build
      - pytorch_linux_trusty_py3_6_gcc5_4_test:
          requires:
            - pytorch_linux_trusty_py3_6_gcc5_4_build
      - pytorch_linux_trusty_py3_6_gcc7_build
      - pytorch_linux_trusty_py3_6_gcc7_test:
          requires:
            - pytorch_linux_trusty_py3_6_gcc7_build
      - pytorch_linux_trusty_pynightly_build
      - pytorch_linux_trusty_pynightly_test:
          requires:
            - pytorch_linux_trusty_pynightly_build
      - pytorch_linux_xenial_py3_clang5_asan_build
      - pytorch_linux_xenial_py3_clang5_asan_test:
          requires:
            - pytorch_linux_xenial_py3_clang5_asan_build
      - pytorch_linux_xenial_cuda8_cudnn6_py3_build
      - pytorch_linux_xenial_cuda8_cudnn6_py3_test:
          requires:
            - pytorch_linux_xenial_cuda8_cudnn6_py3_build
      - pytorch_linux_xenial_cuda8_cudnn6_py3_multigpu_test:
          requires:
            - pytorch_linux_xenial_cuda8_cudnn6_py3_build
      - pytorch_linux_xenial_cuda8_cudnn6_py3_NO_AVX2_test:
          requires:
            - pytorch_linux_xenial_cuda8_cudnn6_py3_build
      - pytorch_linux_xenial_cuda8_cudnn6_py3_NO_AVX_NO_AVX2_test:
          requires:
            - pytorch_linux_xenial_cuda8_cudnn6_py3_build
      - pytorch_short_perf_test_gpu:
          requires:
            - pytorch_linux_xenial_cuda8_cudnn6_py3_build
      - pytorch_doc_push:
          requires:
            - pytorch_linux_xenial_cuda8_cudnn6_py3_build
      - pytorch_linux_xenial_cuda9_cudnn7_py2_build
      - pytorch_linux_xenial_cuda9_cudnn7_py2_test:
          requires:
            - pytorch_linux_xenial_cuda9_cudnn7_py2_build
      - pytorch_linux_xenial_cuda9_cudnn7_py3_build
      - pytorch_linux_xenial_cuda9_cudnn7_py3_test:
          requires:
            - pytorch_linux_xenial_cuda9_cudnn7_py3_build
      - pytorch_linux_xenial_cuda9_2_cudnn7_py3_gcc7_build
      - pytorch_linux_xenial_cuda9_2_cudnn7_py3_gcc7_test:
          requires:
            - pytorch_linux_xenial_cuda9_2_cudnn7_py3_gcc7_build
      - pytorch_linux_xenial_cuda10_cudnn7_py3_gcc7_build

      - pytorch_macos_10_13_py3_build
      - pytorch_macos_10_13_py3_test:
          requires:
            - pytorch_macos_10_13_py3_build
      - pytorch_macos_10_13_cuda9_2_cudnn7_py3_build

      - caffe2_py2_cuda8_0_cudnn6_ubuntu16_04_build
      - caffe2_py2_cuda8_0_cudnn6_ubuntu16_04_test:
          requires:
            - caffe2_py2_cuda8_0_cudnn6_ubuntu16_04_build
      - caffe2_py2_cuda9_0_cudnn7_ubuntu16_04_build
      - caffe2_py2_cuda9_0_cudnn7_ubuntu16_04_test:
          requires:
            - caffe2_py2_cuda9_0_cudnn7_ubuntu16_04_build
      - caffe2_py2_cuda9_1_cudnn7_ubuntu16_04_build
      - caffe2_py2_cuda9_1_cudnn7_ubuntu16_04_test:
          requires:
            - caffe2_py2_cuda9_1_cudnn7_ubuntu16_04_build
      - caffe2_py2_mkl_ubuntu16_04_build
      - caffe2_py2_mkl_ubuntu16_04_test:
          requires:
            - caffe2_py2_mkl_ubuntu16_04_build
      - caffe2_py2_gcc4_8_ubuntu14_04_build
      - caffe2_py2_gcc4_8_ubuntu14_04_test:
          requires:
            - caffe2_py2_gcc4_8_ubuntu14_04_build
      - caffe2_onnx_py2_gcc5_ubuntu16_04_build
      - caffe2_onnx_py2_gcc5_ubuntu16_04_test:
          requires:
            - caffe2_onnx_py2_gcc5_ubuntu16_04_build
      - caffe2_py2_cuda8_0_cudnn7_ubuntu16_04_build
      - caffe2_py2_clang3_8_ubuntu16_04_build
      - caffe2_py2_clang3_9_ubuntu16_04_build
      - caffe2_py2_android_ubuntu16_04_build
      - caffe2_py2_cuda9_0_cudnn7_centos7_build

      - caffe2_py2_ios_macos10_13_build
      - caffe2_py2_system_macos10_13_build
