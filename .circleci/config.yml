docker_config_defaults: &docker_config_defaults
  user: jenkins
  aws_auth:
    # This IAM user only allows read-only access to ECR
    aws_access_key_id: AKIAJ2J6FIG5OSZTQ3IA
    aws_secret_access_key: ${CIRCLECI_AWS_SECRET_KEY_FOR_ECR_READ_ONLY}

pytorch_linux_cpu_build_test_defaults: &pytorch_linux_cpu_build_test_defaults
  resource_class: large
  working_directory: /var/lib/jenkins/workspace
  steps:
  - checkout
  - run:
      name: Build
      command: |
        export SCCACHE_BUCKET=ossci-compiler-cache
        export SCCACHE_MAX_JOBS=`expr $(nproc) - 1`
        export MEMORY_LIMIT_MAX_JOBS=8  # the "large" resource class on CircleCI has 32 CPU cores, if we use all of them we'll OOM
        export MAX_JOBS=$(( ${SCCACHE_MAX_JOBS} > ${MEMORY_LIMIT_MAX_JOBS} ? ${MEMORY_LIMIT_MAX_JOBS} : ${SCCACHE_MAX_JOBS} ))
        # This IAM user allows write access to S3 bucket for sccache
        export AWS_ACCESS_KEY_ID=AKIAJJZUW4G2ASX5W7KA
        export AWS_SECRET_ACCESS_KEY=${CIRCLECI_AWS_SECRET_KEY_FOR_SCCACHE_S3_BUCKET}
        git submodule update --init
        .jenkins/pytorch/build.sh
        .jenkins/pytorch/test.sh

pytorch_linux_build_defaults: &pytorch_linux_build_defaults
  resource_class: large
  working_directory: /var/lib/jenkins/workspace
  steps:
  - checkout
  - run:
      name: Build
      command: |
        export SCCACHE_BUCKET=ossci-compiler-cache
        if [ -n "${CUDA_VERSION}" ]; then
          export TORCH_CUDA_ARCH_LIST=5.2
        fi
        export SCCACHE_MAX_JOBS=`expr $(nproc) - 1`
        export MEMORY_LIMIT_MAX_JOBS=8  # the "large" resource class on CircleCI has 32 CPU cores, if we use all of them we'll OOM
        export MAX_JOBS=$(( ${SCCACHE_MAX_JOBS} > ${MEMORY_LIMIT_MAX_JOBS} ? ${MEMORY_LIMIT_MAX_JOBS} : ${SCCACHE_MAX_JOBS} ))
        # This IAM user allows write access to S3 bucket for sccache
        export AWS_ACCESS_KEY_ID=AKIAJJZUW4G2ASX5W7KA
        export AWS_SECRET_ACCESS_KEY=${CIRCLECI_AWS_SECRET_KEY_FOR_SCCACHE_S3_BUCKET}
        git submodule update --init
        .jenkins/pytorch/build.sh
        mkdir -p pytorch-ci-env/
        cp -r /opt/conda/lib/python${PYTHON_VERSION}/site-packages/torch pytorch-ci-env/torch
        cp -r build/bin pytorch-ci-env/cpp_test_bin
        if [ -d "../cpp-build" ]; then
          cp -r ../cpp-build pytorch-ci-env/cpp-build
        fi
  - persist_to_workspace:
      root: /var/lib/jenkins/workspace/pytorch-ci-env
      paths:
        - "*"

pytorch_linux_test_defaults: &pytorch_linux_test_defaults
  machine:
    image: default
  steps:
  - checkout
  - run:
      name: Prepare workspace
      command: |
        sudo mkdir -p /opt/workspace
        sudo chmod -R 777 /opt/workspace
  - attach_workspace:
      at: /opt/workspace
  - run:
      name: Build
      command: |
        set -x
        sudo pip install awscli
        if [ -n "${CUDA_VERSION}" ]; then
          curl -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
          echo "deb https://nvidia.github.io/libnvidia-container/ubuntu14.04/amd64 /" | sudo tee -a /etc/apt/sources.list.d/nvidia-docker.list
          echo "deb https://nvidia.github.io/nvidia-container-runtime/ubuntu14.04/amd64 /" | sudo tee -a /etc/apt/sources.list.d/nvidia-docker.list
          echo "deb https://nvidia.github.io/nvidia-docker/ubuntu14.04/amd64 /" | sudo tee -a /etc/apt/sources.list.d/nvidia-docker.list
        fi
        sudo apt-get update
        sudo apt-get remove linux-image-generic linux-headers-generic linux-generic
        sudo apt-get install linux-headers-$(uname -r)
        sudo apt-get install linux-image-generic
        if [ -n "${CUDA_VERSION}" ]; then
          wget 'https://s3.amazonaws.com/ossci-linux/nvidia_driver/NVIDIA-Linux-x86_64-396.26.run'
          sudo /bin/bash ./NVIDIA-Linux-x86_64-396.26.run -s --no-drm
          sudo apt-get install -y nvidia-docker2
        fi
        sudo pkill -SIGHUP dockerd
        if [ -n "${CUDA_VERSION}" ]; then
          nvidia-smi
        fi
        # This IAM user only allows read-only access to ECR
        export AWS_ACCESS_KEY_ID=AKIAJ2J6FIG5OSZTQ3IA
        export AWS_SECRET_ACCESS_KEY=${CIRCLECI_AWS_SECRET_KEY_FOR_ECR_READ_ONLY}
        eval $(aws ecr get-login --region us-east-1 --no-include-email)
        docker pull ${DOCKER_IMAGE}
        if [ -n "${CUDA_VERSION}" ]; then
          id=$(docker run --runtime=nvidia -t -d -w /var/lib/jenkins ${DOCKER_IMAGE})
        else
          id=$(docker run -t -d -w /var/lib/jenkins ${DOCKER_IMAGE})
        fi
        pwd
        echo "declare -x PYTHON_VERSION=${PYTHON_VERSION}" > /home/circleci/project/env
        echo "declare -x SCCACHE_BUCKET=${SCCACHE_BUCKET}" >> /home/circleci/project/env
        # This IAM user allows write access to S3 bucket for sccache
        echo "declare -x AWS_ACCESS_KEY_ID=AKIAJJZUW4G2ASX5W7KA" >> /home/circleci/project/env
        echo "declare -x AWS_SECRET_ACCESS_KEY=${CIRCLECI_AWS_SECRET_KEY_FOR_SCCACHE_S3_BUCKET}" >> /home/circleci/project/env
        mkdir -p /home/circleci/project/build
        cp -r /opt/workspace/cpp_test_bin /home/circleci/project/build/bin
        docker cp /home/circleci/project/. "$id:/var/lib/jenkins/workspace"
        echo "mkdir -p /opt/conda/lib/python${PYTHON_VERSION}/site-packages" | docker exec -u jenkins -i "$id" bash
        docker cp "/opt/workspace/torch" "$id:/opt/conda/lib/python${PYTHON_VERSION}/site-packages/torch"
        if [ -d "/opt/workspace/cpp-build" ]; then
          docker cp "/opt/workspace/cpp-build" "$id:/var/lib/jenkins/cpp-build"
        fi
        (echo "source ./workspace/env" && echo 'sudo chown -R jenkins workspace /opt/conda/lib/python${PYTHON_VERSION}/site-packages/torch && cd workspace && git submodule update --init && .jenkins/pytorch/test.sh') | docker exec -u jenkins -i "$id" bash

caffe2_linux_build_defaults: &caffe2_linux_build_defaults
  resource_class: large
  working_directory: /var/lib/jenkins/workspace
  steps:
  - checkout
  - run:
      name: Build
      command: |
        export SCCACHE_BUCKET=ossci-compiler-cache
        # This IAM user allows write access to S3 bucket for sccache
        export AWS_ACCESS_KEY_ID=AKIAJJZUW4G2ASX5W7KA
        export AWS_SECRET_ACCESS_KEY=${CIRCLECI_AWS_SECRET_KEY_FOR_SCCACHE_S3_BUCKET}
        export SCCACHE_MAX_JOBS=`expr $(nproc) - 1`
        export MEMORY_LIMIT_MAX_JOBS=8  # the "large" resource class on CircleCI has 32 CPU cores, if we use all of them we'll OOM
        export MAX_JOBS=$(( ${SCCACHE_MAX_JOBS} > ${MEMORY_LIMIT_MAX_JOBS} ? ${MEMORY_LIMIT_MAX_JOBS} : ${SCCACHE_MAX_JOBS} ))

        set -ex

        # Need to checkout fetch PRs for onnxbot tracking PRs
        git submodule update --init third_party/onnx || true
        cd third_party/onnx && git fetch --tags --progress origin +refs/pull/*:refs/remotes/origin/pr/* && cd -

        # Reinitialize submodules
        git submodule update --init --recursive

        # Ensure jenkins can write to the ccache root dir.
        sudo chown jenkins:jenkins "${HOME}/.ccache"

        # Make ccache log to the workspace, so we can archive it after the build
        mkdir -p build
        ccache -o log_file=$PWD/build/ccache.log

        # Configure additional cmake arguments
        cmake_args=()
        cmake_args+=("$CMAKE_ARGS")

        if [[ $BUILD_ENVIRONMENT == *aten* ]]; then
          cmake_args+=("-DBUILD_ATEN=ON")
        fi

        # conda must be added to the path for Anaconda builds (this location must be
        # the same as that in install_anaconda.sh used to build the docker image)
        if [[ "${BUILD_ENVIRONMENT}" == conda* ]]; then
          export PATH=/opt/conda/bin:$PATH
          sudo chown -R jenkins:jenkins '/opt/conda'
        fi

        # Build
        if test -x ".jenkins/caffe2/build.sh"; then
          ./.jenkins/caffe2/build.sh ${cmake_args[@]}
        else
          ./.jenkins/build.sh ${cmake_args[@]}
        fi

        # Show sccache stats if it is running
        if pgrep sccache > /dev/null; then
          sccache --show-stats
        fi

        # Copy all necessary binaries to shared workspace
        mkdir -p caffe2-ci-env
        cp -r third_party/onnx caffe2-ci-env/onnx
        if [ -d "/usr/local/caffe2" ]; then
          cp -r /usr/local/caffe2 caffe2-ci-env/caffe2
        fi
  - persist_to_workspace:
      root: /var/lib/jenkins/workspace/caffe2-ci-env
      paths:
        - "*"

caffe2_linux_test_defaults: &caffe2_linux_test_defaults
  machine:
    image: default
  steps:
  - checkout
  - run:
      name: Prepare workspace
      command: |
        sudo mkdir -p /opt/workspace
        sudo chmod -R 777 /opt/workspace
  - attach_workspace:
      at: /opt/workspace
  - run:
      name: Build
      command: |
        set -x
        sudo pip install awscli
        if [ -n "${CUDA_VERSION}" ]; then
          curl -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
          echo "deb https://nvidia.github.io/libnvidia-container/ubuntu14.04/amd64 /" | sudo tee -a /etc/apt/sources.list.d/nvidia-docker.list
          echo "deb https://nvidia.github.io/nvidia-container-runtime/ubuntu14.04/amd64 /" | sudo tee -a /etc/apt/sources.list.d/nvidia-docker.list
          echo "deb https://nvidia.github.io/nvidia-docker/ubuntu14.04/amd64 /" | sudo tee -a /etc/apt/sources.list.d/nvidia-docker.list
        fi
        sudo apt-get update
        sudo apt-get remove linux-image-generic linux-headers-generic linux-generic
        sudo apt-get install linux-headers-$(uname -r)
        sudo apt-get install linux-image-generic
        if [ -n "${CUDA_VERSION}" ]; then
          wget 'https://s3.amazonaws.com/ossci-linux/nvidia_driver/NVIDIA-Linux-x86_64-396.26.run'
          sudo /bin/bash ./NVIDIA-Linux-x86_64-396.26.run -s --no-drm
          sudo apt-get install -y nvidia-docker2
        fi
        sudo pkill -SIGHUP dockerd
        if [ -n "${CUDA_VERSION}" ]; then
          nvidia-smi
        fi
        # This IAM user only allows read-only access to ECR
        export AWS_ACCESS_KEY_ID=AKIAJ2J6FIG5OSZTQ3IA
        export AWS_SECRET_ACCESS_KEY=${CIRCLECI_AWS_SECRET_KEY_FOR_ECR_READ_ONLY}
        eval $(aws ecr get-login --region us-east-1 --no-include-email)
        docker pull ${DOCKER_IMAGE}
        if [ -n "${CUDA_VERSION}" ]; then
          id=$(docker run --runtime=nvidia -t -d -w /var/lib/jenkins ${DOCKER_IMAGE})
        else
          id=$(docker run -t -d -w /var/lib/jenkins ${DOCKER_IMAGE})
        fi
        pwd
        echo "declare -x SCCACHE_BUCKET=${SCCACHE_BUCKET}" > /home/circleci/project/env
        # This IAM user allows write access to S3 bucket for sccache
        echo "declare -x AWS_ACCESS_KEY_ID=AKIAJJZUW4G2ASX5W7KA" >> /home/circleci/project/env
        echo "declare -x AWS_SECRET_ACCESS_KEY=${CIRCLECI_AWS_SECRET_KEY_FOR_SCCACHE_S3_BUCKET}" >> /home/circleci/project/env
        echo "declare -x BUILD_ENVIRONMENT=${BUILD_ENVIRONMENT}" >> /home/circleci/project/env

        # TODO: merge this into Caffe2 build.sh
        cat >/home/circleci/project/ci_build_script.sh <<EOL
        # =================== The following code will be executed inside Docker container ===================
        set -ex

        # libdc1394 (dependency of OpenCV) expects /dev/raw1394 to exist...
        sudo ln /dev/null /dev/raw1394

        # conda must be added to the path for Anaconda builds (this location must be
        # the same as that in install_anaconda.sh used to build the docker image)
        if [[ "${BUILD_ENVIRONMENT}" == conda* ]]; then
          export PATH=/opt/conda/bin:$PATH
        fi

        pip install --user --no-cache-dir hypothesis==3.59.0
        pip install --user -b /tmp/pip_install_onnx "file:///var/lib/jenkins/workspace/third_party/onnx#egg=onnx"

        # Hotfix, use hypothesis 3.44.6 on Ubuntu 14.04
        # See comments on https://github.com/HypothesisWorks/hypothesis-python/commit/eadd62e467d6cee6216e71b391951ec25b4f5830
        if [[ "$BUILD_ENVIRONMENT" == *ubuntu14.04* ]]; then
          sudo pip uninstall -y hypothesis
          sudo pip install hypothesis==3.44.6
        fi

        # Build
        if test -x ".jenkins/caffe2/test.sh"; then
          ./.jenkins/caffe2/test.sh
        else
          ./.jenkins/test.sh
        fi

        # Remove benign core dumps.
        # These are tests for signal handling (including SIGABRT).
        rm -f ./crash/core.fatal_signal_as.*
        rm -f ./crash/core.logging_test.*
        # =================== The above code will be executed inside Docker container ===================
        EOL
        chmod +x /home/circleci/project/ci_build_script.sh
        docker cp /home/circleci/project/. "$id:/var/lib/jenkins/workspace"
        if [ -d "/opt/workspace/caffe2" ]; then
          echo "mkdir -p /usr/local/caffe2" | docker exec -u jenkins -i "$id" bash
          docker cp /opt/workspace/caffe2/. "$id:/usr/local/caffe2"
        fi
        docker cp /opt/workspace/onnx/. "$id:/var/lib/jenkins/workspace/third_party/onnx"
        (echo "source ./workspace/env" && echo 'sudo chown -R jenkins workspace && cd workspace && ./ci_build_script.sh') | docker exec -u jenkins -i "$id" bash

caffe2_macos_build_defaults: &caffe2_macos_build_defaults
  macos:
    xcode: "9.0"
  steps:
    - checkout
    - run:
        name: Build
        command: |
          set -ex

          brew install cmake

          # Reinitialize submodules
          git submodule update --init --recursive

          # Reinitialize path (see man page for path_helper(8))
          eval `/usr/libexec/path_helper -s`

          # Use Homebrew Python if configured to do so
          if [ "${PYTHON_INSTALLATION}" == "homebrew" ]; then
            export PATH=/usr/local/opt/python/libexec/bin:/usr/local/bin:$PATH
          fi

          # Install Anaconda if we need to
          if [ -n "${CAFFE2_USE_ANACONDA}" ]; then
            rm -rf ${TMPDIR}/anaconda
            curl -o ${TMPDIR}/anaconda.sh "https://repo.continuum.io/archive/Anaconda${ANACONDA_VERSION}-5.0.1-MacOSX-x86_64.sh"
            /bin/bash ${TMPDIR}/anaconda.sh -b -p ${TMPDIR}/anaconda
            rm -f ${TMPDIR}/anaconda.sh
            export PATH="${TMPDIR}/anaconda/bin:${PATH}"
            source ${TMPDIR}/anaconda/bin/activate
          fi

          # Build
          if [ "${BUILD_IOS:-0}" -eq 1 ]; then
            scripts/build_ios.sh
          elif [ -n "${CAFFE2_USE_ANACONDA}" ]; then
            # All conda build logic should be in scripts/build_anaconda.sh
            scripts/build_anaconda.sh
          else
            scripts/build_local.sh
          fi

version: 2
jobs:
  pytorch_linux_trusty_py2_7_9_build_test:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-py2.7.9:226
        <<: *docker_config_defaults
    <<: *pytorch_linux_cpu_build_test_defaults

  pytorch_linux_trusty_py2_7_build_test:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-py2.7:226
        <<: *docker_config_defaults
    <<: *pytorch_linux_cpu_build_test_defaults

  pytorch_linux_trusty_py3_5_build_test:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-py3.5:226
        <<: *docker_config_defaults
    <<: *pytorch_linux_cpu_build_test_defaults

  pytorch_linux_trusty_py3_6_gcc4_8_build_test:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-py3.6-gcc4.8:226
        <<: *docker_config_defaults
    <<: *pytorch_linux_cpu_build_test_defaults

  pytorch_linux_trusty_py3_6_gcc5_4_build_test:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-py3.6-gcc5.4:226
        <<: *docker_config_defaults
    <<: *pytorch_linux_cpu_build_test_defaults

  pytorch_linux_trusty_py3_6_gcc7_build_test:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-py3.6-gcc7:226
        <<: *docker_config_defaults
    <<: *pytorch_linux_cpu_build_test_defaults

  pytorch_linux_trusty_pynightly_build_test:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-trusty-pynightly:226
        <<: *docker_config_defaults
    <<: *pytorch_linux_cpu_build_test_defaults

  pytorch_linux_xenial_py3_clang5_asan_build:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-py3-clang5-asan:226
        <<: *docker_config_defaults
    environment:
      PYTHON_VERSION: "3.6"
    <<: *pytorch_linux_build_defaults

  pytorch_linux_xenial_py3_clang5_asan_test:
    environment:
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-py3-clang5-asan:226"
      PYTHON_VERSION: "3.6"
    resource_class: large
    <<: *pytorch_linux_test_defaults

  pytorch_linux_xenial_cuda8_cudnn6_py3_build:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda8-cudnn6-py3:226
        <<: *docker_config_defaults
    environment:
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "8"
    <<: *pytorch_linux_build_defaults

  pytorch_linux_xenial_cuda8_cudnn6_py3_test:
    environment:
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda8-cudnn6-py3:226"
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "8"
    resource_class: gpu.small
    <<: *pytorch_linux_test_defaults

  pytorch_linux_xenial_cuda9_cudnn7_py2_build:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda9-cudnn7-py2:226
        <<: *docker_config_defaults
    environment:
      PYTHON_VERSION: "2.7"
      CUDA_VERSION: "9"
    <<: *pytorch_linux_build_defaults

  pytorch_linux_xenial_cuda9_cudnn7_py2_test:
    environment:
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda9-cudnn7-py2:226"
      PYTHON_VERSION: "2.7"
      CUDA_VERSION: "9"
    resource_class: gpu.small
    <<: *pytorch_linux_test_defaults

  pytorch_linux_xenial_cuda9_cudnn7_py3_build:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda9-cudnn7-py3:226
        <<: *docker_config_defaults
    environment:
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "9"
    <<: *pytorch_linux_build_defaults

  pytorch_linux_xenial_cuda9_cudnn7_py3_test:
    environment:
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda9-cudnn7-py3:226"
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "9"
    resource_class: gpu.small
    <<: *pytorch_linux_test_defaults

  pytorch_linux_xenial_cuda9_2_cudnn7_py3_gcc7_build:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda9.2-cudnn7-py3-gcc7:226
        <<: *docker_config_defaults
    environment:
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "9.2"
    <<: *pytorch_linux_build_defaults

  pytorch_linux_xenial_cuda9_2_cudnn7_py3_gcc7_test:
    environment:
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/pytorch-linux-xenial-cuda9.2-cudnn7-py3-gcc7:226"
      PYTHON_VERSION: "3.6"
      CUDA_VERSION: "9.2"
    resource_class: gpu.small
    <<: *pytorch_linux_test_defaults

  pytorch_macos_10_13_py3_build:
    macos:
      xcode: "9.0"
    steps:
      - checkout
      - run:
          name: Build
          environment:
            BUILD_ENVIRONMENT: pytorch-macos-10.13-py3
          command: |
            set -ex

            # Install sccache
            sudo curl https://s3.amazonaws.com/ossci-macos/sccache --output /usr/local/bin/sccache
            sudo chmod +x /usr/local/bin/sccache
            export SCCACHE_BUCKET=ossci-compiler-cache
            # This IAM user allows write access to S3 bucket for sccache
            export AWS_ACCESS_KEY_ID=AKIAJJZUW4G2ASX5W7KA
            export AWS_SECRET_ACCESS_KEY=${CIRCLECI_AWS_SECRET_KEY_FOR_SCCACHE_S3_BUCKET}

            git submodule update --init
            chmod a+x .jenkins/pytorch/macos-build.sh
            .jenkins/pytorch/macos-build.sh
      - persist_to_workspace:
          root: /Users/distiller/pytorch-ci-env
          paths:
            - "*"

  pytorch_macos_10_13_py3_test:
    macos:
      xcode: "9.0"
    steps:
      - checkout
      - run:
          name: Prepare workspace
          command: |
            sudo mkdir -p /Users/distiller/pytorch-ci-env
            sudo chmod -R 777 /Users/distiller/pytorch-ci-env
      - attach_workspace:
          at: /Users/distiller/pytorch-ci-env
      - run:
          name: Build
          environment:
            BUILD_ENVIRONMENT: pytorch-macos-10.13-py3
          command: |
            set -ex
            git submodule update --init
            chmod a+x .jenkins/pytorch/macos-test.sh
            .jenkins/pytorch/macos-test.sh

  pytorch_macos_10_13_cuda9_2_cudnn7_py3_build:
    macos:
      xcode: "9.0"
    steps:
      - checkout
      - run:
          name: Build
          environment:
            JOB_BASE_NAME: pytorch-macos-10.13-cuda9.2-cudnn7-py3-build
            BUILD_ENVIRONMENT: pytorch-macos-10.13-cuda9.2-cudnn7-py3
          command: |
            set -ex

            # Install CUDA 9.2
            sudo rm -rf ~/cuda_9.2.64_mac_installer.app || true
            curl https://s3.amazonaws.com/ossci-macos/cuda_9.2.64_mac_installer.zip -o ~/cuda_9.2.64_mac_installer.zip
            unzip ~/cuda_9.2.64_mac_installer.zip -d ~/
            sudo ~/cuda_9.2.64_mac_installer.app/Contents/MacOS/CUDAMacOSXInstaller --accept-eula --no-window
            sudo cp /usr/local/cuda/lib/libcuda.dylib /Developer/NVIDIA/CUDA-9.2/lib/libcuda.dylib
            sudo rm -rf /usr/local/cuda || true

            # Install cuDNN 7.1 for CUDA 9.2
            curl https://s3.amazonaws.com/ossci-macos/cudnn-9.2-osx-x64-v7.1.tgz -o ~/cudnn-9.2-osx-x64-v7.1.tgz
            rm -rf ~/cudnn-9.2-osx-x64-v7.1 && mkdir ~/cudnn-9.2-osx-x64-v7.1
            tar -xzvf ~/cudnn-9.2-osx-x64-v7.1.tgz -C ~/cudnn-9.2-osx-x64-v7.1
            sudo cp ~/cudnn-9.2-osx-x64-v7.1/cuda/include/cudnn.h /Developer/NVIDIA/CUDA-9.2/include/
            sudo cp ~/cudnn-9.2-osx-x64-v7.1/cuda/lib/libcudnn* /Developer/NVIDIA/CUDA-9.2/lib/
            sudo chmod a+r /Developer/NVIDIA/CUDA-9.2/include/cudnn.h /Developer/NVIDIA/CUDA-9.2/lib/libcudnn*

            # Install sccache
            sudo curl https://s3.amazonaws.com/ossci-macos/sccache --output /usr/local/bin/sccache
            sudo chmod +x /usr/local/bin/sccache
            export SCCACHE_BUCKET=ossci-compiler-cache
            # This IAM user allows write access to S3 bucket for sccache
            export AWS_ACCESS_KEY_ID=AKIAJJZUW4G2ASX5W7KA
            export AWS_SECRET_ACCESS_KEY=${CIRCLECI_AWS_SECRET_KEY_FOR_SCCACHE_S3_BUCKET}

            git submodule update --init
            chmod a+x .jenkins/pytorch/macos-build.sh
            .jenkins/pytorch/macos-build.sh

  caffe2_py2_cuda8_0_cudnn6_ubuntu16_04_build:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda8.0-cudnn6-ubuntu16.04:189
        <<: *docker_config_defaults
    environment:
      CUDA_VERSION: "8"
      BUILD_ENVIRONMENT: "py2-cuda8.0-cudnn6-ubuntu16.04"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_cuda8_0_cudnn6_ubuntu16_04_test:
    environment:
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda8.0-cudnn6-ubuntu16.04:189"
      CUDA_VERSION: "8"
      BUILD_ENVIRONMENT: "py2-cuda8.0-cudnn6-ubuntu16.04"
    resource_class: gpu.small
    <<: *caffe2_linux_test_defaults

  caffe2_py2_cuda9_0_cudnn7_ubuntu16_04_build:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda9.0-cudnn7-ubuntu16.04:189
        <<: *docker_config_defaults
    environment:
      CUDA_VERSION: "9"
      BUILD_ENVIRONMENT: "py2-cuda9.0-cudnn7-ubuntu16.04"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_cuda9_0_cudnn7_ubuntu16_04_test:
    environment:
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda9.0-cudnn7-ubuntu16.04:189"
      CUDA_VERSION: "9"
      BUILD_ENVIRONMENT: "py2-cuda9.0-cudnn7-ubuntu16.04"
    resource_class: gpu.small
    <<: *caffe2_linux_test_defaults

  caffe2_py2_cuda9_0_cudnn7_aten_ubuntu16_04_build:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda9.0-cudnn7-ubuntu16.04:189
        <<: *docker_config_defaults
    environment:
      CUDA_VERSION: "9"
      BUILD_ENVIRONMENT: "py2-cuda9.0-cudnn7-aten-ubuntu16.04"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_cuda9_0_cudnn7_aten_ubuntu16_04_test:
    environment:
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda9.0-cudnn7-ubuntu16.04:189"
      CUDA_VERSION: "9"
      BUILD_ENVIRONMENT: "py2-cuda9.0-cudnn7-aten-ubuntu16.04"
    resource_class: gpu.small
    <<: *caffe2_linux_test_defaults

  caffe2_py2_cuda9_1_cudnn7_ubuntu16_04_build:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda9.1-cudnn7-ubuntu16.04:189
        <<: *docker_config_defaults
    environment:
      CUDA_VERSION: "9.1"
      BUILD_ENVIRONMENT: "py2-cuda9.1-cudnn7-ubuntu16.04"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_cuda9_1_cudnn7_ubuntu16_04_test:
    environment:
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda9.1-cudnn7-ubuntu16.04:189"
      CUDA_VERSION: "9.1"
      BUILD_ENVIRONMENT: "py2-cuda9.1-cudnn7-ubuntu16.04"
    resource_class: gpu.small
    <<: *caffe2_linux_test_defaults

  caffe2_py2_mkl_ubuntu16_04_build:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-mkl-ubuntu16.04:189
        <<: *docker_config_defaults
    environment:
      BUILD_ENVIRONMENT: "py2-mkl-ubuntu16.04"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_mkl_ubuntu16_04_test:
    environment:
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-mkl-ubuntu16.04:189"
      BUILD_ENVIRONMENT: "py2-mkl-ubuntu16.04"
    resource_class: large
    <<: *caffe2_linux_test_defaults

  caffe2_py2_gcc4_8_ubuntu14_04_build:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-gcc4.8-ubuntu14.04:189
        <<: *docker_config_defaults
    environment:
      BUILD_ENVIRONMENT: "py2-gcc4.8-ubuntu14.04"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_gcc4_8_ubuntu14_04_test:
    environment:
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-gcc4.8-ubuntu14.04:189"
      BUILD_ENVIRONMENT: "py2-gcc4.8-ubuntu14.04"
    resource_class: large
    <<: *caffe2_linux_test_defaults

  caffe2_onnx_py2_gcc5_ubuntu16_04_build:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-gcc5-ubuntu16.04:189
        <<: *docker_config_defaults
    environment:
      BUILD_ENVIRONMENT: "onnx-py2-gcc5-ubuntu16.04"
    <<: *caffe2_linux_build_defaults

  caffe2_onnx_py2_gcc5_ubuntu16_04_test:
    environment:
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-gcc5-ubuntu16.04:189"
      BUILD_ENVIRONMENT: "onnx-py2-gcc5-ubuntu16.04"
    resource_class: large
    <<: *caffe2_linux_test_defaults

  caffe2_conda2_ubuntu16_04_build:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/conda2-ubuntu16.04:189
        <<: *docker_config_defaults
    environment:
      BUILD_ENVIRONMENT: "conda2-ubuntu16.04"
    <<: *caffe2_linux_build_defaults

  caffe2_conda2_ubuntu16_04_test:
    environment:
      DOCKER_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/conda2-ubuntu16.04:189"
      BUILD_ENVIRONMENT: "conda2-ubuntu16.04"
    resource_class: large
    <<: *caffe2_linux_test_defaults

  caffe2_py2_cuda8_0_cudnn7_ubuntu16_04_build:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda8.0-cudnn7-ubuntu16.04:189
        <<: *docker_config_defaults
    environment:
      BUILD_ENVIRONMENT: "py2-cuda8.0-cudnn7-ubuntu16.04"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_gcc4_9_ubuntu14_04_build:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-gcc4.9-ubuntu14.04:189
        <<: *docker_config_defaults
    environment:
      BUILD_ENVIRONMENT: "py2-gcc4.9-ubuntu14.04"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_clang3_8_ubuntu16_04_build:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-clang3.8-ubuntu16.04:189
        <<: *docker_config_defaults
    environment:
      BUILD_ENVIRONMENT: "py2-clang3.8-ubuntu16.04"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_clang3_9_ubuntu16_04_build:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-clang3.9-ubuntu16.04:189
        <<: *docker_config_defaults
    environment:
      BUILD_ENVIRONMENT: "py2-clang3.9-ubuntu16.04"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_gcc6_ubuntu16_04_build:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-gcc6-ubuntu16.04:189
        <<: *docker_config_defaults
    environment:
      BUILD_ENVIRONMENT: "py2-gcc6-ubuntu16.04"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_gcc7_ubuntu16_04_build:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-gcc7-ubuntu16.04:189
        <<: *docker_config_defaults
    environment:
      BUILD_ENVIRONMENT: "py2-gcc7-ubuntu16.04"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_cuda8_0_cudnn7_aten_ubuntu16_04_build:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda8.0-cudnn7-ubuntu16.04:189
        <<: *docker_config_defaults
    environment:
      BUILD_ENVIRONMENT: "py2-cuda8.0-cudnn7-ubuntu16.04"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_android_ubuntu16_04_build:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-android-ubuntu16.04:189
        <<: *docker_config_defaults
    environment:
      BUILD_ENVIRONMENT: "py2-android-ubuntu16.04"
    <<: *caffe2_linux_build_defaults

  caffe2_conda3_cuda9_0_cudnn7_ubuntu16_04_build:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/conda3-cuda9.0-cudnn7-ubuntu16.04:189
        <<: *docker_config_defaults
    environment:
      BUILD_ENVIRONMENT: "conda3-cuda9.0-cudnn7-ubuntu16.04"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_cuda9_0_cudnn7_centos7_build:
    docker:
      - image: 308535385114.dkr.ecr.us-east-1.amazonaws.com/caffe2/py2-cuda9.0-cudnn7-centos7:189
        <<: *docker_config_defaults
    environment:
      BUILD_ENVIRONMENT: "py2-cuda9.0-cudnn7-centos7"
    <<: *caffe2_linux_build_defaults

  caffe2_py2_ios_macos10_13_build:
    environment:
      BUILD_IOS: "1"
      PYTHON_INSTALLATION: "system"
      PYTHON_VERSION: "2"
    <<: *caffe2_macos_build_defaults

  caffe2_py2_system_macos10_13_build:
    environment:
      PYTHON_INSTALLATION: "system"
      PYTHON_VERSION: "2"
    <<: *caffe2_macos_build_defaults

  caffe2_conda2_macos10_13_build:
    environment:
      CAFFE2_USE_ANACONDA: 1
      SKIP_CONDA_TESTS: 1
      PYTHON_INSTALLATION: "system"
      ANACONDA_VERSION: "2"
    <<: *caffe2_macos_build_defaults

workflows:
  version: 2
  build:
    jobs:
      - pytorch_linux_trusty_py2_7_9_build_test
      - pytorch_linux_trusty_py2_7_build_test
      - pytorch_linux_trusty_py3_5_build_test
      - pytorch_linux_trusty_py3_6_gcc4_8_build_test
      - pytorch_linux_trusty_py3_6_gcc5_4_build_test
      - pytorch_linux_trusty_py3_6_gcc7_build_test
      - pytorch_linux_trusty_pynightly_build_test
      - pytorch_linux_xenial_py3_clang5_asan_build
      - pytorch_linux_xenial_py3_clang5_asan_test:
          requires:
            - pytorch_linux_xenial_py3_clang5_asan_build
      - pytorch_linux_xenial_cuda8_cudnn6_py3_build
      - pytorch_linux_xenial_cuda8_cudnn6_py3_test:
          requires:
            - pytorch_linux_xenial_cuda8_cudnn6_py3_build
      - pytorch_linux_xenial_cuda9_cudnn7_py2_build
      - pytorch_linux_xenial_cuda9_cudnn7_py2_test:
          requires:
            - pytorch_linux_xenial_cuda9_cudnn7_py2_build
      - pytorch_linux_xenial_cuda9_cudnn7_py3_build
      - pytorch_linux_xenial_cuda9_cudnn7_py3_test:
          requires:
            - pytorch_linux_xenial_cuda9_cudnn7_py3_build
      - pytorch_linux_xenial_cuda9_2_cudnn7_py3_gcc7_build
      - pytorch_linux_xenial_cuda9_2_cudnn7_py3_gcc7_test:
          requires:
            - pytorch_linux_xenial_cuda9_2_cudnn7_py3_gcc7_build
      # We are not running macOS builds on CircleCI currently
      # - pytorch_macos_10_13_py3_build
      # - pytorch_macos_10_13_py3_test:
      #     requires:
      #       - pytorch_macos_10_13_py3_build
      # - pytorch_macos_10_13_cuda9_2_cudnn7_py3_build
      - caffe2_py2_cuda8_0_cudnn6_ubuntu16_04_build
      - caffe2_py2_cuda8_0_cudnn6_ubuntu16_04_test:
          requires:
            - caffe2_py2_cuda8_0_cudnn6_ubuntu16_04_build
      - caffe2_py2_cuda9_0_cudnn7_ubuntu16_04_build
      - caffe2_py2_cuda9_0_cudnn7_ubuntu16_04_test:
          requires:
            - caffe2_py2_cuda9_0_cudnn7_ubuntu16_04_build
      - caffe2_py2_cuda9_0_cudnn7_aten_ubuntu16_04_build
      - caffe2_py2_cuda9_0_cudnn7_aten_ubuntu16_04_test:
          requires:
            - caffe2_py2_cuda9_0_cudnn7_aten_ubuntu16_04_build
      - caffe2_py2_mkl_ubuntu16_04_build
      - caffe2_py2_mkl_ubuntu16_04_test:
          requires:
            - caffe2_py2_mkl_ubuntu16_04_build
      - caffe2_py2_cuda9_1_cudnn7_ubuntu16_04_build
      - caffe2_py2_cuda9_1_cudnn7_ubuntu16_04_test:
          requires:
            - caffe2_py2_cuda9_1_cudnn7_ubuntu16_04_build
      - caffe2_py2_gcc4_8_ubuntu14_04_build
      - caffe2_py2_gcc4_8_ubuntu14_04_test:
          requires:
            - caffe2_py2_gcc4_8_ubuntu14_04_build
      - caffe2_onnx_py2_gcc5_ubuntu16_04_build
      - caffe2_onnx_py2_gcc5_ubuntu16_04_test:
          requires:
            - caffe2_onnx_py2_gcc5_ubuntu16_04_build
      - caffe2_conda2_ubuntu16_04_build
      - caffe2_conda2_ubuntu16_04_test:
          requires:
            - caffe2_conda2_ubuntu16_04_build
      - caffe2_py2_cuda8_0_cudnn7_ubuntu16_04_build
      - caffe2_py2_gcc4_9_ubuntu14_04_build
      - caffe2_py2_clang3_8_ubuntu16_04_build
      - caffe2_py2_clang3_9_ubuntu16_04_build
      - caffe2_py2_gcc6_ubuntu16_04_build
      - caffe2_py2_gcc7_ubuntu16_04_build
      - caffe2_py2_cuda8_0_cudnn7_aten_ubuntu16_04_build
      - caffe2_py2_android_ubuntu16_04_build
      - caffe2_conda3_cuda9_0_cudnn7_ubuntu16_04_build
      - caffe2_py2_cuda9_0_cudnn7_centos7_build
      # We are not running macOS builds on CircleCI currently
      # - caffe2_py2_ios_macos10_13_build
      # - caffe2_py2_system_macos10_13_build
      # - caffe2_conda2_macos10_13_build
