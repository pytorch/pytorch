# Dynamic Range-Based Autotuning - Final Design Document

## ç®€æ´çš„æ–°APIè®¾è®¡ âœ¨

åŸºäºä½ çš„å»ºè®®ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†æ›´ç®€æ´ç›´è§‚çš„APIï¼š

```python
CustomOpRangeConfig(
    tensor_name='x',           # æ¸…æ™°ï¼šå“ªä¸ªtensor
    dim_index=1,               # æ¸…æ™°ï¼štensorçš„å“ªä¸ªç»´åº¦
    ranges=[(0, 512), ...],    # æ¸…æ™°ï¼šèŒƒå›´åˆ—è¡¨
    implementations=[...],      # æ¸…æ™°ï¼šå€™é€‰å®ç°åˆ—è¡¨
)
```

### ä¸æ—§APIå¯¹æ¯”

```python
# âŒ æ—§APIï¼šå­—ç¬¦ä¸²è§£æï¼Œä¸æ¸…æ™°
CustomOpRangeConfig(
    range_dim='x.shape[1]',    # éœ€è¦è§£æå­—ç¬¦ä¸²
    ...
)

# âœ… æ–°APIï¼šæ˜ç¡®çš„å‚æ•°ï¼Œç±»å‹å®‰å…¨
CustomOpRangeConfig(
    tensor_name='x',           # string
    dim_index=1,               # int
    ...
)
```

## å®Œæ•´ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šåŸºäºåºåˆ—é•¿åº¦çš„Range Tuning

```python
import torch
from torch._inductor.kernel.custom_op import (
    CustomOpRangeConfig,
    register_custom_op_autotuning,
)

# å®šä¹‰ä¸åŒçš„å®ç°
def short_seq_impl(x: torch.Tensor, weight: torch.Tensor) -> torch.Tensor:
    """çŸ­åºåˆ—ï¼šä½¿ç”¨einsum"""
    return torch.einsum("bsh,h->bsh", x, weight)

def medium_seq_impl(x: torch.Tensor, weight: torch.Tensor) -> torch.Tensor:
    """ä¸­ç­‰åºåˆ—ï¼šåˆ†å—å¤„ç†"""
    batch_size, seq_len, hidden_dim = x.shape
    chunk_size = 256
    chunks = []
    for start in range(0, seq_len, chunk_size):
        end = min(start + chunk_size, seq_len)
        chunk = x[:, start:end, :]
        chunks.append(chunk * weight)
    return torch.cat(chunks, dim=1)

def long_seq_impl(x: torch.Tensor, weight: torch.Tensor) -> torch.Tensor:
    """é•¿åºåˆ—ï¼šå¹¿æ’­"""
    return x * weight.view(1, 1, -1)

# å®šä¹‰custom op
@torch.library.custom_op("mylib::weighted_scale", mutates_args=())
def weighted_scale(x: torch.Tensor, weight: torch.Tensor) -> torch.Tensor:
    return x * weight

@weighted_scale.register_fake
def _(x: torch.Tensor, weight: torch.Tensor):
    return torch.empty_like(x)

# æ³¨å†Œrange-based autotuning
register_custom_op_autotuning(
    weighted_scale,
    configs=[
        CustomOpRangeConfig(
            tensor_name='x',      # â† æ¸…æ™°ï¼šæ£€æŸ¥xè¿™ä¸ªtensor
            dim_index=1,          # â† æ¸…æ™°ï¼šx.shape[1]ï¼ˆåºåˆ—é•¿åº¦ï¼‰
            ranges=[
                (0, 512),         # èŒƒå›´1ï¼š[0, 512)
                (512, 2048),      # èŒƒå›´2ï¼š[512, 2048)
                (2048, float('inf')),  # èŒƒå›´3ï¼š[2048, âˆ)
            ],
            implementations=[
                short_seq_impl,   # å€™é€‰å®ç°1
                medium_seq_impl,  # å€™é€‰å®ç°2
                long_seq_impl,    # å€™é€‰å®ç°3
            ],
        )
    ],
    input_gen_fns={
        "x": lambda fake: torch.randn_like(fake, device='cuda'),
        "weight": lambda fake: torch.ones_like(fake, device='cuda'),
    },
)

# ä½¿ç”¨
@torch.compile
def model(x, weight):
    return weighted_scale(x, weight)

# æµ‹è¯•ä¸åŒåºåˆ—é•¿åº¦
x_short = torch.randn(2, 256, 128, device='cuda')    # seq_len=256 < 512
x_medium = torch.randn(2, 1024, 128, device='cuda')  # 512 <= seq_len < 2048
x_long = torch.randn(2, 4096, 128, device='cuda')    # seq_len >= 2048
weight = torch.ones(128, device='cuda')

# ç³»ç»Ÿä¼šè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜å®ç°
result_short = model(x_short, weight)   # å¯èƒ½é€‰short_seq_impl
result_medium = model(x_medium, weight)  # å¯èƒ½é€‰medium_seq_impl
result_long = model(x_long, weight)     # å¯èƒ½é€‰long_seq_impl
```

### ç¤ºä¾‹2ï¼šåŸºäºBatch Sizeçš„Range Tuning

```python
# å®šä¹‰ä¸åŒçš„å®ç°
def small_batch_impl(query, key, value):
    """å°batchï¼šä¼˜åŒ–å†…å­˜è®¿é—®"""
    return torch.nn.functional.scaled_dot_product_attention(query, key, value)

def large_batch_impl(query, key, value):
    """å¤§batchï¼šä¼˜åŒ–å¹¶è¡Œåº¦"""
    return flash_attention(query, key, value)

@torch.library.custom_op("mylib::attention", mutates_args=())
def attention(query, key, value):
    return torch.nn.functional.scaled_dot_product_attention(query, key, value)

register_custom_op_autotuning(
    attention,
    configs=[
        CustomOpRangeConfig(
            tensor_name='query',  # â† æ¸…æ™°ï¼šæ£€æŸ¥query tensor
            dim_index=0,          # â† æ¸…æ™°ï¼šquery.shape[0]ï¼ˆbatch sizeï¼‰
            ranges=[
                (0, 32),          # å°batch
                (32, float('inf')),  # å¤§batch
            ],
            implementations=[
                small_batch_impl,
                large_batch_impl,
            ],
        )
    ],
)
```

### ç¤ºä¾‹3ï¼šå¤šä¸ªtensorçš„æƒ…å†µ

```python
# å½“å‡½æ•°æœ‰å¤šä¸ªtensorå‚æ•°æ—¶ï¼Œå¯ä»¥é€‰æ‹©ä»»æ„ä¸€ä¸ªä½œä¸ºdispatchä¾æ®
def my_op(x, y, z):
    """x, y, zéƒ½æ˜¯tensor"""
    return x + y + z

register_custom_op_autotuning(
    my_op,
    configs=[
        # é€‰é¡¹1ï¼šåŸºäºxçš„ç»´åº¦
        CustomOpRangeConfig(
            tensor_name='x',    # ä½¿ç”¨xçš„shape
            dim_index=0,        # x.shape[0]
            ranges=[...],
            implementations=[...],
        ),
        
        # é€‰é¡¹2ï¼šåŸºäºyçš„ç»´åº¦  
        CustomOpRangeConfig(
            tensor_name='y',    # ä½¿ç”¨yçš„shape
            dim_index=1,        # y.shape[1]
            ranges=[...],
            implementations=[...],
        ),
    ],
)
```

## ç³»ç»Ÿå·¥ä½œæµç¨‹

### é˜¶æ®µ1ï¼šæ³¨å†Œæ—¶

```python
register_custom_op_autotuning(
    my_op,
    configs=[
        CustomOpRangeConfig(
            tensor_name='x',
            dim_index=1,
            ranges=[(0, 512), (512, 2048), (2048, inf)],
            implementations=[impl_a, impl_b, impl_c],
        )
    ],
)

# ç³»ç»Ÿè®°å½•ï¼š
# - è¦æ£€æŸ¥x.shape[1]
# - æœ‰3ä¸ªranges
# - æ¯ä¸ªrangeæœ‰3ä¸ªå€™é€‰å®ç°
```

### é˜¶æ®µ2ï¼šç¼–è¯‘æ—¶Benchmark

```python
# ç”¨æˆ·ä»£ç 
@torch.compile
def model(x, weight):
    return my_op(x, weight)

# Inductoråœ¨ç¼–è¯‘æ—¶ï¼š
# 1. æ£€æµ‹åˆ°my_opæ˜¯range-based autotuned custom op
# 2. æå–x.shape[1]çš„å€¼ï¼ˆå¯èƒ½æ˜¯symbolicï¼‰
# 3. å¯¹æ¯ä¸ªrangeè¿›è¡Œbenchmark

# Range [0, 512):
#   representative_value = 256  # (0 + 512) / 2
#   test_input = generate_input_with_shape(batch=2, seq=256, hidden=128)
#   
#   benchmark impl_a with test_input â†’ 0.5ms
#   benchmark impl_b with test_input â†’ 0.8ms  
#   benchmark impl_c with test_input â†’ 1.0ms
#   
#   â†’ é€‰æ‹©impl_aï¼ˆæœ€å¿«ï¼‰

# Range [512, 2048):
#   representative_value = 1280
#   test_input = generate_input_with_shape(batch=2, seq=1280, hidden=128)
#   
#   benchmark impl_a with test_input â†’ 2.0ms
#   benchmark impl_b with test_input â†’ 1.5ms  â† æœ€å¿«
#   benchmark impl_c with test_input â†’ 1.8ms
#   
#   â†’ é€‰æ‹©impl_b

# Range [2048, inf):
#   representative_value = 4096  # 2048 * 2
#   test_input = generate_input_with_shape(batch=2, seq=4096, hidden=128)
#   
#   benchmark impl_a with test_input â†’ 5.0ms
#   benchmark impl_b with test_input â†’ 3.0ms
#   benchmark impl_c with test_input â†’ 2.5ms  â† æœ€å¿«
#   
#   â†’ é€‰æ‹©impl_c

# ç»“æœï¼š
best_impl_per_range = {
    (0, 512): impl_a,
    (512, 2048): impl_b,
    (2048, inf): impl_c,
}
```

### é˜¶æ®µ3ï¼šä¼˜åŒ–å†³ç­–

```python
# æ£€æŸ¥æ˜¯å¦æ‰€æœ‰rangeç”¨åŒä¸€ä¸ªimpl
unique_impls = {impl_a, impl_b, impl_c}  # 3ä¸ªä¸åŒçš„impl

if len(unique_impls) == 1:
    # âœ… æƒ…å†µ1ï¼šæ‰€æœ‰rangeç”¨åŒä¸€impl
    # ç›´æ¥ä½¿ç”¨è¯¥implï¼ˆfusion-friendlyï¼‰
    log.info("All ranges use the same impl, using direct implementation")
    
    def optimized_lowering(*args, **kwargs):
        return single_impl(*args, **kwargs)
        
else:
    # âš ï¸ æƒ…å†µ2ï¼šä¸åŒrangeç”¨ä¸åŒimpl
    # ç”Ÿæˆtorch.cond dispatchï¼ˆno fusionï¼‰
    log.info("Different ranges use different impls, generating torch.cond dispatch")
    
    def dispatch_lowering(*args, **kwargs):
        dim_value = x.shape[1]
        
        return torch.cond(
            dim_value < 512,
            lambda: impl_a(*args, **kwargs),
            lambda: torch.cond(
                dim_value < 2048,
                lambda: impl_b(*args, **kwargs),
                lambda: impl_c(*args, **kwargs)
            )
        )
```

### é˜¶æ®µ4ï¼šä»£ç ç”Ÿæˆå’Œè¿è¡Œ

```python
# å¦‚æœæ‰€æœ‰rangeç”¨åŒä¸€implï¼š
# âœ… ç”Ÿæˆå•ä¸ªkernelï¼Œå¯ä»¥fusion

# kernel_fused:
#   result = impl_a(x, weight)  # å†…è”å±•å¼€
#   result = relu(result)        # å’Œåç»­æ“ä½œfusion
#   return result

# å¦‚æœä¸åŒrangeç”¨ä¸åŒimplï¼š
# âš ï¸ ç”Ÿæˆå¤šä¸ªkernels + dispatch

# kernel_impl_a:
#   return impl_a(x, weight)
#
# kernel_impl_b:
#   return impl_b(x, weight)
#
# kernel_impl_c:
#   return impl_c(x, weight)
#
# dispatch:
#   if x.shape[1] < 512:
#       result = kernel_impl_a(x, weight)
#   elif x.shape[1] < 2048:
#       result = kernel_impl_b(x, weight)
#   else:
#       result = kernel_impl_c(x, weight)
#   
#   # åç»­æ“ä½œæ— æ³•fusion
#   result = relu(result)
```

## æ€§èƒ½åˆ†æ

### Benchmarkå¼€é”€

```python
# é…ç½®ï¼š
num_ranges = 3
num_implementations = 3
benchmark_time_per_impl = 10ms

# æ€»æ—¶é—´ï¼š
total_benchmark_time = num_ranges Ã— num_implementations Ã— benchmark_time_per_impl
                     = 3 Ã— 3 Ã— 10ms
                     = 90ms

# è¿™æ˜¯ä¸€æ¬¡æ€§ç¼–è¯‘å¼€é”€ï¼Œç”¨æˆ·ä¸ä¼šæ„ŸçŸ¥
```

### Runtimeæ€§èƒ½æå‡

| åœºæ™¯ | vs å›ºå®šå®ç° | Fusion | è¯´æ˜ |
|-----|-----------|--------|------|
| **æ‰€æœ‰rangeåŒä¸€impl** | +20-30% | âœ… å¯ä»¥ | æœ€ä¼˜impl + fusionåŠ é€Ÿ |
| **ä¸åŒrangeä¸åŒimpl** | +10-20% | âŒ ä¸èƒ½ | æ¯ä¸ªrangeæœ€ä¼˜ï¼Œä½†æ— fusion |

### å®é™…æ€§èƒ½å¯¹æ¯”

```python
# åœºæ™¯ï¼šçŸ­åºåˆ— (seq_len=256)

# Baselineï¼ˆå›ºå®šç”¨long_seq_implï¼‰:
time = 1.5ms  # ä¸æ˜¯æœ€ä¼˜impl

# Range-basedï¼ˆé€‰short_seq_implï¼‰:
time = 0.5ms  # â† 3x faster!

# æå‡ï¼š(1.5 - 0.5) / 1.5 = 67%
```

## APIå‚æ•°è¯¦è§£

### CustomOpRangeConfigå‚æ•°

```python
class CustomOpRangeConfig:
    """Range-based autotuningé…ç½®"""
    
    def __init__(
        self,
        tensor_name: str,           # è¦æ£€æŸ¥çš„tensorå‚æ•°å
        dim_index: int,             # tensorçš„ç»´åº¦ç´¢å¼•ï¼ˆ0-basedï¼‰
        ranges: list[tuple[float, float]],  # èŒƒå›´åˆ—è¡¨ï¼Œæ ¼å¼ï¼š[(start, end), ...]
        implementations: list[Callable],     # å€™é€‰å®ç°å‡½æ•°åˆ—è¡¨
    ):
        ...
```

#### tensor_nameï¼ˆå¿…éœ€ï¼‰
- **ç±»å‹**ï¼š`str`
- **è¯´æ˜**ï¼šcustom opçš„tensorå‚æ•°å
- **ç¤ºä¾‹**ï¼š`'x'`, `'query'`, `'input'`
- **éªŒè¯**ï¼šå¿…é¡»æ˜¯å‡½æ•°ç­¾åä¸­çš„æœ‰æ•ˆå‚æ•°å

#### dim_indexï¼ˆå¿…éœ€ï¼‰
- **ç±»å‹**ï¼š`int`
- **è¯´æ˜**ï¼šè¦æ£€æŸ¥çš„ç»´åº¦ç´¢å¼•ï¼ˆ0-basedï¼‰
- **ç¤ºä¾‹**ï¼š
  - `0` â†’ batch size (tensor.shape[0])
  - `1` â†’ sequence length (tensor.shape[1])
  - `2` â†’ hidden dimension (tensor.shape[2])
- **éªŒè¯**ï¼šå¿…é¡»æ˜¯æœ‰æ•ˆçš„ç»´åº¦ç´¢å¼•

#### rangesï¼ˆå¿…éœ€ï¼‰
- **ç±»å‹**ï¼š`list[tuple[float, float]]`
- **æ ¼å¼**ï¼š`[(start1, end1), (start2, end2), ...]`
- **è¯´æ˜**ï¼šåŠå¼€åŒºé—´ [start, end)
- **çº¦æŸ**ï¼š
  - ä¸èƒ½é‡å 
  - å¿…é¡»æŒ‰startæ’åº
  - `start < end`
  - å¯ä»¥ç”¨`float('inf')`è¡¨ç¤ºæ— ç©·å¤§
- **ç¤ºä¾‹**ï¼š
  ```python
  ranges=[
      (0, 512),           # [0, 512)
      (512, 2048),        # [512, 2048)
      (2048, float('inf')),  # [2048, âˆ)
  ]
  ```

#### implementationsï¼ˆå¿…éœ€ï¼‰
- **ç±»å‹**ï¼š`list[Callable]`
- **è¯´æ˜**ï¼šå€™é€‰å®ç°å‡½æ•°åˆ—è¡¨
- **è¦æ±‚**ï¼š
  - æ‰€æœ‰å‡½æ•°ç­¾åå¿…é¡»ä¸custom opä¸€è‡´
  - æ‰€æœ‰å‡½æ•°å¿…é¡»äº§ç”Ÿæ•°å€¼ç­‰ä»·çš„ç»“æœ
- **ç¤ºä¾‹**ï¼š
  ```python
  implementations=[
      short_seq_impl,
      medium_seq_impl,
      long_seq_impl,
  ]
  ```

## é”™è¯¯å¤„ç†

### å¸¸è§é”™è¯¯å’Œè§£å†³æ–¹æ¡ˆ

#### é”™è¯¯1ï¼štensor_nameä¸å­˜åœ¨

```python
# âŒ é”™è¯¯
CustomOpRangeConfig(
    tensor_name='y',  # ä½†å‡½æ•°å‚æ•°æ˜¯xï¼
    ...
)

def my_op(x, weight):  # æ²¡æœ‰yå‚æ•°
    ...

# é”™è¯¯ä¿¡æ¯ï¼š
ValueError: Tensor 'y' not found in function arguments. 
Available arguments: ['x', 'weight']
```

#### é”™è¯¯2ï¼šdim_indexè¶Šç•Œ

```python
# âŒ é”™è¯¯
CustomOpRangeConfig(
    tensor_name='x',
    dim_index=5,  # ä½†xåªæœ‰3ä¸ªç»´åº¦ï¼
    ...
)

# x.shape = [2, 128, 512]  # åªæœ‰3ä¸ªç»´åº¦(0, 1, 2)

# é”™è¯¯ä¿¡æ¯ï¼š
ValueError: Dimension index 5 out of range for tensor 'x' with shape [2, 128, 512]
```

#### é”™è¯¯3ï¼šrangesé‡å 

```python
# âŒ é”™è¯¯
CustomOpRangeConfig(
    ranges=[
        (0, 512),
        (256, 1024),  # ä¸ç¬¬ä¸€ä¸ªé‡å ï¼
    ],
    ...
)

# é”™è¯¯ä¿¡æ¯ï¼š
ValueError: Ranges 0 and 1 overlap: [0, 512) and [256, 1024)
```

#### é”™è¯¯4ï¼šimplementationä¸å¯è°ƒç”¨

```python
# âŒ é”™è¯¯
CustomOpRangeConfig(
    implementations=[
        my_func,
        "not_a_function",  # å­—ç¬¦ä¸²ä¸æ˜¯callableï¼
    ],
    ...
)

# é”™è¯¯ä¿¡æ¯ï¼š
TypeError: Implementation 1 must be callable, got <class 'str'>
```

## æµ‹è¯•ç­–ç•¥

### æµ‹è¯•1ï¼šéªŒè¯åŒä¸€implä¼˜åŒ–

```python
def test_single_impl_optimization():
    """å½“æ‰€æœ‰rangeé€‰åŒä¸€implæ—¶ï¼ŒéªŒè¯ç³»ç»Ÿç›´æ¥ä½¿ç”¨ï¼ˆä¸ç”Ÿæˆcondï¼‰"""
    
    # è®¾è®¡ï¼šä¸€ä¸ªimplåœ¨æ‰€æœ‰rangeéƒ½æœ€å¿«
    def fast_impl(x, weight):
        return x * weight  # ç®€å•å¿«é€Ÿ
    
    def slow_impl(x, weight):
        time.sleep(0.01)  # æ•…æ„æ…¢
        return x * weight
    
    register_custom_op_autotuning(
        my_op,
        configs=[
            CustomOpRangeConfig(
                tensor_name='x',
                dim_index=1,
                ranges=[(0, 512), (512, 2048), (2048, float('inf'))],
                implementations=[fast_impl, slow_impl],
            )
        ],
    )
    
    # éªŒè¯ï¼š
    # 1. æ‰€æœ‰rangeéƒ½é€‰fast_impl
    # 2. æ²¡æœ‰ç”Ÿæˆtorch.cond
    # 3. å¯ä»¥fusion
```

### æµ‹è¯•2ï¼šéªŒè¯ä¸åŒimpl dispatch

```python
def test_different_impl_dispatch():
    """å½“ä¸åŒrangeé€‰ä¸åŒimplæ—¶ï¼ŒéªŒè¯ç”Ÿæˆtorch.cond"""
    
    def short_impl(x, weight):
        return torch.einsum("bsh,h->bsh", x, weight)
    
    def long_impl(x, weight):
        return x * weight.view(1, 1, -1)
    
    register_custom_op_autotuning(
        my_op,
        configs=[
            CustomOpRangeConfig(
                tensor_name='x',
                dim_index=1,
                ranges=[(0, 512), (512, float('inf'))],
                implementations=[short_impl, long_impl],
            )
        ],
    )
    
    # éªŒè¯ï¼š
    # 1. range [0,512) é€‰short_impl
    # 2. range [512,inf) é€‰long_impl  
    # 3. ç”Ÿæˆäº†torch.cond dispatch
```

### æµ‹è¯•3ï¼šæ•°å€¼æ­£ç¡®æ€§

```python
def test_numerical_correctness():
    """éªŒè¯æ‰€æœ‰rangeçš„ç»“æœæ•°å€¼æ­£ç¡®"""
    
    test_cases = [
        (2, 256, 128),   # è§¦å‘range [0, 512)
        (2, 1024, 128),  # è§¦å‘range [512, 2048)
        (2, 4096, 128),  # è§¦å‘range [2048, inf)
    ]
    
    for batch, seq, hidden in test_cases:
        x = torch.randn(batch, seq, hidden, device='cuda')
        weight = torch.ones(hidden, device='cuda')
        
        result = my_op(x, weight)
        expected = x * weight
        
        torch.testing.assert_close(result, expected, rtol=1e-5, atol=1e-5)
```

## æœªæ¥æ‰©å±•

### å¯èƒ½çš„å¢å¼º1ï¼šè‡ªåŠ¨å‘ç°æœ€ä¼˜åˆ†ç•Œç‚¹

```python
# å½“å‰ï¼šç”¨æˆ·æŒ‡å®šåˆ†ç•Œç‚¹
ranges=[(0, 512), (512, 2048), ...]

# æœªæ¥ï¼šç³»ç»Ÿè‡ªåŠ¨å‘ç°æœ€ä¼˜åˆ†ç•Œç‚¹
auto_discover_ranges=True,
benchmark_shapes=[128, 256, 512, 1024, 2048, 4096],
# ç³»ç»Ÿæµ‹è¯•åå¯èƒ½å‘ç°ï¼š
# - æœ€ä¼˜åˆ†ç•Œç‚¹æ˜¯ (0, 473), (473, 1856), ...
```

### å¯èƒ½çš„å¢å¼º2ï¼šå¤šç»´åº¦ç»„åˆ

```python
# åŒæ—¶åŸºäºå¤šä¸ªç»´åº¦
MultiDimRangeConfig(
    dims={
        'x': {0: [(0, 32), (32, inf)],    # batch size ranges
              1: [(0, 1024), (1024, inf)]},  # seq length ranges
    },
    implementations=[...],
)
# ç³»ç»Ÿä¼šæµ‹è¯•æ‰€æœ‰ç»„åˆï¼š2Ã—2=4ä¸ªç»„åˆ
```

### å¯èƒ½çš„å¢å¼º3ï¼šProfiling-Guided Optimization

```python
# åŸºäºå®é™…è¿è¡Œprofilingé€‰æ‹©æœ€ä¼˜impl
enable_profiling=True,
profiling_iterations=100,
# ç³»ç»Ÿä¼šåœ¨å®é™…workloadä¸Šprofilingï¼Œè€Œä¸æ˜¯synthetic inputs
```

## æ€»ç»“

è¿™ä¸ªæ–°APIè®¾è®¡å…·æœ‰ä»¥ä¸‹ä¼˜ç‚¹ï¼š

1. **âœ… ç®€æ´ç›´è§‚**
   - `tensor_name='x'` - æ˜ç¡®
   - `dim_index=1` - æ¸…æ™°
   - ä¸éœ€è¦å­—ç¬¦ä¸²è§£æ

2. **âœ… ç±»å‹å®‰å…¨**
   - å‚æ•°ç±»å‹æ˜ç¡®ï¼ˆstr, int, listï¼‰
   - IDEè‡ªåŠ¨è¡¥å…¨æ”¯æŒå¥½
   - ç¼–è¯‘æ—¶ç±»å‹æ£€æŸ¥

3. **âœ… æ˜“äºéªŒè¯**
   - å‚æ•°éªŒè¯ç®€å•
   - é”™è¯¯ä¿¡æ¯æ¸…æ™°
   - è°ƒè¯•å‹å¥½

4. **âœ… æ€§èƒ½ä¼˜åŒ–**
   - åŒä¸€impl â†’ ç›´æ¥ä½¿ç”¨ï¼ˆfusionï¼‰
   - ä¸åŒimpl â†’ torch.condï¼ˆä»ä¼˜äºå›ºå®šå®ç°ï¼‰

5. **âœ… çµæ´»æ‰©å±•**
   - æ”¯æŒå¤šä¸ªtensorå‚æ•°
   - æ”¯æŒä»»æ„ç»´åº¦
   - æœªæ¥å¯æ‰©å±•åˆ°å¤šç»´åº¦

å®Œæ•´ç¤ºä¾‹ä»£ç ï¼š

```python
from torch._inductor.kernel.custom_op import CustomOpRangeConfig, register_custom_op_autotuning

register_custom_op_autotuning(
    my_custom_op,
    configs=[
        CustomOpRangeConfig(
            tensor_name='x',           # â† ç®€æ´æ˜äº†
            dim_index=1,               # â† ç±»å‹å®‰å…¨
            ranges=[(0, 512), (512, 2048), (2048, float('inf'))],
            implementations=[impl_a, impl_b, impl_c],
        )
    ],
)
```

å°±æ˜¯è¿™ä¹ˆç®€å•ï¼ğŸ‰
