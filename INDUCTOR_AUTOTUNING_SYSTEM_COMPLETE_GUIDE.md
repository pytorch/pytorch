# PyTorch Inductor Autotuning System - å®Œæ•´æŠ€æœ¯æ–‡æ¡£

> **ä½œè€…**: Research Analysis
> **æ—¥æœŸ**: 2025-01-10
> **ç‰ˆæœ¬**: 1.0
> **åŸºäºä»£ç ç‰ˆæœ¬**: PyTorch main branch

---

## ğŸ“– ç›®å½•

1. [ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ](#ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ)
2. [æ ¸å¿ƒç³»ç»Ÿå¯¹æ¯”](#æ ¸å¿ƒç³»ç»Ÿå¯¹æ¯”)
3. [Kernelç±»å‹æ˜ å°„è¡¨](#kernelç±»å‹æ˜ å°„è¡¨)
4. [Heuristicç³»ç»Ÿè¯¦è§£](#heuristicç³»ç»Ÿè¯¦è§£)
5. [Max Autotuneä¸Exhaustiveæ¨¡å¼](#max-autotuneä¸exhaustiveæ¨¡å¼)
6. [Template Heuristicsæœºåˆ¶](#template-heuristicsæœºåˆ¶)
7. [é…ç½®æ•°é‡å®Œæ•´è¡¨](#é…ç½®æ•°é‡å®Œæ•´è¡¨)
8. [ä»£ç ä½ç½®ç´¢å¼•](#ä»£ç ä½ç½®ç´¢å¼•)
9. [å®è·µå»ºè®®](#å®è·µå»ºè®®)

---

## ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ

### æ•´ä½“è®¾è®¡

PyTorch Inductorçš„autotuningç³»ç»Ÿé‡‡ç”¨**åˆ†å±‚æ¶æ„**ï¼Œè€Œéå¤šå¥—ç‹¬ç«‹ç³»ç»Ÿï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PyTorch Inductor Autotuning ç³»ç»Ÿ                    â”‚
â”‚                                                                  â”‚
â”‚  Layer 1: Algorithm/Backend Selection (é«˜å±‚å†³ç­–)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  autotune_select_algorithm                               â”‚  â”‚
â”‚  â”‚  - å†³ç­–: ä½¿ç”¨å“ªä¸ªbackendå®ç°ï¼Ÿ                            â”‚  â”‚
â”‚  â”‚  - è¾“å…¥: [Triton, CUTLASS, ATen, CK, CPP, ...]          â”‚  â”‚
â”‚  â”‚  - è¾“å‡º: æœ€ä¼˜ChoiceCaller æˆ– MultiTemplateBuffer         â”‚  â”‚
â”‚  â”‚  - åœºæ™¯: Template kernels (GEMM, Conv, Attention)       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                     â”‚                                           â”‚
â”‚                     â–¼ (é€‰ä¸­Triton template)                     â”‚
â”‚                                                                  â”‚
â”‚  Layer 2: Config Parameter Tuning (ä½å±‚ä¼˜åŒ–)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  CachingAutotuner                                        â”‚  â”‚
â”‚  â”‚  - å†³ç­–: å“ªä¸ªconfigå‚æ•°æœ€ä¼˜ï¼Ÿ                             â”‚  â”‚
â”‚  â”‚  - è¾“å…¥: å•ä¸ªTriton kernel + configs                     â”‚  â”‚
â”‚  â”‚  - è¾“å‡º: æœ€ä¼˜launcher                                     â”‚  â”‚
â”‚  â”‚  - åœºæ™¯: Triton kernelå†…éƒ¨ + Codegen fusion kernels     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚  Heuristics: Configç”Ÿæˆå™¨ (æ”¯æ’‘å±‚)                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Runtime Heuristics (triton_heuristics.py)              â”‚  â”‚
â”‚  â”‚  - pointwise(), reduction(), persistent_reduction()     â”‚  â”‚
â”‚  â”‚  - ç”Ÿæˆ: CachingAutotunerçš„configs                       â”‚  â”‚
â”‚  â”‚                                                          â”‚  â”‚
â”‚  â”‚  Template Heuristics (template_heuristics/)             â”‚  â”‚
â”‚  â”‚  - CUDAMMTemplateConfigHeuristic, ROCmMM, ...           â”‚  â”‚
â”‚  â”‚  - ç”Ÿæˆ: autotune_select_algorithmçš„configs             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å…³é”®æ´å¯Ÿ

**è¿™ä¸æ˜¯ä¸¤å¥—ç³»ç»Ÿï¼Œè€Œæ˜¯ä¸€ä¸ªç³»ç»Ÿçš„ä¸¤ä¸ªå±‚çº§ï¼**

- **Layer 1 (autotune_select_algorithm)**: é€‰æ‹©å¼€å“ªè¾†è½¦ï¼ˆbackendï¼‰
- **Layer 2 (CachingAutotuner)**: è°ƒæ•´è½¦çš„å‚æ•°ï¼ˆconfigï¼‰
- **Heuristics**: æä¾›å€™é€‰é€‰é¡¹ï¼ˆç”Ÿæˆå™¨ï¼‰

---

## æ ¸å¿ƒç³»ç»Ÿå¯¹æ¯”

### 1. CachingAutotuner vs autotune_select_algorithm

#### ä»£ç ä½ç½®

| ç»„ä»¶ | æ–‡ä»¶ | è¡Œå· |
|------|------|------|
| **CachingAutotuner** | `/torch/_inductor/runtime/triton_heuristics.py` | 260-1456 |
| **autotune_select_algorithm** | `/torch/_inductor/select_algorithm.py` | 4076-4087 |
| **AlgorithmSelectorCache** | `/torch/_inductor/select_algorithm.py` | 2619-3050 |
| **MultiTemplateBuffer** | `/torch/_inductor/ir.py` | 5269-5357 |

#### åŠŸèƒ½å¯¹æ¯”è¡¨

| ç»´åº¦ | CachingAutotuner | autotune_select_algorithm |
|------|-----------------|---------------------------|
| **å±‚çº§** | ä½å±‚ - Config tuning | é«˜å±‚ - Backend selection |
| **è¾“å…¥** | å•ä¸ªTriton kernel + configsåˆ—è¡¨ | å¤šä¸ªChoiceCaller (è·¨backend) |
| **è¾“å‡º** | æœ€ä¼˜launcher | ChoiceCalleræˆ–MultiTemplateBuffer |
| **å†³ç­–** | BLOCK_M=64è¿˜æ˜¯128? | ç”¨Tritonè¿˜æ˜¯CUTLASS? |
| **ç¼“å­˜** | ç£ç›˜ (size_hints key) | å†…å­˜ + ç£ç›˜ (operation key) |
| **æ—¶æœº** | è¿è¡Œæ—¶ | ç¼–è¯‘æ—¶ |
| **ä½¿ç”¨åœºæ™¯** | Tritonå†…éƒ¨ä¼˜åŒ– + Codegen kernels | Template kernels (MM/Conv/Attn) |

#### å†³ç­–æ ‘

```
Operationéœ€è¦ç¼–è¯‘
    â”‚
    â”œâ”€ æ˜¯Template kernel? (MM/Conv/Attention)
    â”‚  â”‚
    â”‚  â””â”€ YES â†’ autotune_select_algorithm()
    â”‚      â”œâ”€ æ”¶é›†choices: [Triton, CUTLASS, ATen, CK, ...]
    â”‚      â”œâ”€ é¢„ç¼–è¯‘æ‰€æœ‰choices
    â”‚      â”œâ”€ Benchmarkæ¯ä¸ªchoice
    â”‚      â”œâ”€ é€‰æ‹©æœ€ä¼˜ â†’ å‡è®¾é€‰ä¸­Triton
    â”‚      â”‚
    â”‚      â””â”€ Tritonå†…éƒ¨ â†’ CachingAutotuner
    â”‚          â”œâ”€ configs: [Config(BLOCK_M=64), Config(BLOCK_M=128), ...]
    â”‚          â”œâ”€ Benchmarkæ‰€æœ‰configs
    â”‚          â””â”€ é€‰æ‹©æœ€ä¼˜launcher
    â”‚
    â””â”€ æ˜¯Codegen fusion? (pointwise/reduction)
       â”‚
       â””â”€ YES â†’ ç›´æ¥ CachingAutotuner
           â”œâ”€ @cached_autotuneè£…é¥°å™¨
           â”œâ”€ configsç”±heuristicç”Ÿæˆ
           â””â”€ Benchmarké€‰æœ€ä¼˜
```

### 2. MultiTemplateBuffer

**å®šä¹‰**: å»¶è¿Ÿbackendé€‰æ‹©çš„å®¹å™¨ï¼Œæ”¯æŒepilogue fusionä¼˜åŒ–

**åˆ›å»ºä½ç½®**: **ä»…åœ¨** `select_algorithm.py:2963`

```python
# åˆ›å»ºæ¡ä»¶
if return_multi_template and (config.max_autotune or config.max_autotune_gemm):
    return ir.TensorBox.create(
        ir.MultiTemplateBuffer(
            layout,
            input_nodes,
            get_timings,              # å»¶è¿Ÿbenchmarkå‡½æ•°
            choices,                  # æ‰€æœ‰backend choices
            allowed_prologue_inps,
        )
    )
```

**ä½¿ç”¨åœºæ™¯**:
1. âœ… autotune_select_algorithmåˆ›å»º
2. âœ… Schedulerä¸­è¿›è¡Œepilogue fusion
3. âœ… è”åˆbenchmark (kernel + fusion)
4. âŒ CachingAutotuner **ä¸ä½¿ç”¨** MultiTemplateBuffer

**ä¸ºä»€ä¹ˆCachingAutotunerä¸ç”¨?**
- å¤„ç†å•ä¸ªkernelï¼Œæ— éœ€è·¨backend
- ç«‹å³benchmarkï¼Œä¸å»¶è¿Ÿ
- å·²åœ¨Layer 2ï¼Œæ— éœ€æ›´é«˜å±‚æŠ½è±¡

---

## Kernelç±»å‹æ˜ å°„è¡¨

### Template Kernels â†’ autotune_select_algorithm

| Operation | ATenæ“ä½œç¬¦ | æ–‡ä»¶ä½ç½® | Backendé€‰é¡¹ | MultiTemplateæ”¯æŒ |
|-----------|-----------|---------|------------|------------------|
| **Matrix Multiply** | `aten.mm` | `mm.py:1323` | Triton, CUTLASS, ATen, CK, CPP | âœ… |
| **Batch MM** | `aten.bmm` | `bmm.py:135` | Triton, CUTLASS, ATen, CK | âœ… |
| **Add MM** | `aten.addmm` | `mm.py:1378` | Triton, CUTLASS, ATen, CK | âœ… |
| **Scaled MM** | `aten._scaled_mm` | `mm.py:1772` | Triton, CUTLASS, ATen | âœ… |
| **Grouped MM** | `aten._grouped_mm` | `mm_grouped.py:791` | Triton, CUTLASS, ATen | âœ… |
| **Convolution** | `aten.convolution` | `conv.py:650` | Triton, CK, ATen | âœ… |
| **Flex Attention** | custom | `flex_attention.py:429` | Triton (å¤švariants) | âœ… |
| **Flex Decoding** | custom | `flex_decoding.py:388` | Triton (å¤švariants) | âœ… |
| **Custom Op** | user-defined | `custom_op.py:320` | ç”¨æˆ·å®šä¹‰ | âœ… |

### Codegen Fusion Kernels â†’ CachingAutotuner

| Kernelç±»å‹ | Heuristicå‡½æ•° | ConfigèŒƒå›´ | æ–‡ä»¶ä½ç½® |
|-----------|--------------|-----------|---------|
| **Pointwise 1D** | `pointwise()` | XBLOCK, num_warps | `triton_heuristics.py:2599` |
| **Pointwise 2D** | `pointwise()` | XBLOCK, YBLOCK, num_warps | `triton_heuristics.py:2673` |
| **Pointwise 3D** | `pointwise()` | XBLOCK, YBLOCK, ZBLOCK | `triton_heuristics.py:2712` |
| **Reduction** | `reduction()` | XBLOCK, R0_BLOCK, num_warps | `triton_heuristics.py:2798` |
| **Persistent Reduction** | `persistent_reduction()` | XBLOCK, R0_BLOCK | `triton_heuristics.py:3396` |
| **Foreach** | `foreach()` | num_warps | `triton_heuristics.py:3613` |
| **Split Scan** | `split_scan()` | XBLOCK, R0_BLOCK | `triton_heuristics.py:3463` |

### åˆ¤æ–­è§„åˆ™

```python
# ä¼ªä»£ç 
if kernelæœ‰@register_loweringä¸”æ˜¯template:
    system = "autotune_select_algorithm"
    configs_source = "template_heuristics/"
elif kernelæ˜¯codegenç”Ÿæˆ:
    system = "CachingAutotuner"
    configs_source = "triton_heuristics.py"
else:
    system = "Direct execution"
    configs_source = None
```

---

## Heuristicç³»ç»Ÿè¯¦è§£

### 1. Heuristicçš„æœ¬è´¨

**Heuristic â‰  Autotuning**

```
Heuristic = Configç”Ÿæˆå™¨
Autotuning = Performanceæµ‹è¯•å™¨

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input Shapes â”‚
â”‚ size_hints   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Heuristicå‡½æ•°         â”‚
â”‚  æ ¹æ®shapeç”Ÿæˆconfigs  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€ max_autotune=OFF â†’ [1ä¸ªconfig]
       â””â”€ max_autotune=ON  â†’ [4-13ä¸ªconfigs]
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Autotuner             â”‚
â”‚  Benchmarkè¿™äº›configs  â”‚
â”‚  é€‰æ‹©æœ€ä¼˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Runtime Heuristics (triton_heuristics.py)

#### Pointwise Heuristics

**æ–‡ä»¶ä½ç½®**: `triton_heuristics.py:2599-2740`

**å†³ç­–é€»è¾‘**:
```python
def pointwise(size_hints, inductor_meta, ...):
    max_autotune = inductor_meta.get("max_autotune") or \
                   inductor_meta.get("max_autotune_pointwise")

    if len(size_hints) == 1:  # 1D
        if not autotune_pointwise and not max_autotune:
            return [1ä¸ªconfig]  # å¿«é€Ÿè·¯å¾„
        else:
            return [2-3ä¸ªåŸºç¡€ + ROCmé¢å¤–5ä¸ª]  # å®Œæ•´autotuning

    elif len(size_hints) == 2:  # 2D
        if not autotune_pointwise and not max_autotune:
            return [1ä¸ªconfig(32,32)]
        else:
            return [6ä¸ªåŸºç¡€ + ROCmé¢å¤–4ä¸ª]

    elif len(size_hints) == 3:  # 3D
        if not autotune_pointwise:
            return [1ä¸ªconfig]
        else:
            return [7ä¸ªåŸºç¡€configs]
```

#### Reduction Heuristics

**æ–‡ä»¶ä½ç½®**: `triton_heuristics.py:2798-3000`

**å†³ç­–é€»è¾‘**:
```python
def _reduction_configs(size_hints, inductor_meta, ...):
    max_autotune = inductor_meta.get("max_autotune") or \
                   inductor_meta.get("max_autotune_pointwise")

    # ç”ŸæˆåŸºç¡€configs
    contiguous_config = make_config(x=1, r=min(rnumel, 2048))
    outer_config = make_config(x=64, r=8)
    tiny_config = make_config(...)

    # æ£€æŸ¥å¿«é€Ÿè·¯å¾„
    if not max_autotune:
        if reduction_hint == ReductionHint.INNER:
            return [contiguous_config]  # 1ä¸ª
        elif reduction_hint == ReductionHint.OUTER:
            return [outer_config]  # 1ä¸ª
        elif reduction_hint == ReductionHint.OUTER_TINY:
            return [tiny_config]  # 1ä¸ª

    # å®Œæ•´autotuningè·¯å¾„
    return [
        contiguous_config,
        outer_config,
        tiny_config,
        make_config(64, 64),
        make_config(8, 512),
        make_config(64, 4, num_warps=8),
        # + ROCmé¢å¤–2ä¸ª
    ]  # 7-9ä¸ª
```

#### Persistent Reduction Heuristics

**æ–‡ä»¶ä½ç½®**: `triton_heuristics.py:3396-3460`

**xblockå€¼èŒƒå›´**:
```python
if torch.version.hip:  # ROCm
    xblock_vals = [1, 4, 8, 16, 32, 64, 128, 256]  # 8ä¸ª
else:  # CUDA
    xblock_vals = [1, 8, 32, 128]  # 4ä¸ª
```

**å†³ç­–é€»è¾‘**:
```python
def _persistent_reduction_configs(...):
    configs = [ç”Ÿæˆxblock_valsçš„configs]

    if not max_autotune:
        if reduction_hint == INNER and rnumel >= 256:
            return configs[:1]  # ä»…ç¬¬ä¸€ä¸ª
        elif reduction_hint == OUTER:
            return configs[-1:]  # ä»…æœ€åä¸€ä¸ª
        # ...
    else:
        # è¿”å›æ‰€æœ‰configs
        return configs  # 4-9ä¸ª
```

### 3. Template Heuristics (template_heuristics/)

#### ç›®å½•ç»“æ„

```
template_heuristics/
â”œâ”€â”€ __init__.py              # åŒ…åˆå§‹åŒ–
â”œâ”€â”€ registry.py              # æ³¨å†Œç³»ç»Ÿ
â”œâ”€â”€ base.py                  # TemplateConfigHeuristicsåŸºç±»
â”œâ”€â”€ params.py                # å‚æ•°é…ç½®ç±»
â”œâ”€â”€ triton.py               # ä¸»è¦å®ç° (~2600è¡Œ)
â”œâ”€â”€ gemm.py                 # GEMMåŸºç±»
â”œâ”€â”€ cutedsl.py              # CuTe DSLæ”¯æŒ
â”œâ”€â”€ decompose_k.py          # Kåˆ†è§£ç­–ç•¥
â”œâ”€â”€ contiguous_mm.py        # è¿ç»­æ€§ä¼˜åŒ–
â””â”€â”€ aten.py                 # ATenåç«¯
```

#### æ³¨å†Œæœºåˆ¶

**æ–‡ä»¶ä½ç½®**: `template_heuristics/registry.py`

```python
# æ³¨å†Œè£…é¥°å™¨
@register_template_heuristic(
    template_name="mm",      # æ¨¡æ¿å
    device_type="cuda",      # è®¾å¤‡ç±»å‹
    op_name="addmm",        # æ“ä½œåï¼ˆå¯é€‰ï¼‰
    register=True           # æ¡ä»¶æ³¨å†Œ
)
class CUDAAddMMTemplateConfigHeuristic(BaseHeuristic):
    pass

# æŸ¥è¯¢ä¼˜å…ˆçº§
def get_template_heuristic(template_name, device_type, op_name):
    """
    ä¼˜å…ˆçº§ï¼ˆä»é«˜åˆ°ä½ï¼‰ï¼š
    1. (template_name, device_type, op_name)  # æœ€å…·ä½“
    2. (template_name, None, op_name)          # è·¨è®¾å¤‡
    3. (template_name, device_type, None)      # è·¨æ“ä½œ
    4. (template_name, None, None)             # é€šç”¨
    """
```

#### ä¸select_algorithmé›†æˆ

**è°ƒç”¨é“¾**:
```
kernel/mm.py (get_mm_configs)
    â†“
choices.py (get_ktcæ–¹æ³•)
    â†“
registry.get_template_heuristic(template_name, device_type, op_name)
    â†“
heuristic.get_template_configs(kernel_inputs, op_name)
    â†“
make_ktc_generator() â†’ KernelTemplateChoice
    â†“
select_algorithm.py (ChoiceCallerç”Ÿæˆä¸autotuning)
```

---

## Max Autotuneä¸Exhaustiveæ¨¡å¼

### 1. é…ç½®æ ‡å¿—å®šä¹‰

**æ–‡ä»¶ä½ç½®**: `config.py:459-543`

```python
# æ€»å¼€å…³
max_autotune = os.environ.get("TORCHINDUCTOR_MAX_AUTOTUNE") == "1"

# ç‹¬ç«‹å¼€å…³
max_autotune_pointwise = os.environ.get("TORCHINDUCTOR_MAX_AUTOTUNE_POINTWISE") == "1"
max_autotune_gemm = os.environ.get("TORCHINDUCTOR_MAX_AUTOTUNE_GEMM") == "1"

# GEMMæœç´¢ç©ºé—´
max_autotune_gemm_search_space: Literal["DEFAULT", "EXHAUSTIVE"] = \
    os.environ.get("TORCHINDUCTOR_MAX_AUTOTUNE_GEMM_SEARCH_SPACE", "DEFAULT").upper()
```

### 2. ä¸‰ç§æ¨¡å¼å¯¹æ¯”

| é…ç½® | max_autotune | max_autotune_gemm | search_space | è¡Œä¸º |
|------|-------------|-------------------|--------------|------|
| **é»˜è®¤** | False | False | DEFAULT | æ— autotuningæˆ–è½»é‡çº§ |
| **ä»…GEMM** | False | True | DEFAULT | ä»…GEMMä½¿ç”¨20ä¸ªconfigs |
| **å…¨å±€** | True | True (æ¨å¯¼) | DEFAULT | æ‰€æœ‰opsä½¿ç”¨å®Œæ•´configs |
| **GEMMç©·ä¸¾** | True | True | EXHAUSTIVE | GEMMä½¿ç”¨1875ä¸ªconfigs |

### 3. max_autotuneçš„ä½œç”¨

#### Layer 1: Backendé€‰æ‹©

```python
# kernel/mm.py:1200-1250
if not (max_autotune or max_autotune_gemm):
    # å¿«é€Ÿè·¯å¾„ï¼šä»…ATen
    choices = [aten_mm]
else:
    # å®Œæ•´è·¯å¾„ï¼šå¤šbackend
    choices = [
        aten_mm,
        triton_mm_template,
        cutlass_template,
        ck_template,
    ]
```

#### Layer 2: Configæ•°é‡

```python
# triton_heuristics.py:2629-2633 (pointwiseä¾‹å­)
if not max_autotune and not max_autotune_pointwise:
    configs = [1ä¸ªconfig]
else:
    configs = [2-10ä¸ªconfigs]
```

### 4. EXHAUSTIVEæœç´¢ç©ºé—´

#### GEMMé…ç½®ç”Ÿæˆ

**æ–‡ä»¶ä½ç½®**: `template_heuristics/triton.py:253-261`

```python
exhaustive_configs = [
    GemmConfig(BLOCK_M, BLOCK_N, BLOCK_K, num_stages, num_warps, group_m)
    for BLOCK_M in [16, 32, 64, 128, 256]      # 5ä¸ª
    for BLOCK_N in [16, 32, 64, 128, 256]      # 5ä¸ª
    for BLOCK_K in [16, 32, 64, 128, 256]      # 5ä¸ª
    for num_stages in [1, 2, 3, 4, 5]          # 5ä¸ª
    for num_warps in [2, 4, 8]                 # 3ä¸ª
    for group_m in [8]                          # 1ä¸ª
]
# æ€»è®¡: 5 * 5 * 5 * 5 * 3 * 1 = 1875ä¸ªconfigs
```

#### ç©·ä¸¾å‰ªæç­–ç•¥

**æ–‡ä»¶ä½ç½®**: `template_heuristics/triton.py:679-704`

```python
def _prune_exhaustive_configs(configs, dtype_size):
    """
    å‰ªææ¡ä»¶:
    1. Shared memoryè¶…é™
    2. Registeræ•°é‡ > 255 (å¿…ç„¶spill)
    """
    pruned = []
    for config in configs:
        # æ£€æŸ¥registerå‹åŠ›
        acc_regs = math.ceil(
            config.block_m * config.block_n / (config.num_warps * 32)
        )
        if acc_regs > 255:
            continue  # è·³è¿‡

        pruned.append(config)
    return pruned
```

#### ä¸åŒè®¾å¤‡çš„EXHAUSTIVE

| è®¾å¤‡ | åŸºç¡€configs | é¢å¤–å‚æ•° | æ€»æ•° |
|------|-----------|---------|------|
| **CUDA** | 1875 | - | **1875** |
| **ROCm** | 1875 | matrix_instrÃ—2, waves_per_euÃ—2, kpackÃ—1 | **7500** |
| **Flex Attention** | - | BLOCK_MÃ—4, BLOCK_NÃ—3, stagesÃ—4, warpsÃ—3 | **144** |

---

## é…ç½®æ•°é‡å®Œæ•´è¡¨

### 1. Triton Codegen Kernels (CachingAutotuner)

#### Pointwise

| ç»´æ•° | max_autotune=OFF | max_autotune=ON | +ROCm | æ€»è®¡(ON) |
|------|-----------------|-----------------|-------|---------|
| **1D** | 1 | 2-3 | +5 | **7-10** |
| **2D** | 1 | 6 | +4 | **10-13** |
| **3D** | 1 | 7 | 0 | **7-10** |

**å…³é”®å› ç´ **:
- `autotune_pointwise` flag
- `TileHint.SQUARE` (2Dæƒ…å†µ)
- `AutotuneHint` é¢å¤–configs

**ä»£ç ä½ç½®**: `triton_heuristics.py:2599-2740`

#### Reduction

| åœºæ™¯ | max_autotune=OFF | max_autotune=ON | +ROCm | deterministic |
|------|-----------------|-----------------|-------|---------------|
| **with hint (INNER/OUTER/TINY)** | 1 | 7 | +2 | 1 |
| **without hint** | 6 | 7 | +2 | 1 |
| **3D tiling** | å¯å˜ | å¯å˜ | - | 1 |

**å…³é”®å› ç´ **:
- `reduction_hint` (INNER/OUTER/OUTER_TINY/DEFAULT)
- `deterministic` modeå¼ºåˆ¶è¿‡æ»¤åˆ°1ä¸ª
- `force_filter_reduction_configs`

**ä»£ç ä½ç½®**: `triton_heuristics.py:2798-3000`

#### Persistent Reduction

| åœºæ™¯ | max_autotune=OFF | max_autotune=ON | xblock_vals | æ€»è®¡(ON) |
|------|-----------------|-----------------|------------|---------|
| **CUDA** | 1 | 4 | [1,8,32,128] | **4** |
| **ROCm** | 1 | 8-9 | [1,4,8,16,32,64,128,256] | **8-9** |

**å…³é”®å› ç´ **:
- `reduction_hint`
- `rnumel` (reductionå…ƒç´ æ•°é‡)
- å¹³å° (CUDA vs ROCm)

**ä»£ç ä½ç½®**: `triton_heuristics.py:3396-3460`

#### Foreach

| æ¨¡å¼ | max_autotune=OFF | max_autotune=ON |
|------|-----------------|-----------------|
| **num_warps** | [8] | [1, 2, 4, 8] |
| **æ€»è®¡** | **1** | **4** |

**ä»£ç ä½ç½®**: `triton_heuristics.py:3613-3635`

### 2. Template Kernels (autotune_select_algorithm)

#### GEMM Templates

| Template | Device | DEFAULT | EXHAUSTIVE | æ–‡ä»¶ä½ç½® |
|----------|--------|---------|------------|---------|
| **MM** | CUDA | 20 | 1875 | `triton.py:253` |
| **MM** | ROCm | 20 | 7500 | `triton.py:1161` |
| **Persistent TMA MM** | CUDA | 15 | - | - |
| **Scaled MM** | CUDA | 18 | - | - |
| **Blackwell MM** | CUDA | 12 | - | - |

**DEFAULT configsç¤ºä¾‹** (triton.py:60-81):
```python
mm_configs = [
    GemmConfig(64, 64, 32, 2, 4, 8),
    GemmConfig(64, 128, 32, 3, 4, 8),
    GemmConfig(128, 64, 32, 3, 4, 8),
    GemmConfig(128, 128, 32, 3, 4, 8),
    GemmConfig(256, 64, 32, 4, 4, 8),
    # ... å…±20ä¸ª
]
```

#### Attention Templates

| Template | DEFAULT | EXHAUSTIVE | è¯´æ˜ |
|----------|---------|------------|------|
| **Flex Attention Forward** | 18 | 144 | BLOCK_MÃ—4, BLOCK_NÃ—3, stagesÃ—4, warpsÃ—3 |
| **Flex Attention Backward** | 10 | 120 | - |
| **Flex Decoding** | 12 | 96 | - |

**ä»£ç ä½ç½®**: `template_heuristics/triton.py:495-519`

#### Grouped GEMM

| Template | DEFAULT | EXHAUSTIVE |
|----------|---------|------------|
| **Grouped MM (Triton)** | 15 | 600 |
| **Grouped MM (CuTe)** | 8 | 128 |

### 3. å®Œæ•´å†³ç­–çŸ©é˜µ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Kernelç±»å‹          â”‚ max_autotune=OFF â”‚ max_autotune=ON  â”‚ EXHAUSTIVEæ¨¡å¼   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ POINTWISE_1D        â”‚ 1                â”‚ 7-10             â”‚ åŒON             â”‚
â”‚ POINTWISE_2D        â”‚ 1                â”‚ 10-13            â”‚ åŒON             â”‚
â”‚ POINTWISE_3D        â”‚ 1                â”‚ 7-10             â”‚ åŒON             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ REDUCTION (hint)    â”‚ 1                â”‚ 7-9              â”‚ åŒON             â”‚
â”‚ REDUCTION (no hint) â”‚ 6                â”‚ 7-9              â”‚ åŒON             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PERSISTENT (CUDA)   â”‚ 1                â”‚ 4                â”‚ åŒON             â”‚
â”‚ PERSISTENT (ROCm)   â”‚ 1                â”‚ 8-9              â”‚ åŒON             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ FOREACH             â”‚ 1                â”‚ 4                â”‚ åŒON             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ MM (CUDA)           â”‚ 1 (ATen only)    â”‚ 20               â”‚ 1875             â”‚
â”‚ MM (ROCm)           â”‚ 1 (ATen only)    â”‚ 20               â”‚ 7500             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ FLEX_ATTN_FWD       â”‚ N/A              â”‚ 18               â”‚ 144              â”‚
â”‚ FLEX_ATTN_BWD       â”‚ N/A              â”‚ 10               â”‚ 120              â”‚
â”‚ FLEX_DECODING       â”‚ N/A              â”‚ 12               â”‚ 96               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**è¯´æ˜**:
- Codegen kernelsçš„EXHAUSTIVEä¸ONç›¸åŒï¼ˆæ— template_heuristicsï¼‰
- Template kernelsçš„EXHAUSTIVEæ˜¾è‘—å¢åŠ configsæ•°é‡

---

## Template Heuristicsæœºåˆ¶

### 1. å·¥ä½œæµç¨‹

```
1. Kernel Lowering
   â”œâ”€ tuned_mm(mat1, mat2) è¢«è°ƒç”¨
   â””â”€ éœ€è¦ç”Ÿæˆbackend choices
      â†“
2. Template HeuristicæŸ¥è¯¢
   â”œâ”€ get_template_heuristic("mm", "cuda", "mm")
   â””â”€ è¿”å› CUDAMMTemplateConfigHeuristic å®ä¾‹
      â†“
3. Configç”Ÿæˆ
   â”œâ”€ heuristic.get_template_configs(kernel_inputs, "mm")
   â”œâ”€ å†…éƒ¨è°ƒç”¨ _get_config_generator()
   â”‚  â”œâ”€ search_space="DEFAULT" â†’ get_mm_configs()
   â”‚  â””â”€ search_space="EXHAUSTIVE" â†’ get_exhaustive_mm_configs()
   â””â”€ è¿”å› configs iterator
      â†“
4. Configé¢„å¤„ç†
   â”œâ”€ preprocess_mm_configs(m, n, k, configs, ...)
   â”œâ”€ _filter_configs() - è®¾å¤‡ç‰¹å®šè¿‡æ»¤
   â”œâ”€ _scale_mm_configs() - æ ¹æ®shapeç¼©æ”¾
   â”œâ”€ _prune_exceeding_max_shared_mem_configs()
   â””â”€ _prune_exhaustive_configs() (if EXHAUSTIVE)
      â†“
5. ç”ŸæˆKernelTemplateChoice
   â”œâ”€ make_ktc_generator(template, configs, ...)
   â””â”€ æ¯ä¸ªconfigç”Ÿæˆä¸€ä¸ªchoice
      â†“
6. Autotuning
   â”œâ”€ autotune_select_algorithm(choices)
   â””â”€ é€‰æ‹©æœ€ä¼˜choice
```

### 2. Configç¼©æ”¾é€»è¾‘

**æ–‡ä»¶ä½ç½®**: `template_heuristics/triton.py:762-882`

```python
def _scale_mm_configs(self, m, n, k, configs, scale, ...):
    """
    æ ¹æ®M/N/Kå¤§å°åŠ¨æ€ç¼©æ”¾configå‚æ•°
    """
    # å°shapeæ£€æµ‹
    if m <= 32 and n <= 32:
        # ä½¿ç”¨tiny configs
        configs = [c for c in configs if c.block_m <= 32 and c.block_n <= 32]

    # å¤§shapeæ£€æµ‹
    if m >= 2048 and n >= 2048:
        # ä½¿ç”¨å¤§block configs
        configs = [c for c in configs if c.block_m >= 128]

    # Kç»´åº¦è°ƒæ•´
    if k <= 64:
        configs = [c for c in configs if c.block_k <= 64]

    # ç¼©æ”¾å› å­åº”ç”¨
    for config in configs:
        config.block_m = min(config.block_m * scale, m)
        config.block_n = min(config.block_n * scale, n)

    return configs
```

### 3. è®¾å¤‡ç‰¹å®šä¼˜åŒ–

#### CUDAä¼˜åŒ– (triton.py:697-742)

```python
class CUDAConfigHeuristic(BaseConfigHeuristic):
    def _filter_configs(self, configs):
        # CUDAç‰¹å®šè¿‡æ»¤é€»è¾‘
        # 1. ç§»é™¤num_stages=0çš„configs
        # 2. è°ƒæ•´num_warpsåŸºäºSMæ•°é‡
        return filtered_configs
```

#### ROCmä¼˜åŒ– (triton.py:1068-1208)

```python
class ROCmConfigHeuristic(BaseConfigHeuristic):
    def _filter_configs(self, configs):
        # ROCmç‰¹å®šä¼˜åŒ–
        # 1. matrix_instr_nonkdimå‚æ•°
        # 2. waves_per_euè°ƒæ•´
        # 3. kpackè®¾ç½®
        # 4. num_stagesé™åˆ¶ï¼ˆé€šå¸¸â‰¤2ï¼‰
        return filtered_configs
```

---

## ä»£ç ä½ç½®ç´¢å¼•

### æ ¸å¿ƒç³»ç»Ÿæ–‡ä»¶

| æ–‡ä»¶ | è·¯å¾„ | å…³é”®å†…å®¹ |
|------|------|---------|
| **CachingAutotuner** | `/torch/_inductor/runtime/triton_heuristics.py` | è¡Œ260-1456 |
| **autotune_select_algorithm** | `/torch/_inductor/select_algorithm.py` | è¡Œ4076-4087 |
| **AlgorithmSelectorCache** | `/torch/_inductor/select_algorithm.py` | è¡Œ2619-3050 |
| **MultiTemplateBuffer** | `/torch/_inductor/ir.py` | è¡Œ5269-5357 |
| **CoordescTuner** | `/torch/_inductor/runtime/coordinate_descent_tuner.py` | å…¨æ–‡ä»¶ |

### Runtime Heuristics

| å‡½æ•° | æ–‡ä»¶ | è¡Œå· |
|------|------|------|
| `pointwise()` | `triton_heuristics.py` | 2599-2740 |
| `reduction()` | `triton_heuristics.py` | 3187-3224 |
| `_reduction_configs()` | `triton_heuristics.py` | 2798-3000 |
| `persistent_reduction()` | `triton_heuristics.py` | 3396-3460 |
| `foreach()` | `triton_heuristics.py` | 3613-3635 |
| `split_scan()` | `triton_heuristics.py` | 3463-3498 |
| `template()` | `triton_heuristics.py` | 3503-3536 |
| `user_autotune()` | `triton_heuristics.py` | 3590-3610 |

### Template Heuristics

| æ–‡ä»¶ | è·¯å¾„ | å†…å®¹ |
|------|------|------|
| **registry.py** | `/torch/_inductor/template_heuristics/` | æ³¨å†Œç³»ç»Ÿ |
| **triton.py** | `/torch/_inductor/template_heuristics/` | CUDA/ROCm GEMM configs |
| **gemm.py** | `/torch/_inductor/template_heuristics/` | GEMMåŸºç±» |
| **cutedsl.py** | `/torch/_inductor/template_heuristics/` | CuTe DSL |
| **decompose_k.py** | `/torch/_inductor/template_heuristics/` | Kåˆ†è§£ç­–ç•¥ |

### Kernel Implementations

| æ“ä½œ | æ–‡ä»¶ | è¡Œå· |
|------|------|------|
| **tuned_mm** | `/torch/_inductor/kernel/mm.py` | 1100-1329 |
| **tuned_addmm** | `/torch/_inductor/kernel/mm.py` | 1370-1433 |
| **tuned_bmm** | `/torch/_inductor/kernel/bmm.py` | 135+ |
| **convolution** | `/torch/_inductor/kernel/conv.py` | 650+ |
| **flex_attention** | `/torch/_inductor/kernel/flex/flex_attention.py` | 429+ |
| **grouped_mm** | `/torch/_inductor/kernel/mm_grouped.py` | 791+ |

### Configuration

| é…ç½® | æ–‡ä»¶ | è¡Œå· |
|------|------|------|
| **max_autotune** | `/torch/_inductor/config.py` | 459 |
| **max_autotune_gemm** | `/torch/_inductor/config.py` | 465 |
| **max_autotune_pointwise** | `/torch/_inductor/config.py` | 462 |
| **max_autotune_gemm_search_space** | `/torch/_inductor/config.py` | 541-543 |
| **coordinate_descent_tuning** | `/torch/_inductor/config.py` | 583-591 |

---

## å®è·µå»ºè®®

### 1. ä¸åŒåœºæ™¯çš„é…ç½®å»ºè®®

#### åœºæ™¯1: æ¨¡å‹å¼€å‘/è°ƒè¯•

```python
# ä¼˜å…ˆç¼–è¯‘é€Ÿåº¦
torch._inductor.config.max_autotune = False
torch._inductor.config.max_autotune_gemm = False
torch._inductor.config.coordinate_descent_tuning = False

# é¢„æœŸï¼š
# - ç¼–è¯‘æ—¶é—´: ~1-5ç§’
# - æ€§èƒ½: åŸºçº¿ (70-80% of optimal)
```

#### åœºæ™¯2: è®­ç»ƒ (åŠ¨æ€shape)

```python
# å¹³è¡¡ç¼–è¯‘å’Œæ€§èƒ½
torch._inductor.config.max_autotune = False
torch._inductor.config.max_autotune_gemm = True  # ä»…GEMM
torch._inductor.config.max_autotune_gemm_search_space = "DEFAULT"

# é¢„æœŸï¼š
# - ç¼–è¯‘æ—¶é—´: ~10-30ç§’
# - æ€§èƒ½: 85-90% of optimal
```

#### åœºæ™¯3: æ¨ç† (å›ºå®šshape)

```python
# æè‡´æ€§èƒ½
torch._inductor.config.max_autotune = True
torch._inductor.config.max_autotune_gemm = True
torch._inductor.config.max_autotune_gemm_search_space = "DEFAULT"
torch._inductor.config.coordinate_descent_tuning = True
torch._inductor.config.coordinate_descent_check_all_directions = True

# é¢„æœŸï¼š
# - ç¼–è¯‘æ—¶é—´: ~1-5åˆ†é’Ÿ
# - æ€§èƒ½: 95-99% of optimal
```

#### åœºæ™¯4: ç”Ÿäº§éƒ¨ç½² (æé™ä¼˜åŒ–)

```python
# ç©·ä¸¾æœç´¢
torch._inductor.config.max_autotune = True
torch._inductor.config.max_autotune_gemm = True
torch._inductor.config.max_autotune_gemm_search_space = "EXHAUSTIVE"
torch._inductor.config.coordinate_descent_tuning = True
torch._inductor.config.coordinate_descent_check_all_directions = True
torch._inductor.config.coordinate_descent_search_radius = 2

# é¢„æœŸï¼š
# - ç¼–è¯‘æ—¶é—´: ~10-30åˆ†é’Ÿ (ä¸€æ¬¡æ€§)
# - æ€§èƒ½: æ¥è¿‘ç†è®ºæœ€ä¼˜
# - é€‚ç”¨: ç¼–è¯‘ä¸€æ¬¡ï¼Œè¿è¡Œç™¾ä¸‡æ¬¡
```

### 2. ç¼–è¯‘æ—¶é—´ vs æ€§èƒ½æƒè¡¡

| é…ç½® | ç¼–è¯‘æ—¶é—´ | è¿è¡Œæ€§èƒ½ | é€‚ç”¨åœºæ™¯ |
|------|---------|---------|---------|
| **é»˜è®¤** | 1-5s | 70-80% | å¼€å‘/è°ƒè¯• |
| **ä»…GEMM** | 10-30s | 85-90% | è®­ç»ƒï¼ˆGEMMå¯†é›†å‹ï¼‰ |
| **å…¨å±€ON** | 1-5min | 95-98% | å›ºå®šshapeæ¨ç† |
| **EXHAUSTIVE** | 10-30min | 98-100% | ç”Ÿäº§éƒ¨ç½² |

### 3. å¸¸è§é—®é¢˜æ’æŸ¥

#### Q1: ç¼–è¯‘å¤ªæ…¢æ€ä¹ˆåŠï¼Ÿ

```python
# æ–¹æ¡ˆ1: å‡å°‘autotuningèŒƒå›´
config.max_autotune = False
config.max_autotune_gemm = True  # ä»…ä¼˜åŒ–GEMM

# æ–¹æ¡ˆ2: ä½¿ç”¨å­è¿›ç¨‹autotuning
config.autotune_in_subproc = True

# æ–¹æ¡ˆ3: è°ƒæ•´è¶…æ—¶
config.precompilation_timeout_seconds = 300  # 5åˆ†é’Ÿ
```

#### Q2: æ€§èƒ½ä¸å¦‚é¢„æœŸï¼Ÿ

```python
# æ£€æŸ¥1: ç¡®è®¤autotuningå·²å¯ç”¨
print(f"max_autotune: {config.max_autotune}")
print(f"max_autotune_gemm: {config.max_autotune_gemm}")

# æ£€æŸ¥2: æŸ¥çœ‹ç¼“å­˜å‘½ä¸­
import torch._inductor.select_algorithm as sa
print(sa.get_algorithm_selector_cache().cache_info())

# æ£€æŸ¥3: å¯ç”¨æ›´æ¿€è¿›çš„ä¼˜åŒ–
config.max_autotune_gemm_search_space = "EXHAUSTIVE"
config.coordinate_descent_tuning = True
```

#### Q3: å†…å­˜ä¸è¶³ï¼Ÿ

```python
# æ–¹æ¡ˆ1: å‡å°‘å¹¶è¡Œç¼–è¯‘
config.compile_threads = 1

# æ–¹æ¡ˆ2: ç¦ç”¨æŸäº›backend
config.max_autotune_gemm_backends = "TRITON,ATEN"  # ç§»é™¤CUTLASS

# æ–¹æ¡ˆ3: å¢åŠ shared memoryå‰ªæ
config.max_autotune_prune_choices_based_on_shared_mem = True
```

### 4. æ€§èƒ½åˆ†æå·¥å…·

```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging
logging.getLogger("torch._inductor").setLevel(logging.DEBUG)

# å¯ç”¨kernelæ€§èƒ½åˆ†æ
config.triton.cudagraphs = True
config.benchmark_kernel = True

# å¯¼å‡ºautotuningç»“æœ
config.trace.enabled = True
config.trace.log_autotuning_results = True

# è¿è¡Œååˆ†æ
# æŸ¥çœ‹ .torch_inductor/autotune_cache/ ç›®å½•
# æŸ¥çœ‹ç¼–è¯‘æ—¥å¿—æ‰¾åˆ°æœ€ä¼˜configs
```

### 5. ç¼“å­˜ç®¡ç†

```python
# æ¸…é™¤ç¼“å­˜ï¼ˆå¼ºåˆ¶é‡æ–°autotuningï¼‰
import shutil
import os
cache_dir = os.path.expanduser("~/.triton/cache")
shutil.rmtree(cache_dir, ignore_errors=True)

# å¯ç”¨è¿œç¨‹ç¼“å­˜ï¼ˆå›¢é˜Ÿå…±äº«ï¼‰
config.autotune_remote_cache = "s3://my-bucket/inductor-cache"

# å¯ç”¨FX graphç¼“å­˜ï¼ˆè·¨ç¼–è¯‘å¤ç”¨ï¼‰
config.fx_graph_cache = True
```

---

## é™„å½•

### A. ç¯å¢ƒå˜é‡é€ŸæŸ¥

```bash
# å¯ç”¨max_autotune
export TORCHINDUCTOR_MAX_AUTOTUNE=1

# ä»…GEMM
export TORCHINDUCTOR_MAX_AUTOTUNE_GEMM=1

# ç©·ä¸¾æœç´¢
export TORCHINDUCTOR_MAX_AUTOTUNE_GEMM_SEARCH_SPACE=EXHAUSTIVE

# Coordinate descent
export TORCHINDUCTOR_COORDINATE_DESCENT_TUNING=1
export TORCHINDUCTOR_COORDINATE_DESCENT_CHECK_ALL_DIRECTIONS=1
export TORCHINDUCTOR_COORDINATE_DESCENT_RADIUS=2

# Backendé€‰æ‹©
export TORCHINDUCTOR_MAX_AUTOTUNE_GEMM_BACKENDS=ATEN,TRITON,CUTLASS

# å­è¿›ç¨‹autotuning
export TORCHINDUCTOR_AUTOTUNE_IN_SUBPROC=1

# ç¼“å­˜è®¾ç½®
export TRITON_CACHE_DIR=/path/to/cache
```

### B. å…³é”®æ•°æ®ç»“æ„

```python
# TritonConfig (tritonåŒ…)
class Config:
    def __init__(self, kwargs, num_warps, num_stages):
        self.kwargs = kwargs  # {"BLOCK_M": 64, "BLOCK_N": 128, ...}
        self.num_warps = num_warps
        self.num_stages = num_stages

# GemmConfig (template_heuristics)
class GemmConfig:
    def __init__(self, block_m, block_n, block_k, num_stages, num_warps, group_m):
        self.block_m = block_m
        self.block_n = block_n
        self.block_k = block_k
        self.num_stages = num_stages
        self.num_warps = num_warps
        self.group_m = group_m

# ChoiceCaller (select_algorithm)
class ChoiceCaller:
    def __init__(self, choice, input_nodes, layout):
        self.choice = choice  # ExternKernelChoice or TritonTemplate
        self.input_nodes = input_nodes
        self.layout = layout

    def benchmark(self, *args):
        # å®é™…åœ¨GPUä¸Šè¿è¡Œ
        pass
```

### C. æœ¯è¯­è¡¨

| æœ¯è¯­ | è§£é‡Š |
|------|------|
| **Backend** | kernelå®ç°åº“ (Triton/CUTLASS/ATen/CK/CPP) |
| **Template** | æ‰‹å†™çš„kernelæ¨¡æ¿ï¼Œæ”¯æŒå‚æ•°åŒ– |
| **Codegen** | ç¼–è¯‘å™¨è‡ªåŠ¨ç”Ÿæˆçš„kernel |
| **Choice** | ä¸€ä¸ªå¯é€‰çš„kernelå®ç°ï¼ˆbackend + configï¼‰ |
| **Config** | Triton kernelçš„å‚æ•°é…ç½® |
| **Heuristic** | åŸºäºshapeçš„configç”Ÿæˆè§„åˆ™ |
| **Launcher** | ç¼–è¯‘åå¯è°ƒç”¨çš„kernelå¯¹è±¡ |
| **Size hints** | è¾“å…¥å¼ é‡çš„shapeä¿¡æ¯ |
| **Fusion** | å¤šä¸ªæ“ä½œåˆå¹¶ä¸ºå•ä¸ªkernel |
| **Epilogue fusion** | åœ¨ä¸»kernelåè¿½åŠ é¢å¤–æ“ä½œ |

---

## æ€»ç»“

PyTorch Inductorçš„autotuningç³»ç»Ÿæ˜¯ä¸€ä¸ªç²¾å¿ƒè®¾è®¡çš„**åˆ†å±‚æ¶æ„**ï¼š

1. **ä¸¤ä¸ªå±‚çº§ï¼Œä¸€ä¸ªç³»ç»Ÿ**
   - Layer 1: Backendé€‰æ‹© (autotune_select_algorithm)
   - Layer 2: Configä¼˜åŒ– (CachingAutotuner)

2. **Heuristicæ˜¯Configç”Ÿæˆå™¨**
   - Runtime heuristics: ä¸ºcodegen kernelsç”Ÿæˆconfigs
   - Template heuristics: ä¸ºtemplate kernelsç”Ÿæˆconfigs

3. **max_autotuneæ§åˆ¶ä¸¤æ–¹é¢**
   - æ˜¯å¦å¯ç”¨backendé€‰æ‹©
   - ç”Ÿæˆå¤šå°‘configs

4. **EXHAUSTIVEæ˜¯æœç´¢ç©ºé—´å¤§å°**
   - DEFAULT: 20ä¸ªconfigs (å¿«é€Ÿ)
   - EXHAUSTIVE: 1875ä¸ªconfigs (æè‡´)

5. **å®è·µæŒ‡å—**
   - å¼€å‘: å…³é—­autotuningï¼Œå¿«é€Ÿè¿­ä»£
   - è®­ç»ƒ: å¯ç”¨GEMM autotuning
   - æ¨ç†: å…¨å±€autotuning + coordinate descent
   - ç”Ÿäº§: EXHAUSTIVE + å®Œæ•´ä¼˜åŒ–æ ˆ

---

**æ–‡æ¡£ç»´æŠ¤**

å¦‚æœ‰ç–‘é—®æˆ–éœ€è¦æ›´æ–°ï¼Œè¯·è”ç³» PyTorch Inductorå›¢é˜Ÿã€‚

æœ€åæ›´æ–°: 2025-01-10
