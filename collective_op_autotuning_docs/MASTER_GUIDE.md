# Collective Op Autotuning - å®Œæ•´å®æ–½æŒ‡å—

**ç‰ˆæœ¬**: V1 å®ç”¨æ–¹æ¡ˆ
**æ—¥æœŸ**: 2024-11
**çŠ¶æ€**: Ready for Implementation

---

## ğŸ“‹ ç›®å½•

1. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
2. [æ ¸å¿ƒè®¾è®¡](#æ ¸å¿ƒè®¾è®¡)
3. [å®æ–½æ­¥éª¤](#å®æ–½æ­¥éª¤)
4. [V2é¢„ç•™è®¾è®¡](#v2é¢„ç•™è®¾è®¡)
5. [æµ‹è¯•è®¡åˆ’](#æµ‹è¯•è®¡åˆ’)
6. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç›®æ ‡
ä¸ºPyTorch Inductoræ·»åŠ collective operations (all_reduce, all_gatherç­‰) çš„autotuningæ”¯æŒï¼Œç‰¹åˆ«é’ˆå¯¹vLLMç­‰åˆ†å¸ƒå¼åœºæ™¯ã€‚

### V1æ–¹æ¡ˆæ¦‚è¿°
- **å…¼å®¹æ€§ä¼˜å…ˆ**: ä¸ç°æœ‰subgraph/custom opå®Œå…¨å…¼å®¹
- **æœ€å°ä¾µå…¥**: åªä¿®æ”¹custom_op.pyå’Œselect_algorithm.py
- **å®ç”¨å¯¼å‘**: å…ˆè®©åŠŸèƒ½workï¼Œä¸ºV2ç•™å‡ºå¤ç”¨ç©ºé—´
- **å¼€å‘æ—¶é—´**: 1-2å¤©

### æ ¸å¿ƒåˆ›æ–°
1. âœ… **Timeoutä¿æŠ¤**: é˜²æ­¢æŸrank hangå¯¼è‡´ç³»ç»Ÿå¡æ­»
2. âœ… **è·¨rankåŒæ­¥**: Barrier + all_reduceç¡®ä¿å‡†ç¡®benchmark
3. âœ… **ä¿ç•™fusion**: Inline fusionæœºåˆ¶ä¸å˜ï¼Œschedulerå¯ç»§ç»­fuse

---

## ğŸ—ï¸ æ ¸å¿ƒè®¾è®¡

### æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Custom Op Registration                                 â”‚
â”‚  register_custom_op_autotuning(my_allreduce, configs)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Lowering Phase (autotune_custom_op)                   â”‚
â”‚  â”œâ”€ æ£€æµ‹æ˜¯å¦collective op                               â”‚
â”‚  â”œâ”€ æå–process_group                                   â”‚
â”‚  â””â”€ ç”Ÿæˆchoices (SubgraphChoiceCaller)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Autotuning Phase (autotune_select_algorithm)          â”‚
â”‚  â”œâ”€ å¦‚æœis_collective: ä½¿ç”¨CollectiveBenchmarker        â”‚
â”‚  â”‚   â”œâ”€ Pre-sync with timeout (~5ms)                   â”‚
â”‚  â”‚   â”œâ”€ Benchmark each choice with barriers            â”‚
â”‚  â”‚   â””â”€ All-reduce timing (max across ranks)           â”‚
â”‚  â””â”€ å¦åˆ™: ä½¿ç”¨regular benchmarker                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Choice Selection & Inlining                            â”‚
â”‚  â”œâ”€ é€‰æ‹©æœ€ä¼˜choice                                       â”‚
â”‚  â”œâ”€ inline_subgraph_to_ir_nodes() (å¦‚æœæœ‰gm)            â”‚
â”‚  â””â”€ è¿”å›fusable IR nodes                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å…³é”®å†³ç­–

**Q: ä¸ºä»€ä¹ˆä¸ç”¨MultiTemplateBuffer (V2)?**

A: V1ç›®æ ‡æ˜¯**å¿«é€ŸéªŒè¯**å’Œ**å…¼å®¹æ€§**ï¼š
- âœ… ä¿æŒä¸ç°æœ‰custom opæµç¨‹ä¸€è‡´
- âœ… ä¸ä¿®æ”¹scheduler.py (é£é™©ä½)
- âœ… ä¿ç•™inline fusion (schedulerå¯ç»§ç»­fuse epilogue)
- âœ… 1-2å¤©å®Œæˆï¼Œå¿«é€Ÿè¿­ä»£

**Q: V1èƒ½åšfusionå—?**

A: âœ… å¯ä»¥ï¼é€šè¿‡inline fusion:
```python
# Winning choiceçš„subgraphä¼šè¢«inlineæˆIR nodes
my_allreduce(x) â†’ inline â†’ IR nodes (all_reduce_ir + ...)

# åç»­epilogueä»ç„¶å¯ä»¥è¢«scheduler fuse
y = my_allreduce(x)  # IR nodes
z = y + 1            # Schedulerå¯ä»¥fuse: all_reduce + add
```

**é™åˆ¶**: ä¸èƒ½benchmark "æœ‰æ— epilogue"çš„æ€§èƒ½å·®å¼‚ (è¿™æ˜¯V2çš„ä¼˜åŠ¿)

---

## ğŸ”§ å®æ–½æ­¥éª¤

### Step 1: å·²å®Œæˆ âœ…
- `collective_benchmarking.py` (åŒ…å«timeoutæœºåˆ¶)
  - `is_collective_op()` - æ£€æµ‹collective ops
  - `benchmark_collective_op()` - è·¨rank benchmarking
  - `sync_with_timeout()` - é˜²æ­¢hang
  - `CollectiveBenchmarker` - å°è£…ç±»

### Step 2: ä¿®æ”¹ custom_op.py

**æ–‡ä»¶**: `/data/users/tianren/pytorch/torch/_inductor/kernel/custom_op.py`

**ä¿®æ”¹ä½ç½®**: Line 324-332 (autotune_custom_opå‡½æ•°)

```python
def autotune_custom_op(
    name: str,
    decompositions: list[Callable[..., Any]],
    inputs: list[Any],
    non_tensor_args: list[dict[str, Any]],
    op_overload: torch._ops.OpOverload,
    user_input_gen_fns: Optional[...] = None,
) -> Union[TensorBox, Any]:
    # ... existing code ...

    # ============ NEW CODE START ============
    # æ£€æµ‹æ˜¯å¦ä¸ºcollective operation
    is_collective = False
    process_group = None

    if op_overload:
        from torch._inductor.runtime.collective_benchmarking import is_collective_op

        op_name = str(op_overload)
        is_collective = is_collective_op(op_name)

        if is_collective:
            # å°è¯•ä»non_tensor_argsä¸­æå–process_group
            for kwargs_dict in non_tensor_args:
                if 'group' in kwargs_dict:
                    process_group = kwargs_dict['group']
                    break
                elif 'process_group' in kwargs_dict:
                    process_group = kwargs_dict['process_group']
                    break

            # Log collective op detection
            import torch.distributed as dist
            if dist.is_initialized():
                rank = dist.get_rank()
                log.info(
                    f"[Rank {rank}] Detected collective op: {op_name} "
                    f"(process_group={'default' if process_group is None else 'custom'})"
                )
    # ============ NEW CODE END ============

    # ... existing choice generation code ...

    # Line 325: ä¼ é€’collectiveä¿¡æ¯ç»™autotune_select_algorithm
    selected_result, winning_choice = autotune_select_algorithm(
        name=name,
        choices=choices,
        input_nodes=list(inputs),
        layout=choices[0].layout,
        input_gen_fns=input_gen_fns,
        return_choice=True,
        is_collective=is_collective,      # NEW
        process_group=process_group,      # NEW
    )

    # ... existing inline code (ä¸å˜) ...
```

**å…³é”®ç‚¹**:
1. âœ… æ£€æµ‹collective opä½¿ç”¨`is_collective_op()`
2. âœ… ä»kwargsæå–process_group (ä¼˜å…ˆ'group'ï¼Œå…¶æ¬¡'process_group')
3. âœ… ä¼ é€’`is_collective`å’Œ`process_group`ç»™autotuning
4. âœ… **ä¿æŒinlineé€»è¾‘ä¸å˜** (å…¼å®¹ç°æœ‰æœºåˆ¶)

---

### Step 3: ä¿®æ”¹ select_algorithm.py

**æ–‡ä»¶**: `/data/users/tianren/pytorch/torch/_inductor/select_algorithm.py`

#### ä¿®æ”¹3.1: autotune_select_algorithmå‡½æ•°ç­¾å

**ä½ç½®**: Line ~3908

```python
def autotune_select_algorithm(
    name,
    choices,
    input_nodes,
    layout,
    *,
    input_gen_fns=None,
    return_choice=False,
    is_collective=False,      # NEW
    process_group=None,        # NEW
    **kwargs,
):
    """
    Autotune a group of choices and select the best one.

    NEW: Supports collective operations with distributed synchronization.
    """
    cache = get_algorithm_selector_cache()

    if "return_multi_template" not in kwargs:
        kwargs["return_multi_template"] = (
            torch._inductor.config.benchmark_epilogue_fusion
        )

    if "precompilation_timeout_seconds" not in kwargs:
        kwargs["precompilation_timeout_seconds"] = config.precompilation_timeout_seconds

    # ä¼ é€’æ–°å‚æ•°ç»™cache
    return cache(
        name,
        choices,
        input_nodes,
        layout,
        input_gen_fns=input_gen_fns,
        return_choice=return_choice,
        is_collective=is_collective,      # NEW
        process_group=process_group,      # NEW
        **kwargs,
    )
```

#### ä¿®æ”¹3.2: AlgorithmSelectorCache.__call__æ–¹æ³•

**ä½ç½®**: æ‰¾åˆ°`class AlgorithmSelectorCache`çš„`__call__`æ–¹æ³•

```python
class AlgorithmSelectorCache:
    def __call__(
        self,
        name,
        choices,
        input_nodes,
        layout,
        *,
        input_gen_fns=None,
        return_choice=False,
        return_multi_template=False,
        is_collective=False,      # NEW
        process_group=None,        # NEW
        **kwargs,
    ):
        # ... existing cache key generation and lookup ...

        # ============ æ‰¾åˆ°benchmarkä»£ç çš„ä½ç½® ============
        # é€šå¸¸åœ¨cached result missä¹‹åï¼Œéœ€è¦å®é™…benchmark

        # ============ NEW CODE - æ·»åŠ collective benchmarkingåˆ†æ”¯ ============
        if is_collective:
            import torch.distributed as dist

            if not dist.is_initialized():
                log.warning(
                    f"Collective op '{name}' detected but distributed not initialized. "
                    f"Falling back to regular benchmarking."
                )
                is_collective = False
            else:
                # ä½¿ç”¨CollectiveBenchmarker
                from torch._inductor.runtime.collective_benchmarking import (
                    CollectiveBenchmarker,
                )

                rank = dist.get_rank(process_group)
                log.info(
                    f"[Rank {rank}] Using CollectiveBenchmarker for '{name}' "
                    f"with {len(choices)} choices"
                )

                # åˆ›å»ºspecialized benchmarker
                collective_benchmarker = CollectiveBenchmarker(
                    process_group=process_group,
                    nruns=config.benchmark_kernel_nruns,
                    estimate=False,
                )

                # ä½¿ç”¨collective benchmarkingé€»è¾‘
                # æ³¨æ„: è¿™é‡Œéœ€è¦é›†æˆåˆ°ç°æœ‰çš„benchmarkæµç¨‹ä¸­
                # å¯ä»¥é€šè¿‡æ›¿æ¢benchmarkerå®ä¾‹æˆ–è€…æ·»åŠ æ¡ä»¶åˆ†æ”¯

                # TODO: å…·ä½“å®ç°éœ€è¦æŸ¥çœ‹benchmarkä»£ç çš„ç»“æ„
                # å…³é”®æ˜¯åœ¨è°ƒç”¨choice.benchmark()æ—¶ä½¿ç”¨æˆ‘ä»¬çš„CollectiveBenchmarker

        # ... ç»§ç»­ç°æœ‰çš„benchmarkå’Œselectioné€»è¾‘ ...
```

**æ³¨æ„**: è¿™éƒ¨åˆ†éœ€è¦æ ¹æ®å®é™…çš„benchmarkä»£ç ç»“æ„è°ƒæ•´ã€‚å…³é”®æ˜¯åœ¨benchmark choicesæ—¶ï¼Œå¦‚æœ`is_collective=True`ï¼Œä½¿ç”¨`CollectiveBenchmarker`è€Œä¸æ˜¯é»˜è®¤çš„benchmarkerã€‚

---

### Step 4: é›†æˆBenchmarking (å…³é”®)

åœ¨`select_algorithm.py`ä¸­æ‰¾åˆ°å®é™…benchmark choicesçš„ä»£ç ï¼Œé€šå¸¸æ˜¯ï¼š

```python
# æ‰¾åˆ°ç±»ä¼¼è¿™æ ·çš„ä»£ç 
for choice in choices:
    timing = choice.benchmark(*args, out=out)
    timings[choice] = timing
```

**ä¿®æ”¹ä¸º**:

```python
# å¦‚æœæ˜¯collective opï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
if is_collective:
    from torch._inductor.runtime.collective_benchmarking import (
        try_collective_benchmark_with_timeout,
    )

    for choice in choices:
        # ä½¿ç”¨specialized collective benchmarking
        # æ³¨æ„: è¿™é‡Œéœ€è¦é€‚é…choice.benchmarkçš„æ¥å£

        # å°è¯•benchmark with timeout
        timing = try_collective_benchmark_with_timeout(
            comm_func=choice.kernel if hasattr(choice, 'kernel') else choice,
            comm_func_name=choice.name,
            input_tensors=prepared_inputs,
            output_tensor=prepared_output,
            process_group=process_group,
            nruns=config.benchmark_kernel_nruns,
            timeout_seconds=30.0,
        )

        if timing is not None:
            timings[choice] = timing
        else:
            # Timeout or failure
            log.warning(
                f"[Collective] Choice {choice.name} timed out, using inf"
            )
            timings[choice] = float('inf')
else:
    # ç°æœ‰çš„regular benchmarking
    for choice in choices:
        timing = choice.benchmark(*args, out=out)
        timings[choice] = timing
```

---

## ğŸ”„ V2é¢„ç•™è®¾è®¡ (å¯å¤ç”¨éƒ¨åˆ†)

### å®Œå…¨å¯å¤ç”¨çš„ç»„ä»¶

1. âœ… **collective_benchmarking.py** - 100%å¤ç”¨
   - `is_collective_op()` - V2ä¹Ÿéœ€è¦æ£€æµ‹
   - `benchmark_collective_op()` - V2çš„æ ¸å¿ƒbenchmarkå‡½æ•°
   - `sync_with_timeout()` - V2çš„pre-syncä¼šç”¨
   - `CollectiveBenchmarker` - V2ä¹Ÿç”¨è¿™ä¸ªç±»

2. âœ… **custom_op.pyä¸­çš„detectioné€»è¾‘** - éƒ¨åˆ†å¤ç”¨
   - V2ä»ç„¶éœ€è¦æ£€æµ‹æ˜¯å¦collective
   - V2ä»ç„¶éœ€è¦æå–process_group
   - **åŒºåˆ«**: V2ä¼šè®¾ç½®`return_multi_template=True`

3. âœ… **Timeoutæœºåˆ¶** - 100%å¤ç”¨
   - V2çš„pre-syncå’Œbenchmarkéƒ½éœ€è¦timeoutä¿æŠ¤

### V2éœ€è¦æ–°å¢çš„éƒ¨åˆ†

1. ğŸ†• **CollectiveMultiTemplateBufferç±»** (ir.py)
   - ç»§æ‰¿è‡ªMultiTemplateBuffer
   - åŒ…å«process_groupå’Œcollective_op_type

2. ğŸ†• **Schedulerçš„unified sync** (scheduler.py)
   - `collect_collective_nodes()` - æ”¶é›†æ‰€æœ‰collective nodes
   - `try_sync_collective_nodes()` - ç»Ÿä¸€pre-sync
   - `_finalize_collective_choice()` - Specialized finalize

3. ğŸ†• **select_algorithm.pyçš„MultiTemplateBufferåˆ›å»º**
   - å½“`return_multi_template=True`ä¸”`is_collective=True`æ—¶
   - åˆ›å»ºCollectiveMultiTemplateBufferè€Œä¸æ˜¯æ™®é€šMultiTemplateBuffer

### V1åˆ°V2çš„å‡çº§è·¯å¾„

```python
# V1 (å½“å‰å®æ–½)
custom_op.py:
  is_collective = detect_collective()
  autotune_select_algorithm(..., is_collective=is_collective)

select_algorithm.py:
  if is_collective:
    use CollectiveBenchmarker  # â† V2å¯ä»¥å¤ç”¨
  benchmark and select winner
  return winning_result

custom_op.py:
  inline_subgraph_to_ir_nodes()
  return IR nodes

# V2 (æœªæ¥å‡çº§)
custom_op.py:
  is_collective = detect_collective()  # â† å¤ç”¨V1çš„æ£€æµ‹é€»è¾‘
  autotune_select_algorithm(...,
                           is_collective=is_collective,
                           return_multi_template=True)  # â† æ–°å¢

select_algorithm.py:
  if return_multi_template and is_collective:
    return CollectiveMultiTemplateBuffer(...)  # â† å»¶è¿Ÿbenchmark
  # ä¸ç«‹å³benchmark

scheduler.py:
  unified_sync()  # â† æ–°å¢: ç»Ÿä¸€åŒæ­¥
  for each CollectiveMultiTemplateBuffer:
    use CollectiveBenchmarker  # â† å¤ç”¨V1çš„benchmarker
    finalize_choice()
```

**å…³é”®**: `CollectiveBenchmarker`åœ¨V1å’ŒV2ä¸­éƒ½ç”¨ï¼Œæ˜¯100%å¯å¤ç”¨çš„æ ¸å¿ƒç»„ä»¶ã€‚

---

## ğŸ§ª æµ‹è¯•è®¡åˆ’

### Phase 1: å•ä¸ªCollective Op, 2 Ranks

**ç›®æ ‡**: éªŒè¯åŸºç¡€åŠŸèƒ½

**æµ‹è¯•ä»£ç **:
```python
# test/inductor/test_collective_autotuning.py

import torch
import torch.distributed as dist
from torch.testing._internal.common_distributed import (
    MultiProcessTestCase,
    skip_if_lt_x_gpu,
)

class TestCollectiveAutotuning(MultiProcessTestCase):

    @skip_if_lt_x_gpu(2)
    def test_single_allreduce_2ranks(self):
        """Test single all_reduce with 2 ranks"""

        # Initialize distributed
        dist.init_process_group(backend='nccl')
        rank = dist.get_rank()

        # Define custom collective op
        @torch.library.custom_op("test::my_allreduce", mutates_args=())
        def my_allreduce(x: torch.Tensor) -> torch.Tensor:
            return torch.ops._c10d_functional.all_reduce_(x, "sum")

        # Implementation 1: Direct NCCL
        def allreduce_nccl(x):
            return torch.ops._c10d_functional.all_reduce_(x, "sum")

        # Implementation 2: Simulate chunked (for testing)
        def allreduce_chunked(x, chunk_size=1024):
            return torch.ops._c10d_functional.all_reduce_(x, "sum")

        # Register autotuning
        from torch._inductor.kernel.custom_op import (
            register_custom_op_autotuning,
            CustomOpConfig,
        )

        register_custom_op_autotuning(
            my_allreduce,
            configs=[
                CustomOpConfig(allreduce_nccl),
                CustomOpConfig(allreduce_chunked, chunk_size=1024),
            ],
        )

        # Test model
        class SimpleModel(torch.nn.Module):
            def forward(self, x):
                return my_allreduce(x)

        model = torch.compile(SimpleModel())

        # Run
        x = torch.randn(128, 128, device=f'cuda:{rank}')
        y = model(x)

        # Verify
        expected = x * 2  # sum across 2 ranks
        torch.testing.assert_close(y, expected)

        if rank == 0:
            print("âœ… Single allreduce test passed!")

        dist.destroy_process_group()
```

**éªŒè¯ç‚¹**:
- âœ… èƒ½æ£€æµ‹åˆ°collective op
- âœ… Timeoutæœºåˆ¶ä¸è§¦å‘ (æ­£å¸¸å®Œæˆ)
- âœ… 2 ranksåŒæ­¥æ­£å¸¸
- âœ… Benchmarkç»“æœåˆç†
- âœ… é€‰æ‹©çš„å®ç°èƒ½æ­£ç¡®è¿è¡Œ

---

### Phase 2: å¤šä¸ªCollective Ops, 2 Ranks

**ç›®æ ‡**: éªŒè¯å¤šä¸ªopsçš„sync overhead

**æµ‹è¯•ä»£ç **:
```python
@skip_if_lt_x_gpu(2)
def test_multiple_collectives_2ranks(self):
    """Test 3 collective ops with 2 ranks"""

    dist.init_process_group(backend='nccl')
    rank = dist.get_rank()

    # Define 3 different collective ops
    # ... (æ³¨å†Œmy_allreduce, my_allgather, my_reduce_scatter)

    # Test model with multiple collective ops
    class MultiCollectiveModel(torch.nn.Module):
        def forward(self, x):
            y1 = my_allreduce(x)          # Collective 1
            y2 = my_allgather(y1)         # Collective 2
            y3 = my_reduce_scatter(y2)    # Collective 3
            return y3

    model = torch.compile(MultiCollectiveModel())

    # Measure compilation time
    import time
    start = time.time()
    x = torch.randn(128, 128, device=f'cuda:{rank}')
    y = model(x)
    compile_time = time.time() - start

    if rank == 0:
        print(f"âœ… Multiple collectives test passed!")
        print(f"   Compilation time: {compile_time:.2f}s")
        print(f"   Expected: 3 ops Ã— ~50ms sync = ~150ms overhead")

    dist.destroy_process_group()
```

**éªŒè¯ç‚¹**:
- âœ… 3ä¸ªcollective opséƒ½èƒ½æ­£ç¡®autotune
- âœ… ç¼–è¯‘æ—¶é—´åˆç† (~150ms sync overhead for V1)
- âœ… ç»“æœæ­£ç¡®æ€§
- âš ï¸ æ³¨æ„è§‚å¯Ÿsync overhead (ä¸ºV2æä¾›æ•°æ®æ”¯æŒ)

---

### Phase 3: æ›´å¤šOps, æ›´å¤šRanks

**ç›®æ ‡**: å‹åŠ›æµ‹è¯•å’ŒscalabilityéªŒè¯

**æµ‹è¯•ä»£ç **:
```python
@skip_if_lt_x_gpu(4)
def test_scalability_4ranks(self):
    """Test 5 collective ops with 4 ranks"""

    dist.init_process_group(backend='nccl')
    rank = dist.get_rank()
    world_size = dist.get_world_size()

    # 5ä¸ªcollective ops
    class LargeCollectiveModel(torch.nn.Module):
        def forward(self, x):
            y1 = my_allreduce(x)
            y2 = my_allreduce(y1)
            y3 = my_allgather(y2)
            y4 = my_reduce_scatter(y3)
            y5 = my_allreduce(y4)
            return y5

    model = torch.compile(LargeCollectiveModel())

    # Measure
    import time
    start = time.time()
    x = torch.randn(256, 256, device=f'cuda:{rank}')
    y = model(x)
    compile_time = time.time() - start

    if rank == 0:
        print(f"âœ… Scalability test (4 ranks, 5 ops) passed!")
        print(f"   Compilation time: {compile_time:.2f}s")
        print(f"   Expected V1: 5 ops Ã— ~50ms = ~250ms overhead")
        print(f"   Expected V2: 1 Ã— 5ms = ~5ms overhead (potential savings)")

    dist.destroy_process_group()
```

**éªŒè¯ç‚¹**:
- âœ… 4 ranksèƒ½æ­£å¸¸åŒæ­¥
- âœ… 5ä¸ªopséƒ½èƒ½autotune
- âœ… ç»“æœæ­£ç¡®æ€§
- ğŸ“Š **å…³é”®æ•°æ®**: å¦‚æœsync overhead > 200msï¼ŒV2æœ‰æ˜æ˜¾ä»·å€¼

---

### Phase 4: Timeoutæµ‹è¯•

**ç›®æ ‡**: éªŒè¯timeoutä¿æŠ¤æœºåˆ¶

**æµ‹è¯•ä»£ç **:
```python
@skip_if_lt_x_gpu(2)
def test_timeout_protection(self):
    """Test that timeout mechanism prevents hang"""

    dist.init_process_group(backend='nccl')
    rank = dist.get_rank()

    # æ¨¡æ‹Ÿ: rank 1 sleepï¼Œrank 0 æ­£å¸¸
    if rank == 1:
        import time
        time.sleep(10)  # Simulate hang

    # æ³¨å†Œä¸€ä¸ªä¼štimeoutçš„å®ç°
    # ... register with short timeout ...

    model = torch.compile(SimpleModel())

    # Should NOT hang, should timeout gracefully
    try:
        x = torch.randn(128, 128, device=f'cuda:{rank}')
        y = model(x)

        if rank == 0:
            print("âœ… Timeout protection worked! Did not hang.")
    except Exception as e:
        if rank == 0:
            print(f"âš ï¸ Expected timeout exception: {e}")

    dist.destroy_process_group()
```

**éªŒè¯ç‚¹**:
- âœ… ä¸ä¼šindefinitely hang
- âœ… Timeoutåèƒ½fallback
- âœ… æœ‰æ¸…æ™°çš„warning/error message

---

### æµ‹è¯•è¿è¡Œå‘½ä»¤

```bash
# 2 ranks
torchrun --nproc_per_node=2 -m pytest test/inductor/test_collective_autotuning.py::TestCollectiveAutotuning::test_single_allreduce_2ranks -v

# 4 ranks
torchrun --nproc_per_node=4 -m pytest test/inductor/test_collective_autotuning.py::TestCollectiveAutotuning::test_scalability_4ranks -v
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: V1å’Œç°æœ‰custom opæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ

**A**: V1å®Œå…¨å…¼å®¹ç°æœ‰æœºåˆ¶ï¼Œåªæ˜¯åœ¨collective opåœºæ™¯ä¸‹ï¼š
- ä½¿ç”¨`CollectiveBenchmarker`æ›¿ä»£regular benchmarker
- æ·»åŠ äº†timeoutä¿æŠ¤
- è·¨rankåŒæ­¥benchmark
- å…¶ä»–æµç¨‹(inline fusionç­‰)å®Œå…¨ä¸å˜

### Q2: V1ä¼šå½±å“non-collective opså—ï¼Ÿ

**A**: ä¸ä¼šã€‚æ£€æµ‹é€»è¾‘åªåœ¨`is_collective=True`æ—¶è§¦å‘ï¼Œå…¶ä»–opsèµ°åŸæœ‰è·¯å¾„ã€‚

### Q3: å¦‚æœdistributedæ²¡æœ‰initializedæ€ä¹ˆåŠï¼Ÿ

**A**: è‡ªåŠ¨fallbackåˆ°regular benchmarkingï¼Œå¹¶æ‰“å°warningã€‚

### Q4: V1çš„æ€§èƒ½overheadæ˜¯å¤šå°‘ï¼Ÿ

**A**:
- å•ä¸ªcollective op: ~50ms (å’Œregular autotuningç±»ä¼¼)
- Nä¸ªcollective ops: N Ã— 50ms (æ¯ä¸ªopå•ç‹¬sync)
- V2å¯ä»¥ä¼˜åŒ–åˆ°: 5ms + N Ã— benchmark_time

### Q5: ä»€ä¹ˆæ—¶å€™åº”è¯¥å‡çº§åˆ°V2ï¼Ÿ

**A**: å½“æ»¡è¶³ä»¥ä¸‹ä»»ä¸€æ¡ä»¶ï¼š
- æœ‰3+ä¸ªcollective ops (sync overhead > 150ms)
- éœ€è¦benchmark epilogue fusionçš„æ€§èƒ½
- V1ç¨³å®šè¿è¡Œåï¼Œæœ‰å¼€å‘æ—¶é—´

---

## ğŸ“ æ–‡ä»¶æ¸…å•

### å·²å®ç°
- âœ… `torch/_inductor/runtime/collective_benchmarking.py` (å®Œæ•´å®ç°)

### å¾…ä¿®æ”¹
- ğŸ”² `torch/_inductor/kernel/custom_op.py` (æ·»åŠ detection)
- ğŸ”² `torch/_inductor/select_algorithm.py` (é›†æˆCollectiveBenchmarker)

### å¾…åˆ›å»º
- ğŸ”² `test/inductor/test_collective_autotuning.py` (æµ‹è¯•)

### æ–‡æ¡£
- âœ… æœ¬æ–‡æ¡£ (MASTER_GUIDE.md)
- âœ… collective_benchmarking.pyçš„docstrings

---

## ğŸ¯ å®æ–½Checklist

### Week 1: æ ¸å¿ƒå®ç°
- [ ] ä¿®æ”¹custom_op.pyæ·»åŠ detectioné€»è¾‘
- [ ] ä¿®æ”¹select_algorithm.pyé›†æˆCollectiveBenchmarker
- [ ] ç¼–å†™Phase 1æµ‹è¯• (å•ä¸ªop, 2 ranks)
- [ ] éªŒè¯åŸºç¡€åŠŸèƒ½

### Week 2: å®Œå–„å’Œæµ‹è¯•
- [ ] ç¼–å†™Phase 2æµ‹è¯• (å¤šä¸ªops, 2 ranks)
- [ ] ç¼–å†™Phase 3æµ‹è¯• (æ›´å¤šops, æ›´å¤šranks)
- [ ] ç¼–å†™Phase 4æµ‹è¯• (timeout)
- [ ] æ€§èƒ½æ•°æ®æ”¶é›†
- [ ] å†³å®šæ˜¯å¦éœ€è¦V2

### Week 3+: V2å®æ–½ (å¯é€‰)
- [ ] åˆ›å»ºCollectiveMultiTemplateBufferç±»
- [ ] ä¿®æ”¹scheduler.pyæ·»åŠ unified sync
- [ ] å®Œæ•´æµ‹è¯•å’Œä¼˜åŒ–
- [ ] æ–‡æ¡£æ›´æ–°

---

## ğŸ“Š æˆåŠŸæŒ‡æ ‡

### V1æˆåŠŸæ ‡å‡†
1. âœ… èƒ½æ­£ç¡®autotune custom collective ops
2. âœ… Timeoutæœºåˆ¶æœ‰æ•ˆï¼Œä¸ä¼šhang
3. âœ… 2-4 ranksæµ‹è¯•é€šè¿‡
4. âœ… ç»“æœæ­£ç¡®æ€§éªŒè¯é€šè¿‡
5. âœ… ç¼–è¯‘æ—¶é—´åœ¨é¢„æœŸèŒƒå›´å†…

### æ€§èƒ½ç›®æ ‡
- å•ä¸ªcollective op: < 100ms autotuning overhead
- å¤šä¸ªcollective ops: å¯ä»¥æ¥å—çº¿æ€§å¢é•¿ (V1é™åˆ¶)
- æ— hangæˆ–crash

### ä¸ºV2åšå‡†å¤‡
- æ”¶é›†sync overheadæ•°æ®
- ç¡®è®¤å¯å¤ç”¨ç»„ä»¶
- éªŒè¯è®¾è®¡æ–¹å‘

---

## ğŸš€ å¼€å§‹å®æ–½

**æ¨èæµç¨‹**:
1. é˜…è¯»æœ¬æ–‡æ¡£
2. æŸ¥çœ‹`collective_benchmarking.py`äº†è§£API
3. ä¿®æ”¹`custom_op.py` (Step 2)
4. ä¿®æ”¹`select_algorithm.py` (Step 3-4)
5. ç¼–å†™Phase 1æµ‹è¯•
6. è¿­ä»£ä¼˜åŒ–

**è”ç³»æ–¹å¼**:
- Owner: PyTorch Inductor Team
- Module: `torch._inductor`

---

**Let's build it!** ğŸ‰
