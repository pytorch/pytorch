bc1b1e8253,nn,bug_fixes,fixing mkldnn_linear & backward with silent error (#51713)
c034e0750c,mobile,Untopiced,"[QNNPACK, Sparsity] Code refactoring to allow for more generic block (#51118)"
6b2811f288,mobile,Untopiced,"[QNNPACK, Sparsity] Add 8x1 block sparse kernels for aarch32. (#51119)"
19753af6ea,mobile,Untopiced,[QNNPACK Sparsity] Add aarch64 kernel of 8x1 sparsity (#51120)
215d9daceb,fx,Untopiced,Refactor internal methods into debugging utilities (#51737)
9a964ce89b,jit,Untopiced,Enables backend preprocessing to take place outside of the backend interface (#51757)
8a9090219e,jit,Untopiced,[pyper] register aten::index_out (#51742)
fa70168804,jit,Untopiced,Add metacompile of Ternary if (#51789)
6488b2bc3a,skip,Untopiced,Revert D26282829: [pytorch][PR] Adding support for CUDA 11.2 in our nightly build matrix
4968227058,caffe2,Untopiced,add shape inference for Int8GenQuantParamsMinMax
0c313564af,sparse_frontend,Untopiced,Backward through sparse_coo_tensor (#50361)
bce4c82f0d,caffe2,Untopiced,[C2] Add TypeAndShape Inference logic for ReduceMean (#51828)
79832f3d77,skip,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
c89f15ec6d,skip,Untopiced,Reland nightlies 11.2 (#51874)
7467f90b13,skip,Untopiced,Report test time regressions (#50171)
d454a84bab,autograd_frontend,Untopiced,derivatives.yaml cleanup + restore codegen code forgotten in refactor (#51721)
b97a040f71,python_frontend,devs,ENH: toggle TORCH_WARN_ONCE to TORCH_WARN for tests (#48560)
0dd1d60d54,jit,Untopiced,[JIT] Remove Dropout during Frozon Optimization (#51589)
649e683255,python_frontend,Untopiced,Fix torch.nonzero type annotation (#51635)
1aaddd83a5,build_frontend,devs,don't set the same C++ and C standards twice (#51832)
21dccbca62,skip,Untopiced,Revert D26232345: [pytorch][PR] Report test time regressions
d9e6750759,cuda,Untopiced,fix multi_output_kernel (#51827)
6fa5e96f2e,composability,Untopiced,remove unnecessary BoxedKernelWrapper specialization now that ops are all c10-full (#50963)
41bab9a4b6,composability,Untopiced,Plumbing dispatch keys through the dispatcher (#49354)
b9acfcddeb,jit,Untopiced,Support mypy ignore annotation with particular rule specified (#51675)
d90911adf9,nn_frontend,Untopiced,fix AdaptiveAveragePooling crash problem for non support input (#51443)
159c48b19b,nn_frontend,Untopiced,Fix triplet margin loss and reciprocal docs (#51650)
97e35858ec,distributed,Untopiced,[Resubmit] Add compare_set operation and test to TCPStore (#51815)
58eb23378f,python_frontend,devs,Clean up usage of torch._six partially (#49785)
1e70b4bb73,releng,Untopiced,Add GH Actions CI to build nightly Docker and push to GitHub Container Registry (#51755)
9e4f3b89c4,distributed,Untopiced,[Gradient Compression] Add register_comm_hook API to DDP communication hooks documentation page (#51846)
21ef248fb8,releng,Untopiced,[reland] Report test time regressions (#50171)
dac730af11,releng,Untopiced,Warn if mypy version doesn't match CI (#51799)
7b9ca54ecf,autograd_frontend,Untopiced,Reset checkpoint_valid flag when error happens during function execution (#51746)
2303c244fc,composability,Untopiced,skip a second call to shouldUseRecordFunction for BackendSelect ops (#50891)
034a007ad8,composability,Untopiced,Remind about AutoNonVariableTypeMode in error message. (#51655)
8ab22a080b,mobile,Untopiced,Build pytorch_android using Gradle wrapper. (#51067)
482b94ae51,dataloader_frontend,Untopiced,move RoutedDecoder Dataset to DataPipe (#51704)
015cabf82a,dataloader_frontend,Untopiced,move GroupByFilename Dataset to DataPipe (#51709)
d5a2429c24,autograd_frontend,Untopiced,Fix flake8 failures (#51963)
d61d8d886b,skip,Untopiced,correct value argument name for Tensor.index_fill_ docs (#51763)
35b3e16091,nn_frontend,Untopiced,[pytorch] Fix torch.nn.functional.normalize to be properly scriptable (#51909)
42635c3e59,python_frontend,devs,Fix regex in collect_env.py for CUDA 11 (#51852)
285e69a9cd,package,Untopiced,[package] more reliable method for determining standard library-ness (#51694)
85b25257ff,package,Untopiced,[package] Use custom persistent_load in PackageImporter (#51595)
c357f8b826,package,Untopiced,[package] make torch.package produce unified format (#51826)
20fe2e12d6,skip,Untopiced,typo (#48887)
8c09cc6475,releng,Untopiced,Remove android toolchain in Windows CircleCI image (#51405)
5dd1568aa3,amd,Untopiced,[ROCm] skip more magma tests (#51915)
b3fda95fe7,nn_frontend,Untopiced,Add LazyBatchNormXd (#51862)
141f615161,jit,Untopiced,Support torch.type (#51904)
1e171f024b,python_frontend,Untopiced,Fix warnings in TensorShape (#51642)
fc314350ad,caffe2,Untopiced,Make RebatchingBuffer compatible with auto shape inference
0ec00c1292,quantization,Untopiced,[docs] Add docs for storage and tensors for quantized Tensor (#51817)
8fab33f942,cpp_frontend,Untopiced,Fix the lifetime of PyTensorType (#51649)
2f2b170068,mobile,Untopiced,[Pytorch Mobile] Only preserve bundled input helpers for forward if they exist (#51884)
0410cba23e,fx,Untopiced,[FX] make map_arg require a callable (#51907)
7e54a64828,caffe2,Untopiced,[C2] Add shape inference logic for ColwiseMax operator. (#51914)
12d85b536e,jit,Untopiced,Fixing Softmax bench. (#51898)
e964d77fca,jit,Untopiced,[pytorch] recast infer_type error and amend with name and item that failed inferring
104371e1dc,dataloader_frontend,Untopiced,[DataLoader] Implement FilterIterDataPipe (#51783)
9eb70c3c78,dataloader_frontend,Untopiced,[DataLoader] Rename Callable to Map IterDataPipe (#51879)
1921b244f6,dataloader_frontend,Untopiced,[DataLoader] Rename files of functional datapipes (#51880)
c6b4fc8a90,releng,Untopiced,[ROCm] add 4.0.1 docker image (#51507)
3af7b673ef,cuda,Untopiced,Let child CUDAFuture wait for parent CUDAFuture's CUDAEvents (#51820)
475278f1c0,fx,Untopiced,[FX] Make some modifications to limitation section (#51928)
d5a9627f10,composability,Untopiced,[PyTorch] Re-order TensorImpl fields to save a word (#50920)
d4e84b0c07,fx,Untopiced,[FX] Fix leaf modules in Transformer (#51998)
256f93fb0f,fx,Untopiced,[FX][EZ] Fix tuple type annotations (#52010)
d23cb94098,fx,Untopiced,[FX] Generalize dict key check in `create-arg` (#51927)
18e0a61388,distributed,Untopiced,add more logging fields that can be set in construction time (#51260)
5a9bac58be,skip,Untopiced,Automated submodule update: FBGEMM (#52014)
929b91a24d,quantization,Untopiced,ns_eager: rename Logger I/O var names to logger_cls (#51359)
768662913a,cuda,Untopiced,Migrate masked_fill__cuda to ATen (#51404)
5f9fb93c14,caffe2,Untopiced,[model loading] Add max_batch_size override for batch size exploration
0620c96fd6,distributed,Untopiced,"Back out ""Revert D26009829: Optimize relu on cpu using clamp_min"" (#51819)"
74082f0d6f,jit,Untopiced,[te][llvm] Generate arithmetic vs logical right shift as appropriate (#51749)
ff73be7e45,jit,Untopiced,[te] Introduce likely/unlikely CompareSelect hint (#51751)
2e35fe9535,jit,Untopiced,[te] Implement log approximation using the VML approach (#51752)
602434bcbe,jit,Untopiced,[te] Benchmark vml-based logit (#51771)
9c0caf0384,jit,Untopiced,Adding support for comparing two bool varibales (#51844)
594a66d778,python_frontend,Untopiced,Warn about floor_divide performing incorrect rounding (#50281) (#50281)
3cf78395cb,skip,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
8b0cb5ede3,python_frontend,Untopiced,OpInfo: Added clamp and trunc tests with aliases (#51167)
c1b7ca8062,skip,Untopiced,Early terminate CUDA on common_utils TestCases (#50914)
50e6f0fdb6,nn_frontend,Untopiced,Add benchmark for torch.nn.functional.interpolate
c4a8f0ceaa,jit,Untopiced,[torch script] Add pure list producing ops to alias analysis (#51999)
03e82f7944,releng,Untopiced,Use CUDA 11.2 for nightly docker build. (#51990)
b7b944a319,distributed,Untopiced,Avoid TensorPipe agent spamming logs when unable to guess IP address (#51784)
a1c67b0763,distributed,Untopiced,Silence harmless error logs of TensorPipe agent during shutdown (#51785)
ce8ba5f3bc,releng,Untopiced,Fix test time history report if no ancestor report (#52054)
bd6248106b,jit,Untopiced,Keep alive graph when creating iterators from it (#51951)
9b8d414a9c,releng,Untopiced,update sccache wrapper to accommodate new sccache for macos build (#51357)
a1b8f3d4b6,releng,Untopiced,Replace CUDA 11.1 Linux CI with CUDA 11.2 (#51905)
d0fd41dcfe,mobile,Untopiced,Add size op in nnapi serializer (#52026)
9f1f5636d7,skip,Untopiced,Revert D26019289: [pytorch][PR] Early terminate CUDA on common_utils TestCases
410ef1335a,jit,Untopiced,[JIT] Add buffer/parameter metadata test to test_save_load.py (#49594)
5431d87c3e,jit,Untopiced,[JIT] Use `is_buffer` in `BufferPolicy::valid` (#49588)
bff8194522,releng,Untopiced,Replace 11.1 with 11.2 on CI for Windows (#51598)
fa325d7c9f,python_frontend,devs,Use `sum_integers` and `multiply_integers` (#51146)
4add8502c3,composability,Untopiced,inlining a function that i noticed were hot during previous benchmarking (#50848)
705fa7e964,jit,Untopiced,[Usability] Capture argument names for traced functions and modules (#51775)
de334e6a2f,complex_frontend,Untopiced,fast-path is_complex() in the dispatcher (#50054)
d7ea0fe75a,python_frontend,devs,[testing] Add OpInfo for rad2deg and deg2rad (#51283)
faaff0cd9b,caffe2,Untopiced,[caffe2 and pytorch] use new sparse adagrad JIT'ed function in fbgemm
9653161fb4,releng,Untopiced,bump nightlies to 1.9.0 (#51891)
39aa3db62b,caffe2,Untopiced,use make_shared and make_unique and clean unneeded code (#51829)
4ab0ef36a4,quantization,Untopiced,change back to multiple_outputs_gpu_kernel for learnable fake per-channel quantization (#52017)
fd41ed1cce,distributed,Untopiced,Fix flaky TestTrainingLoop - TestE2ETensorPipe (#51939)
bc856b49d4,fx,Untopiced,Add support for constants to fx_glow (#52094)
7763c127cd,jit,Untopiced,[PyTorch] move aten::dict to lite interpreter (#52032)
fb2693a632,python_frontend,devs,Use bool/float instead of np.bool/np.float (#52103)
0de7a4582e,releng,Untopiced,Fix Pytorch docker image name by adding the registry prefix (#52089)
aa2fede201,autograd_frontend,Untopiced,Fix autograd when `inputs` contains tensors without materialized grad_fn (#51940)
425a5dc3f7,dataloader_frontend,Untopiced,[DataLoader] Modify SamplerIDP signature (#52104)
10d407647f,composability,Untopiced,[PyTorch] Reduce template expansion in call_functor_with_args_from_stack (#51313)
c931c29120,composability,Untopiced,[PyTorch][easy] Fix TODOs in CppFunction constructors (#51315)
c4eb22009e,caffe2,Untopiced,Drop some Python 2 compatibility code (#51769)
81b9aa743b,caffe2,Untopiced,[pytorch] Update caffe2/python to eliminate Pyre errors (#52083)
0bc7b9843b,releng,Untopiced,use sccache 2.15 over the outdated sccache (#52095)
497b772547,complex_frontend,Untopiced,Add custom implementation for `csqrt` if libc++ is used (#52018)
517185f946,caffe2,Untopiced,test_lc_1d: Increase deadline to 5 seconds (#52013)
b6806308ac,distributed,Untopiced,typo in docs ddp_comm_hooks.rst (#51986)
76c6e12a5c,skip,Untopiced,Minor spelling updates (#52149)
4c93a79a04,distributed,Untopiced,[Dist Profiling] Support shape recording for profiling collectives (#51822)
ea8aadf4b6,releng,Untopiced,Use self-hosted runner for nightly docker build CI. (#52148)
8908874003,jit,Untopiced,Gh/taylorrobie/import timer fbcode (#52124)
deb74edb28,releng,Untopiced,Add script to display history for a single test across multiple jobs over time (#52000)
4c58be4573,jit,Untopiced,[StaticRuntime] Clean up input references (#51952)
70a805a286,amd,Untopiced,[ROCm] skip one more magma test that is flaky (#52064)
6385c13630,vulkan,Untopiced,[vulkan] Efficient gemm implementation (#49609)
ac2bdf553e,releng,Untopiced,update build_host_protoc command for macos cross compilation (#50922)
22b12179db,composability,Untopiced,[PyTorch] Make TORCH_INTERNAL_ASSERT use torchCheckFail too (#52086)
ba7a2f6513,releng,Untopiced,Add debug helper function to check target property (#52093)
578f0a04c7,nn_frontend,Untopiced,fix torch.nn.parallel.scatter_gather.gather to handle NamedTuples and handle moving output to CPU (#51104)
dc25c90cfc,caffe2,Untopiced,Check kernel launches in caffe2/aten/src/THCUNN (#52172)
db6e0c7c0e,caffe2,Untopiced,Replace a platform.system() check with sys.platform (#51766)
e4203c4306,skip,Untopiced,Automated submodule update: FBGEMM (#52129)
0c9d72b5e1,jit,Untopiced,[StaticRuntime] Clean up output references and remove dead code (#51991)
992d251c39,skip,Untopiced,Revert D26333953: [StaticRuntime] Clean up output references and remove dead code
d22f700f9e,caffe2,Untopiced,Link torch_global_deps to libtbb.so if USE_TBB is enabled (#51741)
e8ab58bfc7,cuda,Untopiced,[reland] Early terminate CUDA on common_utils TestCases (#52126)
1795398c24,python_frontend,Untopiced,"Updates rounding_mode documentation to remove ""true"" (#52202)"
de54510f15,caffe2,Untopiced,Check kernel launches in caffe2/caffe2/image (#52173)
05b60921ae,mobile,Untopiced,[iOS][PyTorch][OSS] fix iOS nightly build (#52197)
fa0a049d4e,caffe2,Untopiced,Add a make_tempdir() utility function to the TestCase base class (#51762)
0dc0cb1d8d,caffe2,Untopiced,Enable FP16 sparse regularizer
49c8be516e,releng,Untopiced,Add ARM64 cross-compilation build on OS X (#49751)
7b21c6be67,distributed,Untopiced,[Dist Profiling] Enable profiling for gloo send/recv (#52004)
a8321855ad,caffe2,Untopiced,Check kernel launches in caffe2/aten/src/THC (#52174)
b2d8f0a431,mobile,Untopiced,[pytorch][bot] update mobile op deps (#52110)
2900cf2b94,autograd_frontend,Untopiced,Refactor autograd discovery code (#52057)
bfe6e23209,fx,Untopiced,Early version of fx graph matcher for NS (#51588)
37622db76a,fx,Untopiced,"ns for fx - stubs of the three APIs (compare weights, activations, activations with shadow) (#51669)"
1657d59641,jit,Untopiced,Walk Python AST to check for unsupported attribute type annotations (#51805)
4cc10563e7,fx,Untopiced,Customize traceback for calls to symbolically-traced code (#51648)
388c38505c,mobile,Untopiced,[Metal] Add concat op for metal
71d0b5632b,mobile,Untopiced,Add SqueezeNet to PyTorch Playground
4ab86c87a2,caffe2,Untopiced,[caffe2 and pytorch] replace temp name of new sparse adagrad JIT'ed function in fbgemm (#52193)
a184ef8df5,skip,Untopiced,[TorchScript] C++ interface of to_<backend> (#51797)
96fd5d87f7,jit,Untopiced,Add `dict()` constructor (#51934)
87c0b6bffc,distributed,Untopiced,[RPC] Move confirmation future in rref context to jit future (#51695)
8ff5a46c32,distributed,Untopiced,[RPC] waitForThreadLocalRRefs returns jitFuture (#51696)
846755af2f,skip,Untopiced,Remove unused include in TensorIteratorDynamicCasting.h (#51824)
490eb3e735,nn_frontend,Untopiced,Add 3D depthwise seperable convolution (#51027)
52e6ef8b53,jit,Untopiced,[TensorExpr] Add another test for ExternalCalls. (#52162)
b8f3a658f9,jit,Untopiced,"Do not include ""DynamicLibrary.h"" into a top-level header (#52182)"
357e5baf7e,releng,Untopiced,Extend DynamcLibrary constructor to support alternative library name (#52183)
73de98204d,jit,Untopiced,[JIT] Add static method support for TorchBind (#51177)
4949eea0ff,composability,Untopiced,[StaticRuntime] Clean up output references and remove dead code (#52237)
eaddadd4f7,skip,Untopiced,"Revert D26403094: ns for fx - stubs of the three APIs (compare weights, activations, activations with shadow)"
1903b32c35,caffe2,Untopiced,Directly Return when Numel == 0 for WeightedSum and ScatterWeightedSum
cd46ee6175,skip,Untopiced,Revert D26280518: [TorchScript] C++ interface of to_<backend>
df837d0384,cpp_frontend,devs,Use the libc++ detection instead of clang detection around std:isinfinite (#52164)
68e2a8c420,nn_frontend,Untopiced,Reenable test_nn tests for Windows (#52051)
4df8e774e6,amd,Untopiced,[ROCm] warn unsupported PYTORCH_CUDA_FUSER_DISABLE_FMA (#50508)
b01b7ea4f3,releng,Untopiced,store artifacts for windows binary build (#52239)
0019a20a2b,jit,Untopiced,[WIP] Add a `_flush_compilation_cache` for testing (#52001)
71d5a8ea62,jit,Untopiced,[nnc] Benchmark inference batchnorm (#52251)
b887c30980,jit,Untopiced,Out version for sum (#52225)
f3f72b5c6b,caffe2,Untopiced,"when BUILD_SPLIT_CUDA=ON, create dummy torch_cuda (#52305)"
63206ada8f,releng,Untopiced,Adding back CUDA 11.1 CI (#52171)
52af23b912,releng,Untopiced,Update PyBind to official v2.6.2 tag (#52304)
4e36891e4f,jit,Untopiced,Temporary disable cat tests on MacOS due to Sandcastle failure
059c564ba4,dataloader_frontend,Untopiced,[DataLoader] Fix module import (#52224)
9409a3a39b,caffe2,Untopiced,Check kernel launches in caffe2/operators (#52240)
4156588365,jit,Untopiced,[nnc] Allow 1 ulp tolerance in log approximation (#52165)
fa393b56e7,jit,Untopiced,"[static runtime] use NNC to generate logit, relu and tanh (#52322)"
bfc7e28188,fx,Untopiced,"reland - ns for fx - stubs of the three APIs (compare weights, activations, activations with shadow) (#52302)"
bb9e0c625e,jit,Untopiced,[nnc] Add dummy reference to llvm::cfg::Update<BasicBlock> (#52321)
35b0560ea2,skip,Untopiced,Automated submodule update: FBGEMM (#52255)
8c185e62f9,amd,Untopiced,torchvision hipify revamp fix (#51453)
f235c65a2b,jit,Untopiced,[TorchScript] C++ interface of to_<backend> (Re-land) (#52340)
680c4ce1dd,jit,Untopiced,[PyTorch] Avoid some extra intrusive_ptr<Tuple> copies in Unpickler (#51902)
6e1a5b1196,composability,Untopiced,[PyTorch] Use real if constexpr behind macro in hot template (#51368)
4501b52fe5,quantization,Untopiced,Benchmark for torch.ops.quantized.linear_prepack_fp16 operator (#52229)
a6e94d274f,mobile,Untopiced,[Pytorch] Add python binding to use mobile cpu allocator. (#52323)
87ebaa4eb1,mobile,Untopiced,"[Pytorch, Sparsity] Integrate sparse qnnpack operator in framework"
d8bb932245,jit,Untopiced,Support AST rewriting for submodules (#52297)
99619ea3b7,skip,Untopiced,Automated submodule update: FBGEMM (#52354)
a8885ee7e6,caffe2,Untopiced,[BE][typing] add caffe2/torch proto stubs (1 of 2) (#52341)
975d9f2551,releng,Untopiced,Mypy fixes for pytorch master (#52090)
c442776f3c,composability,Untopiced,[PyTorch] Debug-gate static_assert in KernelFunction::makeFromUnboxedFunctor (#51367)
a9f5e7229e,composability,Untopiced,[PyTorch] Remove reference_cast in make_boxed_from_unboxed_functor (#51319)
b2aa63f17c,jit,Untopiced,[PyTorch] Fix return value of IValue::to for Tensor/String (#51463)
0e2520baae,jit,Untopiced,[PyTorch] Don't read 1 char per iteration in Unpickler::readString (#51901)
e36a900e89,releng,Untopiced,[tools] Use anonymous access to access S3 bucket (#52338)
324c6aada1,nn_frontend,Untopiced,BFloat16: enable prepacked weights's inference (#48922)
cbede834d4,jit,Untopiced,[JIT] Add support for default argument values to Torchbind (#51253)
72d1ccd3ca,mobile,Untopiced,"Revert D26263480: [Pytorch, Sparsity] Integrate sparse qnnpack operator in framework"
4305609d66,complex_frontend,Untopiced,Fix complex acos edge cases (#52287)
059ee85ca4,composability,Untopiced,[PyTorch] Devirtualize TensorImpl::storage() (#51050)
6dabe0b291,distributed,Untopiced,[Dist Profiling] Enable dist profiling for DDP (gloo only) (#52031)
440fddf07b,jit,Untopiced,Remove unnecessary statement in `capture_stderr` (#52366)
b8584b884e,quantization,Untopiced,[quant] Quantizable MultiheadAttention (#49866)
a07530e57f,quantization,Untopiced,[quant] Factoring out the list of no_observers (#50459)
edf8130e9e,composability,Untopiced,[PyTorch] Add set_data_ptr_noswap & use where possible (#52244)
51c28e4d7e,amd,Untopiced,[ROCm] enable fft tests (#51581)
6c875f17ca,mobile,Untopiced,Enable PyTorch_QNNPACK for Apple Silicon builds (#52308)
e7f28d4241,mobile,Untopiced,[PyTorch Mobile] Restructure DispatchStub::operator() code to move template independent code into an external method (#51403)
5003d417d4,composability,Untopiced,[PyTorch Mobile] Outline DispatchStub::get_call_ptr() (#51908)
f6e0f5b85a,cpp_frontend,devs,[typing] ignore mypy false positives in aten_test.py (#52370)
f7a3634466,fx,Untopiced,[WIP][FX] Normalize torch.nn.functional calls (#51816)
7e2becb70f,jit,Untopiced,[PyTorch] Reduce copy/move in c10::ivalue::from (#52324)
79e10ce97b,jit,Untopiced,[PyTorch] Construct IValue from List without copies in args (#52325)
2775ff4a47,cpp_frontend,devs,[BE] Decorate unused functions with C10_UNUSED (#52378)
2b202667c1,jit,Untopiced,[1/N] CPU pointwise optimization: Add a benchmark for Relu
76af821c36,composability,Untopiced,"[PyTorch] ""Fix"" wrong-looking move in TensorImpl (#52344)"
b9f051db9f,caffe2,Untopiced,Add type hints for the _import_c_extension module (#51767)
70bed6a55a,jit,Untopiced,Removes deprecated preprocess method from the backend interface (#52258)
908ba05a06,mobile,Untopiced,[Pytorch] Add python binding to use mobile cpu allocator. (#52376)
08b95e3c48,mobile,Untopiced,"[Pytorch, Sparsity] Integrate sparse qnnpack operator in framework (#52377)"
27d89057f8,caffe2,Untopiced,[caffe2] fix deserialization of unknown tensor data_type values (#52411)
f7aa88b400,caffe2,Untopiced,[caffe2] Explicitly define all DataTypes in python/core.py (#51768)
eaad002cf6,composability,Untopiced,[PyTorch] s/__attribute__((__noinline__))/__attribute__((noinline))/ (#52362)
f1e004b954,build_frontend,Untopiced,Fix compiler warning for MathConstants.h (#52123)
f6321977e9,caffe2,Untopiced,Fix shape inference for multiple outputs with different output dtypes (#52417)
7a408c7290,complex_frontend,Untopiced,[complex] `masked_fill`: Complex Autograd support and update masked_scatter skips. (#52035)
de9016007a,python_frontend,devs,[PyTorch][easy] Coalesce string literals in data_ptr error message (#52379)
f6a6814a4f,jit,Untopiced,Dont look at reduction output args when computing mem dependencies (#52170)
62d5f60ad2,jit,Untopiced,Avoid using ReduceOp->output_args() in rfactor (#52177)
a788c2d777,jit,Untopiced,[nnc] Remove output_args from ReduceOp (#52187)
ac121165e2,jit,Untopiced,Remove ReduceOp::accumulator (#52196)
8228086e64,jit,Untopiced,"[static runtime] Use VML-inspired logarithm with NNC, tweak scheduling (#52423)"
7a67a7a396,jit,Untopiced,[static runtime] Generate sigmoid with NNC (#52424)
9cf6be6b3e,nn_frontend,Untopiced,Fix torch.nn.functional.interpolate microbenchmark for non-4D inputs
60518d10f6,jit,Untopiced,[deploy] torch::deploy API (#51754)
758aa45563,skip,Untopiced,Revert D26369476: [pytorch][PR] [complex] `masked_fill`: Complex Autograd support and update masked_scatter skips.
c8b3686a3e,nn_frontend,Untopiced,Make bias in lazy modules lazy and avoid create empty tensors (#52212)
ba77b8d84e,composability,Untopiced,[PyTorch][easy] Make shared empty string static instead of thread_local (#52220)
efbb854ed8,composability,Untopiced,[PyTorch] Avoid std::string in TORCH_CHECK when possible (#52221)
3978ffb37a,quantization,Untopiced,NS for FX: add test for a simple sparsenn model (#52092)
d903106bad,quantization,Untopiced,[wip] ns for fx: add support for subgraph matching (#52130)
a937d1cb16,quantization,Untopiced,ns for fx: make weights comparison work on N models (#52356)
ad9746456e,quantization,Untopiced,ns for fx: make unshadowed activation comparison work for N models (#52357)
c7b0005831,python_frontend,Untopiced,Enhance Tensor.unflatten to support -1 as the inferred size (#51955)
b52e2e6045,cuda,Untopiced,[BE] _get_torch_cuda_version should return tuple (#52409)
983347fa25,python_frontend,Untopiced,Allow broadcasting against lerp weights. (#52319)
9e54532947,skip,Untopiced,[PyTorch Mobile] 15KiB size reduction by reducing MaxTypeIndex from 256 to 32 (#51881)
8f3ed60d3e,nn_frontend,Untopiced,enable mkldnn conv2d backward to support mkldnn tensor input (#48994)
c7a70eec1b,jit,Untopiced,Make LLVM the default backend for TE (#52314)
49c90648d3,mobile,Untopiced,[iOS GPU] Fix max_pool_2d (#52431)
2d4354423e,releng,Untopiced,Revert nightly docker build cuda version to 11.1.1. (#52234)
22adea04df,mobile,Untopiced,Revert D26299594: [PyTorch Mobile] 15KiB size reduction by reducing MaxTypeIndex from 256 to 32
e0b6252de0,distributed,Untopiced,[ROCm] Enable test_ddp_hooks.py test cases (#52403)
bb7e07ce8e,caffe2,Untopiced,[glow] Extending AOT config with two more fields (#5359)
65f6e665e6,fx,Untopiced,Improvements for FX tracer (#52232)
82548f3a00,complex_frontend,Untopiced,[ROCm] missing template declarations for complex blas (#52472)
f4c33edb45,onnx,Untopiced,Add onnxifi interface for set/get options (#52388)
d8b28579c3,jit,Untopiced,Add NNC support for aten::hardtanh (a hot operation in mobilenet v2/v3) (#52394)
83feaebfc3,python_frontend,Untopiced,Add support for pow (#52374)
fb9f89507a,quantization,Untopiced,[quant][graphmode][fx] Fix fp16 dynamic quant for functional linear (#52369)
3adc8f8cf7,python_frontend,Untopiced,Enable min & max for Float16 & BFloat16 (#51244)
4ee5bc74d3,dataloader_frontend,Untopiced,[DataLoader] Change signature of Functional DataPipe (#52458)
c29e279f72,distributed,Untopiced,[DDP] unittest for when params arent used in backward pass (#52384)
0c46b6b3f6,distributed,Untopiced,[DDP] Enhance warning for find_unused_params (#52385)
c75fa39b6c,distributed,Untopiced,add stats that can only be collected at runtime (#51386)
d0795ab358,distributed,Untopiced,log newly added construction and runtime stats at randomly selected iterations (#51394)
3b11822825,distributed,Untopiced,[RPC] Refactor rref_context to not use utils::Future (#51697)
df3d1d9378,cpp_frontend,Untopiced,[RPC] delete torch/csrc/utils/future.h (#51698)
7ca9776874,linalg_frontend,Untopiced,Fixed _out variants of linear algebra functions (#51560)
b71215a909,skip,Untopiced,Revert D26515596: [pytorch][PR] Add support for pow
93c4067f25,composability,Untopiced,[BE] Cleanup UnaryOpsKernel.cpp (#52444)
dbeda994db,releng,Untopiced,"Update FindvecLib.cmake for macOS 10.14, 10.15 and Big Sur (#51288)"
8094e4844d,jit,Untopiced,[ROCm] Enable test_jit_c10.py tests for ROCm (#52410)
5fda3b094c,complex_frontend,Untopiced,Add conj OpInfo and fix out inconsistency (#52059)
9699c703c2,python_frontend,Untopiced,Stable sort for the CPU take 2. (#51790)
bc6852c192,distributed,Untopiced,Change TCPStore world_size and is_master to be optional (#51809)
76e8324370,package,Untopiced,[package] rename ex/importer.py to package_ex/importer.py (#52320)
d5ac929b62,package,Untopiced,[package] Introduce Importer to manage module namespace collisions. (#51975)
752d808fa0,jit,Untopiced,Trace linear as aten::linear (#51897)
08017f4598,releng,Untopiced,Add explicit cudart_static dependency for cublas_static (#52509)
12cbd6975a,onnx,Untopiced,[ONNX] Fix for sequence of mutations in blocks (#51577) (#52347)
26e8f8f223,onnx,Untopiced,[ONNX] Update fuseLogSoftmaxNllLoss function to handle autocasting (#51729) (#52349)
49a923c8b5,onnx,Untopiced,[ONNX] Update LayerNorm symbolic to handle autocasting (#52199) (#52350)
338d2eca4a,quantization,Untopiced,[quant][graphmode][fx] Enable test for non quantized input for add/mul (#52412)
bcd77cece4,jit,Untopiced,[JIT] Display an error message when with item is not an object (#52335)
28e3dfdcca,jit,Untopiced,[JIT] Allow __exit__ to have a return value (#52336)
c9c4b871a5,jit,Untopiced,[pytorch] reintroduce static dispatch (#51957)
b6ed05130e,jit,Untopiced,Adding a flag to enable CPU fusion in benchmarks (#48612)
44ff79d849,build_frontend,Untopiced,Automatically set BUILD_SPLIT_CUDA for cpp exts (#52503)
b6cf17deee,complex_frontend,Untopiced,[reland][complex] `masked_fill`: Complex Autograd support and update masked_scatter skips. (#52483)
d6755934fa,composability,Untopiced,[PyTorch] Make c10::str(const char*) return const char* (#52222)
566f7c79d3,composability,Untopiced,[c10] Take advantage of c10::str optis for simple CAFFE_ENFORCE (#52223)
7cd9892f83,composability,Untopiced,[PyTorch] Sync TORCH_INTERNAL_ASSERT optis with TORCH_CHECK (#52226)
0c0de542be,quantization,Untopiced,[quant][graphmode][fx] Guard the supported quantization type for add/mul (#52413)
db33afbf9f,releng,Untopiced,Change cmake to allow building with MLC kick-off build (#51326)
941ebecc54,onnx,Untopiced,[glow aot] Support --onnxifi_min_ops in AOT flow (#52380)
626756ac39,quantization,Untopiced,[quant][graphmode][api] debug --> reference (#52179)
09516d2d0c,cuda,Untopiced,Reenables skipped tests for all CUDA versions except 11.2 (#52359)
8fe6d17847,releng,Untopiced,Moving 11.2 CI to master only (#52536)
a3e693789f,quantization,Untopiced,[qunat][graphmode][fx] Enable test for non quantized input for cat (#52414)
ef8d17e112,distributed,Untopiced,[DDP] Separate error messages for unused params in forward and not all outputs (#52391)
72f9b3c8d5,jit,Untopiced,[StaticRuntime] Add function to check for memory leak (#52342)
1c64f862f6,complex_frontend,Untopiced,Update vec_mergee operand specifiers (_vecb) (#52091)
bb34fd6191,dataloader_frontend,Untopiced,[DataLoader] Fix util ImportError (#52459)
53373a8e8c,jit,Untopiced,remove deprecated function (#52426)
d9161d6da3,jit,Untopiced,Optimize `setDebugName` time complexity (#52346)
a62b0deae0,jit,Untopiced,[pytorch] make is_tracing scriptable (#49853)
15892a651f,mobile,Untopiced,[PyTorch Mobile] Create compile time string for passing in to the exception message instead of 4 arguments that will be concatenated at runtime (#52303)
597c9f8b22,quantization,Untopiced,fix zero_point rounding for _fake_quantize_learnable_per_channel_affine (#52290)
65bfa1389d,composability,Untopiced,[PyTorch Mobile] Do not create a static variable in Dispatcher::singleton() (#52447)
a61a8d059e,onnx,Untopiced,Restore fast path in OnnxifiOp::adjustOutputBatchSize (#52498)
a935118c90,jit,Untopiced,Fix caffee2 to use MaybeAlign when using LLVM trunk
14f7bf0629,build_frontend,Untopiced,[PyTorch] update CMake to build libtorch lite (#51419)
d819a21692,jit,Untopiced,Support any (#52360)
e677b71056,python_frontend,Untopiced,Add support for pow (#52374)
d491fc6d48,build_frontend,Untopiced,[PyTorch] Add comment to unify macro and rename one macro (#52573)
d177654981,mobile,Untopiced,[Take-2] [PyTorch Mobile] 15KiB size reduction by reducing MaxTypeIndex from 256 to 32 (#52466)
c2b9283d4a,composability,Untopiced,[PyTorch Mobile] Use real if constexpr behind macro in hot template (copy D26154964 in a different setting) (#52420)
ee04cd9587,skip,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
c78a4a52d2,composability,Untopiced,remove unnecessary/dead code in upsample_nearest1d cuda kernel (#51916)
f3ea5ca672,structured_frontend,Untopiced,port upsample_linear1d to structured (#51917)
d659477ae0,structured_frontend,Untopiced,port upsample_bilinear2d and upsample_bicubic2d to structured (#52012)
57637e0ab4,structured_frontend,Untopiced,port upsample_nearest3d and upsample_trilinear3d to structured (#52065)
ed71cbdd39,complex_frontend,Untopiced,"Revert PR 52483 ""[reland][complex] `masked_fill` (#52587)"
d02a2bd5d1,composability,Untopiced,codegen'd API for redispatching (#52008)
014d2123a3,composability,Untopiced,Replace all AT_ASSERTM in ATen (#51677)
4386a3803c,composability,Untopiced,Replace all ASSERTM in serialization (#51756)
116d402200,complex_frontend,Untopiced,Skip handle_r_to_c for dot & vdot (#52474)
ad3319cbc2,nn_frontend,Untopiced,fractional_max_pool{2/3}d : Fix segfaults for incorrect kernel_size and output_size (#51626)
03ae6d9903,distributed,Untopiced,Remove useless _allgather_then_aggregate_hook (#52593)
783b5c0c9f,jit,Untopiced,op_whitelist -> op_allowlist (#52150)
847d1d4d53,jit,Untopiced,add debug_flush_compilation_cache to `Method` (#52317)
09c56ef45e,jit,Untopiced,Remove DepTracker from LoopNest (#52405)
067fd78f05,jit,Untopiced,add RECORD_FUNCTION to grad_sum_to_size (#52516)
6b8e670eb7,releng,Untopiced,[CI][IOS] Add lite interpreter ios build job (#52567)
80240d0888,autograd_frontend,Untopiced,update autograd kernels to use redispatch (#51363)
947225cd1b,autograd_frontend,Untopiced,update tracing codegen to use redispatch API (#52009)
2eb9c0832e,distributed,Untopiced,Modernize for-loops in torch misc (#52452)
bfc2645981,releng,Untopiced,[BE] force cmake to always generate version.py (#52477)
a39b1c42c1,nn_frontend,bc_breaking,MHA: Fix regression and apply bias flag to both in/out proj (#52537)
b72a72a477,package,Untopiced,torch.Package extend PyTorchStreamWriter to track written records (#52218)
0bc57f47f0,package,Untopiced,torch.Package zipfile debugging printer (#52176)
973e306c84,jit,Untopiced,"changed TE 'Allocate' API to take one argument 'Buf' instead of three arguments 'Var', 'dtype', 'dims'. (#50167)"
09fe753a33,distributed,Untopiced,Enable TCPStore fixed slow test (#52511)
fd5792f857,jit,Untopiced,docs: add :nosignatures: in torch.jit (#52555)
3309f034aa,python_frontend,devs,remove pointless test (#52609)
108ec77fa7,jit,Untopiced,[NNC] Added reductions to NNC python bindings. (#52492)
1865499d49,jit,Untopiced,[Pytorch Mobile] Improve export_opnames Documentation (#52333)
7f4dff5496,nn_frontend,Untopiced,docs: add FractionalMaxPool3d in pooling layers (#52556)
a0652c8f08,caffe2,Untopiced,[static runtime] Fix up deprecated exact equality in tests (#52617)
a59c4039e0,cuda,Untopiced,Fix undefined symbol for CUDA 11.1 Windows (#52506)
6cfe55dea9,build_frontend,Untopiced,Add psutil to requirements.txt (#52285)
f111ec48c1,nn_frontend,Untopiced,docs: add fractional_max_pool in nn.functional (#52557)
fa8568184f,caffe2,Untopiced,[caffe2] Delete some unused fields from TensorProto (#52521)
7ecc1b603a,distributed,Untopiced,[TensorPipe] Update [Cpu|Cuda]Buffer fwd declarations (#52600)
67794b14bb,python_frontend,Untopiced,Use `int8_t` instead of `char` in [load|store]_scalar` (#52616)
b63a1e31d3,jit,Untopiced,[TensorExpr] Inlining: allow inlining into Load exprs. (#52627)
64847c7f0b,jit,Untopiced,[TensorExpr] Properly handle ExternalCalls in LoadStore analysis and Inliner. (#52628)
49b59e3472,python_frontend,Untopiced,Add OpInfo entries for i0 and logical_not (#51956)
2680ff7759,skip,Untopiced,Revert D26598115: [pytorch][PR] Update XNNPACK
e658d7c37b,jit,Untopiced,Ignore user annotated ignored attributes (#52367)
e3a805b9c5,quantization,Untopiced,Fake Quantization support for f16 and f32 (#52612)
1c63cb2c0f,distributed,Untopiced,Pass child error to parent in distributed tests. (#52632)
e2afb269b8,caffe2,Untopiced,[caffe2] add a Python test for SaveOp chunking
1cddb27f39,fx,Untopiced,[FX acc]Store shape and dtype in serialized output node args (#52462)
ecf3ca00d8,fx,Untopiced,[fx] Separate globals assignment from code generation (#51974)
d5ed57569b,releng,Untopiced,Move cuda9 and cuda11.2 CI jobs to a scheduled workflow (#52693)
df30cb78d2,cpp_frontend,devs,Remove unused variable (#52652)
420fc42eab,nn_frontend,Untopiced,add OneDNN pooling backward (#49454)
cabb1e7a94,cpp_frontend,devs,Fix wrong TORCH_CHECK usages (#52670)
b534466f01,dataloader_frontend,Untopiced,[DataLoader] TransformsIterDataPipe (#52604)
caa377f546,nn_frontend,Untopiced,replace type().backend() with device() (#52558)
26419815af,skip,Untopiced,Modernize for-loops (#52330)
238b0bbb68,fx,Untopiced,Allow Transformer accept output result that is not Proxy (#52473)
0c455332e8,nn_frontend,Untopiced,docs: add link to Tensor.share_memory_ in Module.share_memory (#52561)
755c60bffc,jit,Untopiced,[PyTorch Mobile] Allow loading of all extra files using the extra_file argument (#52635)
2d75346c25,distributed,Untopiced,[Gradient Compression] Add a minimum compression rate threshold for PowerSGD communication hook (#52541)
075bbe0d6a,skip,Untopiced,Fix for incorrect usage of logging in torch/distributed/distributed_c10d.py (#51739)
958d9a8364,package,Untopiced,[fx/package] make GraphModules packageable (#51976)
b56f59ea20,skip,Untopiced,Revert D26599390: [pytorch][PR] Fix for incorrect usage of logging in torch/distributed/distributed_c10d.py
8af648354f,jit,Untopiced,[nnc] Benchmarks for concat (#52592)
3489b4a7b8,distributed,Untopiced,Fix the ordering of TCPStore's compare_set parameters (#52696)
08d7f29601,python_frontend,Untopiced,Add discontiguous kwarg to make_tensor (#51985)
59ac0ff037,nn_frontend,Untopiced,Change `maybe_resize_storage_cpu` `new_size` arg to unsigned (#52671)
b4b7db2f3b,fx,Untopiced,[FX acc]Add fx_glow support for multi outputs (#52527)
27d04f291e,releng,devs,Clarify usage and output of tools/test_history.py (#52640)
7ae7768617,distributed,Untopiced,"[ZeroRedundancyOptimizer] Remove pseudo futures handling, not needed (#52698)"
08d266943d,structured_frontend,Untopiced,structured kernels - error check when structured_delegate is not marked structured (#52227)
88a160dc21,jit,Untopiced,[TensorExpr] LoopNest: Cleanup LoopNest constructors. (#52726)
3cf08eaf15,jit,Untopiced,[Pytorch Mobile] Improve Bundled Inputs Error Checking (#52386)
7b54a8fc23,quantization,Untopiced,[quant] Reference option for conv module (#52316)
964d47dfb9,linalg_frontend,Untopiced,Add torch.linalg to generated annotated_args for test_overrides (#52464)
0396f492b9,linalg_frontend,Untopiced,Implemented torch.linalg.multi_dot (#51807)
98873b9258,skip,Untopiced,Update Gloo submodule (#52754)
0567988e74,cuda,Untopiced,Kernel launch checks for aten/src/ATen (#52185)
373a20ad4a,distributed,Untopiced,Modernize for-loops in caffe2/torch (#52618)
29c4290a8d,composability,Untopiced,Use c10::irange for great good (#52153)
c954817696,linalg_frontend,Untopiced,print matrix dims in torch cuda matrix multiply error (#52780)
c140a5ec04,distributed,Untopiced,Use finer-grained mutexes in TensorPipe RPC agent (#52749)
a6b7da7dfe,nn_frontend,Untopiced,Add 64bit indexing support for softmax (#52713)
a649d808e6,nn_frontend,Untopiced,Added fast path in the case of no hooks (#52576)
2bdf6305a0,cpp_frontend,Untopiced,Drop unused variables (#52643)
30cb6ac53c,skip,Untopiced,Introduce `mlc` device (ML Compute device) to PyTorch's device list (#50634)
d3b427a0e3,jit,Untopiced,[TensorExpr] Add an unmasked `Load` constructor. (#52790)
57947c5d85,jit,Untopiced,[TensorExpr] Add `Placeholder::handle` method to get the corresponding `BufHandle`. (#52793)
0048d97eda,python_frontend,Untopiced,remove index_fill side-effect for scalar tensors (#52209)
92a4ee1cf6,linalg_frontend,Untopiced,Revert D26375734: Implemented torch.linalg.multi_dot
f71d9e28f9,releng,Untopiced,Store test filename in test report path (#52791)
1ac59d9db3,distributed,Untopiced,Fix RPC get_worker_info for rank=0 (#52804)
914126901e,releng,devs,Fix typos in tools/test_history.py helpstring (#52840)
fa7575ea05,cpp_frontend,devs,Update backwards compatibility check to ignore reverted op (#52841)
99a428ab22,cpp_frontend,Untopiced,Lower ReLu6 to aten (#52723)
13121598ef,quantization,Untopiced,"[Pytorch, sparsity] Bug fix to update requantization and zp parameters of input (#52797)"
64b4e37c26,quantization,Untopiced,ns for fx: allow graph matching of parents of cat (#52368)
4483c48eb1,quantization,Untopiced,ns for fx: support linear_relu for weight matching (#52395)
608f44b24b,quantization,Untopiced,ns for fx: update graph matching to not match nodes with equal types (#52402)
1618dc2ac6,quantization,Untopiced,ns for fx: update graph matching to handle dicts and tuples in node args (#52681)
316eabe9ba,nn_frontend,Untopiced,fix(docs): remove redundant hardsigmoid() in docstring to show up `inplace` parameter (#52559)
39fa0b5d0a,cuda,Untopiced,Add scatter_add to amp promote list (#52133)
3ff6c9174a,skip,Untopiced,Update TensorPipe submodule (#52677)
163a91bed3,distributed,Untopiced,Fix TensorPipe agent trying to double-set error (#52837)
f974cf4688,distributed,Untopiced,Test for distributed RL with RPC (#52393)
a11b601100,distributed,Untopiced,Expose Store's timeout and TCPStore's host and port in Python API (#52784)
7972036bbb,dataloader_frontend,Untopiced,Adding functional way of stacking DataPipes (#52507)
0e86f14ec0,skip,Untopiced,Upgrade onednn to v.1.8.1 (#51184)
c871abecf5,python_frontend,devs,Added torch.no_grad() to update_bn (#52654)
19a8ada8d5,quantization,Untopiced,quant: fix conv transpose with qconfig == None (#52844)
e94940b169,build_frontend,Untopiced,Use touch() in pathlib for better compatibility on Windows (#52729)
c2558b4b61,vulkan,Untopiced,[vulkan] Add nonVarTypeModeGuard to vulkan tests and speed_benchmark_torch (#52535)
da732c76c4,skip,Untopiced,Revert D26644079: [pytorch][PR] Adding functional way of stacking DataPipes
0b93974075,python_frontend,Untopiced,Fix incorrect runtime error in mul_() when the tensor layout is Mkldnn (#51758)
8ba7c4918a,jit,Untopiced,[nnc] Test for direct usage of ramp/broadcast
94da8b9816,distributed,Untopiced,Fix resource leak bug in TCPStore constructor (#52860)
a52001f923,python_frontend,Untopiced,Improve test_reference_numerics (#51604)
0f3a3f22af,distributed,Untopiced,Add sample validation for LKJCholesky.log_prob (#52763)
649760e5f1,cpp_frontend,Untopiced,`maybe_resize_storage_cuda` new_size argument should be unsigned (#52672)
569d4fe3f9,releng,Untopiced,.github: Add workflow to build conda packages (#51243)
51d8543ac7,fx,Untopiced,[FX] Use precompiled regex in graph name processing (#52853)
a27aaa49aa,quantization,Untopiced,quant norm layers: move scale + zp to buffers (#52861)
6514a47385,quantization,Untopiced,[quant] Fix conv packed param serialization in state_dict (#52787)
f40c9db622,fx,Untopiced,[FX][EZ] Hoist custom class .so loading into setUp (#52883)
9a03e65456,dataloader_frontend,Untopiced,Adding functional way of stacking DataPipes with fixed mypy (#52885)
a0a1bb074b,releng,Untopiced,Make NumPy dependency dynamic (#52794)
fdd25f82c9,composability,Untopiced,Update to replace AT_ERROR with TORCH_CHECK (#52711)
3969391c07,skip,Untopiced,[caffe2] move the SaveOp implementation from a header to a .cc file
b4a8d98247,skip,Untopiced,[caffe2] use AddNAlreadyReserved() when serializing blobs
cd9ac54ea7,skip,Untopiced,[caffe2] update load_save_test.py to also verify the chunking behavior
7094d970d1,quantization,Untopiced,ns for fx: decouple subgraph names from node names (#52771)
fe068157de,quantization,Untopiced,ns for fx: unify return types of weight and activation APIs (#52779)
d2e88246d8,quantization,Untopiced,ns for fx: make return type of ns APIs future proof (#52789)
1d3172130d,quantization,Untopiced,ns for fx: add node name and type to results (#52798)
25001a0148,quantization,Untopiced,"ns for fx: remove "".stats"" suffix (#52799)"
c423733967,jit,Untopiced,Add support for builtin sum (#52188)
69b2d5c7c3,skip,Untopiced,Revert D26641599: [caffe2] update load_save_test.py to also verify the chunking behavior
21c3f6f415,skip,Untopiced,Revert D26617038: [caffe2] use AddNAlreadyReserved() when serializing blobs
af1fb4e4ee,skip,Untopiced,Revert D26641600: [caffe2] move the SaveOp implementation from a header to a .cc file
a3cd881890,skip,Untopiced,Fix grammar in reducer warning (#52835)
7cfe140705,distributed,Untopiced,Add distributed debug mode func to python (#52481)
7a178a8a52,jit,Untopiced,[Static Runtime] Add memoray alloc/dealloc time to benchmark (#52902)
97568d7471,releng,devs,Use --delta=0 by default for tools/test_history.py (#52877)
18ee39944a,releng,Untopiced,.circleci: Change conda image to be cuda specific (#51494)
155b19ef1a,mobile,Untopiced,[Pytorch Mobile] Remove useless line from bundled_inputs (#52824)
44b9fcfb55,build_frontend,Untopiced,Fix local version generation (#52898)
502a85990d,build_frontend,Untopiced,[PyTorch] Move Aten level source list to build_variable.bzl (#52792)
b2520ab3dc,jit,Untopiced,Add a demo backend with compiler (#52603)
b8e6e2971c,distributed,Untopiced,Run distributed_test with NCCL_ASYNC_ERROR_HANDLING (#52619)
cb6b65699f,quantization,Untopiced,[quant][graphmode][fx] Add support for packed params in state_dict (#51639)
1d6bd15790,jit,Untopiced,[JIT] Add torch._C._jit submodule (#52910)
10087337c7,skip,Untopiced,Exclude 'test' from codecoverage (#52935)
94e23e51c4,caffe2,Untopiced,[caffe2] EnforceFinite: log blobs finiteness in workspace on error (#52892)
e63ec556bf,jit,Untopiced,[TensorExpr] PyBind: bind ExternalCalls. (#52905)
177694681e,quantization,Untopiced,[quant][graphmode][fx] Add reference option support for linear_dynamic_fp16 (#52534)
7f1693d95e,dataloader_frontend,Untopiced,Fix type hints of the callable arguments for DataLoader (#52924)
b685864f50,quantization,Untopiced,[quant][graphmode][fx] Add reference option support for linear_static_fp16 (#52650)
249c213462,distributed,Untopiced,[ZeroRedundancyOptimizer] Pytorch compliant state (#52960)
a296fa36ac,caffe2,Untopiced,[Caffe2] Implement BlackBoxPredictor::BenchmarkIndividualOps (#52903)
0818dbf49d,quantization,Untopiced,[quant][refactor] Merge add and mul handler (#52651)
729d88119a,distributed,Untopiced,Fix GradBucket Typing (#52943)
2962fbb03c,quantization,Untopiced,[quant][graphmode][fx][fp16] Add fp16 support for {add|mul}{_relu} (#52714)
f2f7fdba05,quantization,Untopiced,[quant][graphmode][fx][test][refactor] Refactoring binary op tests to split int8 and float16 tests (#52807)
4d94ee566e,jit,Untopiced,Ge v1 (#52136)
2c44b256d8,quantization,Untopiced,[quant][graphmode][fx] Add support for fp16 bmm pattern (#52808)
b9e12a0e82,nn_frontend,Untopiced,[pytorch] Fix mkldnn heuristic for multithreaded convolution (#52909)
57c7a61237,jit,Untopiced,[NNC] Added NNC IR specification (#52912)
e43ea227fe,skip,Untopiced,Automated submodule update: tensorpipe (#52930)
3a024a7ae2,skip,Untopiced,Revert D26655616: [quant][graphmode][fx] Add support for fp16 bmm pattern
03693c7e4a,skip,Untopiced,Revert D26655617: [quant][graphmode][fx][test][refactor] Refactoring binary op tests to split int8 and float16 tests
312b297b82,skip,Untopiced,Revert D26626092: [quant][graphmode][fx][fp16] Add fp16 support for {add|mul}{_relu}
f5617b0932,python_frontend,Untopiced,[testing] Add Opinfo for torch.frac and minor fixes (#52660)
a06cf5d8a4,python_frontend,Untopiced,"[numpy] torch.{rad2deg, deg2rad}: promote integer inputs to float (#51853)"
0569f638fe,skip,Untopiced,Update CODEOWNERS for torch.nn (#52942)
907ee5b290,quantization,Untopiced,ns for fx: docblock fixes (#52925)
5b93cdace1,quantization,Untopiced,ns for fx: remove model_name from get_matching_activations API (#52926)
87be8c1d7c,quantization,Untopiced,ns for fx: clean up duplicate code in get_matching_activations_a_shadows_b (#52927)
0d46926c63,quantization,Untopiced,ns for fx: remove subgraphs from user facing API (#52928)
66f07c0c12,performance_as_product,Untopiced,Optimized bilinear interpolation using TensorIterator (#51653)
6d29aa5486,dataloader_frontend,Untopiced,Make lambda supported by Map DataPipe (#52856)
3403babd94,python_frontend,Untopiced,[doc] Fix documentations of torch functions (#52982)
b22b082cc8,dataloader_frontend,Untopiced,Fixed the error of generator in the RandomSampler. (#52956)
7d060735ca,jit,Untopiced,"Back out ""[TensorExpr] PyBind: bind ExternalCalls."""
d4527b4e16,jit,Untopiced,add a full pipeline test for a TypeCheck (#52933)
8870c391e9,releng,Untopiced,Update mkl to 2020.2.254 (#52964)
e36576d153,foreach_frontend,Untopiced,Probable fix for out of place BinaryOpScalar bad values and/or IMAs on 11.2 (ci-all edition) (#52634)
4daa81e267,skip,Untopiced,Automated submodule update: FBGEMM (#52992)
0a70ec45d1,amd,Untopiced,[ROCm] Enable test cases in autocast_test_lists.py for ROCm (#52737)
f2657d2e4f,amd,Untopiced,[ROCm] Enable test cases in test_cuda.py for ROCm (#52739)
89b1053413,dataloader_frontend,Untopiced,[DataLoader] Move BufferedShuffle from Dataset to DataPipe (#52141)
096bea5251,quantization,Untopiced,[reland][quant][graphmode][fx][fp16] Add fp16 support for {add|mul}{_relu} (#52714) (#53019)
a9f7ae5357,dataloader_frontend,Untopiced,[ROCm] Enable test cases in test/test_dataloader.py for ROCm (#52766)
e00e42dbab,quantization,Untopiced,[reland][quant][graphmode][fx][test][refactor] Refactoring binary op tests to split int8 and float16 tests (#52807) (#53020)
084839faa6,distributed,Untopiced,Clang-format test_c10d.py (#52978)
e10d2f477b,distributed,Untopiced,Clang-format c10d/init.cpp (#53008)
812339ca3d,distributed,Untopiced,[ZeroRedundancyOptimizer] Buckets as tensor view + minimize public interface (#52987)
b039dd15ce,skip,Untopiced,Delete defunct LegacyTHFunctions templates (#53016)
991160ebd9,quantization,Untopiced,[quant][graphmode][fx] Add support for fp16 bmm pattern (#52808) (#53021)
ec42c2d89c,jit,Untopiced,[pyper] fuse clip_ranges+gather_ranges (#52461)
b3bf08e67f,distributed,Untopiced,Log nccl debug level in ProcessGroupNCCL (#52803)
3993fb2bf9,profiler,Untopiced,fix(docs): indent in docstring of key_averages (#53006)
e2462745ba,skip,Untopiced,Update kineto submodule (#53039)
fd4722949d,python_frontend,Untopiced,Fix the repeated entry in the Tensor Attributes doc (#52995)
07ae4e9309,releng,Untopiced,scripts: Add script to prep wheels for pypi (#53056)
c7c03dd388,python_frontend,Untopiced,"[PyTorch] Fix TORCH_CHECK_INDEX(false, ...) in IndexKernel (#53028)"
cfa41cea7e,python_frontend,Untopiced,[numpy] torch.logit: promote integer inputs to float (#52028)
8467e5cad3,releng,Untopiced,Remove ci-all and release branches running scheduled tests (#53069)
b5ae8e69a7,jit,Untopiced,[Lite Interpreter] Support features from to_backend (#52870)
272dfc7bb9,releng,Untopiced,Add MANIFEST.in (#52908)
ec128eadea,package,Untopiced,[package] _custom_import_pickler -> _package_pickler (#53048)
83a93ee145,package,Untopiced,[package] Pull out _UnpicklerWrapper into PackageUnpickler (#53049)
3bd779cec6,distributed,Untopiced,[rpc] make pickler/unpickler pluggable in RPC (#53050)
e22da0a5c4,jit,Untopiced,[TensorExpr] Add IRVerifier. (#52901)
a176c73ed5,jit,Untopiced,"[TensorExpr] Reland: ""PyBind: bind ExternalCalls."" (#53063)"
a586c02962,skip,Untopiced,Update and expose ZeroRedundancyOptimizer docs (#52937)
7a60b7dc3e,jit,Untopiced,Add support to compare devices (#53045)
bfae3789ba,amd,Untopiced,Move conv to mkldnn (#51483)
4b40141d2c,amd,Untopiced,Add support for linear in mkldnn fusion (#51484)
43f56e19a6,jit,Untopiced,[NNC] Make NNC sanitize input names (#52786)
a2f7e929ef,jit,Untopiced,Add MKLDNN fuser (#51600)
32fed3f375,amd,Untopiced,Handle mkldnn broadcasting in mkldnn fuser (#51736)
42bfda36e1,amd,Untopiced,Add 0-dim support for binary mkldnn ops (#51921)
f41c80c267,amd,Untopiced,Dont error on 0-dim in convolution (#51922)
9a990dafd9,jit,Untopiced,Add a filter to remove mutation (#51923)
b1284cfbfb,jit,Untopiced,Only functionalize ops which we want to include in mkldnn group (#51924)
dbbe21dfd7,vmap_frontend,Untopiced,Remove unused subgraph vmap api (#52512)
6149a26adb,jit,Untopiced,Extend subgraph utils to cover merging a node following a subgraph (#52513)
506f756a0a,jit,Untopiced,Include max pool in fusion groups (#52613)
ac122a5a6d,package,Untopiced,[package] catch exceptions from calling reduce function. (#53061)
87b6702833,distributed,Untopiced,[distributed] make the pickler in distributed_c10d pluggable (#53060)
748285ccd7,complex_frontend,Untopiced,[complex] add autograd support for torch.polar (#52488)
aae188c529,jit,Untopiced,[NNC] Handle non literal constant bounds in Unroll. (#53029)
f448c59a57,jit,Untopiced,Fix jit.trace mis-handling of InterfaceType (#53052)
d382693263,jit,Untopiced,[NNC] Build aggregate stmt for kernel before LoopNest. (#53024)
a6af93e921,quantization,Untopiced,[quant][graphmode][fx][fp16] Add fp16 support for sub (#52809)
97c51d5d5d,quantization,Untopiced,[quant][graphmode][fx][fp16] Add fp16 support for div (#52810)
fc6fdade9f,quantization,Untopiced,[quant][graphmode][fx][fp16] Add fp16 support for torch.sum (#52811)
3fb324f05b,quantization,Untopiced,[quant][graphmode][fx][fp16] Add fp16 support for layer_norm (#52862)
d40b501cfc,quantization,Untopiced,[quant][graphmode][fx][fp16] Add fp16 support for sigmoid (#52863)
267aeb8a56,quantization,Untopiced,[quant][graphmode][fx][fp16] Add fp16 support for tanh (#52864)
46bd76fdec,quantization,Untopiced,[quant][graphmode][fx][fp16] Add fp16 support for silu (#52865)
931100f829,skip,Untopiced,Revert D26696938: Update and expose ZeroRedundancyOptimizer docs
09ce9b5877,releng,Untopiced,Store test file in S3 as well for every TestSuite (#52869)
28f87bb734,releng,Untopiced,Don't run cpp tests a second time in the sharded ort_test2 job (#53067)
048e3917f9,releng,Untopiced,Add duplicate scheduled-ci to allow for debugging (#53109)
2d67b76fa6,jit,Untopiced,[static runtime] Add Alias analysis to Memory Management/Planning (#50060)
d4e64dad15,jit,Untopiced,[static runtime] Register both TupleConstruct and ListConstruct as out variants (#52684)
4fb82a8808,composability,Untopiced,Skip dispatch for `is_floating_point` (#52998)
aa603cb2ce,python_frontend,devs,add OpInfo entry for signbit (#52198)
fbf9745c85,skip,Untopiced,add submodules to sys.modules so their attributes can be pickled (#53107)
2bf079d060,python_frontend,devs,Remove useless test_reference_numerics skip infos (#52890)
d8ef3a4793,nn_frontend,Untopiced,[ROCm] Enable test cases in test_nn.py for ROCm (#52836)
e5e54ada61,python_frontend,Untopiced,fix logcumsumexp functor to properly handle infs and nans (#52947)
43f810fa96,cuda,Untopiced,Add streams boundary check to `torch::cuda::scatter`` (#53057)
73a57246d9,dataloader_frontend,Untopiced,disable dill extension behavior (#53118)
2d7119f943,skip,Untopiced,Revert D26753571: [pytorch][PR] add submodules to sys.modules so their attributes can be pickled
62d1cdd725,skip,Untopiced,Automated submodule update: tensorpipe (#53012)
cb1596a193,memory_format_frontend,Untopiced,[operator_benchmark] Added channels last 3d option to interpolate test (#53117)
890e051047,distributed,Untopiced,Clang-format quantization_hooks.py (#53100)
fbf2883d35,skip,Untopiced,Revert D26733731: [pytorch][PR] Skip dispatch for `is_floating_point`
c5a67f1675,composability,Untopiced,Fix minor inaccuracy in translate error reporting (#53032)
37bf6c134b,structured_frontend,Untopiced,Register DefaultBackend implementations for functional/inplace structured operators (#53037)
66b20bb738,jit,Untopiced,[CUDA graphs] [JIT] improves readability and nvfuser convenience for graph-safe cuda RNG (#51580)
29034b9487,distributed,Untopiced,[Reland] Update and expose ZeroRedundancyOptimizer docs (#53112)
d697090260,distributed,Untopiced,Add a note in DDP doc to point to ZeroRedundancyOptimizer (#53113)
41765d4681,releng,Untopiced,Store coverage files as artifacts for better debugging (#53126)
2444b4d122,distributed,Untopiced,Add wait_for_worker param to TCPStore and fix port in use flaky test failures (#52888)
ab7f6f3f5b,cuda,Untopiced,Add default arguments to cuda stream and events (#53025)
ecb5ac90ed,distributed,Untopiced,[Gradient Compression] Add get_per_parameter_tensors method to GradBucket class (#53009)
4997c38a15,distributed,Untopiced,[Gradient Compression] Don't provide default values in GradBucket constructor (#53102)
b05dd931ee,distributed,Untopiced,[Gradient Compression] Add is_the_last_bucket_to_allreduce method to GradBucket class (#53010)
521e1e83ea,distributed,Untopiced,[Gradient Compression] Remove some low-level methods of GradBucket class (#53098)
baed2cfe01,skip,Untopiced,"Back out ""Revert D26753571: [pytorch][PR] add submodules to sys.modules so their attributes can be pickled"" (#53127)"
a3a2150409,autograd_frontend,Untopiced,Codegen python bindings to access attributes of grad_fn (#52451)
6ab3a8b6f2,quantization,Untopiced,Update torch.nn.quantizable.MultiHeadAttention docstring (#53106)
c4c20a5d2d,cpp_frontend,Untopiced,Suppress unsigned comparison warning (#52653)
593b0fbade,skip,Untopiced,Revert D26720919: [Gradient Compression] Remove some low-level methods of GradBucket class
e2ecfb60a6,nn_frontend,Untopiced,FIX Validates target in cosine_embedding (#53110)
2c8f9aec64,python_frontend,Untopiced,avoid TLS in has_names (#53003)
e86476f736,nn_frontend,Untopiced,Huber loss (#50553)
fd582af06c,dataloader_frontend,Untopiced,enable coverage test for dataloader on Windows (#52550)
870bac13bc,linalg_frontend,Untopiced,Fixed out= variant of linalg.inv (#51977)
c0b31a5ba7,jit,Untopiced,[StaticRuntime] Clean up (#53096)
3ac9013235,linalg_frontend,Untopiced,Implements `torch.linalg.lstsq` (#49093)
0f7f600e01,cpp_frontend,Untopiced,Fix constexpr __host__ warning (#52702)
aba33b0042,jit,Untopiced,[TensorExpr] IRVerifier: add index verifier for Store. (#53137)
d8730194e7,jit,Untopiced,use device methods (#52899)
565d8235e5,jit,Untopiced,[nnc] Test cases for uneven split + reorder (#53091)
0dac7d86ca,cpp_frontend,Untopiced,blas copy and axpy to aten (#52345)
5c1c8cb93b,caffe2,Untopiced,[caffe2] Fix shape inference for pruning ops (#53082)
e1e19a71ce,caffe2,Untopiced,[shape inference] fix pruning
0819d5f9e9,fx,Untopiced,[FX] Added docstring for concrete_args (#53151)
e29d8477a6,skip,Untopiced,Added CUDA support for torch.orgqr (#51348)
bd7ac755d8,jit,Untopiced,Fix loop type (#50484)
926e011cde,linalg_frontend,Untopiced,Fixed out= variant of linalg.solve (#51968)
816646bd6f,python_frontend,devs,Add OpInfo for `bitwise_not` and make ROCM and CUDA OpInfo tests consistent (#51944)
70d0aab7bd,autograd_frontend,Untopiced,De-prioritise Dimname and DimnameList in python overload resolution (#51350)
a2a88990cd,build_frontend,Untopiced,[PyTorch] Remove extra RNN.cpp file (#53169)
30dd15e778,mobile,Untopiced,[PyTorch] Add doc string for lite interpreter related api in Android (#53136)
d90d7245f4,jit,Untopiced,[PyPer] Optimize sigrid_hash (#53065)
59b2b8b091,skip,Untopiced,Revert D26727660: [pytorch][PR] Add OpInfo for `bitwise_not` and make ROCM and CUDA OpInfo tests consistent
0aa9f22f1a,dataloader_frontend,Untopiced,Move groupbykey to grouping (#53122)
c957e2ab42,dataloader_frontend,Untopiced,Add more datapipe to functional API (#53123)
b3c4ac6319,build_frontend,Untopiced,Fix OpenBLAS discovery (#53168)
85e5fdb919,distributed,Untopiced,disable TCPStore multi_worker tests for windows (#53156)
1559fa6a5c,python_frontend,Untopiced,[operator benchmarks] Added more modes to interpolation tests (#53186)
a1d204807a,caffe2,Untopiced,Add shape inference for SparseLengthsSumSparseLookup
c8cc2e2133,skip,Untopiced,Update CODEOWNERS for test_public_bindings (#53158)
fbf60b5aaf,releng,Untopiced,Store only coverage info as artifacts (#53150)
20860ab01a,skip,Untopiced,Revert D26727918: [pytorch][PR] Added CUDA support for torch.orgqr
5c15a5bb46,skip,Untopiced,Deduplicate shared params before constructing Reducer in DDP (#51929)
43906f9b8b,distributed,Untopiced,[ZeroRedundancyOptimizer] Minor stub fix (#53165)
f5e725527d,composability,Untopiced,[PyTorch] Save a single add instruction in the dispatcher (#52543)
99098c1d70,cpp_frontend,Untopiced,Delete dead Backend toSparse (#53116)
fd3004d3ee,cpp_frontend,Untopiced,Add NoOpDeviceGuardImpl (#53142)
0f81a69a96,python_frontend,Untopiced,Make meta a device (getting rid of empty_meta) (#53143)
ecd8e4c1d5,caffe2,Untopiced,Add guard to run on current thread (#52361)
f8238d7917,python_frontend,Untopiced,[optim] bugfix when all parameters have no grad (#52944)
510c03d922,skip,Untopiced,[Gradient Compression] Remove some low-level methods of GradBucket class (#53098)
8b5b7fa83d,fx,Untopiced,[WIP][FX] Optionally record stack traces when symtracing (#53081)
25a3732c8d,vulkan,Untopiced,"[vulkan] Add, sub, mul, and div ops with broadcasting for Vulkan (#52842)"
7cec4b3d4a,quantization,Untopiced,[quant][fx] add _remove_qconfig flag to convert_fx (#53166)
f3190a77b2,vulkan,Untopiced,[Vulkan] Update VMA to VMA::e74dc79903f3e59b15a48f112b5c804fea2220b0. (#52938)
e5ecd1ddf8,vulkan,Untopiced,[Vulkan]Fix build warnings-treated-as-error on Linux. (#52781)
59c0c19be2,distributed,Untopiced,Add RemoteModule to master RPC docs. (#53084)
4008df3507,jit,Untopiced,Add property binding in torchbind (#50670)
86166f2124,quantization,Untopiced,[quant][fix] MHA tensor assignment fix (#53031)
f7d65c5cd2,cuda,Untopiced,Use .gv instead of .dot for Graphviz in fast_nvcc (#53208)
096c66a99f,mobile,Untopiced,[sparsity][refactor] Rename row/col to out/in features
a812175173,skip,Untopiced,Update Kineto revision (#53199)
9c2673df46,skip,Untopiced,Revert D26723384: [pytorch][PR] Implements `torch.linalg.lstsq`
d30f4d1dfd,distributed,Untopiced,Migrate apex.parallel.SyncBatchNorm channels_last to pytorch (#46906)
ba36e32406,distributed,Untopiced,[Gradient Compression] Correct the usage of min_compression_rate (#52979)
79944f7ad9,fx,Untopiced,[fx] simple doc fix
c94b8e13ec,releng,Untopiced,Remove docker_config_defaults from CircleCI config (#53200)
14a2ef0932,releng,Untopiced,Deduplicate test cases in suites by taking the longer test case (#53154)
12d63cc2f5,python_frontend,Untopiced,Add assert_async (#53086)
9b7396e7e2,jit,Untopiced,[pyper] casted_batch_one_hot_lengths with 4-arg to (#53215)
248e8b42fa,jit,Untopiced,[Static Runtime] Use native version of at::empty (#53216)
b59075eced,distributed,Untopiced,[Gradient Compression] Refactor tensor grouping in PowerSGD (#52981)
68b62493b8,distributed,Untopiced,[Gradient Compression] Make GradBucket class public (#53099)
38a34887ac,jit,Untopiced,"[PyTorch] Fix missing move in {List,Tuple}Construct (#53206)"
30a8a13a7d,skip,Untopiced,Revert D26625807: [pytorch][PR] Deduplicate shared params before constructing Reducer in DDP
fc7171badc,composability,Untopiced,inline TensorIteratorConfig setters (#52661)
d5507aa5b5,python_frontend,Untopiced,fix output dtype test in compute_types (#52731)
457b9f672c,releng,Untopiced,[CI]Shard cuda11_1 tests (#53235)
68810c1836,caffe2,Untopiced,Delete test_rand_quantization (#53234)
d98839e53e,jit,Untopiced,[static runtime] register pow out variant (#52454)
c5b0c2fa8b,complex_frontend,Untopiced,Support torch.complex (#53227)
c4c77e2001,python_frontend,Untopiced,[special] add `torch.special` namespace (#52296)
bf5e5bf901,amd,Untopiced,"[ROCm] Enable test in test_linalg.py, test_optim.py and test_vmap.py  (#52818)"
b864457743,skip,Untopiced,Revert D26744062: Add assert_async
5095332ab9,caffe2,Untopiced,Minor cleanup of interpolate microbenchmark
e698a634cc,python_frontend,Untopiced,Enabled amin & amax for float16 & bfloat16 (#52579)
6dce0cd0d4,fx,Untopiced,Optimize module path finding (#52990)
6557ea0509,jit,Untopiced,Context manager for hiding source ranges (#53188)
9e5e5a7d96,python_frontend,Untopiced,Revert D26815021: Revert D26744062: Add assert_async
8c54cd7f37,distributed,Untopiced,Declare NamedTuple at top level (#53273)
3826a07a63,composability,Untopiced,[PyTorch] Don't inline Dispatcher::call on mobile (#53197)
7aeee2849b,nn_frontend,Untopiced,Parametrization Functionality (#33344)
b4395b046a,nn_frontend,Untopiced,Edit SiLU documentation (#53239)
b0aa03b703,caffe2,Untopiced,fix tensorpipe_agent linked even when USE_TENSORPIPE is turned off (#53281)
51718c2f3c,skip,Untopiced,Update CODEOWNERS to be tagged as reviewer (#53277)
72ec718373,autograd_frontend,Untopiced,Leak autograd threads after wait limit (#53170)
85109ce427,fx,Untopiced,Support submodule manipulation in GraphModule (#52358)
4739d15a67,autograd_frontend,Untopiced,Skip some nodes during discovery using sequence number (#52180)
6db2f012a5,cpp_frontend,Untopiced,[PyTorch] Reduce size of register_symbols.cpp (#53278)
a3c3141dd2,autograd_frontend,Untopiced,Fix gradfn attr bindings when saved variable is of an output (#53205)
18277137ff,jit,Untopiced,make torch.load() aware of import path changes: torch.tensor -> torch._tensor (#53139)
36180c1322,jit,Untopiced,[static runtime] aten::to copy out variant (#52343)
ac668c55e5,jit,Untopiced,[Static Runtime] Remove dead code in MemoryPlanner and rename unmanaged_value_set to unmanaged_ivalue_set
97d4ed3d2d,python_frontend,Untopiced,[torch.futures] Add note about error handling for non-chained futures. (#53212)
47dbdfcfe9,jit,Untopiced,[Static Runtime] remove redundant gather_ranges when fusing (#53323)
110a17a4d9,foreach_frontend,Untopiced,Update foreach APIs to use scalar lists (#51893)
1accffe450,skip,Untopiced,Revert D26819810: Revert D26815021: Revert D26744062: Add assert_async
17495e0318,mobile,Untopiced,"[PyTorch Mobile] Fix case when error messages are stripped, and stack value isn't popped off in lite-interpreter (#53201)"
795ed5ca3f,build_frontend,Untopiced,Enable Kineto in CPU builds (#53174)
fdd074e806,caffe2,Untopiced,[caffe2] Fix shape inference for Softmax (#53132)
842ba90739,build_frontend,Untopiced,[iOS] Bump up the Cocoapods version (#53335)
f1eedfa2c8,package,Untopiced,[package] Add `allow_empty` flag to mock and extern (#53232)
51592a9e0a,package,Untopiced,[package] Add `deny` method to `PackageExporter` (#53233)
cfd9360d09,python_frontend,Untopiced,Revert D26837780: Revert D26819810: Revert D26815021: Revert D26744062: Add assert_async
8bac382d9d,jit,Untopiced,[TensorExpr] Remove unused classes from TensorExprKernel. (#53283)
dfd5331e9c,profiler,Untopiced,Skip tests on ROCm (#53339)
35364c3641,jit,Untopiced,[static runtime] Enable ClipRangesGatherRangesX2SigridHash fusion for SigridHashPrecompute (#53324)
69bb0e0285,caffe2,Untopiced,[caffe2] Avoid some double (and triple) lookups in workspace (#53319)
63e0e88ccc,jit,Untopiced,[PyPer] More at::empty -> at::detail::empty_cpu (#53333)
854cc53594,skip,Untopiced,Automated submodule update: tensorpipe (#53265)
42e0983230,jit,Untopiced,[NNC] Added some APIs for dealing directly with Bufs (instead of Tensors) (#53011)
e9d7137072,complex_frontend,Untopiced,fixes #38775 #38779: complex support for linspace and logspace (#38875)
268b96f069,skip,Untopiced,Automated submodule update: tensorpipe (#53353)
5ebfabb310,linalg_frontend,Untopiced,MAGMA: Initialize ipiv data to avoid internal memory access violation (#53064)
56f8379802,jit,Untopiced,[static runtime] Move all heavy constructor logic into InferenceModule (renamed to StaticModule) (#51564)
c697e48023,foreach_frontend,Untopiced,Refactor ForeachUnaryOp.cu (#51894)
1b35b1a0c4,distributed,Untopiced,Properly skip distributed tests when distributed module is not built (#52945)
68134374cb,distributed,Untopiced,Refactor/fix DDP model check during init (#52887)
bdbfc2582d,distributed,Untopiced,[Dist Debugality] Log key DDP metrics to stderr under debug mode. (#52957)
5d9b7bee1a,distributed,Untopiced,[DDP Logging] Log nccl_async_error_handling (#52965)
14fa47631b,distributed,Untopiced,[DDP Logging] Log comm. hook in ddp logging (#52966)
ba75cedfc5,distributed,Untopiced,[1/n][torch/elastic][upstream] Move torchelastic/rendezvous to torch/distributed/rendezvous (#53172)
c3405e5ba1,skip,Untopiced,"Revert ""Automated submodule update: tensorpipe (#53012)"" (#53394)"
efebc6524d,skip,Untopiced,Call nvidia-smi.exe before running tests Windows (#53334)
00bd0e9862,caffe2,Untopiced,[caffe2] Fix shape inference for LpNorm (#53332)
c0adabe172,releng,Untopiced,automate sharding using S3 test time stats (#53269)
387d9a6bab,distributed,Untopiced,Simplify async execution for script calls. (#53204)
f58f7b786c,distributed,Untopiced,add distributed backend options in setup.py (#53214)
474fe7d976,releng,Untopiced,docker: Update default cuda => 11.1 (#53299)
f595ba1bae,caffe2,Untopiced,[caffe2] move the SaveOp implementation from a header to a .cc file (#53298)
6cbbef2fea,python_frontend,Untopiced,Modify assert order to correct the error message when nan appears in multinomial on cuda (#53288)
7bfa9dc7de,distributed,Untopiced,Simplify async execution for script remote calls. (#53207)
1974969842,distributed,Untopiced,Cleanup async execution for python RPC calls. (#53230)
cab2689eb1,skip,Untopiced,Revert D26849826: [pytorch][PR] Call nvidia-smi.exe before running tests Windows
8c798e0622,releng,Untopiced,Forbid trailing whitespace (#53406)
758fb94fcb,python_frontend,Untopiced,"Prefix assert_async with underscore, fix some bugs in assert_async CUDA testing (#53276)"
369601355f,caffe2,Untopiced,[caffe2] Use extended versions of cuDNN calls for SpatialBN
a0d1e701db,cpp_frontend,Untopiced,Replace `internal::GRAIN_SIZE` by `grain_size` (parameter). (#53177)
1fe6a6507e,jit,Untopiced,[WIP][FX] Fix tracing support for torchbind (#52884)
1ba80264f4,dataloader_frontend,Untopiced,[DataLoader] ConcatDataPipe (#53301)
dbbe0a2105,dataloader_frontend,Untopiced,[DataLoader] Introduce deterministic context (#53271)
3236efa4de,quantization,Untopiced,[Static Runtime] Call native resize_/resize_as_ as much as possible (#53425)
b26c0bb2b9,mobile,Untopiced,[PyTorch Mobile] Allow skipping operator exists check when bytecode model is loaded (#52814)
e08aae2613,skip,Untopiced,Automated submodule update: FBGEMM (#53478)
affdcce833,distributed,Untopiced,Extract TensorPipeAgent's collectNames to be a standalone utility function (#53202)
c7b1979b6b,distributed,Untopiced,Use Store collect and verify names in all RPC agents (#53209)
d3cde6c23c,jit,Untopiced,[NNC] Implementation for aten::cat without conditionals. (#53128)
54a2498919,python_frontend,Untopiced,Modify tests to use assertWarnsOnceRegex instead of maybeWarnsRegex (#52387)
a5ada2127d,python_frontend,Untopiced,[reland] Add OpInfo for `bitwise_not` and make ROCM and CUDA OpInfo tests consistent (#53181)
d54be1a946,skip,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
0ca029b22d,caffe2,Untopiced,[caffe2] Fix DBFileReader (#53498)
c07a62b854,fx,Untopiced,[FX] change dynamic control flow example to a *more* dynamic version (#53250)
656930df26,fx,Untopiced,[FX] Fix default to align with documentation in `fuser.py` (#53457)
93f1b10f72,nn_frontend,Untopiced,Add missing attr in LazyModuleMixin doc (#53363)
2b359dd6dc,skip,Untopiced,Automated submodule update: tensorpipe (#53504)
1e306b9a71,distributed,Untopiced,Disable failing distributed test (#53527)
36dc5d3b3a,mobile,Untopiced,[iOS GPU][BE][1/n] - Remove unused headers + improve error message (#53428)
1588df6b99,releng,devs,Fix typo in tools/test_history.py (#53514)
117a49c4cb,releng,Untopiced,.circleci: Restore docker builds for scheduled workflows (#53412)
1fc8831322,build_frontend,Untopiced,Add missing tensor header (#53489)
25a9f45a5a,quantization,Untopiced,fix broken quantization_test in operator_benchmark (#53153)
98943bb863,caffe2,Untopiced,[PyTorch] Enable explicit ATen level sources for lite interpreter (#52769)
b64acfa9ac,composability,Untopiced,[PyTorch] Move non-template part of TensorImpl::Resize to cpp (#53388)
b2758cdc77,composability,Untopiced,[PyTorch] Don't copy vector arguments to caffe2::Tensor::Resize (#53389)
7b7775bec2,caffe2,Untopiced,feature_segmented_histogram_binning_calibration
64255294ba,releng,Untopiced,[PyTorch][CI] Enable building test_lite_interpreter_runtime unittest in CI (macos) (#52566)
e90e773445,python_frontend,Untopiced,Fix to empty_like example (#53088)
48ec939d39,mobile,Untopiced,[iOS GPU][BE][2/n] - Use dispatcher in MPSCNNTests.mm (#53429)
c72473fe2c,releng,Untopiced,Adding print_test_stats.py job to Windows CI (#53387)
067ad31210,jit,Untopiced,[NNC] Added some more external function bindings (#53420)
1e992810b5,skip,Untopiced,Revert D26811466: [pytorch][PR] [reland] Add OpInfo for `bitwise_not` and make ROCM and CUDA OpInfo tests consistent
7c0a4e78ca,jit,Untopiced,[static runtime] convert to->to_copy (#53524)
a0d425d38d,skip,Untopiced,Automated submodule update: FBGEMM (#53509)
d0b32156f0,python_frontend,Untopiced,move test to CUDA only (#53561)
0d04e51233,caffe2,Untopiced,[caffe2] Add an optimization to avoid extra fp32->fp16 conversions in Onnxifi (#53560)
b0984f7925,jit,Untopiced,[pytorch] use correct warning type for tracer warnings (#53460)
53c77e7d5d,distributed,Untopiced,Add mock.patch() to clear environment for test (#53537)
a947bfaa26,jit,Untopiced,[Pytorch] Remove assumption forward exists in freeze_module (#52918)
97460d3545,jit,Untopiced,[static runtime] Minimum fusion group size (#50217)
17d00319bc,releng,Untopiced,Install GCC-9 into ROCm builders (#53459)
5b52ff6c8e,fx,Untopiced,[fx] Add DCE pass (#52658)
d521fd799d,fx,Untopiced,[FX Acc] Add support for multi partitions in fx-glow (#53280)
dc29604fd1,mobile,Untopiced,[iOS GPU][BE][3/n] - Rename MetalTensor to MetalTensorImplStorage (#53430)
2dffb4e38e,jit,Untopiced,[Static Runtime] Back out D26659824 (#53570)
aa687bb6f4,mobile,Untopiced,[iOS GPU][BE][4/n] - Convert Objective-C class methods to C functions (#53431)
cb36e503d8,mobile,Untopiced,[iOS GPU][BE][5/n] Remove indirection calls from MPSCNNOps.mm and MetalAten.mm (#53432)
c2ccb3578e,python_frontend,Untopiced,Fix inport -> import typo in documentation (#53589)
bf88a4dad5,jit,Untopiced,Support parsing Ellipsis in JIT frontend (#53576)
34d9278c19,jit,Untopiced,"Remove notion of ""level"" from `Module::dump_to_str`. (#52539)"
0a97712326,composability,Untopiced,[caffe2] don't use static for template declarations in headers (#53602)
f4b344ad5c,skip,Untopiced,Definition infrastructure for instruction count ubenchmarks (#53293)
9df1b98bab,benchmark,Untopiced,Quality of life improvements to Timer (#53294)
2d36b30a8c,python_frontend,Untopiced,Expands OpInfo out= testing (#53259)
28d6e01511,composability,Untopiced,Add TORCH_CHECK_NOT_IMPLEMENTED/c10::NotImplementedError; make dispatch use it (#53377)
707fc354eb,cpp_frontend,Untopiced,Add debug only layout assert for empty_cpu (#53396)
02c0c7a32b,cpp_frontend,Untopiced,Add Meta support for empty_strided (#53397)
2f91cda37e,caffe2,Untopiced,Modify error message (#53525)
7e6a84d238,releng,Untopiced,Add logic to auto-fetch submodules (#53461)
9f2aea7b88,quantization,Untopiced,[Pytorch] Fix embedding bag bug accessing unaligned memory (#53300)
ef3765b992,nn_frontend,Untopiced,"Fix a cuda max_pool3d issue, do multiplication in int64 (#52828)"
b0afe945a7,skip,Untopiced,Fix pylint error torch.tensor is not callable (#53424)
a496520c1d,skip,Untopiced,Automated submodule update: tensorpipe (#53599)
bcd94e220d,mobile,Untopiced,[PyTorch] Fix typo in QNNPACK
e87a686d21,releng,Untopiced,.circleci: Remove hardcoded tag for rocm (#53636)
efb1895f81,caffe2,Untopiced,[caffe2] use snprintf() instead of sprintf() in the Checkpoint operator (#53434)
4fa11147c5,skip,Untopiced,Automated submodule update: FBGEMM (#53632)
c0c5f80f36,nn_frontend,Untopiced,Lazy Modules Documentation Clarifications (#53495)
a9e4bb56e5,cuda,Untopiced,Add more kernel launch checks (#53286)
a8ecf306da,jit,Untopiced,[Static Runtime] Remove dead code (#53588)
f8e7d8bb0d,fx,Untopiced,[FX][docs] Render inherited methods in fx.Tracer API reference (#53630)
8acb74c405,jit,Untopiced,[PyTorch] Make IValue::toTensor() inlineable (#53213)
0606057af3,cpp_frontend,Untopiced,[PyTorch] Add c10::MaybeOwned and Tensor::expect_contiguous (#53317)
a3465214ba,nn_frontend,Untopiced,move rnn cell size check to cpp (#51964)
233b9490c2,memory_format_frontend,Untopiced,fix channels_last bug in upsample kernels (#53535)
b9c3edd583,cpp_frontend,Untopiced,Remove hacky wrapper from a lot of unary operators. (#52276)
cff22f8794,structured_frontend,Untopiced,Port sin to structured. (#52277)
5dca8ff6de,fx,Untopiced,[FX] Make TracerBase._find_user_frame private (#53654)
60ed8fb244,jit,Untopiced,[JIT] Enable ModuleList non-literal indexing (#53410)
409a76f72c,jit,Untopiced,[Static Runtime] Fix bug in static_runtime::to_copy (#53634)
0257eddc16,python_frontend,Untopiced,Editing pass on native/README.md updates (#53638)
c3f8d57c70,composability,Untopiced,use DimVector for sizes and strides (#53001)
3b0e4a6ed4,fx,Untopiced,[GraphModule] Improve buffer registration during init (#53444)
8a6df06a0e,onnx,Untopiced,Print onnxifi failed status code in readable format (#53648)
a20b36b03d,jit,Untopiced,[JIT] Fix backward compatibility test broken by #53410 (#53683)
215950e2be,nn_frontend,Untopiced,Convert type annotations in nn/functional.py to py3 syntax (#53656)
c5cd993add,jit,Untopiced,Adds a bool is_available() method to the backend contract (#53068)
6aa5148df2,python_frontend,Untopiced,Filter 0's returned by exponential distribution (#53480)
039402b945,distributed,Untopiced,"If distributed module isn't available, don't run distributed/pipeline tests (#53547)"
e787872a47,distributed,Untopiced,[RELAND] Deduplicate shared params before constructing Reducer in DDP (#53279)
4dbd0b639d,python_frontend,Untopiced,Convert a few more checks to raise NotImplementedError (#53610)
6e020a4844,composability,Untopiced,Fix inaccurate dispatch table for fill_ (#53611)
70733f2e67,python_frontend,Untopiced,Marginally improve pytest collection for top-level test files (#53617)
1c9fc38eb2,releng,Untopiced,Remove reference to 9.2 as it's been removed from nightlies (#53716)
bcbe07200c,releng,Untopiced,Improve logic for S3 stats gathering. Uses automatic SLOW_TESTS. (#53549)
e937db5dba,linalg_frontend,Untopiced,Added CUDA support for torch.orgqr (#51348)
e13ef777a7,nn_frontend,Untopiced,Use native ctc loss for target length 256 (#53557)
05e0ea9661,releng,Untopiced,[android] bump gradle version to 6.8.3 (#53567)
5658ab5f77,releng,Untopiced,[andoid] publishing to maven central (#53568)
b99b6065f8,skip,Untopiced,Removes trailing whitespace (#53728)
8f15a2f052,linalg_frontend,Untopiced,eig_backward: faster and with complex support (#52875)
a08fc1a7fc,distributed,Untopiced,allow users to set sample rate and add per iteration latency breakdowns (#53145)
7d4b229d61,distributed,Untopiced,add is_multi_device_module logging field (#53149)
d032287ec3,distributed,Untopiced,fix data type logging (#53162)
a76b4736db,distributed,Untopiced,clang format reducer and logger files (#53148)
70a43425e0,nn_frontend,Untopiced,Simplify init._calculate_fan_in_and_fan_out (#53522)
bfc80b3566,releng,Untopiced,Give line numbers in git-grep-based lints (#53733)
b4d8f4af82,package,Untopiced,[package] implement `get_resource_reader` API (#51674)
17bc70e6f7,package,Untopiced,[package] make importer a little more obscure (#51676)
cb68039363,skip,Untopiced,Port NumPy typing testing style to PyTorch (#52408)
b03c92a9c5,distributed,Untopiced,[2/n][torch/elastic][upstream] Move torchelastic/timer torchelastic/multiprocessing to torch/distributed/elastic (#53574)
76b58dd9ae,distributed,Untopiced,Fix distributions which don't properly honor validate_args=False (#53600)
669fcf3093,python_frontend,Untopiced,Replace supports_tensor_out with supports_out (#53745)
c68cc24cee,nn_frontend,Untopiced,update upsample tests in test_nn.py to test for memory_format (#53665)
5563248b58,jit,Untopiced,[JIT] [Remove Mutation] Add handling of normal_ (#52175)
56f3cb7a99,jit,Untopiced,Add AST rewriter to acc_tracer (#53644)
d9fa957ecc,quantization,Untopiced,[quant][graphmode][fix] Handle the case when observed node has no users (#53210)
2cf90982e9,distributed,Untopiced,[TestZeroRedundancyOptimizer] Add multi gpu checker (#53564)
99d7c8ff94,caffe2,Untopiced,[caffe2] use AddNAlreadyReserved() when serializing blobs (#53400)
023948e6d7,caffe2,Untopiced,[caffe2] update load_save_test.py to also verify the chunking behavior (#53401)
fee263595c,skip,Untopiced,Remove trailing whitespace introduced in #52175 (#53762)
4351d09683,python_frontend,Untopiced,Fix error message in setStorage (#53198)
741d0f41d6,package,Untopiced,[package] split tests (#53749)
c988b78be2,distributed,Untopiced,Add a description of GradBucket Python class (#53596)
fe0810e2f8,distributed,Untopiced,Add a section to introduce GradBucket class in ddp_comm_hooks.rst (#53253)
895735c69f,foreach_frontend,Untopiced,TensorIterator: Avoid nesting two levels of function_ref in for_each (#53613)
f9185973d1,quantization,Untopiced,[quantization] Add some support for 3d operations (#50003)
0584fd9339,quantization,Untopiced,[quant][fx][graphmode][fix] Only insert observers for fixed qparam ops (#53330)
21f9a6da7d,caffe2,Untopiced,Avoid of creating a copy of statusString every inference time (#53756)
49a5f99440,composability,Untopiced,skip dispatch in resize_ (#53575)
997f05cd34,jit,Untopiced,[NNC] Add an initialization expression to Reduce() (#53751)
1f01899e4a,skip,Untopiced,Simplify index expressions constructed in loop flattening - #51173 (#52882)
14acf92b2b,composability,Untopiced,[PyTorch] Speed up Tensor::data_ptr (#53723)
ced91bb713,jit,Untopiced,[deploy] namespace and rename (#53670)
d49c5c74f5,skip,Untopiced,[docs] Add starter content for new TorchScript language reference (#52494)
a5e19126b6,jit,Untopiced,[NNC] LoopNest cleanup (#53688)
3bd250fd03,jit,Untopiced,[NNC] Test ability to vectorize reads from an intermediate tensor (#53752)
ebfa9276d8,jit,Untopiced,Move prim::layout for lite jit (#53781)
37ab711822,cpp_frontend,Untopiced,Adding learning rate schedulers to C++ API (#52268)
1053c96693,fx,Untopiced,[GraphModule] Back out changes to module root version of __init__ (#53791)
cfaa0bf286,jit,Untopiced,[JIT] Update Namespace from cuda to _cuda (#53378)
351f6f5e02,jit,Untopiced,[JIT] Update set_stream API to change the device (#53741)
95d2318510,jit,Untopiced,Adding parallel support for the LLVM backend. (#53243)
07d315fce8,skip,Untopiced,Revert D26676150: Simplify index expressions constructed in loop flattening - #51173
ffac9b2ead,skip,Untopiced,Revert D26965463: [pytorch][PR] [docs] Add starter content for new TorchScript language reference
f364e492df,autograd_frontend,Untopiced,Autograd functional API should enable_grad (#47543)
05f137c765,releng,Untopiced,"Remove GHA ""Checkout PR tip"" step (#53719)"
0a549f9412,python_frontend,Untopiced,[ROCm] Disable flaky tests on ROCm (#53192)
5842d34fac,cuda,Untopiced,Call nvidia-smi.exe before running tests on Windows (#53422)
4c1af249fb,build_frontend,Untopiced,[ROCM] load hipfft separately from rocfft (#53408)
7484c56fa3,quantization,Untopiced,[quant][graphmode][fx] Fix a condition check for CopyNode (#53585)
d7b5a6faaa,composability,Untopiced,"Revert ""Revert D26733731: [pytorch][PR] Skip dispatch for `is_floatin (#53242)"
ec713c0eb5,mobile,Untopiced,[Pytorch] Improve scale and zero point extraction for per channel quantized (#53726)
5648fe6093,python_frontend,Untopiced,Make storage access throw for meta tensors (#53681)
3f9c803fe8,onnx,Untopiced,[ONNX] Redesign onnx pass to enable shape type dependent pattern conversion - cont (#51795) (#53304)
5cf4527c88,releng,Untopiced,Update repo name for add-annotations-github-action (#53826)
bbce574ccf,releng,Untopiced,Pass commit_sha to add-annotations-github-action again (#53834)
ec484981c6,distributed,Untopiced,[3/n][torch/elastic][upstream] Move torchelastic/events to torch/distributed/events (#53760)
8b9e3e6fd4,complex_frontend,Untopiced,[complex] enable complex autograd cumsum (#53240)
379f1f1ede,skip,Untopiced,Automated submodule update: tensorpipe (#53810)
1acced4eba,jit,Untopiced,Implemented getCodeText(string attr) in llvm/cuda codegen and added python bindings for it - #52974 (#53664)
7e5ffbfa94,caffe2,Untopiced,[caffe2] add a SerializationOptions field for the save operator (#53402)
fa980bb22a,distributed,Untopiced,[wip][Dist Profiling] Enable dist profiling for MPI backend (#52949)
14d02517e1,distributed,Untopiced,replace data with data_ptr (#53097)
8016d28c0b,distributed,Untopiced,[Gradient Compression] Update the comment on fp16_compress_hook (#53780)
cdac61ecd4,cpp_frontend,Untopiced,Prevent VS from emitting ambiguous symbol errors (third time) (#53490)
ec6a7cace3,amd,Untopiced,[ROCm] Fix the flaky test test_stream_event_nogil (#53850)
13f63fda5f,skip,Untopiced,Automated submodule update: FBGEMM (#53722)
6da0b94dd8,composability,Untopiced,Add note on forwarding arguments in the dispatcher (#53641)
5344c3ea9e,distributed,Untopiced,Remove `join_workers` from Pipeline destructor. (#53433)
8d8a4a0624,distributed,Untopiced,"Remove the extra "":noindex:"" in ddp_comm_hooks.rst (#53855)"
d57ae6c46d,skip,Untopiced,Revert D26906509: Adding parallel support for the LLVM backend.
b69dd910e8,jit,Untopiced,[docs] Add starter content for new TorchScript language reference (#53837)
c15d943149,build_frontend,Untopiced,[PyTorch] Fix broken build caused by keyword missing on Windows (#53562)
06cf6d37b5,distributed,Untopiced,[ROCm] Enable test cases in test_data_parallel.py for ROCm (#52708)
dfb5f029da,distributed,Untopiced,Disable TF32 on DDP tests (#52941)
5c2b3d7784,distributed,Untopiced,[ROCm] Enable RNN test in test_c10d_spawn.py for ROCm (#52707)
d726ce6668,distributed,Untopiced,Support loading a non-DP/DDP model from a DP/DDP state_dict (#53224)
cffe9aa617,profiler,Untopiced,[libkineto] Log CUPTI errors on libkineto initialization
9f75de278f,autograd_frontend,Untopiced,Move common autograd utils functions from gen_variable_type.py to api/autograd.py. (#53340)
ce670238ba,skip,Untopiced,Revert D26927500: [libkineto] Log CUPTI errors on libkineto initialization
d4602b7e45,jit,Untopiced,[NNC] Fixes case where inlining wouldn't work because dim-size was 1. (#53254)
0c2fe02ec1,distributed,Untopiced,[DDP] Fix wrong call to dist.get_rank() (#53793)
e09e97ebf9,distributed,Untopiced,[DDP] add _distributed_rank helper function (#53795)
aeb3e93351,autograd_frontend,Untopiced,Move view handling logic to gen_inplace_or_view_type.py (#53341)
8737c2a1a2,jit,Untopiced,"[TensorExpr] Reland: ""Simplify index expressions constructed in loop flattening. Fixes #51173"" (#53861)"
1772e26f63,mobile,Untopiced,[PyTorch] Move selected_mobile_ops.h codegen function to tools (#53786)
38414d29a1,onnx,Untopiced,[ONNX] Remove the last Cast in pow symbolic_opset9 (#52646) (#53305)
57d1df071f,onnx,Untopiced,[ONNX] Support inplace operations on inplace indexing (#52063) (#53306)
7f17058894,onnx,Untopiced,[ONNX] Symbolic shape inference (#51481) (#53307)
be344e9d88,onnx,Untopiced,Update test cases generated by make_test() method to support running them in script mode. (#52748) (#53308)
8dab886d3b,onnx,Untopiced,[ONNX] enable several script unit tests using new jit passes (#51722) (#53309)
4c1d9e58c2,onnx,Untopiced,Fix copy_ export (#53046) (#53310)
a6a811f23a,onnx,Untopiced,[ONNX] Add repeat_interleave symbolic (#52855) (#53312)
705131c5d3,onnx,Untopiced,[ONNX] Update ONNX documentation (#51362) (#53313)
ee4ce8e9d9,onnx,Untopiced,[ONNX] fix export of embedding with padding_idx (#53053) (#53530)
a51f130d37,jit,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
4873641602,distributed,Untopiced,Fix TCPStore wait() hang when key is previously set (#53860)
ccab6680d5,quantization,Untopiced,[not for land yet] hacky fix for x.ndim followed by sub (#53120)
93d5807c1e,quantization,Untopiced,[not for land yet]fix using size of quant layer in torch._assert (#53187)
279b5372ab,quantization,Untopiced,[not for land] fix fx quant for quant_layer -> stack -> sum (#53196)
4884a6ab51,quantization,Untopiced,fx quant: clean up names of quantize handlers (#53614)
7297556d5d,autograd_frontend,Untopiced,Add support for single tensor in `inputs` argument for backward (#53827)
fff0a3f906,dataloader_frontend,Untopiced,[DataLoader] ZipIterDataPipe (#53554)
924c15c962,dataloader_frontend,Untopiced,[doc] reorg dist init and non-init functions (#52976)
a7ddd15d15,composability,Untopiced,fix static dispatch linker error (#53859)
ae7984b1d6,releng,Untopiced,Do not use shards for single run tests (#53883)
b00cdfe136,releng,Untopiced,Fix run_test_module logic (#53884)
d73e36a44a,quantization,Untopiced,ns for fx: change API to take nn.Module instead of GraphModule (#53075)
cc940f3580,quantization,Untopiced,ns for fx: change dtype cast from once per N node to once per node
421e91dfd2,quantization,Untopiced,ns for fx: add support for logging inputs
7d27eb8068,quantization,Untopiced,ns for fx: clean up API naming (#53729)
986e3c0a00,quantization,Untopiced,ns for fx: extract common code in tests to util functions (#53748)
19fe8a529e,quantization,Untopiced,ns for fx: move conv weight test case to new API (#53761)
9c8f112ada,quantization,Untopiced,ns for fx: move linear weight test case to new API (#53764)
a71cd135ae,quantization,Untopiced,ns for fx: move linear dynamic weight test case to new API (#53765)
01c6e9360e,quantization,Untopiced,ns for fx: move lstm dynamic weight test case to new API (#53772)
57bf13409a,quantization,Untopiced,ns for fx: move compare activations for conv test to new API (#53776)
2912ad1324,quantization,Untopiced,ns for fx: move linear activation test case to new API (#53777)
7f4aff8203,composability,Untopiced,Skip dispatch for is_signed (#53847)
804f3f9879,cpp_frontend,Untopiced,[PyTorch] Remove unnecessary assert in maybe_resize_storage_cpu (#53724)
90dfdef226,skip,Untopiced,[CUDA graphs] Private mempools for CUDA graphs (#51436)
7763bb6cb3,releng,Untopiced,Use the conda channel defined in docker.Makefile to install cudatoolkit (#53316)
91531d3047,caffe2,Untopiced,[caffe2] add a CAFFE2_NODISCARD macro to help support old compilers (#53754)
33aaea912a,caffe2,Untopiced,[caffe2] Support deserializing tensors using alternate serialization formats (#53403)
89fce74d55,python_frontend,Untopiced,fix for method_tests() random failures (#53854)
f62e9156dc,python_frontend,Untopiced,Add missing decorators in test_spectral_ops (#53736)
d4c877b59b,python_frontend,Untopiced,"Fix typo ""informations"" -> ""information"" (#53746)"
fdbd667e31,distributed,Untopiced,compareSet method for HashStore and FileStore (#53803)
fe38027fc3,python_frontend,Untopiced,[fix] torch.cat : cross-device check for out and input tensors (#53004)
76129c7cdf,skip,Untopiced,Revert D26993790: [pytorch][PR] [CUDA graphs] Private mempools for CUDA graphs
4932342363,jit,Untopiced,[Static Runtime] Fix bug in ClipRangesGatherRangesX2SigridHash (#53799)
afa1ff8e04,linalg_frontend,Untopiced,Implements `torch.linalg.lstsq` (#49093)
fe08671756,linalg_frontend,Untopiced,Added cuBLAS path for torch.triangular_solve (#53147)
00771eff8e,python_frontend,devs,[reland] Add OpInfo for `bitwise_not` (#53181)
5b648ef909,skip,Untopiced,Revert D26922420: [ONNX] fix export of embedding with padding_idx (#53053)
8a5b946ff6,caffe2,Untopiced,[caffe2] Don't call TensorImpl::size() in dim32() (#53852)
3078233e9a,distributed,Untopiced,[Gradient Compression] Make FP16 compression as a wrapper that can be combined with other communication hooks (#53808)
ce0fd095a8,jit,Untopiced,Implemented embedding_bag for SR (#52429)
ef07a04072,jit,Untopiced,[NNC] New APIs to get loops corresponding to a Buf (#53778)
317ff429d3,visualization,Untopiced,[TB] Support writing new style scalar (#53496)
3ce51fd5f4,skip,Untopiced,remove th_fill and th_mul dead code (#52546)
ca4aae85fa,distributed,Untopiced,[Gradient Compression] Update the docstring of fp16_compress_wrapper (#53955)
de70cdb66b,distributed,Untopiced,Clang format default_hooks.py (#53956)
84af0c7acd,foreach_frontend,Untopiced,Refactor ForeachUtils.h (#51131)
142c6b0e55,caffe2,Untopiced,increase timeout for test_op_nnpi_fp16
39f50f468d,python_frontend,Untopiced,matmul performance benchmarks (#51647)
d46978cc55,linalg_frontend,Untopiced,Refines test_orgqr_* skip (#53975)
7df176b1f9,linalg_frontend,Untopiced,Added OpInfo-based testing of some linalg functions (#51107)
790326d49b,linalg_frontend,Untopiced,Fixed the size of the workspace array in functions calling LAPACK (#53909)
319ab58e27,linalg_frontend,Untopiced,Skips test_linalg_lstsq on ROCm (#53977)
f6df18f6ca,caffe2,Untopiced,Clean up future imports for Python 2 (#53349)
d47d246206,releng,Untopiced,Add 'noarch' tests which only run in one CI config (#53747)
c2f41b6b84,python_frontend,Untopiced,"Add meta device to generic device testing framework, skip NotImplementedError (#53682)"
547f435763,structured_frontend,Untopiced,Fix restriding logic for structured kernels (#53759)
df7c0a06d6,python_frontend,Untopiced,[testing] assert no duplicate in method_tests for an OpInfo entry (#53492)
530dc828ae,mobile,Untopiced,[iOS GPU] Support element-wise broadcasting for binary ops in shaders (#53949)
bb21aea37a,mobile,Untopiced,[iOS GPU] Add the reset of binary ops (#53950)
2782126bfe,skip,Untopiced,Automated submodule update: tensorpipe (#53892)
700c817a6a,caffe2,Untopiced,Add install for libCaffe2_perfkernels_avx*.a (#53825)
8734e88f0b,distributed,Untopiced,delete has no more data after the key (#53886)
4f62c622b3,skip,Untopiced,Cleanup of unused list in adam.py (#53874)
da10ccd35f,python_frontend,Untopiced,Implements cpu_kernel_multiple_outputs and torch.frexp (#51097)
7e39a40300,skip,Untopiced,Fix typo in torchvision_models.py (#53968)
5b62b0d9bc,skip,Untopiced,[RPC] Fix typo in rref_context.cpp (#53978)
4bb34c2a75,foreach_frontend,Untopiced,Update Binary Ops with scalar lists (#49249)
b5cdb53af1,foreach_frontend,Untopiced,Add division logic to a slow/fast path (#49250)
7ff4955de5,linalg_frontend,Untopiced,[doc] Fix documentation for tensorsolve (#53320)
7f88840495,distributed,Untopiced,Fix prefix store timeout bug (#53928)
33e3deed4f,amd,Untopiced,add OneDNN relu backward and reshape backward (#49455)
793a29a7d5,amd,Untopiced,add OneDNN batch_norm backward (#50460)
67f765328b,releng,Untopiced,scripts: Change promote pypi to be more flexible (#53774)
65087dd1d4,cpp_frontend,Untopiced,Fix broken link from load_inline to new test location (#53701)
a7ba3f3aa8,skip,Untopiced,Automated submodule update: tensorpipe (#53999)
8f98b87212,skip,Untopiced,Update Kineto revision (#53940)
274b96b878,build_frontend,Untopiced,Move as_view/increment_version to its separate key. (#53342)
e87ab2ac4d,dataloader_frontend,Untopiced,[DataLoader] Switch to guaranteed determinism & add option to non_deterministic (#53532)
b9fdf72174,skip,Untopiced,Fix doc (#53996)
e91aeb0470,distributed,Untopiced,[4/n][torch/elastic][upstream] Move torchelastic/metrics to torch/distributed/elastic/metrics (#53870)
ee35060888,releng,Untopiced,Fix sharding algo + test it (#53942)
8c2c9450cc,package,Untopiced,[package] autoformat (#53783)
f52a3bd634,distributed,Untopiced,[DDP] remove dedupe check in reducer (#53919)
08f04c0db2,fx,Untopiced,Test forward reference annotations (#53713)
2c5579702a,jit,Untopiced,[PyTorch Mobile] Add module size to logged metadata (#53578)
603097be18,amd,Untopiced,OneDNN MaxPooling: reduce memory use for inference path (#52728)
4dd1c72dde,cpp_frontend,Untopiced,Treat Scalar parameter as if it is constant (#53582)
2ecb2c7931,composability,Untopiced,Pass Scalar by reference (#53583)
e8e570e9c5,releng,Untopiced,[MacOS] Cross compile stub when building for M1 on x86 (#54046)
bea3cb7069,composability,Untopiced,remove aliasMultinomial decode from TH and THC (#52585)
b27e678dfb,cuda,Untopiced,[RELAND] [CUDA graphs] Private mempools for CUDA graphs (#54038)
2c4a64589b,amd,Untopiced,fix mkldnn_add in-place behavior (#51687)
6332fd6255,releng,Untopiced,enable sc1090 and sc1091 (#54069)
1f5b9170aa,performance_as_product,Untopiced,Faster backwards for cumsum and cumprod (#53711)
c0fafcc766,python_frontend,Untopiced,Don't actually print anomalies in TTRR (#54078)
aa8714dfed,complex_frontend,Untopiced,[complex] torch.lerp: complex autograd support (#53689)
665d5e2a4f,jit,Untopiced,[PyTorch][JIT] Audit interpreter for extra copies (#54029)
3c457043fb,cpp_frontend,Untopiced,Also propagate storage_access_should_throw_ when copying tensor metadata (#53816)
d47fd3df81,composability,Untopiced,Compute type_equal() without reference to backend() (#53823)
4878415688,cpp_frontend,Untopiced,Make storage access error NotImplementedError (#53972)
282eefebf3,complex_frontend,Untopiced,Delete defunct ComplexCPU/ComplexCUDA dispatch keys (#54013)
524cb0a514,jit,Untopiced,[PyTorch Mobile] Dedup method names in bytecode serialization (#53677)
4b00bce156,distributed,Untopiced,[Gradient Compression] Introduce fp16_compress_wrapper in ddp_comm_hooks.rst (#54052)
dc070605f1,python_frontend,devs,TST Replaces assertEqualIgnoreTypes with assertEqual in test_indexing (#53115)
8533a485ea,cuda,Untopiced,Fix SIGSEGV in CudaIPCTypes.cpp. (#53080)
c4f50162be,caffe2,Untopiced,[typing] suppress errors in `fbcode/caffe2` - batch 2
252916ab61,skip,Untopiced,Update TensorPipe submodule (#54070)
b936abd840,cpp_frontend,Untopiced,fix nest openmp performance bug in thnn_conv2d (#52577)
fb7bab97c4,skip,Untopiced,Automated submodule update: FBGEMM (#53947)
04d5278cb6,jit,Untopiced,[Static Runtime] Only run ReplaceWithCopy pass when enable_out_variant is true (#54111)
11a135ec82,skip,Untopiced,Remove _th_take (#52665)
0c8f16622b,caffe2,Untopiced,[caffe2] Rework CAFFE_ENFORCE_THAT (#53303)
2e8a9d2bfe,mobile,Untopiced,[iOS GPU] Support multi-dimension tensors via MPSImage (#54106)
e579b39b9e,mobile,Untopiced,[iOS GPU] Implement view and reshape in metal shaders (#54107)
527c1e0e37,mobile,Untopiced,[iOS GPU] Remove unnecessary texture size changing (#54108)
ce15f312a8,cpp_frontend,Untopiced,[PyTorch] Align function parameters across declaration and definition for max pool 2d (#54105)
8f1af02f35,mobile,Untopiced,[PyTorch][mobile] Audit mobile interpreter for extra copies (#54031)
4a24c552cc,jit,Untopiced,[PyTorch] Fix string copy in WARN path for both interpreters (#54076)
ce40ff5c64,distributed,Untopiced,Avoid DDP race condition with find_unused_parameters=True when all params are used (#53160)
91747a5e93,distributed,Untopiced,add tests for ddp with activation check points (#52894)
0806126aad,fx,Untopiced,[fx][trivial] Add TestConstFold coverage to test_fx (#54072)
a852fdb6b5,jit,Untopiced,[NNC] Test for using int64 dimensions (#54094)
7367bca066,jit,Untopiced,[NNC] Tests for proposed feature: loop bounds conditional simplification (#54121)
f30a7a2739,releng,Untopiced,Add export-historic-test-times option to dump S3 test times into a JSON file (#54083)
7e7533b2e2,composability,Untopiced,Delete denseTypeIdWithDefault and toDense (#54016)
a2a7179695,python_frontend,Untopiced,Fix bug in assertRaises NotImplemented handling when no exception is thrown (#54126)
ccdcfba5de,caffe2,Untopiced,[caffe2] Refactor tensor serialization function (#53404)
2e7311ef25,releng,Untopiced,First step to refactoring S3 reading logic (#53755)
fd5c1123e4,jit,Untopiced,wrap AliasDb in Python (#51336)
79534867ac,composability,Untopiced,Migrate about 100 kernel to C10 full dispatcher (#54109)
8cc06e3ca3,distributed,Untopiced,Disable CUDA RPC tests that use new device in user-function outputs (#54023)
e442d5c8a5,distributed,Untopiced,Disallow CUDA RPC to use new devices in output tensors (#54024)
957700be7e,performance_as_product,Untopiced,Improved aten::to performance from inline cvr remote_request_only (#53800)
cd776560d0,vulkan,Untopiced,[vulkan] Add hardswish and hardsigmoid activations to Vulkan (#53362)
407d60ee91,releng,Untopiced,Upgrade actions/setup-python from v1 to v2 (#54202)
8f61b13e80,mobile,Untopiced,[Pytorch Mobile] Optimize Non Forward for Mobile (#53314)
94b22b5b3b,releng,Untopiced,try catch test upload failures (#54194)
7d1e1c7e0d,distributed,Untopiced,Pyre-ify torch.jit.interface's (#54084)
06cb9293c5,releng,Untopiced,Add GitHub Actions workflow to test tools (#54207)
2eb3917629,vulkan,Untopiced,[Vulkan] Add reflection_pad2d to Vulkan (#53604)
8ecb2d35bc,dataloader_frontend,Untopiced,Add ability to override _reduce_ex_ function of DataPipe (#52858)
74993dcf7b,skip,Untopiced,Add repeats to Timer.collect_callgrind(...) (#53295)
ac78d05d05,skip,Untopiced,[Kineto] Update rev for fix to #53848 (#54226)
a4f0f8b1e9,distributed,Untopiced,[distributed] add base processgroup::options (#53662)
f4a044ca1d,distributed,Untopiced,[distributed] add options field in ProcessGroupGloo/NCCL (#54090)
fef0219f7e,amd,Untopiced,[ROCM] Fix hipfft transform type error (#53411)
ef9ee46756,distributed,Untopiced,Avoid modifying rebuild buckets state in no_grad context (#54159)
ca429fedd3,jit,Untopiced,[StaticRuntime] Fuse SigridTransforms + ListUnpack (#53920)
0dc5abfaa9,skip,Untopiced,Revert D26907093: Add repeats to Timer.collect_callgrind(...)
255b103c1b,fx,Untopiced,[WIP] Function to retrieve inspect.Signature instances for PyTorch ops (#53830)
a27f46bbe3,fx,Untopiced,[FX] Experimental type annotation pass using Python signatures (#53831)
72c7983f23,composability,Untopiced,Remove __get__ from Tensor stub. (#54208)
2d8795c552,fx,Untopiced,[FX] Normalize torch. namespace ops (#53832)
133000fe7a,distributed,Untopiced,[distributed] add processgroup options as argument (#53663)
c618dc13d2,skip,Untopiced,Use type-erased union for Buffer. (#322)
8caa7889fc,skip,Untopiced,Revert D27001339: Use type-erased union for Buffer.
2f3b194dc2,cuda,Untopiced,Add cusolver potrf and potrfBatched to the backend of torch.cholesky decomposition (#53104)
564456ac44,autograd_frontend,Untopiced,Added autograd support for torch.orgqr (#52637)
382a47b493,linalg_frontend,Untopiced,Add torch.linalg.vector_norm function (#51099)
444552e7f9,jit,Untopiced,Optimize alias_analysis node lookup (#54115)
9f86b656ba,jit,Untopiced,Resubmit: Adding parallel support for the LLVM backend. (#54122)
dc35848804,composability,Untopiced,[PyTorch] Rename XPLAT_MOBILE_BUILD to TEMPLATE_SELECTIVE_BUILD (#54217)
4b2abc4b8e,jit,Untopiced,[NNC] Adding API to distribute loops (#53865)
a52e295cbb,releng,Untopiced,Add MyPY to lint GHA workflow (#54067)
cba8516b52,autograd_frontend,Untopiced,make internal forwardAD methods on at::Tensor internal (#54099)
a425eb2135,autograd_frontend,Untopiced,Add size check for forward grads (#54100)
09b4af2f0f,skip,Untopiced,Remove legacy from optional-related function names (#54101)
004db37358,autograd_frontend,Untopiced,properly make AutogradMeta/DifferentiableViewMeta attributes internal (#54102)
cc92117aad,autograd_frontend,Untopiced,cleanup static_cast of AutogradMeta (#54103)
f0056f89a4,cuda,Untopiced,Final kernel launch checks (#54214)
04a2506091,skip,Untopiced,Fixed the size of the workspace array in functions calling MAGMA (#54009)
d85faf8d8e,releng,Untopiced,Cleanup mypy lint job (#54260)
3b1e3103ca,profiler,Untopiced,Remove usage of onEachDevice from legacy profiler (#54125)
0645e2b490,releng,Untopiced,"Use shard file if present, improve functions used for sharding (#54210)"
a95abc4648,releng,devs,Test tools/test_history.py (#54259)
90bbe0b38b,build_frontend,Untopiced,cmake: auto-detect ccache to speed up developer builds (#49389)
4626886f21,jit,Untopiced,[jit] Add CUDNN Conv-Add-Relu fusion for Frozen Model Optimization (#52102)
8cd4dac78f,releng,Untopiced,Move mypy wrapper to tools (#54268)
75498164fe,releng,Untopiced,Remove nonexistent files (#54276)
04e0cbf5a9,nn_frontend,Untopiced,"Add padding='same' mode to conv{1,2,3}d (#45667)"
53d8778b4d,skip,Untopiced,Update clang-format linux hash and yaml import calls (#53932)
bbb06c05a8,releng,Untopiced,remove type_hint_tests and convert the files to use the new test style (#53167)
19792b45db,releng,Untopiced,add a pytest.ini file (#53152)
bfd009836e,python_frontend,Untopiced,"[torch.special] Add special.erf{c, inv} (#53260)"
acf03b13f1,jit,Untopiced,[Static Runtime] Check for number of uses of op inputs > 1 in ReplaceWithCopy (#54230)
8f755b9ed0,python_frontend,Untopiced,initial draft for assert_tensors_(equal|allclose) in torch.testing (#53820)
a84afb3a7c,distributed,Untopiced,Use type-erased union for Buffer. (#54251)
f2b4b0e9eb,skip,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
887759c9b9,autograd_frontend,Untopiced,Changes to autograd/custom functions to handle optional arguments (#54270)
544a996f83,skip,Untopiced,Revert D27155845: [pytorch][PR] Fixed the size of the workspace array in functions calling MAGMA
e0aebe241d,composability,Untopiced,Refactor tensor_new.cpp to use TensorOptions instead of DispatchKey (#54034)
49f1336106,composability,Untopiced,"Add Tensor::is_cpu, genericize TensorIterator (#54079)"
645a3e9a92,composability,Untopiced,Fix inaccurate dispatch tables (#54127)
cc7a28d727,python_frontend,devs,Refactor Unary Ops tests (#49712)
61b074581c,complex_frontend,Untopiced,`torch.prod` backward for complex types. (#48125)
bc4f521178,structured_frontend,Untopiced,port at::mul to structured (#52692)
05a03a6c8c,fx,Untopiced,[FX][EZ] Fix type correctness on GraphModule.graph (#54305)
fa07d0c8eb,releng,Untopiced,.github: Add workflow to build libtorch (#53292)
f1cbd10276,caffe2,Untopiced,[PyPer] Port c2 add to pt (#54229)
da18313de3,caffe2,Untopiced,[caffe2] expose whether FBGEMM is available to the Python code (#54274)
679f07a017,releng,Untopiced,Backup .circleci/config.yml before regenerating (#54345)
454dd7ba86,onnx,Untopiced,Add codeowners for onnx export (#54287)
779cae9e42,structured_frontend,Untopiced,port at::pow to structured (#53669)
fa482aa4ef,structured_frontend,Untopiced,"port sub to structured, fix sub.Scalar bug (#53679)"
6f7a5a47af,structured_frontend,Untopiced,port div to structured (#53680)
6a4d2c61d5,build_frontend,Untopiced,Allow linking against vcomp on Windows (#54132)
27048c1dfa,cpp_frontend,Untopiced,Remove legacy constructor calls from _torch_ folder. (#53889)
270d675f86,distributed,Untopiced,update distributed doc table for alltoall nccl (#54277)
41b1ea216f,linalg_frontend,Untopiced,Fix `torch.linalg.qr` example (#54342)
d58c00a5d8,package,Untopiced,[package] Make exporters write to buffer in fbcode (#54303)
9d9986fd10,python_frontend,Untopiced,Support for Half / bfloat16 / index_select and better testing (#53898)
4fa47e5e7d,python_frontend,Untopiced,Support non-tensor inputs and outputs for checkpointed functions. (#52422)
98baad5764,jit,Untopiced,[NNC] Remove cached argv from LLVMCodeGen to fix race condition (#54286)
08e4312559,skip,Untopiced,Tag distributed team for review for /torch/nn/parallel (#54221)
8294bff20d,jit,Untopiced,[StaticRuntime] Copy version of reshape/flatten (#54353)
cffa70d36d,distributed,Untopiced,Merge channel hierarchies. (#54333)
f48a9712b7,jit,Untopiced,Rewrite functional.tensordot to be TorchScript-able (#53672)
fc58b3f146,python_frontend,Untopiced,Skips failing pinv and pinverse test (#54392)
80a4a50081,skip,Untopiced,Automated submodule update: FBGEMM (#54118)
ab8e9188dc,releng,Untopiced,add --gpu-max-threads-per-block=256 to hipMAGMA build (#54161)
7b939d934e,python_frontend,devs,Simplifes OpInfo test matrix to reduce test time (#53255)
4ffafbac40,python_frontend,Untopiced,Make test_cpp_extensions_aot handle lack of pytest more gracefully (#53740)
36ce673f16,jit,Untopiced,Disable the fusion group which is not supported by XPU device. (#54239)
d226985257,composability,Untopiced,"Read out layout from options directly, rather than via backend (#54074)"
635595f706,releng,Untopiced,Change sharding in ci (#54228)
2355f61f19,caffe2,Untopiced,Add logging for debugging S223170
ef472d5b31,quantization,Untopiced,"Back out ""[PT QNNPACK] Temporarily disable input pointer caching"" (#52917)"
b6bbb41fd8,python_frontend,Untopiced,Temporary disable TestNumbaIntegration.test_from_cuda_array_interface* (#54430)
afb560065c,python_frontend,devs,[testing] OpInfo for sgn and sign (#53885)
c2c97cd290,jit,Untopiced,<tensorexpr> Add python bindings for missing loop transformations in LoopNest (#54355)
19f77700ec,skip,Untopiced,clean up typos in submodule (#54372)
a46d56f988,skip,Untopiced,Update tensorpipe submodule. (#54412)
6e7a3c1fdd,skip,Untopiced,Clang-format distributed.py (#54402)
8bb07c7e21,build_frontend,Untopiced,[CI]Install older cmath during Windows build (#54431)
17f9b5ff4a,caffe2,Untopiced,[caffe2] increase deadline of test_dnnlowp_batch_matmul_int_constant_B (#54241)
7bda8b650c,caffe2,Untopiced,[caffe2] Fix caffe2 build with TensorRT support (#54322)
263cd5cf98,releng,Untopiced,Disable all cu92 in scheduled-ci (#54421)
1e09880b45,jit,Untopiced,Add support for list insertion for mutation removal (#54271)
0f628d1503,build_frontend,Untopiced,[ROCm][doc] add ROCm section for building from source (#53845)
f1e72a7e18,releng,Untopiced,add uncommit change detector (#54373)
9fef25e579,mobile,Untopiced,[Pytorch Mobile] optimize_for_mobile: Remove dropout from any function (#53846)
4919fecf23,cpp_frontend,Untopiced,Delete dead TensorOptions::key_set (#54004)
2130f4ccc4,jit,Untopiced,Use c10::ArrayRef instead of std::vector for the jit::unpickle's tensor_table. (#54428)
5a27199149,composability,Untopiced,Add device_of overload for optional<Tensor> (#54262)
edfc787df4,composability,Untopiced,Migrate kernels with Tensor? to C10 full dispatcher (#54263)
92770d25cd,skip,Untopiced,fix comparison of narrow type with wide type in loop condition (#53951)
2668149b8c,jit,Untopiced,Export torch::jit::toIValue (#54449)
decbdf7b0b,distributed,Untopiced,"Get rid of {Cpu,Cuda}{Channel,Context} in tensorpipe_agent. (#54432)"
568d43b935,skip,Untopiced,Automated submodule update: FBGEMM (#54447)
7e33dc3498,jit,Untopiced,[PyTorch] Avoid extra intrusive_ptr copy in IValue::toIntrusivePtr (#54124)
3959d393b8,jit,Untopiced,[PyTorch][JIT] Less shared_ptr use in dictConstruct (#54110)
18c04a3f0f,jit,Untopiced,Avoid dispatch overhead in call to mkldnn convolution (#52614)
81c6e5fb38,jit,Untopiced,use reshape when possible in broadcasting (#53326)
9be4c75fa0,jit,Untopiced,[jit] Add Reinplacing to MKLDNN Subgraphs (#53908)
c411017a41,skip,Untopiced,Only allow hub.load() from original repo. (#54451)
52abd3bd7b,jit,Untopiced,[Static Runtime] Fix bug in reshape_copy (#54467)
5870346173,cpp_frontend,Untopiced,Port index_copy from TH to ATen (#52203)
77ccd4f9a3,distributed,Untopiced,[5/n][torch/elastic][upstream] Move torchelastic/agent to torch/distributed/elastic/agent (#54343)
349a17f1c0,cpp_frontend,Untopiced,Replace some tensor.device().is_cpu() calls with direct tensor.is_cpu() (#54397)
c00d66f73c,composability,Untopiced,Move compute_native_function_declaration to its own dest module (#54419)
bf2ca35f35,structured_frontend,Untopiced,Rejigger to use NativeFunctionsGroup even without structured: True (#54426)
6e8c4ad7fd,structured_frontend,Untopiced,s/StructuredNativeFunctions/NativeFunctionsGroup/ (#54427)
6d0027197c,composability,Untopiced,Delete all unnecessary singular Math entries (#54436)
c22fc448cd,distributed,Untopiced,[Gradient Compression] Remove cuda.syncrhonize in batched powerSGD (#54482)
8518b0ee55,skip,Untopiced,[PyTorch] Update Bazel build for TensorPipe (#54416)
1041fdd069,nn_frontend,Untopiced,Grammatically update tech docs (#54370)
3519625a34,onnx,Untopiced,Fix onnx warning message (#54371)
f2a38a0edd,python_frontend,Untopiced,Enabled BFloat16 support for argmax & argmin on both CPU & CUDA (#52582)
fee470d8ef,jit,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
2a53897114,jit,Untopiced,[jit][tensorexpr] Added aten::batch_norm into fuser when in inference mode (#54204)
a4a21e7d8d,skip,Untopiced,Automated submodule update: FBGEMM (#54486)
ba9f12d235,releng,Untopiced,Fix minor whitespace typo in tools/test_history.py (#54504)
f3c00047ce,caffe2,Untopiced,Reset Optimizer counter while deserializing netWithBackwardOptions
acffa604cc,releng,Untopiced,disable cu112 test on windows (#54512)
583c4bf7d3,mobile,Untopiced,[Pytorch Mobile] optimize_for_mobile: Fuse Add Relu on any function (#54441)
21a9a93eb4,releng,Untopiced,gdb special command to print tensors (#54339)
446e477d4f,complex_frontend,Untopiced,[complex] torch.rsub(): complex autograd support (#53702)
e5b97777e3,amd,Untopiced,[ROCm] allow PYTORCH_ROCM_ARCH in cpp_extension.py (#54341)
1b792a7f15,skip,Untopiced,Fix Flake8 (#54540)
35186eb983,skip,Untopiced,Update TensorPipe submodule (#54507)
c06d979731,jit,Untopiced,[Static Runtime] Name refactoring to make MemoryPlanning more readable (#54045)
792f5ffb83,releng,Untopiced,Also strip slow_test (#54528)
345b26ca08,mobile,Untopiced,[android][utils] Support ChannelsLast in TensorImageUtils (#48990)
f9e7f132fb,linalg_frontend,Untopiced,Added torch.linalg.matrix_power (#52608)
591084abb8,linalg_frontend,Untopiced,Deprecate torch.matrix_power in favor of torch.linalg.matrix_power (#53538)
7e3cf1ee24,python_frontend,Untopiced,[pytorch] Add native support for segment reduce step1: API definition (#53727)
4a74b0f2dd,fx,Untopiced,Fix logic in TestFX.test_get_torch_func_signature_exhaustive (#54510)
5754816597,releng,Untopiced,fix SC2126 introduced error (#54545)
66a3614b47,releng,Untopiced,Fix typo in .github/workflows/lint.yml (#54551)
91d37d7d2f,releng,Untopiced,[CI] Install compatible cmath for Win binary builds (#54527)
33b95c6bac,nn_frontend,Untopiced,Add __torch_function__ support for torch.nn.functional.embedding (#54478)
5781aec74e,skip,Untopiced,Automated submodule update: FBGEMM (#54509)
b93ab10b7a,complex_frontend,Untopiced,torch.lerp: cuda complex support (#54129)
789dc6d445,distributed,Untopiced,[NCCL] Add more details for checkForNCCLErrors (#54117)
5cd8a77e01,python_frontend,Untopiced,Skip inplace autograd test if inplace variant doesn't exist (#54460)
5105250e16,fx,Untopiced,[FX] Add docs for shape propagation (#54554)
601e79200d,jit,Untopiced,[NNC] Implementing LoopFusion (#54461)
afe339d7dd,jit,Untopiced,[static runtime] support DictConstruct (#54438)
a4ca394f8a,benchmark,Untopiced,"Revert ""Revert D26907093: Add repeats to Timer.collect_callgrind(...)"" (#54484)"
0d81528a47,benchmark,Untopiced,Definition infrastructure for instruction count ubenchmarks (#53296)
d3f784244e,caffe2,Untopiced,fix comparison of narrow type with wide type in loop condition part2 (#54471)
bac566bf61,python_frontend,Untopiced,torch.square : OpInfo and minor fixes (#52551)
c371542efc,python_frontend,devs,testing: dont skip test_ops suite for operators testing against scipy (#54186)
05c8ddfe05,skip,Untopiced,[AutoAccept][Codemod][FBSourceGoogleJavaFormatLinter] Daily `arc lint --take GOOGLEJAVAFORMAT`
732815af7a,skip,Untopiced,Automated submodule update: tensorpipe (#54582)
67e4618037,nn_frontend,Untopiced,Add arg layer_norm_eps to transformer layers (#54494)
2f5db68797,releng,Untopiced,Make nightly checkout work with generated testing py (#54477)
f9ca0d87a7,complex_frontend,Untopiced,Teach Python TS frontend to parse complex literals (#52881)
12a61a172e,skip,Untopiced,Fix missing class in cpp tensor documentation (#54488)
2b07bcf9eb,benchmark,Untopiced,[operator benchmarks] Added more interpolation test cases (#54584)
b032316c41,nn_frontend,Untopiced,Improve `nn.Sequential` documentation (#53380)
87989a6cf9,caffe2,Untopiced,[caffe2] support serializing float data as bfloat16 (#53735)
145bc5cd51,composability,Untopiced,Rename Math to CompositeImplicitAutograd (#54466)
556fc8d418,linalg_frontend,Untopiced,skip test_symeig if MAGMA not detected (#54526)
d371a9f9c5,composability,Untopiced,Change ScatterGather kernel names on dtype dispatch. (#54498)
796be045bb,autograd_frontend,Untopiced,Refactor gradcheck (#53857)
673ed4623e,autograd_frontend,Untopiced,Gradcheck small fixes (#53916)
7605ce4ed8,build_frontend,Untopiced,[PyTorch] Enable test_lite_interpreter_runtime running in android (#54579)
ac33432606,linalg_frontend,Untopiced,Fixed out= variants of non-symmetric eigendecomposition and QR decomposition (#54056)
1442a92741,distributed,Untopiced,Ensure local_used_maps_tmp is distinct from local_used_maps_[i] (#54474)
347ab5d8b8,skip,Untopiced,Update Kineto submodule (#54621)
6f8328ef44,python_frontend,Untopiced,[special] Add special.entr (#53500)
1ceb90405b,jit,Untopiced,[TensorExpr] Add plumbing for conv2d fusion. (#54439)
fe2c1268b7,jit,Untopiced,More name refactoring of memory planning codes to make it more readable (#54272)
64d31e3f45,caffe2,Untopiced,Add double tensor type to DivFakeFp16 Op (#54636)
9f336bdf10,nn_frontend,Untopiced,Fixes new tf32 failures in test_nn.py (#52871)
947ab84fd2,nn_frontend,Untopiced,enable_and_enhance_bf16_threshold (#54384)
2662e34e92,jit,Untopiced,Add PyTorchDeploy predictor model type (#54120)
c0bcd5a58f,distributed,Untopiced,Remove NestedTensor from DefaultBackend alias (#54559)
55dfb4a575,skip,Untopiced,Update CODEOWNERS for distributed training (#54661)
6cdabb2e40,releng,Untopiced,Update .gitignore to ignore NFS handle files (#54618)
9029d0d7d8,cpp_frontend,Untopiced,Introduce a fluent API to construct tensors from external data. (#54530)
93bbbeccf7,python_frontend,Untopiced,Make SharedCache thread-safe (#53750)
267fc27d39,jit,Untopiced,Ensure torch.futures.wait_all exits early on error. (#53953)
4bf90558e0,distributed,Untopiced,[Gradient Compression] Add logging for gradient compression stats. (#54647)
f251bb40c1,releng,Untopiced,Cancel redundant GHA workflows (#54685)
0b0a5dd35f,skip,Untopiced,Revert D27327999: [pytorch][PR] Cancel redundant GHA workflows
d12118c0aa,nn_frontend,Untopiced,Handle stride > 1 with im2col in CUDA thnn conv2d (#54080)
53596cdb73,skip,Untopiced,Remove hacky wrapper for about 100 kernels (#54367)
71b9f2dd76,releng,Untopiced,Add GHA to cancel redundant GHA workflows except on master (#54689)
f1edaabc35,structured_frontend,Untopiced,Simplify creation of unary structured kernels. (#54592)
a7c7fc96ff,structured_frontend,Untopiced,Add doc warnings for default SELU gain (#54057)
9c60fc9cd9,mobile,Untopiced,Fix broken javadoc URL in README (#54434)
911b8b1bfc,package,Untopiced,[package] rename PackageExporter.external to PacakgeExporter.extern_modules (#54601)
68bdeef2ce,build_frontend,Untopiced,[CMake] Simplify CPU architecture detection logic (#54637)
3bb0f1f343,skip,Untopiced,Automated submodule update: tensorpipe (#54686)
dfc7fa03e5,linalg_frontend,Untopiced,lu_backward: more numerically stable and with complex support. (#53994)
6b7652e26c,distributed,Untopiced,[DDP logging] Prefer use of c10::Join (#54649)
9db4802184,jit,Untopiced,[fuser] Support bfloat16 (#54571)
fd58ececab,releng,Untopiced,Pin autocanceling GHA repo to specific commit (#54738)
a28c7db9f9,fx,Untopiced,[FX] Garbage collect values in Interpreter (#54726)
b81e10a291,fx,Untopiced,fx quant: fix bug with fusion patterns and disabling quantization (#54654)
c656a5befa,fx,Untopiced,[FX] Normalize Python operators to `torch.` ops when called with Tensors (#54236)
52a8075f16,fx,Untopiced,ns for fx: add support for lstm activation matching (#53779)
3dc8ba27a5,quantization,Untopiced,ns for fx: move shadow activations conv test to new API (#53818)
cfe7364809,quantization,Untopiced,ns for fx: move shadow activations linear test to new API (#53819)
9e8e744efe,quantization,Untopiced,ns for fx: move shadow lstm test to new API (#53828)
454832e5fa,quantization,Untopiced,ns for fx: create subgraph type (#54253)
182d8c375c,quantization,Untopiced,ns for fx: add partial support for subgraphs with base_op_node (#54254)
0a18211989,quantization,Untopiced,ns for fx: add weight matching for linear fp16 emulation (#54257)
b7b481bd07,caffe2,Untopiced,[PyTorch] Enable template build at aten operator level (#53801)
5e62da2efd,distributed,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
1126d51de9,linalg_frontend,Untopiced,Remove useless contiguous calls from torch.matmul (#54616)
d4045e9aa1,releng,Untopiced,initial commit to refactor all s3 access codes to s3_stats_parser (#54681)
645119eaef,nn_frontend,Untopiced,Lowering NLLLoss/CrossEntropyLoss to ATen code (#53789)
f6634be4c2,python_frontend,devs,Fix OpInfo failing without scipy (#54735)
2be1b486ce,skip,Untopiced,Drop Python 2 support in common_device_type.py (#54691)
20d8fe83cd,skip,Untopiced,[TSAN] Suppress data races in caffe2/c10/util/Logging.cpp
4399aadcc7,releng,Untopiced,add sndfile yum package to centos dockerfile (#54687)
5c6208abba,releng,Untopiced,remove docker dir (#54729)
70dd2a2bdd,skip,Untopiced,Add myself on all native_functions.yaml code reviews (#54595)
13b1ca9466,composability,Untopiced,Rename DefaultBackend to CompositeExplicitAutograd (#54470)
db3a9d7f8a,nn_frontend,Untopiced,Fix __torch_function__ tests. (#54492)
0435059ddf,distributed,Untopiced,docs: fix docstring signature in `all_reduce_multigpu` (#54665)
df70e2fde5,autograd_frontend,Untopiced,Refactor get analytical jacobian (#54049)
1e9ad6e5cd,jit,Untopiced,[jit] Fix TupleType.annotation_str to conform to `typing` module syntax for empty tuple type (#54641)
3db2333d09,jit,Untopiced,[jit] Make NoneType annotation_str emit `NoneType` instead of `None` (#54642)
14a2501786,build_frontend,Untopiced,Update max-version in setup.py to 3.9 (#54690)
ee73c752c6,skip,Untopiced,Delete unnecessary empty file (#54796)
593295daac,composability,Untopiced,Migrate kernels with TensorOptions to C10 full dispatcher (#54539)
416ba5c48f,jit,Untopiced,Merge CUDA Streams and Events (#53902)
394b720e38,cuda,Untopiced,Fix raw_deleter() bug with PYTORCH_NO_CUDA_MEMORY_CACHING=1 (#54775)
f22bad752d,skip,Untopiced,Move some variable ops out of VariableTypeManual. (#54459)
ba1f640928,python_frontend,Untopiced,Optimize memory usage in logsumexp_out (#51239)
0e320ddb36,jit,Untopiced,Lazily initialize alias db constant prop (#54640)
2620bce42a,amd,Untopiced,[ROCM] load only hipfft separately past rocm4.1 (#54349)
71201340c6,cpp_frontend,Untopiced,Remove 13 hacky wrapper not required (#54793)
e542e67253,jit,Untopiced,[NNC] Test case for computeAt with reduction (#54755)
24f589df44,jit,Untopiced,[NNC] Disabled test case for failure in implementing conv1d (#54756)
e4d19798f3,jit,Untopiced,[NNC][tests] Convert a bunch of FileCheck to checkIR
316804e373,distributed,Untopiced,[test_c10d] Add wait in nccl high priority stream test (#54714)
f612d4eb58,distributed,Untopiced,Add 'remote_parameters' and 'get_module_rref' to RemoteModule docs. (#54645)
8eb896ce99,jit,Untopiced,Improve error message while setting error twice. (#54464)
d63dd07f06,complex_frontend,Untopiced,Add JIT support for cmath unary ops (#54089)
1d5cc6c53d,autograd_frontend,Untopiced,Move requires_grad_/backward out of VariableTypeManual. (#54543)
65781f94ad,distributed,Untopiced,Enable faulthandler for distributed tests. (#54531)
6eaf96961d,skip,Untopiced,[codemod] fix tautological imports
d59fb7a2f6,complex_frontend,Untopiced,Add complex autograd support for `torch.unfold` (#52999)
e5634f5f25,distributed,Untopiced,More types for torch (#54037)
e70f3d1189,jit,Untopiced,Nasty little hack to preserve NotImplementedError raised in interpreter (#54627)
90e70ace9b,linalg_frontend,Untopiced,Fix some more native_functions.yaml mistakes (#54597)
05fa570bbc,python_frontend,Untopiced,"Add empty_generic, which allocates an empty tensor in a device-generic way (#54703)"
d9a7c758e1,linalg_frontend,Untopiced,Rename linalg.det test so that it generates a valid method name (#54704)
b5ab348253,python_frontend,Untopiced,Fix missing format string qualifier (#54705)
ed560cf2c6,skip,Untopiced,Disambiguate where 'Doesn't run' error message comes from (#54706)
c9e0aab2bf,nn_frontend,Untopiced,Make convolution_overrideable default implementation raise NotImplementedError (#54707)
6445c9a1cb,composability,Untopiced,"Avoid testing device in cdist when called in a ""Math"" context (#54708)"
c782949e17,jit,Untopiced,Make the fuser raise NotImplementedError when unknown device is hit (#54709)
f067972527,composability,Untopiced,Make memory overlap a little less precise so it works with null data ptr (#54710)
2309173143,composability,Untopiced,Compute Tensor::toString() without reference to backend (#54711)
7caa464631,skip,Untopiced,Implement public API InferenceMode and its error handling (#53343)
671f80a313,distributed,Untopiced,[c10d] s/torch::autograd::variable/at::Tensor/g (#54763)
5c3d80d8fa,distributed,Untopiced,[DDP] Mark a few variables as const in reducer (#54764)
695eef05a4,caffe2,Untopiced,optimizer exploration - v1 and v2 + fix position_weighted optimizer + decoupled weight decay (#54042)
eec48303c0,cpp_frontend,Untopiced,Make index_add take a scalar argument alpha (#54176)
0527d14248,python_frontend,Untopiced,[numpy] Add torch.take_along_dim (#52833)
01b1557014,performance_as_product,Untopiced,enable bf16 vec copy (#54671)
07350da3b4,performance_as_product,Untopiced,enable bf16 for cat serial kernel (#54674)
b7c5d57563,python_frontend,Untopiced,[testing] support op with args/kwargs in test_unary_ufunc (#52194)
9e6877c5c5,python_frontend,devs,Port torch.outer method_tests() to OpInfos (#54798)
a0a7a2d648,quantization,Untopiced,"[quant][fx] store dtype, axis as literals in the graph (#54624)"
4e5af53d29,skip,Untopiced,Deprecate legacy constructor `torch.Tensor()` (#54414)
86b1f4e9f2,memory_format_frontend,Untopiced,fix silent correctness bug with channels_last usage of upsample cuda kernels (#54744)
6d2bf76bba,releng,Untopiced,Using latest windows CUDA exe (#54596)
2fd1eb3a9f,releng,Untopiced,make all arguments in test_history.py optional kwarg (#54797)
94efb48e16,complex_frontend,Untopiced,Adds the cfloat dtype to the eager and jit variant consistency tests (#54854)
1f36ce6e4d,python_frontend,Untopiced,Restore storage on meta tensors; increase meta coverage (#53973)
3ddc6174da,skip,Untopiced,Raise error in clip_grad_norm_ if norm is non-finite (#53843)
717e70a824,releng,Untopiced,(BE) Refactor get-test-times-from-S3 into s3_stat_parser (#54808)
68af6d9565,complex_frontend,Untopiced,Use custom sqrt if stdc++ does not fall back to C99 csqrt (#54820)
56f12e6199,skip,Untopiced,Add annotations to PRs from forks (#54779)
12a454788b,python_frontend,Untopiced,docs: fix parameter in `torch.take` (#54667)
84232b762b,cuda,Untopiced,docs: add `reset_peak_memory_stats` in cuda.rst (#54668)
59d1f08b4c,onnx,Untopiced,"docs: fix docstring signature of torch.{onnx,utils} (#54662)"
475251631b,jit,Untopiced,docs: reference links to serialization.html (#54659)
7eef0c3ab5,nn_frontend,Untopiced,docs: add functional group_norm (#54673)
02f5c50828,nn_frontend,Untopiced,docs: separate autosummary for flatten layers (#54663)
6dedecc77c,python_frontend,Untopiced,docs: add `memory_format` in torch.empty (#54664)
74e01c1dd9,autograd_frontend,Untopiced,docs: change to FloatTensor for `requires_grad=True` (#54658)
63997db6ec,jit,Untopiced,[jit] fix freezing with mkldnn tensors (#54632)
9ef53f7e0f,skip,Untopiced,docs: remove extra backticks in `narrow_copy` (#54669)
1551bcc670,caffe2,Untopiced,change logging.warn to logging.warning (#51727)
263180d7fc,skip,Untopiced,Revert D26973911: Implement public API InferenceMode and its error handling
3187a71bbe,releng,Untopiced,[test] vc toolchain modification (#54589)
ec1bbe130c,skip,Untopiced,Revert D27364777: [pytorch][PR] Add annotations to PRs from forks
67d44377e3,skip,Untopiced,Remove hacky wrapper for about 100 kernels (#54751)
51fa25443f,skip,Untopiced,[PyTorch][easy] Move strings into class_::defineMethod (#54533)
ff537b77ff,skip,Untopiced,[PyTorch][easy] Move more strings in torch::class_ (#54547)
8cf97cbb55,amd,Untopiced,[ROCm] add 4.1 to nightly builds (#54635)
7c8b0f2600,complex_frontend,Untopiced,Test torch.chain_matmul for complex dtype (#54885)
8e89d30f09,jit,Untopiced,[NNC] Lower scalar constants as doubles/longs (#54824)
4541f60390,distributed,Untopiced,Gloo-only CPU-based monitored barrier (#53773)
d185719455,distributed,Untopiced,Expose dist.monitored_barrier() API (#53787)
8c13dde458,distributed,Untopiced,[DDP] Remove redundant pass statement (#54219)
028d2d6e63,distributed,Untopiced,[NCCL] Enhance watchdog to log exceptions (#54557)
d5564618d0,distributed,Untopiced,[NCCL][Blocking Wait] Log set exceptions when checking for exceptions in (#54558)
49b07ac5d1,fx,Untopiced,"Enable complex autograd for `index`, add `index` and `index_put` OpInfos (#54562)"
e829754992,composability,Untopiced,[PyTorch] Inline Tensor keyset-checking methods & similar getters (#54806)
1a0b77e7c4,composability,Untopiced,Suggest TORCH_LIBRARY_FRAGMENT in duplicate TORCH_LIBRARY error message (#54883)
f4dfa02c03,jit,Untopiced,Add documentation for torch.jit.Attribute and torch.jit.annotate (#54485)
1bccd48465,complex_frontend,Untopiced,"Allow creating SugaredValue for a complex valued IValue and deserialization logic for ""infj"" and ""nanj"" global constants (#54328)"
1267efce75,jit,Untopiced,[NNC] Add a default constructor for Placeholder
fbaad8c0f9,composability,Untopiced,[PyTorch] TensorIterator::output should return const reference (#54811)
a1bd7918cc,quantization,Untopiced,[docs][quant] Fix FX Graph Mode Quantization tutorial link (#54715)
5c12d97d96,releng,Untopiced,Add script to export a JSON of slow test case times (#54907)
f9097c43b9,skip,Untopiced,Support mix of int32 and int64 offsets/indices for EmbeddingBag and its variants (#53655)
626bb3d310,mobile,Untopiced,[iOS GPU][Design] Use function_constants to simply shader kernels (#54518)
32bb5c3609,mobile,Untopiced,[iOS GPU][Kernel] Fix the softmax kernels (#54519)
46e7f6773f,benchmark,Untopiced,[Static Runtime] Check for inplace ops explicitly in ReplaceWithCopy (#54657)
0269a5f481,complex_frontend,Untopiced,"Re-enable `cmath.sqrt(complex(-1,-0.0))` test (#54923)"
2503028ff5,nn_frontend,Untopiced,Fix ConvTranspose with padding as a list of values (#54911)
c690ed0ae8,python_frontend,Untopiced,Fix override for __iter__ (#54702)
a7dc0ab845,quantization,Untopiced,[quant][fx][pyper] Get first linear use of quantize_per_tensor for FQN (#54859)
6f63126b5c,quantization,Untopiced,[quant][fx] Add pass in convert to fold quant-dequant sequence (#54860)
6c31f56bf4,distributed,Untopiced,[Gradient Compression] Add cuda.syncrhonize back to batched powerSGD (#54838)
7c0941ee63,distributed,Untopiced,Clang-format powerSGD_hook.py (#54839)
6c8d783830,python_frontend,Untopiced,Generate no-op meta functions for all inplace operations (#54901)
9b9e19a808,complex_frontend,Untopiced,Fix test_variant_consistency_jit_addmm for complex types (#54917)
728d18f976,profiler,Untopiced,Enable USE_KINETO (#51273)
75ed6fbd91,releng,Untopiced,Fix CUDA 11.2 jobs for Windows (#54955)
c9d0c855f7,python_frontend,Untopiced,[special] Alias for special.expm1 and special.exp2 (#54670)
4e110528bd,linalg_frontend,Untopiced,Added cuSOLVER path for torch.linalg.eigh/eigvalsh (#53040)
9f93d82907,python_frontend,Untopiced,"OpInfo: Add opinfo for cum{min,max} and minor fixes (#54762)"
d60874354f,jit,Untopiced,[docs] Add updated TorchScript language reference section for types (#53673)
d49beba071,jit,Untopiced,[pyper] out variant of sigrid_transforms_torch_bind + ListUnpack (#54761)
46c27ea84d,nn_frontend,Untopiced,Enabling OneDNN for group conv (#54890)
f5d6b90c35,distributed,Untopiced,Add a missing sys import in test/distributed/rpc/test_tensorpipe_agent.py (#54925)
18e61d1ce9,fx,Untopiced,Improve placeholder matching in subgraph rewriter (#54958)
eafa235582,releng,Untopiced,Clarify and document commit choice for CI jobs (#54967)
5bcbbf5373,releng,Untopiced,Lint trailing newlines (#54737)
85c056a508,jit,Untopiced,[jit] Add EliminateExceptions pass. (#54730)
0e43a73f76,skip,Untopiced,Support needsOutputs for RecordFunction and ObserverUtil improvements (#54442)
4694452d08,complex_frontend,Untopiced,[complex] `masked_fill`: Complex Autograd support and update masked_scatter skips. (#54244)
920eb01e2e,cuda,Untopiced,Add scatter_add to amp docs (#54908)
0e543b2b00,distributed,Untopiced,Provide a decorator to set/unset nccl blocking wait for tests (#54740)
3f1cd2e3a0,distributed,Untopiced,test_c10d: Run tests with nccl_async_error_handling (#54741)
23b15ef98a,distributed,Untopiced,test_c10d: use with_nccl_blocking_wait decorator (#54742)
5b448cf21a,skip,Untopiced,Revert D25966661: Support needsOutputs for RecordFunction and ObserverUtil improvements
ea37fe34ff,composability,Untopiced,[PyTorch] Avoid refcount bump in TensorArg (#54934)
dde7fff0e9,linalg_frontend,Untopiced,[PyTorch] Avoid refcount bumps in addmm_out_cuda_impl (#54935)
d490e0120f,nn_frontend,Untopiced,[PyTorch] One less refcount bump in linear() (#54936)
d92e2520de,caffe2,Untopiced,[caffe2] Support Log1p operator (#54968)
1bf57430f1,skip,Untopiced,Remove hacky wrappers for 21 operators (#54819)
2df4acd025,skip,Untopiced,Remove hacky wrapper for about 70 kernels (#54898)
f956b7524e,jit,Untopiced,lazily init AliasDb and add `changed` status to CSE (#54776)
3baeeb3f57,releng,Untopiced,Added Azure Pipelines build steps for PyTorch (#54039)
b907d6e3b6,releng,Untopiced,[ROCm] skip some tests to enable 4.1 CI upgrade (#54536)
d4c37b314e,composability,Untopiced,Mark redispatch functions with TORCH_API (#54966)
1dffbe759b,caffe2,Untopiced,[ROCm] utilize PUBLIC vs PRIVATE linking to avoid incorrect dependencies (#54727)
854c92078a,linalg_frontend,Untopiced,Fixed the default size of the workspace array for MAGMA's SVD (#54875)
2bee09a577,releng,Untopiced,"[android] fbjni android use prefab dependency, version 0.2.2 (#54792)"
4865195cf4,cpp_frontend,Untopiced,[PyTorch] Add DimVector variant of infer_size (#54882)
444e5f0b60,jit,Untopiced,Add Type System (I) (#53244)
8a170fbacd,package,Untopiced,[package] fix mangling issues with TorchScript (#54915)
6d87b3667f,python_frontend,Untopiced,Added support for TensorList inputs in OpInfo (#54922)
25e07c6e91,skip,Untopiced,Revert D27422219: [caffe2] Support Log1p operator
09756e7280,skip,Untopiced,"Revert D27370295: [android] fbjni android use prefab dependency, version 0.2.2"
99a423f8fc,skip,Untopiced,Automated submodule update: tensorpipe (#54970)
449a9514d1,skip,Untopiced,Update Kineto submodule (#55011)
aeedd5c7df,onnx,Untopiced,cmake: fix ONNX_NAMESPACE if USE_SYSTEM_ONNX (#54973)
0dd873bdd5,releng,Untopiced,[ROCm] add 4.1 docker image (#54628)
a0ae3e520f,mobile,Untopiced,[Pytorch Mobile] 'fix' filter of named parameters for FL (#54633)
24bfcd537e,fx,Untopiced,[FX] Added FX prepare_for_inference for Intel CPUs (#53805)
7fc03dd7c9,cuda,Untopiced,"Back out ""[pytorch][PR] Merge CUDA Streams and Events"" (#54996)"
a74b10def9,releng,Untopiced,Keep Markdown ToCs up to date (#54974)
f1f3c8b0fa,build_frontend,Untopiced,Adding PyTorch + DNNL + AMD BLIS path (#54953)
43d4f3b8d0,skip,Untopiced,Implement public API InferenceMode and its error handling (#55008)
cff266544a,skip,Untopiced,Fix minor style/typos problems in comment_device_type.py (#54768)
57519e705a,onnx,Untopiced,Link onnx_library when BUILD_TEST=0 for Windows (#51937)
bab8a1a81e,skip,Untopiced,[reland] Add annotations to PRs from forks (#54779)
f71a0daeb7,distributed,Untopiced,Use faulthandler to dump traceback of timed out processes in unit tests. (#54818)
07602bf7e1,caffe2,Untopiced,[caffe2] Use the CXX11 version of the USE_C99_COMPLEX macro
2a7df657fe,amd,Untopiced,[ROCm] use hiprtc precompiled header (#54350)
8ad32dbbd7,build_frontend,Untopiced,update build tutorial - choose the correct VS version (#54933)
0bd96458ba,skip,Untopiced,Revert D26820202: Support mix of int32 and int64 offsets/indices for EmbeddingBag and its variants
507b46f23e,mobile,Untopiced,[android] fbjni from prefab dependency 0.2.2 (#55066)
b64d775636,releng,Untopiced,Adding workflow to auto-label PRs with ROCm (#54989)
bcb4583170,fx,Untopiced,[FX] Add a metadata dict to Node and switch shapeprop to use that (#54926)
7f87358840,mobile,Untopiced,[android] bump nigtlies version to 1.9.0 (#55076)
26c1e2ee83,amd,Untopiced,[ROCM] enable miopen for rnn f16 (#52475)
fb1c193eed,nn_frontend,Untopiced,Simplify convolution double backward gradInput formulas (#54840)
5c3963373a,nn_frontend,Untopiced,Handle 1D input for xnnpack::linear (#54986)
2726de0119,composability,Untopiced,[Pytorch] Expose ops present in dispatcher (#54791)
8eb9a934bc,releng,Untopiced,Clarify tools/test_history.py output for re-runs (#55106)
63c70ae032,performance_as_product,Untopiced,various overhead improvements to cuda addmm (#55026)
28daa6b7dd,distributed,Untopiced,[Futures] enhance error handling in then() (#54475)
a37fbf9b45,jit,Untopiced,[Futures] Bump log verbosity when ignoring cb errors in python future. (#54476)
908a74e8c1,jit,Untopiced,[Refactoring] make transformations return whether graph is modified (#54777)
70af5db7ca,composability,Untopiced,Remove use_c10_dispatcher option (#54969)
f29039677d,skip,Untopiced,Refactor get numerical jacobian (#54092)
0d80f378f6,releng,Untopiced,fix boto3 resource not close (#55082)
c85d3f501f,fx,Untopiced,Move shape prop inside acc_tracer (#55091)
eb52e36460,skip,Untopiced,Revert D27469727: [pytorch][PR] [android] fbjni from prefab dependency 0.2.2
55544cb13a,quantization,Untopiced,[quant][graphmode][fx] Add support for one value being quantized with different qconfigs (#53586)
c2adedf6fe,quantization,Untopiced,[quant][graphmode][refactor] Remove reduandent code (#54073)
c0d6dbdce4,quantization,Untopiced,[quant][fx][graphmode][refactor] Change activation_post_process_map to track the observer name instead (#54643)
c57541ce06,quantization,Untopiced,[quant][graphmode][fx] Separate handling Copy operator to a helper function (#54644)
c445f4ee93,quantization,Untopiced,[quant][graphmode][fx][refactor] Factor out insert_observers_for_model to a separate function (#54733)
790b69e096,jit,Untopiced,Language Ref for Statements in Torchscript (#52847)
8b8c4096ee,python_frontend,Untopiced,Added OpInfo gradcheck_wrapper to replace output_func (#54914)
15f04e3466,skip,Untopiced,Revert D27408378: [quant][graphmode][fx][refactor] Factor out insert_observers_for_model to a separate function
6c235ef267,python_frontend,Untopiced,"Allow `std=0` in `torch.normal`, and error if `std<0` (#51317)"
ce48b14060,onnx,Untopiced,[ONNX] Improve index_put symbolic to handle singular Bool updates (#53690) (#54863)
cd9dd653e9,onnx,Untopiced,[ONNX] Support primitive type input/outputs and attributes (#53550) (#54864)
849dcb8b69,onnx,Untopiced,[ONNX] Fix if output shape mismatch error & Fix graph input directly used as output (#53219) (#54865)
cb0cee4a3d,onnx,Untopiced,[ONNX] Replace decomposeLinear pre process pass with a symbolic (#53077) (#54866)
c5f3d92816,onnx,Untopiced,[ONNX] Update scripting docs (#54634) (#54868)
40869884cd,onnx,Untopiced,Add outer export to onnx (#53603) (#54869)
7824d8277a,onnx,Untopiced,[ONNX] Fix export of copy_ operator (#51938) (#54870)
d2aab53dc2,linalg_frontend,Untopiced,[PyTorch] Check is_same instead of data_ptr in addmm_out_cuda_impl (#55111)
058357a439,distributed,Untopiced,[Gradient Compression] Report compression rate for batched PowerSGD hook (#55103)
547346d663,caffe2,Untopiced,[caffe2] Fix -Wundef
6145ac07b5,caffe2,Untopiced,[caffe2] Reintroduce Log1p operator (#55073)
ba95e08a95,cpp_frontend,Untopiced,[PyTorch] Use DimVector for inputs to as_strided that don't grow dim (#55016)
50cb75edce,jit,Untopiced,[tensorexpr] Add python bindings for TensorExprKernel (#54450)
5a1191d050,nn_frontend,Untopiced,Check exception messages in embedding_bag_proxy unit test
5d68b3695c,linalg_frontend,Untopiced,[Relanding] Implemented torch.linalg.multi_dot (#52859)
d98072b027,linalg_frontend,Untopiced,Deprecate torch.chain_matmul in favor of torch.linalg.multi_dot (#53453)
3036777305,linalg_frontend,Untopiced,Replace torch.chain_matmul calls to torch.linalg.multi_dot (#55064)
204ac21bf1,skip,Untopiced,Revert D27449031: [pytorch][PR] [ROCm] use hiprtc precompiled header
9d6a81d1a6,distributed,Untopiced,"Avoid aggregate initialization for tensorpipe::{Cpu,Cuda}Buffer and tensorpipe::Message::Tensor. (#55136)"
8b02d1207b,jit,Untopiced,Fixed OpInfo jit tests failing for TensorList inputs (#54954)
b880854f31,structured_frontend,Untopiced,port copysign to structured kernel (#55040)
0cfd9e881f,quantization,Untopiced,[static runtime] fix out variant for 4bit embedding bag (#55096)
1324b0dd44,fx,Untopiced,[FX] Adds C-level monkeypatching of `torch.randn` so that we can capture it during tracing. (#54060)
967e59e557,jit,Untopiced,[tensorexpr] Add sliceHead/sliceTail APIs with short parameter list (#55115)
f83668b4e5,skip,Untopiced,Update release notes scripts following runbook update (#54594)
69c5fd1e00,distributed,Untopiced,SyncBatchNorm.forward() to handle optional weight (#54568)
f0dafeb0cb,skip,Untopiced,Trigger azure pipeline for multi gpu tests (#52490)
8d5df95551,skip,Untopiced,"Make TensorIterator, SparseTensorMath and UnaryOps clang-tidy clean (#55087)"
6b20046491,releng,Untopiced,Pin ShellCheck version to v0.7.1 (#55109)
36c27fd0ac,linalg_frontend,Untopiced,SVD docs improved (#54002)
2798f38c86,python_frontend,devs,Added checks for dtype and device of OpInfo's sample_inputs (#54949)
a4125876c9,composability,Untopiced,Move BackendSelect to default_included_set. (#55117)
53609b4cac,skip,Untopiced,fix typo in ReduceMinMaxKernel (#54984)
c64e006fc3,releng,Untopiced,Fix security of ROCm labeling workflow (#55157)
1b2b3ca86d,jit,Untopiced,Language Ref Python Builtin Functions and Values (#52830)
0eba63ec93,python_frontend,devs,Improve testing documentation in `CONTRIBUTING.md` (#54904)
cdd9911a12,skip,Untopiced,Revert D27470071: [pytorch][PR] Trigger azure pipeline for multi gpu tests
f34de6a9f4,linalg_frontend,Untopiced,Modified lstsq_helper to accept rank and singular_values (#54719)
b74795c460,jit,Untopiced,[Pyper] resize_as_ -> resize_ (#55098)
070169e4d0,cpp_frontend,Untopiced,[ATen] tensor.contiguous() -> tensor.expect_contiguous (#55022)
dfa2daac1d,composability,Untopiced,[PyTorch] Remove outdated C++11 note on C10_DEPRECATED (#55061)
84ad5df8e3,releng,Untopiced,Correct the name of the label in auto-label-rocm (#55170)
0a329c66bf,skip,Untopiced,[PyTorch] Remove stray comments in TensorBody (#54985)
787854ce41,distributed,Untopiced,"[ZeroRedundancyOptimizer] bounding the multiple gpus unit test to 4 gpus, hardcoded values (#54788)"
2962fee99a,complex_frontend,Untopiced,Fix/suppress a type warning in PyTorch (#55142)
faa4da49ff,releng,Untopiced,Add code to ensure workflow consistency for autocanceling (#55171)
8dc29e8a4a,jit,Untopiced,[PyTorch] Allow IValue to construct from Tuple with fewer copies (#54534)
22f3b4eaa8,composability,Untopiced,Tensor::register_hook: Avoid wrapping hook in two levels of std::function (#53917)
dded5d72a4,composability,Untopiced,[PyTorch] Move Tensor::has_names inline (#54965)
057ec81b17,composability,Untopiced,[PyTorch] OperandInfo ctor should take rvalue reference (#54972)
3575e71be8,distributed,Untopiced,[DDP Logging] Log use of uneven inputs API (#54919)
047a487b07,releng,Untopiced,Fix accidental Flake8 excludes (#55178)
8822c7e052,skip,Untopiced,Update TensorPipe submodule. (#55164)
5610e8271b,distributed,Untopiced,Fix skip_if_not_multigpu decorator (#54916)
0d47374c54,cuda,Untopiced,construct only necessary elements in OffsetCalculator (#55107)
688e350725,jit,Untopiced,[TensorExpr] Nuke DepTracker and findAllNeededTensors. (#54997)
0b75f862c7,jit,Untopiced,[TensorExpr] Nuke FunctionCall. (#54998)
bdbfb2a035,jit,Untopiced,[TensorExpr] Nuke BaseCallNode. (#54999)
f8f30a5e27,jit,Untopiced,[TensorExpr] Remove stale docs from DesignOverview.md. (#55000)
1ccaec0238,jit,Untopiced,[TensorExpr] Cleanup IRNodeType enum. (#55001)
ff6b3c76ab,jit,Untopiced,[TensorExpr] Add TORCH_APIs to all expr classes. (#55002)
ed4a1d54a7,jit,Untopiced,[OpInfo] Enable jit tests for multi_dot (#55147)
b074a24394,python_frontend,Untopiced,Port torch.copysign method_tests() to OpInfo (#54945)
09f1f14569,jit,Untopiced,Transition to new tensorpipe::Pipe API. (#55193)
271879fe67,composability,Untopiced,[PyTorch Edge] Provide a method ObservedOperators::getUnobservedOperatorList() so that model tracer can empty it out during tracing (#55017)
ec609e7420,jit,Untopiced,Adds torch.* API section for TorchScript Lang Ref (#53236)
93d0f636bb,distributed,Untopiced,[c10] Add default constructor to Maybeowned (#55128)
61914cb2fa,quantization,Untopiced,[ATen][qembeddingbag] Avoid tensor refcount bumps (#55023)
3e185253b6,distributed,Untopiced,Use tensorpipe::Buffer::device() instead of tensorpipe::Buffer::deviceType().
bdb225e9f0,skip,Untopiced,Revert D27478436: Use tensorpipe::Buffer::device() instead of tensorpipe::Buffer::deviceType().
f43eb59a68,skip,Untopiced,add channels last for MaxPool2d (#48917)
757e3cbf82,quantization,Untopiced,ns for fx: add support for shadowing linear fp16 patterns (#54275)
cbcde79023,quantization,Untopiced,ns for fx: refactor test cases (#54280)
b8019cee0e,quantization,Untopiced,ns for fx: make input logging work for multi-node subgraphs (#54326)
5319d17be4,quantization,Untopiced,ns for fx: make input logging work for multi node subgraphs (#54327)
c6cb99a6c7,quantization,Untopiced,ns for fx: weight extraction for nni.ConvReLU2d (#54335)
f6b25e758d,quantization,Untopiced,ns for fx: move it to top level file (#55060)
a590fa7af4,quantization,Untopiced,ns for fx: clean up debug print statements (#55077)
80b1b7e4b1,quantization,Untopiced,ns for fx: ensure kwargs are handled when graph matching (#55078)
8062545c63,quantization,Untopiced,ns for fx: weight extaction for conv1d and conv3d (#55079)
e406d4e6cb,linalg_frontend,Untopiced,Modified lstsq_helper to accept lapack error codes tensor (#54720)
978fca64a6,skip,Untopiced,Revert D25399470: add channels last for MaxPool2d
09670c7d43,releng,Untopiced,Don't globally disable any ShellCheck warnings (#55165)
181de40688,autograd_frontend,Untopiced,Split copy_ kernel to InplaceOrView. (#55133)
24c904951c,skip,Untopiced,Replace AutoNonVariableTypeMode with InferenceMode in fbcode. (#55114)
02af4b511d,distributed,Untopiced,Enhance Pipe docs to explicitly mention RPC initialization. (#55187)
a0bb0968d5,composability,Untopiced,[PyTorch] Don't bother with SmallVector in TensorMaker (#55125)
7ab53eb960,jit,Untopiced,[StaticRuntime] Unbreak benchmarks. (#55199)
e593044748,distributed,Untopiced,[Gradient Compression] Update a warning in ddp_comm_hooks.rst (#55031)
6e2d020037,python_frontend,Untopiced,Add interpolation kwarg to torch.quantile (#49267)
6866c033d5,jit,Untopiced,[jit] Add recursive scripting for class type module attributes (#55124)
38a08a49ea,nn_frontend,Untopiced,Flip clip_grad_norm default for error_if_nonfinite to false (#55169)
fb64caedb5,releng,Untopiced,"Don't fail ""Add annotations"" if ""Lint"" is canceled (#55242)"
91a809bbd7,distributed,Untopiced,[c10] Adjust macro check that detects if glibc++ use c99 csqrt (#55177)
29916dbf1e,distributed,Untopiced,Clang-format _distributed_c10d.pyi (#55220)
6e33420436,fx,Untopiced,Add embedding bag support to fx_glow (#54909)
6a40339920,distributed,Untopiced,[SPMD] Error out SPMD mode (#54454)
e589247a19,distributed,Untopiced,[SPMD] Change assertions to raising value errors in distributed.py (#54825)
2452182e6c,distributed,Untopiced,[SPMD] Remove test_grad_layout_1devicemodule_2replicaperprocess (#54826)
159fdde9ae,composability,Untopiced,Support needsOutputs for RecordFunction and ObserverUtil improvements (#55012)
560e3be587,dataloader_frontend,Untopiced,[DataLoader] Implement issubtype for type hints (#54299)
44edf8c421,dataloader_frontend,Untopiced,[DataLoader] Typing Enforcement for DataPipe at Compile-time (#54020)
1535520f08,dataloader_frontend,Untopiced,[DataLoader] Typing Enforcement for DataPipe at construct-time (#54066)
0b1c3dfae4,dataloader_frontend,Untopiced,[DataLoader] Typing Enforcement for DataPipe at runtime (#54544)
c549a147a9,dataloader_frontend,Untopiced,[DataLoader] Typing Doc (#54773)
6d030c14cf,skip,Untopiced,Added pow() on CPU for float16 & bfloat16 (#50999)
28531c97b2,caffe2,Untopiced,[caffe2] Shape inference for Transpose (#55188)
641d4ff160,fx,Untopiced,[FX] Add stride to shape_prop pass (#55108)
e8dbd0e1a0,jit,Untopiced,[TensorExpr] Minor cleanups in kernel.cpp. (#55257)
4170a6cc24,cpp_frontend,Untopiced,Migrate `mode` from TH to ATen (#52043)
322854d2f0,distributed,Untopiced,[SPMD] Error out SPMD in C++ Reducer (#55212)
041b4431b2,skip,Untopiced,irange for size_t (#55163)
a84c92b78b,package,Untopiced,[package] populate a special attribute on imported modules (#55255)
8377e6221a,skip,Untopiced,Revert D27478225: [pytorch][PR] Added pow() on CPU for float16 & bfloat16
8ed20b3f65,caffe2,Untopiced,Leak Caffe2 threadpool in child processes right after fork to prevent segfault (#54895)
e3691be2d9,distributed,Untopiced,Dump C++ stack traces of all threads for distributed tests. (#55003)
c0ac0fef4e,skip,Untopiced,Revert D27448156: irange for size_t
e309ab8510,skip,Untopiced,OpInfo: `atan2` (#55132)
0ec1af4b7e,distributed,Untopiced,[c10d] Enforce order of waited ranks in monitored barrier. (#55009)
19a0eb4cdb,distributed,Untopiced,[c10d] Monitored barrier: option to collect all failed ranks (#55010)
d2a58bfe6f,amd,Untopiced,Add mkldnn tanh operator (#54656)
0a81034dd0,structured_frontend,Untopiced,Port atan2 to structured kernel (#55130)
bcdcf347cb,linalg_frontend,Untopiced,Add cusolver potrs and potrsBatched to the backend of torch.cholesky_solve (#54315)
3d492b0697,skip,Untopiced,Revert D27505153: [pytorch][PR] OpInfo: `atan2`
c821b83ab3,caffe2,Untopiced,[typing] make mypy-protobuf output compatible with pyre for caffe2 type stubs (#55294)
edb919376d,jit,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
f3969d3db6,python_frontend,devs,Fix bug in self.assertExpectedInline (#55149)
5e72571df3,autograd_frontend,Untopiced,Fix wrong changes from #54103 (#54610)
197f9f0826,cuda,Untopiced,Merge CUDA Streams and Events (#53902)
980d6f2589,linalg_frontend,Untopiced,torch.linalg.det (#53119)
ebf40e6ed2,releng,Untopiced,CI: Run test_lite_interpreter_runtime from built lib directly (#55291)
6c8270ea21,skip,Untopiced,fix bc breakage of #52043 (#55303)
7fd3c030ef,python_frontend,Untopiced,Write OpInfo for dist (#55092)
a102adb55e,skip,Untopiced,Automated submodule update: FBGEMM (#54575)
c9b214f9fb,build_frontend,Untopiced,Add Python-3.9 PyTorch M1 nightly builds (#55278)
c5a1eb4156,benchmark,Untopiced,extend benchmarks (#54651)
5339d534a3,benchmark,Untopiced,Add runner for instruction count benchmarks. (#54652)
fffdc5fa2f,build_frontend,Untopiced,docs: Pin docutils to 0.16 (#55309)
f4a618bb5a,composability,Untopiced,[PyTorch] Don't create intermediate Tensor for at::result_type w/Scalar (#55232)
d0ffada9ee,releng,Untopiced,.github: Add scale-config.yml (#55315)
62aa924368,skip,Untopiced,[PyTorch] Devirtualize is_contiguous (#54896)
e61f5b586b,skip,Untopiced,Revert D27404164: [PyTorch] Devirtualize is_contiguous
7613b1150b,quantization,Untopiced,[docs][quant] Add fx graph mode quant api doc (#55306)
45aaaef22c,benchmark,Untopiced,"Fix timer overflow on small, fast snippets (#55200)"
3acbaf834e,structured_frontend,Untopiced,Make structured functions properly check device/dtype of explicit out args (#55150)
2ee02b30b1,python_frontend,Untopiced,"Replace rounding_mode=""true"" with rounding_mode=None (#51988)"
ef262575dd,composability,Untopiced,[pytorch] Fix printing of optional string arguments in schemas (#55196)
d690973295,composability,Untopiced,irange on int64_t (#55148)
6a2f046504,distributed,Untopiced,[SPMD] Restrict DDP communication hooks to SPSD mode (#55253)
b986a76d91,distributed,Untopiced,Clang-format distributed.py (#55254)
bf37bf7da4,releng,Untopiced,Make JSON files more human readable (#55335)
fd02fc5d71,cpp_frontend,Untopiced,Port put_ and take from TH to ATen (#53356)
15b087cdd2,fx,Untopiced,[fx]Allow rewrite a symbolic traced module (#54011)
e0c5d0ea15,distributed,Untopiced,Add tutorials to pipeline docs. (#55209)
0521e420fd,jit,Untopiced,[Static Runtime] Temporarily disable fusion tests (#55342)
697b130374,skip,Untopiced,Add some missing types to torch (#55184)
0e03a2978a,distributed,Untopiced,[DDP] Call ensure_prior_reduction_finished within lock (#55074)
5584332180,releng,Untopiced,Wrap cub in its own namespace (#55292)
bad8d34780,distributed,Untopiced,[torch/elastic] Revise the rendezvous exception types. (#54803)
de7f05b9eb,distributed,Untopiced,[torch/elastic] Expose a `stderr` parameter in `EtcdServer`. (#54805)
7f06c65a4c,distributed,Untopiced,[torch/elastic] Improve the implementation of the utility functions and add their unit tests. (#54804)
359d0a0205,distributed,Untopiced,[torch/elastic] Improve the implementation of `RendezvousParameters` and add its unit tests. (#146)
df299dbd7d,distributed,Untopiced,[torch/elastic] Revise the rendezvous handler registry logic.
7d9a619796,releng,Untopiced,[PyTorch] Fix bin hash comparison failure in clang format script (#55281)
3551bd31be,jit,Untopiced,[PyTorch] Lite interpreter with a backend delegate (#54462)
cc4036905c,distributed,Untopiced,[Gradient Compression] Update the default value of start_powerSGD_iter and update the docstring (#55272)
1b4bb3691c,distributed,Untopiced,[Gradient Compression] Update _powerSGD_comm_hook_wrapper to only expose 2 most critical hyperparameters (#55295)
c3d0607ffa,jit,Untopiced,[Static Runtime] Make sure the copy version of the op exist in ReplaceWithCopy (#55337)
bf70fe69ae,skip,Untopiced,Revert D27442325: [torch/elastic] Revise the rendezvous handler registry logic.
87d55058f1,releng,Untopiced,Fix the clang-tidy diff SHA for using PR merge (#55318)
e5f66f0059,memory_format_frontend,Untopiced,Optimized generic interpolation using TensorIterator (keeps original 2d/3d channels last impl) (#54500)
815bfad28c,skip,Untopiced,Fix reference cycle in sparse coalesce graph (#52874)
158cdece65,python_frontend,Untopiced,"Correct many OpInfos ""test_out"" skips. (#55141)"
8243ba7205,releng,Untopiced,Add MonkeyType dependency for testing on Linux (#55305)
f8788d5188,skip,Untopiced,Upgrade onednn to v2.1.2 (#54956)
e9c6a51100,distributed,Untopiced,[torchelastic] Make sure torchelastic mp wait for queue to be drained before finishing the process
8e78a1b084,distributed,Untopiced,[Resubmit] Fix for incorrect usage of logging in torch/distributed/distributed_c10d.py (#52757)
ae3a876c9c,skip,Untopiced,Revert D27572158: [torchelastic] Make sure torchelastic mp wait for queue to be drained before finishing the process
ec80981d28,skip,Untopiced,Revert D27246997: [pytorch][PR] Fix reference cycle in sparse coalesce graph
a0d9776104,jit,Untopiced,[jit] Include conv3d in the conv-add-relu fusion (#54772)
a9bcab46ff,python_frontend,Untopiced,Revert back changes in test_custom_ops.cpp. (#55350)
20d7916a6a,mobile,Untopiced,[Pytorch Mobile] Fold Conv BatchNorm for functions besides forward (#54619)
ad5dc84ed3,vulkan,Untopiced,[vulkan] Add Winograd convolutions (#54639)
0e7af36acd,quantization,Untopiced,Make bundled inputs work with quantized zero inputs (#47407)
1be909f074,mobile,Untopiced,[NNAPI] Fix models with no weights (#47517)
38a3c28f17,mobile,Untopiced,[NNAPI] Remove solid weights support (#47518)
beca1fdbec,mobile,Untopiced,[NNAPI] Fix MUL op (#47519)
8d960f7043,mobile,Untopiced,[NNAPI] Fix hardtanh (#47520)
8fcf9ca341,mobile,Untopiced,[NNAPI] Update support for Linear (#54695)
3802edd9ab,mobile,Untopiced,[NNAPI] Add unit test (#47521)
b057d27b0b,mobile,Untopiced,"[NNAPI] Add support for unsqueeze, cat, and mean (#48811)"
476c597ae6,mobile,Untopiced,[NNAPI] Handle binary ops combining NHWC+NCHW in some cases (#48812)
1d1db42340,mobile,Untopiced,Fix NNAPI for internal fbcode build (#48925)
d34d6244e7,mobile,Untopiced,[NNAPI] Use array instead of struct for serializing ints (#54696)
1f1d26137b,mobile,Untopiced,[NNAPI] Use code generation to better support list input/output (#54697)
5936faee7e,mobile,Untopiced,[NNAPI] Rename local variable (#54698)
ca67c17e46,mobile,Untopiced,[NNAPI] Add fixed-size assertions (#54699)
1e3b3a4714,mobile,Untopiced,[NNAPI] Create get_next_operand_id (#54700)
da7a27b847,mobile,Untopiced,[NNAPI] Initial flexible size support (#54701)
84d18727bd,linalg_frontend,Untopiced,"Added linalg.eig, linalg.eigvals (#52491)"
8eaa4a97b7,quantization,Untopiced,"Back out ""[quant][graphmode][fx] Separate handling Copy operator to a helper function"" (#55388)"
4cf42fc62f,cpp_frontend,Untopiced,[PyTorch] Cache self.size(dim) in TensorShape functions (#55336)
933bbbbed6,cpp_frontend,Untopiced,[PyTorch] Fix waste in unfold() (#55339)
5c402d9026,python_frontend,Untopiced,STFT: Clarify output shape in documentation (#54877)
79fe5b7897,python_frontend,Untopiced,[Doc]fix torch.ceil formula issue(pytorch#54948) (#55039)
96655e2b81,releng,Untopiced,Re-enable disabled tests workflow with GHA (#55417)
34a7b4aabb,releng,Untopiced,[tools] Remove newline from clang-format reference hashes (#55328)
add49e7e4e,python_frontend,devs,Enforce PEP263 for PyTorch python codebase (#55346)
35caae6045,composability,Untopiced,Fix boxing/unboxing for Scalar bool values (#53228)
73aeea648e,composability,Untopiced,Fix Scalar formatting (#53229)
db75ebac4a,python_frontend,bc_breaking,Don't allocate result Tensors in out overloads: Reduction Ops (#53218)
4757d4c077,python_frontend,bc_breaking,Don't allocate result Tensors in out overloads: at::kron_out() (#53640)
34b46359e3,jit,Untopiced,Fix forwarding/move bug (#53556)
acfb05ff43,composability,Untopiced,Boxing logic forwards arguments to stack (#53624)
87cf277bd7,linalg_frontend,Untopiced,Don't allocate result Tensors in out overloads: _linalg_solve_out_helper_cuda (#55321)
8c1a70a7c9,caffe2,Untopiced,[A*][Gen-1.5] Add shape inference func for PredictorCall.
82006ba460,mobile,Untopiced,[PyTorch Edge] Implement fb::jpeg_decode_to_NCHW (#55251)
bc05867618,autograd_frontend,Untopiced,Separate TLS for InferenceMode (#55424)
ece075195d,skip,Untopiced,[fix] torch.frac : Handle inf correctly (#52678)
c96f076248,skip,Untopiced,Fix typo in extending.rst (#55408)
6fd20a8dea,skip,Untopiced,"Back out ""[pytorch][PR] [fix] torch.frac : Handle inf correctly"""
263d8ef4ef,nn_frontend,Untopiced,docs: fix formatting for embedding_bag (#54666)
b9a02128bc,nn_frontend,Untopiced,split nn.functional (#55038)
2e9eb5afa2,releng,Untopiced,Use slow tests stats in common_utils (#55190)
17e5ba44f1,python_frontend,devs,[testing] Support input samples where `self` is broadcasted. (#53014)
8e6e7dca09,python_frontend,devs,"[ROCm] if TEST_WITH_ROCM, only instantiate GPU device tests (#55069)"
af2beaf675,profiler,Untopiced,[profiler] Fix time discrepancy between legacy and kineto events (#55226)
3bb1f59a9c,skip,Untopiced,avoid CPU std::copysign segfault when compiling on arm64 with gcc 7.5 / 8 for CUDA (#51834)
f5675f8306,distributed,Untopiced,[torchelastic] Make sure torchelastic mp wait for queue to be drained before finishing the process (#55412)
f9a0bbbeb8,dataloader_frontend,Untopiced,[DataPipe] Remove duplicate dataset (#54553)
56cd1d366e,skip,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
bfee8d0464,mobile,Untopiced,[Pytorch Edge] Dont cache inflated bundled inputs (#55181)
1c78a4a733,skip,Untopiced,move list dict and named tuple tests out of py3 and into test_list_dict.py (#55476)
85fcadc059,build_frontend,Untopiced,[lite-interpreter] speed_benchmark_torch support BUILD_LITE_INTERPRETER (#55402)
0d1058fbc7,skip,Untopiced,Revert D27625646: [pytorch][PR] move list dict and named tuple tests out of py3 and into test_list_dict.py
797d0c4c68,jit,Untopiced,[Hackathon] Add error source range highlighting check in test_recursive_script.py (#55475)
b91d48877d,python_frontend,Untopiced,Reland Fix reference cycle in sparse coalesce graph (#55404)
10abbb812a,jit,Untopiced,Support tensor subclasses in Torchscript (#54817)
dd2bccafc5,jit,Untopiced,nnc hackathon - use new APIs in tests (#55497)
1e70d217e7,python_frontend,devs,Add error message for complex alpha and non-complex inputs (#54964)
afd549bb8f,profiler,Untopiced,[Doc] fix profiler doc (#55449)
2dd7dafb62,jit,Untopiced,[Hackathon][take2] jit py3 move list dict tuple to jit/ (#55515)
e6bfff679d,onnx,Untopiced,[ONNX] Add hardsigmoid symbolic in opset 9 #49649 (#54193)
a20a72d41b,jit,Untopiced,Replace assertRaisesRegex w/ assertRaisesRegexWithHighlight test_backends.py (#55493)
b1bae01e0c,jit,Untopiced,Replace raiseRegex with raiseRegexWithHighlight test_async.py (#55489)
469734ae54,jit,Untopiced,Replace assertRaisesRegex w/ assertRaisesRegexWithHighlight test_builtins (#55496)
b665298dc8,jit,Untopiced,Use assertRaisesRegexWithHighlight test_custom_operators.py (#55519)
11889a51ed,jit,Untopiced,Use assertRaisesRegexWithHighlight test_enum.py (#55521)
5d78c4f701,jit,Untopiced,Use assertRaisesRegexWithHighlight test_class_type.py (#55510)
b9326d418d,jit,Untopiced,[Hackathon] Add error source range highlighting check in test_scriptmod_ann (#55482)
5f90ed550c,jit,Untopiced,[Hackathon] Add source range highligh check to test_string_formatting (#55491)
94a3bad343,jit,Untopiced,[Hackathon] Add source highlighting check in test_type_sharing (#55498)
0f1350055b,jit,Untopiced,[Hackathon] Add source range highlight check to test_with (#55513)
f0ce8593db,jit,Untopiced,[Hackathon] Add source highlight check in test_torchbind (#55495)
524dbe1fa1,package,Untopiced,[Easy] Fix typo in package_exporter.py (#55551)
b3f1fece1b,jit,Untopiced,[Hackathon] add highlight to test_module_interface.py (#55530)
384daacd1e,jit,Untopiced,[Hackathon] Add source range info for tests in test_module_containers (#55500)
e359842f23,composability,Untopiced,Strict typecheck all files in tools/codegen (#55227)
d6cbecbbb6,cpp_frontend,Untopiced,[PyTorch] Reapply D27404164: Devirtualize is_contiguous (#55333)
b39eeb07ed,skip,Untopiced,Revert D27622277: [pytorch][PR] avoid CPU std::copysign segfault when compiling on arm64 with gcc 7.5 / 8 for CUDA
8ac0619784,python_frontend,Untopiced,Avoid infinite recursion in __torch_function__ example (#55391)
493a233c04,distributed,Untopiced,[torch/elastic] Revise the rendezvous handler registry logic. (#55466)
ec38dda1cc,skip,Untopiced,Remove extra close bracket in extending.rst (#55409)
0dff0d1537,linalg_frontend,Untopiced,[ROCM] Disable few tests for Magma (#55534)
3517ee1bcb,cuda,Untopiced,Fix ordered_dict.h for CUDA on Windows (#55275)
ffe301846b,jit,Untopiced,[Hackathon] Add error source range highlighting check in test_hash and test_list_dict (#55490)
f4967d68f5,python_frontend,devs,make torch.testing asserts importable (#54769)
902bf0bbbe,python_frontend,Untopiced,[special] Alias for sigmoid and logit & follow-up (#54759)
37d1b39413,python_frontend,Untopiced,OpInfo: `atan2` (#55132)
f88a3fff65,jit,Untopiced,Set requires_gradient to help autodiff to prune unneeded gradients (#54374)
f1a0b817f0,caffe2,Untopiced,[pthreadpool] Apply cap for macos builds (#55435)
b5647dd52b,skip,Untopiced,Add OpInfo tests for torch.addbmm (#55378)
473d193966,amd,Untopiced,Use mkldnn copy for copy_ when self and src are Mkldnn layout (#54248)
d3d7f57c2c,nn_frontend,Untopiced,Fix a problem when removing parametrizations (#55456)
7d56de1834,python_frontend,Untopiced,DOC: use autosummary on tensors.rst (#55042)
432df40d83,jit,Untopiced,[Hackathon] Move python builtins to test_python_builtins.py (#55479)
3f9492c8b3,jit,Untopiced,[Hackathon] Modernize API used in NNC C++ tests (1/3) (#55512)
8b5da2f48d,releng,Untopiced,rename .pytorch-disabled-tests to disabled-tests.json (#55618)
f665a7f8a1,distributed,Untopiced,[pet] Set error code in reply file when child process is terminated by signals.
60263e0f5a,python_frontend,devs,OpInfo porting for torch.maximum / torch.minimum / torch.fmax / torch.fmin (#55129)
ad823888a1,fx,Untopiced,[FX] Speed up _Namespace.create_name (#55580)
11add8f45f,releng,Untopiced,Add --suppress-diagnostics option (#55612)
2564c0c889,python_frontend,Untopiced,avoid CPU std::copysign segfault when compiling on arm64 (take-2) (#55608)
fd450ff1b9,skip,Untopiced,Revert D27598681: Add OpInfo tests for torch.addbmm
960b40156c,distributed,Untopiced,[6/n][torch/elastic][upstream] Move torchelastic/distributed/api to torch/distributed/elastic/launchers/api (#55471)
adc65974b2,releng,Untopiced,Run ShellCheck on scripts in GitHub Actions workflows (#55486)
778f9eab6c,caffe2,Untopiced,Don't switch streams when running Caffe2 ops from c10. (#55121)
eb5e1fc713,skip,Untopiced,[torch] Add cuda support for segment reduction 'max' (#54175)
305abde976,cuda,Untopiced,Fix nvcc warnings (#55367)
55db156229,jit,Untopiced,remove test_jit_py3.py entirely (#55560)
364639041f,skip,Untopiced,Revert D27121170: [torch] Add cuda support for segment reduction 'max'
fc45ff8177,releng,Untopiced,[skip ci] Document '[skip ci]' (#55418)
bf882929f1,build_frontend,Untopiced,[skip ci] Add explanation for why we split TORCH_CUDA_API (#55641)
cc11aaaa60,releng,Untopiced,Disallow non-breaking spaces (#55465)
3498fde20e,nn_frontend,Untopiced,Add AccumulateType in AdaptiveAveragePooling3d.cu (#53607)
2ca45cb9e8,releng,Untopiced,[hackathon] ci: Only generate cuda tests for cuda configurations (#55522)
c998f3573c,jit,Untopiced,[Hackathon]Move tests related to containers in typing to test_typing.py (#55504)
6a39613f35,jit,Untopiced,[BE] Make torch/csrc/jit/tensorexpr/ clang-tidy clean (#55628)
90f848572c,jit,Untopiced,NNC depthwise conv2d implementation (#54920)
cb4b3b04a8,jit,Untopiced,[NNC] Move device type checks from isSupported to typesAreSupported (#55025)
42486963b2,jit,Untopiced,Integrate NNC conv2d with fuser (#55213)
4d449f915f,quantization,Untopiced,[quant][graphmode][fx] Separate handling Copy operator to a helper function (#54644) (#55429)
6bdf7ef2a3,structured_frontend,Untopiced,Migrate sinh to structured kernel (#55538)
a699cda846,structured_frontend,Untopiced,Migrate acosh to structured kernel (#55540)
19e43eaaf4,structured_frontend,Untopiced,Migrate cosh to structured kernel (#55563)
5b149a0d4a,structured_frontend,Untopiced,Migrate cos to structured kernel (#55564)
d2784c233b,structured_frontend,Untopiced,"Partially migrate sort from THC to ATen, replace the thrust path with cub (#54626)"
0910363e8f,structured_frontend,Untopiced,adds data_ptr checks to in-place OpInfo variant tests and out OpInfo tests (#55527)
bbd2b1bd3c,quantization,Untopiced,[quant][graphmode][fx] Add shape to nontensor op list (#55529)
c7312f5271,releng,Untopiced,Enabled xla device in CI. (#55658)
55d45458bd,nn_frontend,Untopiced,[cuDNN] Enable Conv3d channels_last_3d (#48430)
2a24a2418a,python_frontend,Untopiced,common_utils.py use new file names for disabled/slow tests (#55620)
35a66db774,complex_frontend,Untopiced,Fix complex mean and reduction tests not being run (#55640)
defc649eca,jit,Untopiced,Update to short forms of splitWithTail / splitWithMask (#55542)
159e1100bf,python_frontend,Untopiced,[fix][tests] fix logic if env variables not present (#55664)
076961e8b5,jit,Untopiced,Add tuple add operator (#52292)
43ede4c2e3,quantization,Untopiced,Add Per Tensor Quantization Support to FXIRImporter (#55405)
c0379ac83f,composability,Untopiced,Simplify device guard code generation (#55112)
11dd6d3dbb,python_frontend,Untopiced,Mycontrib Added Example for is_tensor API (#55052)
f3367f917e,releng,Untopiced,Translate annotation line numbers from merge to head (#55569)
53f9fc1802,python_frontend,devs,Port hypot method_tests() to OpInfo (#55140)
fc1d7a85bb,skip,Untopiced,Added an OpInfo for mm & ported its method_tests (#55446)
6ee333cdb5,python_frontend,Untopiced,modernize test_sparse (#54572)
162e1003c9,package,Untopiced,[package] fix whichmodule for OrderedImporter (#55646)
91ab0d9680,python_frontend,devs,[hackathon] port addmv to OpInfo (#55545)
6842da6251,autograd_frontend,Untopiced,[WIP]Relax some limitations of InferenceMode. (#54403)
9f519d2d2d,releng,Untopiced,Simplify benchmark patterns in mypy-strict.ini (#55700)
ee2de8ae3a,mobile,Untopiced,[android] Module load extraFiles (#55644)
6e4e3a1159,autograd_frontend,Untopiced,Fix annotations in _autograd.pyi (#55706)
7671c15d4f,composability,Untopiced,Make VariableVersion::DISABLED the default constructor for VariableVersion. (#55572)
846c8d94c7,nn_frontend,Untopiced,mark embedding backward non-deterministic for max mode rather than all reducing modes (#55574)
7485818a3f,skip,Untopiced,Revert D27670883: [pytorch][PR] Added an OpInfo for mm & ported its method_tests
717d54bc2b,jit,Untopiced,[Hackathon] Add source highlighting check to test_unsupported_ops (#55501)
3e9cbe5ef7,distributed,Untopiced,[SPMD] Remove the code branches only used in SPMD mode from distributed.py (#55353)
fc349cbcde,python_frontend,Untopiced,OpInfo for kron (#55546)
d33829f844,nn_frontend,Untopiced,Fix type annotations for state_dict() override (#55704)
3e8ebb17aa,quantization,Untopiced,[reland][quant][graphmode][fx][refactor] Factor out insert_observers_for_model to a separate function (#54733) (#55307)
263a15c5aa,jit,Untopiced,[tensorexpr] Add PYTORCH_TENSOREXPR_DONT_FUSE env variable to disable fusion on specified operators - fixed #50757 (#55650)
d695ba94f6,jit,Untopiced,Replace AutoNonVariableTypeMode with InferenceMode in static runtime.
5a8cdc2fdb,skip,Untopiced,Revert D27691509: Replace AutoNonVariableTypeMode with InferenceMode in static runtime.
2496a09314,distributed,Untopiced,[Gradient Compression] Fix PowerSGD docstring by removing an extra whitespace (#55666)
fa19b6dd4d,composability,Untopiced,[PyTorch] New expand_inplace API with MaybeOwned<Tensor> and no unary tuples (#55065)
e8dd65102b,composability,Untopiced,[PyTorch] Use infer_size_dimvector in ExpandUtils (#55180)
6fd875923e,composability,Untopiced,[PyTorch] Add MaybeOwned::operator*() && (#55244)
16a9141e2c,composability,bc_breaking,[PyTorch] Update expand_outplace API to match expand_inplace (#55245)
12c19c398c,cpp_frontend,Untopiced,[PyTorch] Update expand_size API to match expand_inplace (#55246)
151869aca6,composability,Untopiced,[PyTorch][easy] Use sizes()[x] instead of size(x) in addr (#55247)
548765d9a5,composability,Untopiced,[PyTorch] Add & use inferExpandGeometry_dimvector (#55316)
c9b94a85e9,python_frontend,devs,change torch.testing helper asserts to checks (#54780)
255494c2aa,python_frontend,Untopiced,torch.testing allclose -> close (#54781)
84a7ab250b,performance_as_product,Untopiced,Optimize constructing tensors from external data (#55705)
facbcec298,caffe2,Untopiced,Make leak_corrupted_threadpool non-atomic (#55341)
b80c6f863f,jit,Untopiced,Disambiguate error message for working with not fully refined tuple types (#55745)
fa29a647db,jit,Untopiced,[JIT] Allow unpacking tuple and assign their values to SELECT-type expressions (#55268)
93bf0ae6fc,cpp_frontend,Untopiced,Remove legacy constructor calls from pytorch codebase. (#54142)
a3c062d4f5,python_frontend,Untopiced,docs: improve torch.matrix_exp() (#55626)
19f15317a0,distributed,Untopiced,[BE][Docs] Improve dist.new_group doc (#55660)
66289673f7,jit,Untopiced,patching requires_grad on DifferentiableGraph (#55701)
399b66c813,python_frontend,devs,Ports logdet from method_tests() to op_db (#55743)
3f8d476857,distributed,Untopiced,Split out CUDA RPC tests (#55695)
ec9b20ddc0,quantization,Untopiced,fx quant: fix edge case with copynode after user function (#55710)
3c6b52ae62,python_frontend,Untopiced,Cache slow/disabled test files (#55682)
1a8ec9c447,releng,Untopiced,Add breakpad to Docker image (#55439)
13153924cc,python_frontend,devs,OpInfo porting for msort operator (#55488)
e05ca753bf,releng,Untopiced,Fix nightly tool for python 3.6 (#55776)
211d31afc9,complex_frontend,Untopiced,symeig supports complex backward (#55085)
c6d9ca0c2b,jit,Untopiced,[reland]Replace AutoNonVariableTypeMode with InferenceMode in static runtime. (#55731)
5fb1142702,python_frontend,Untopiced,Add CSR (compressed sparse row) layout for sparse tensors (#50937)
b9b103ff94,structured_frontend,Untopiced,Port replication_padding1d to structured (#55481)
3b96a7965a,structured_frontend,Untopiced,Port replication_padding3d to structured (#55499)
8dd7e1528f,structured_frontend,Untopiced,Port replication_pad1d_backward to structured (#55537)
c91cf1e7a9,structured_frontend,Untopiced,"Add support for multiple outputs in structured kernels, port fractional_max_pool2d (#55581)"
80d04f910c,python_frontend,Untopiced,fix typo in argmax docstring (#55239)
db394efbb9,quantization,Untopiced,Support batched embeddings for 8Bit embedding bag quantization (#55343)
684589e8e0,skip,Untopiced,[codemod][fbcode][1/n] Apply buildifier
9593af305c,skip,Untopiced,Automated submodule update: tensorpipe (#55137)
01441af763,releng,Untopiced,Use mypy internals instead of fnmatch for mypy wrapper (#55702)
008ec544f4,caffe2,Untopiced,[p2c2][operators] Self binning histogram op error msg
08561cad10,python_frontend,Untopiced,[OpInfo] move matmul to OpInfo (#55543)
f7a51b2ab9,composability,Untopiced,Don't set version_counter on inference tensor for unsafe_ ops. (#55819)
c00b9dc599,skip,Untopiced,Small typo in comment (#55485)
af1a772876,composability,Untopiced,Disable overloading of std::max & std::min for inputs of distinct types (#55638)
566e06eb9b,autograd_frontend,Untopiced,Use _WeakTensorRef over weakref in test_autograd.py (#55726)
69b7b011dc,jit,Untopiced,[JIT] Add cond-add-relu matching pattern to cover in-place ops (#55458)
561b507843,composability,Untopiced,Eliminate device guard in generic dispatch key kernel wrappers (#55131)
dab1cdf7cb,skip,Untopiced,Revert D27708944: [pytorch][PR] [OpInfo] move matmul to OpInfo
d0cd16899f,python_frontend,Untopiced,rework device type filter rule (#55753)
a3c06e69aa,jit,Untopiced,[JIT][write path] Fix TupleType.annotation_str to conform to `typing` module syntax for empty tuple type (#54745)
68e0796466,jit,Untopiced,[JIT][write path] Make NoneType annotation_str emit `NoneType` instead of `None` (#54746)
48ddc9762b,releng,Untopiced,Upgrade mypy to version 0.812 (#55712)
d805908c34,jit,Untopiced,[NNC] API to reorder multiple loops (#55568)
e7bb00cb49,distributed,Untopiced,Add a warning message to retire ProcessGroup RPC backend (#55616)
5ba4cfb7bf,jit,Untopiced,Minor typo fixes in `_script.py` (#55818)
a756a9e553,nn_frontend,Untopiced,Add device id to ConvolutionParams (#50892)
bbcb12614e,releng,Untopiced,Sort slow tests json by test name (#55862)
5cd73df8f8,skip,Untopiced,[Hackathon]Move complex tests to test_complex.py (#55514)
8fc16da649,skip,Untopiced,[Hackathon]Move tests for slice to test_slice.py (#55524)
da01f4398b,autograd_frontend,Untopiced,Add InferenceMode TLS to ThreadLocalState. (#55822)
b3dd8cde61,distributed,Untopiced,[1/n] [torch/elastic] Introduce `DynamicRendezvousHandler` and `RendezvousBackend`. (#55635)
339d3bf394,distributed,Untopiced,[2/n] [torch/elastic] Introduce `C10dRendezvousBackend`. (#55636)
e61b4fa691,distributed,Untopiced,[3/n] [torch/elastic] Introduce `EtcdRendezvousBackend`. (#55637)
5a4e5db9ad,profiler,Untopiced,docs: fix profiler docstring (#55750)
4cfbb2401f,skip,Untopiced,[ROCM] Re-enable 3 previously faling tests in test_cuda.py (#55813)
b4cb020c0f,distributed,Untopiced,[Gradient Compression] Make orthogonalization_epsilon configurable in PowerSGDState (#55738)
37ac271089,skip,Untopiced,[AutoAccept][Codemod][FBSourceGoogleJavaFormatLinter] Daily `arc lint --take GOOGLEJAVAFORMAT`
56212daf7e,python_frontend,Untopiced,allow tests to run locally without setting environment variables (#55880)
4b09756d26,distributed,Untopiced,[SPMD] Move a comment (#55877)
00737efdb2,caffe2,Untopiced,[shape inference] Add shape inference func for Bucketize
9ccae89102,python_frontend,devs,port addcmul to OpInfo (#55517)
505f6f325f,python_frontend,devs,port addcdiv to opinfo (#55518)
192df16a4d,python_frontend,devs,move logaddexp{2} to opinfo (#55535)
5dba4ff786,python_frontend,Untopiced,move topk to use OpInfo (#55547)
d7d7556f17,jit,Untopiced,Move tensor implicit conversions to test_builtins.py (#55532)
24f9a446c9,nn_frontend,Untopiced,Fix wrong detection of depthwise conv on neon (#55794)
99d77c55dd,skip,Untopiced,Automated submodule update: tensorpipe (#55881)
75eb026e07,python_frontend,devs,migrate matrix_exp to opInfo tests (#55533)
4753100a3b,skip,Untopiced,Un-ignore F403 in .flake8 (#55838)
5e625906e9,skip,Untopiced,Fix lint for redundant-workflows list (#55916)
6a738196af,package,Untopiced,[package] Create API reference (#55812)
fc6985eceb,package,Untopiced,[package] Minor fixes to PackageExporter docstrings (#55817)
381b3d8f4b,autograd_frontend,Untopiced,Refactor get numerical jacobian to calculate wrt all outputs at once (#54378)
8c8f8829f0,autograd_frontend,Untopiced,Factor out numerical logic (#54479)
87fcf3072e,quantization,Untopiced,Fix overflow issue in quantized instance_norm/layer_norm/group_norm (#54872)
2bb58a06ef,composability,Untopiced,move logic to skip a redispatch directly inside of resize_output (#55162)
70a09d97d1,caffe2,Untopiced,Use nodes instead of node
6269efde91,distributed,Untopiced,Add stricter typing to caffe2/torch/distributed/elastic/multiprocessing/errors/__init__.py (#55848)
18662d4321,jit,Untopiced,[Static runtime] refactor MemoryPlanner codes to prepare for output tensor memory planning (#55809)
800fa5f369,amd,Untopiced,[ROCM] Enable more dtypes in common_method_invocations (#55808)
2eebd9fdce,distributed,Untopiced,fix ddp logging flaky test (#55414)
85b97e449d,distributed,Untopiced,[RFC]fix test_ddp_logging_data_cpu with tsan (#54465)
c3a49cb30c,jit,Untopiced,Better types in fbcode/caffe2/torch/jit/_script.py (#55856)
0517222dc8,package,Untopiced,[package] Correct usage of miniz API in PyTorchStreamReader (#55725)
657b66e87d,distributed,Untopiced,[NCCL] Log when barrier guesses device to use (#54991)
f61556a7ce,linalg_frontend,Untopiced,"Use autosummary on torch.fft, torch.linalg (#55748)"
57f795c27b,jit,Untopiced,[TensorExpr] Remove unused `LoopNest::hasLoopBodyFor` method. (#55323)
b01a15d3d3,jit,Untopiced,[TensorExpr] Redesign Rfactor loopnest transformation. (#55324)
754b0d073a,jit,Untopiced,[TensorExpr] Unbreak benchmarks. (#55824)
1263448cb2,jit,Untopiced,[TensorExpr] Remove mask field from Load and Store classes. (#55825)
7ab654afd7,jit,Untopiced,[TensorExpr] Rename `Tensor::call` to `Tensor::load` to be consistent with `Buf` and `Placeholder`. (#55826)
72b8864b34,caffe2,Untopiced,[caffe2] constexpr const
8f953ef544,nn_frontend,Untopiced,Increase token count threshold for calling thrust sort in embedding backward (#49913)
bbdb37b93d,jit,Untopiced,[JIT] Use type cache in erasing shape information (#55828)
ea446ed600,composability,Untopiced,[PyTorch] Allow copy operations on MaybeOwned (#55419)
de53de39d7,composability,Untopiced,[PyTorch] Mark borrowed case as C10_LIKELY in MaybeOwned (#55553)
aceceb3d5c,python_frontend,Untopiced,Reland #50999 (Added pow() on CPU for float16 & bfloat16) (#55280)
d1fac54f13,autograd_frontend,Untopiced,[Pytorch] Only print gradient of a tensor if it requires_grad (#54446)
6dd1978d4b,benchmark,Untopiced,print average duration for caffe2 benchmark
5ffc4e3b0f,distributed,Untopiced,refactor prepare_for_backward (#54977)
5a45b1b2f2,python_frontend,Untopiced,Add nondeterministic alert for `index_put_` when `accumulate=False` (#55827)
bf8b790ba7,releng,Untopiced,.github: Bump disk size for auto-scaled workers (#55955)
c47cc30bf5,jit,Untopiced,Skip testing torch.float16 in test_isnan (#55906)
b98f011cd4,cuda,Untopiced,cmake: Enable (s)ccache for nccl builds (#55814)
2237754b13,skip,Untopiced,Update a `batch_first` arg for transformers like GRU and LSTM. (#55285)
8596ac186b,python_frontend,Untopiced,deterministic code path for gather_backward for dim = 1 (#55573)
c218ac3bc0,distributed,Untopiced,[NCCL] Join work clean up thread before aborting communicators (#55444)
de5e3b5eb0,distributed,Untopiced,Fix OSS flaky test_destroy_full_group on MPI backend in pytorch_linux_xenial_cuda10_2_cudnn7_py3_multigpu_test environment by adding a barrier and retrying MPI_Comm_create 3 times (#55921)
a61d91e803,structured_frontend,Untopiced,Port reflection_pad1d to structured kernel (#55531)
2bf26965e7,skip,Untopiced,Revert D27710107: [pytorch][PR] Update a `batch_first` arg for transformers like GRU and LSTM.
8bdea14cd3,fx,Untopiced,[FX] Add memory_format to shape_prop (#55815)
132f5c1f36,distributed,Untopiced,Clang-format ProcessGroupMPI.cpp (#55969)
d398a705c6,skip,Untopiced,Clang-format batchnorm.py and distributed.py (#55971)
cf7c5dcae3,composability,Untopiced,[PyTorch] Avoid double indirection in MaybeOwned's borrowed state (#55685)
86368700e8,composability,Untopiced,[PyTorch] Change MaybeOwned tests to use intrusive_ptr and Tensor (#55684)
a5290adea5,distributed,Untopiced,[c10d] monitored_barrier: ensure all ranks pass or none do (#55197)
09231b5db1,distributed,Untopiced,[c10d] Log API usage of monitored barrier (#55265)
3646fa3621,distributed,Untopiced,Fix tensorpipe test (#55979)
c7aa1026a8,skip,Untopiced,Revert D27548433: [c10d] Log API usage of monitored barrier
48c73d24b8,skip,Untopiced,Revert D27523060: [c10d] monitored_barrier: ensure all ranks pass or none do
2236f43da0,fx,Untopiced,[FX] Put tensor metadata into a NamedTuple in ShapeProp (#55930)
c96b5b2a20,quantization,Untopiced,[quant][graphmode][fx][fix] Fix fp16 reference patterns for linear (#55727)
9f89b53d7d,distributed,Untopiced,Synchronize RRef.to_here() CUDA Streams properly (#54932)
7985753421,package,Untopiced,[package] Add dependency tracing function (#55167)
09c0bb4fb9,structured_frontend,Untopiced,Make replication_pad2d structured (#55511)
67dcd62310,skip,Untopiced,Don't split oversize cached blocks (#44742)
b1d17bc55f,python_frontend,devs,Added OpInfo for torch.sum (#55406)
2587a28bbd,build_frontend,Untopiced,Improve the instructions on how to build the docs (#56018)
444b318a90,quantization,Untopiced,ns for fx: add linear-relu mod weight extraction (#55080)
37a404610f,quantization,Untopiced,ns for fx: add allowlist for ops with same signature across dtypes (#55154)
1fb2abc7ad,quantization,Untopiced,ns for fx: rename SugraphTypeRelationship to SubgraphTypeRelationship (#55155)
13d7b40ea0,quantization,Untopiced,ns for fx: add F.conv2d and F.conv3d weight extraction (#55287)
457fac0a33,quantization,Untopiced,ns for fx: move more weight matching logic to weight_utils.py (#55288)
8fc1ca0d22,quantization,Untopiced,fx quant: fix prepacking for F.conv1d (#55311)
8b992ab0e4,quantization,Untopiced,ns for fx: add conv1d weight extraction (#55327)
784ae23d43,quantization,Untopiced,ns for fx: fix bug in weight extraction testing (#55431)
1ea95fa5b2,quantization,Untopiced,ns for fx: add test case for linear dynamic (#55432)
8188d18f8d,quantization,Untopiced,ns for fx: add functional conv-relu fusion support (#55433)
1688a5d31a,mobile,Untopiced,Cleanup since FEATURE_TORCH_MOBILE is always true. (#55835)
88c06d9dfc,jit,Untopiced,Add cuda device synchronization support in JIT (#55469)
e7e164f9e6,jit,Untopiced,[nnc] Enable CPU fusion only when num_threads == 1 (#55621)
f94c95a2dd,skip,Untopiced,Revert D23752058: [pytorch][PR] Don't split oversize cached blocks
3fe4718d16,nn_frontend,Untopiced,Add `padding_idx` argument to EmbeddingBag (#49237)
1127bab828,releng,Untopiced,Make GHA for consistency cancel_redundant_workflow return useful err msg (#55961)
ba320cec6b,releng,Untopiced,Prepare for Azure Pipeline for multi-gpu tests (#55600)
416c18b7c9,nn_frontend,Untopiced,Add a batch_first arg to Transformer / MHA modules (#55285)
087049000b,skip,Untopiced,Make c10 clang-tidy clean (#55870)
8df5e61fd6,jit,Untopiced,[nnc] Do not try to vectorize kernels that use float16 (#55970)
c8cf9114bf,releng,Untopiced,Include short test suites ln total_seconds stat (#56040)
752f5b1030,distributed,Untopiced,[reland][c10d] Log API usage of monitored barrier (#55989)
bbc4c775bb,distributed,Untopiced,[reland][c10d] monitored_barrier: ensure all ranks pass or none do (#55990)
fd15557ccc,autograd_frontend,Untopiced,breakup autograd documentation (#55672)
40d74e6f71,skip,Untopiced,"breakup optim, cuda documentation (#55673)"
48a7d69946,build_frontend,Untopiced,Catch and ignore tracebacks for compilation errors (#55986)
bc86358cf5,releng,Untopiced,Make run_test.py work even if s3_stat_parser fails to import (#56039)
f8f756efb2,distributed,Untopiced,TCPStore add watchKey method and new listener thread (#54264)
0b8bd22614,build_frontend,Untopiced,Fix bug with rebuilding extensions every import (#56015)
cc7fab6e9c,skip,Untopiced,Update pthreadpool (#55950)
1e225a5187,autograd_frontend,Untopiced,Add a few InferenceMode test cases to the wall. (#55993)
70f5905565,autograd_frontend,Untopiced,Add formulas and basic tests (#49098)
2e7e4d0795,releng,Untopiced,ci: Add job to ensure python2 setup.py compat (#56057)
50bd6a3640,releng,Untopiced,ci: Remove CUDA 10.1 builds (#56056)
ed03a0791e,distributed,Untopiced,Change MessageType values from decimals to hexadecimals for readability (#55985)
817fd932ac,skip,Untopiced,Revert D25607505: Add formulas and basic tests
6b8696172f,cpp_frontend,Untopiced,Fixed some Clang-Tidy checks in Aten Context class (#55942)
44e2c2cdfb,releng,Untopiced,Add a lint for native_functions.yaml (#56059)
1a116a9332,jit,Untopiced,[Static runtime] Add optimize_graph_output_memory flag (#55811)
669a8acc54,package,Untopiced,[package] Allow save_module to accept module as arg (#55996)
55432982d2,python_frontend,devs,[OpInfo][take2] move matmul to OpInfo (#55947)
f8d331b33b,autograd_frontend,Untopiced,PyTorch Execution Graph Observers (#55957)
92a09fb87a,skip,Untopiced,Manual revert of D27369251 (#56080)
c5f9e043e9,benchmark,Untopiced,Collect instruction counts (and wall times) for CI (#55428)
8f663170bd,distributed,Untopiced,[17/n][torch/elastic] Make torchelastic launcher compatible with the caffe2.distributed.launch (#55687)
506eca24b9,skip,Untopiced,Revert D27752279: [nnc] Do not try to vectorize kernels that use float16
ad17fadbfc,skip,Untopiced,Revert D27652485: [nnc] Enable CPU fusion only when num_threads == 1
556dfcb0db,jit,Untopiced,"[TensorExpr] Re-enable ""LoopNest.VectorizeUse"" test. (#56094)"
f5a7b2e641,cpp_frontend,Untopiced,Put llvmMathExtras in c10 namespace (#55886)
1995640d86,amd,Untopiced,Fix compiler warnings in mkldnn Pooling (#56095)
81f181567a,build_frontend,Untopiced,Add `USE_MAGMA` build flag (#55994)
75b6644a4c,caffe2,Untopiced,Add USE_NUMPY define only if PyTorch is compiled with Numpy (#56102)
1e9c7ad4cb,releng,Untopiced,Add a test to measure `import torch` time (#56041)
a128938a75,releng,Untopiced,"[ROCm] add MAGMA_HOME env var hint to cmake, centos-rocm Dockerfile (#54511)"
6eeffc64f1,python_frontend,devs,Port NumPy typing testing style to PyTorch (#54234)
047164437e,distributed,Untopiced,[TensorPipe] Prepare for new Pipe API. (#55820)
3802e577fb,distributed,Untopiced,[TensorPipe] Use Descriptor::Tensor::sourceDevice in tensorpipe_agent. (#55821)
699b47cd2c,python_frontend,Untopiced,Update use_deterministic_algorithms docs (#55413)
84e6580b5f,linalg_frontend,Untopiced,Use cusolver potrs as the backend of cholesky_inverse for batch_size == 1 on CUDA (#54676)
2f895f790a,jit,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
50057e560b,python_frontend,Untopiced,[special] Add `i0e` (#54409)
6350fcef83,python_frontend,Untopiced,[testing] add `broadcasts_input` and verifies the behaviour for inplace_variant. (#55771)
5cab3b9cf6,skip,Untopiced,Revert D27709912: TCPStore add watchKey method and new listener thread
b383b63550,build_frontend,Untopiced,[ROCm] Updating ROCM_HOME handling for >ROCm 4.0 (#55968)
1d49fd31c4,autograd_frontend,Untopiced,[reland] Add formulas and basic tests (#56083)
e0f9a5fed8,python_frontend,Untopiced,[BE] add test selector to test_testing (#55931)
6daa1760d7,skip,Untopiced,Skip geqrf test if compiled without LAPACK (#56105)
61725f15c0,cpp_frontend,Untopiced,cleanup unused implicit argument of expand function (#56101)
71a5314591,fx,Untopiced,Fix ScriptMethod dispatch on __torch_function__ (#56103)
9d3d169d2d,amd,Untopiced,Implement hardswish/hardsigmoid on MKLDNN tensors (#55218)
e8faf69739,python_frontend,Untopiced,fix torch.pow type promotion issue (#54085)
82a7fff3cd,composability,Untopiced,Modify a few APIs to take/return const Tensor& instead of Tensor& (#55797)
61418aa069,autograd_frontend,Untopiced,Make THPVariable_Unpack work on THPVariable too (#55798)
6ec71ed4f9,composability,Untopiced,Replace all direct cdata access with THPVariable_Unpack (#55799)
6c65ce8ee1,distributed,Untopiced,Use THPVariable_Unpack in python_nccl (#56016)
1934725875,nn_frontend,Untopiced,Use cascade summation in nll_loss on CPU (#55841)
51e7a371f5,distributed,Untopiced,[DDP] Param to name mapping in Reducer (#55075)
a60dca8e80,releng,Untopiced,Make the script generate cancel_redundant_workflows.yml (#56092)
49e5e284ea,skip,Untopiced,Additional annotations in fbcode/caffe2/torch/_jit_internal.py (#55855)
7eed077406,mobile,Untopiced,[android] Fix headers publishing in aar (#56068)
728d2e4e0f,distributed,Untopiced,[BE] Speed up runtime of test_ddp_model_diff_across_ranks (#55659)
7c708ef4ea,distributed,Untopiced,[19/n][torch/elastic][upstream] Replace pytorch.distributed.launch with torchelastic launcher (#56037)
71f9e99e29,distributed,Untopiced,[torch/elastic] Introduce aux types required by `DynamicRendezvousHandler` (#55932)
0a06d054d0,skip,Untopiced,"Revert ""Only allow hub.load() from original repo. (#54451)"" (#56048)"
857d8264a7,distributed,Untopiced,Skip RPC's CPU-only tests on CircleCI GPU jobs (#55778)
9f6fed8a15,distributed,Untopiced,[20/n][torch/elastic][upstream] Move torchelastic.distributed.tests to pytorch.distributed (#56077)
6366658fbf,python_frontend,devs,Add OpInfo for torch.nansum (#55523)
6c327ef9d4,jit,Untopiced,matches_jit_signatures is dead (#53637)
5ed3be799d,skip,Untopiced,skip test_filtering_env_var for rocm (#56178)
63f83edcfb,python_frontend,devs,OpInfo porting for torch.real & torch.imag (#55134)
06ea73942a,skip,Untopiced,[easy] Rename fb::jpeg_decode_to_NCHW to fb::image_decode_to_NCHW (#55857)
d56f451820,jit,Untopiced,[NNC] Separate printing of optimized llvm bitcode from assembly (#56117)
16820bba5a,skip,Untopiced,"[nnc][trivial] Trailing underscore style for llvmCode, asmCode members (#56118)"
b940516061,jit,Untopiced,[NNC] Don't fuse fp16 on CPU (#56119)
33159b68a3,skip,Untopiced,"Revert ""Deprecate legacy constructor `torch.Tensor()` (#54414)"" (#55831)"
14d529a368,jit,Untopiced,Add support for refinement for torch.jit.Future (#56148)
aae1023bed,caffe2,Untopiced,[caffe2] allow passing options to the DB in Save operations (#55935)
9bfe16a308,jit,Untopiced,should_check_autodiff is now should_autodiff_node (#56013)
e2036ea342,skip,Untopiced,Revert D27758303: [20/n][torch/elastic][upstream] Move torchelastic.distributed.tests to pytorch.distributed
512c744f2e,distributed,Untopiced,[torch/elastic] Introduce `PeriodicTimer` (#55919)
90e103ddfe,skip,Untopiced,Revert D27753803: [19/n][torch/elastic][upstream] Replace pytorch.distributed.launch with torchelastic launcher
a3a75bd35e,linalg_frontend,Untopiced,Add complex autograd support for `torch.cross` (#55854)
f26a6cb372,quantization,Untopiced,[quantization] Fix deepcopy on quantized ConvNd (#56154)
bb245b6444,python_frontend,Untopiced,[optim] refactor adamax to use functional API (#55830)
8ef13cf976,python_frontend,Untopiced,[optim] refactor rprop to use functional API (#55832)
4e9e7200f2,distributed,Untopiced,[dist_optim] Add distributed functional Adamax optimizer (#55833)
dd090e72b2,distributed,Untopiced,[dist_optim] add distributed functional rprop optimizer (#55834)
f02454f957,nn_frontend,Untopiced,Fix ChanelShuffle named tensor warnings (#55911)
e1752ffa04,jit,Untopiced,[reland][ROCm] use hiprtc precompiled header (#55965)
8e82e932f3,jit,Untopiced,"Reland: D27652485: [nnc] Enable CPU fusion only when num_threads == 1"" (#56120)"
3fbca31be3,structured_frontend,Untopiced,port addmv to structured kernels (#55746)
ff1498e668,caffe2,Untopiced,Add cost inference for MulGradient operator
3c4e1cd141,nn_frontend,Untopiced,remove annoying warnings from common_nn.py (#55982)
cfc9716246,composability,Untopiced,Change all unary functions stubs to use TensorIteratorBase& (#56078)
f17c9ea2ed,structured_frontend,Untopiced,Port all unary float functions to structured (#56082)
52f1a07b63,build_frontend,Untopiced,Python API for Vitals (#53238)
1ca51f0fba,profiler,Untopiced,[kineto] deprecate metdata args from ClientTraceActivity (#55988)
5ad3bc715c,quantization,Untopiced,ns for fx: change node I/O determination to strict allowlist (#55434)
3786c2719d,quantization,Untopiced,ns for fx: make NSTracer inherit from QuantizationTracer (#55505)
1cbc4023e9,quantization,Untopiced,ns for fx: add qat handling for weight extraction (#55506)
f6a3936ab3,quantization,Untopiced,ns for fx: extend functional weight extraction testing to QAT (#55507)
37fbc069f1,quantization,Untopiced,ns for fx: qat test cases for unshadowed activations (#55508)
84b5f67d9b,quantization,Untopiced,ns for fx: add qat tests cases for shadowed activations (#55614)
b461104554,quantization,Untopiced,ns for fx: make get_reversed_fusions reuse quantization fusions (#55803)
c8209a7336,quantization,Untopiced,ns for fx: move pattern utils to separate file (#55805)
f59244ec16,quantization,Untopiced,ns for fx: add test for op relationship coverage (#55837)
bde53cfd9a,jit,Untopiced,[tensorexpr] Add missing python bindings for NNC Stmts (#55570)
400398006f,distributed,Untopiced,[PARAM] Param comms debug info (#55976)
7d410bc3c8,releng,Untopiced,.github: Add initial linux CI workflow (#55176)
42f5d66080,distributed,Untopiced,[DDP] Fixes flaky tests caused by incorrect floating-point comparison (#56192)
94ce10f732,mobile,Untopiced,[iOS GPU] Use setTexture() rather than copyTexture() (#56069)
bd3c63aeeb,jit,Untopiced,[PyTorch Edge] Move torch::jit::mobile::_export_operator_list() from serialization/export_module.cpp to mobile/import.cpp (#56044)
4611387608,distributed,Untopiced,[optim] take kw-only argument for functional optim APIs (#56185)
8f68396462,package,Untopiced,[package] fix error handling with allow_empty (#56190)
d2d1112513,autograd_frontend,Untopiced,Set ThreadLocalState correctly in the autograd engine (#56174)
b405e2ce12,jit,Untopiced,Implicit conversion from null tensor to NoneType (#55823)
0a541e23e1,nn_frontend,Untopiced,[nn] Add allow_duplicate option for named_modules (#54812)
6b5ed5ec45,skip,Untopiced,Revert D27803529: [pytorch][PR] .github: Add initial linux CI workflow
1a1b23f00c,skip,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
b96cc9ab20,fx,Untopiced,[FX][testing] Test tracing into all the standard torch.nn.functional (#55550)
f236c27819,skip,Untopiced,Update Gloo submodule (#56189)
e387bd780e,skip,Untopiced,Ignore envrc files (#56199)
c5e80d30bf,releng,Untopiced,"Harden ""Add annotations"" workflow (#56071)"
f9b3dcba0d,releng,Untopiced,Store coverage.xml as artifact for windows test jobs (#56179)
119b3eccda,python_frontend,devs,"Revert ""Revert D27598681: Add OpInfo tests for torch.addbmm"" (#55908)"
48c6f0c25e,python_frontend,devs,Add OpInfo for torch.mean (#55525)
fe18144618,amd,Untopiced,Generalize HIP-specific launch bounds to apply to CUDA as well (#56143)
5ec6434945,quantization,Untopiced,ns for fx: move op dtype category mapping to separate file (#55858)
430fc03e3f,quantization,Untopiced,ns for fx: add category for ops which accept fp32 or int8 input (#55859)
2380cc7d65,quantization,Untopiced,ns for fx: fill out coverage for node I/O types (#55918)
0fbc2be234,quantization,Untopiced,ns for fx: enable `call_method` nodes in graph matching (#56194)
07f3eaa716,quantization,Untopiced,ns for fx: remove deprecated code (#56195)
6de5d13e0f,quantization,Untopiced,ns for fx: make `call_method` nodes work in NS APIs (#56196)
ae0af8bb51,quantization,Untopiced,ns for fx: move unmatchable mod/fun/meth mapping to mappings file (#56197)
9f216b9499,quantization,Untopiced,ns for fx: enable shadowing int8 to int8 (#56205)
dd8bfe2b93,python_frontend,bc_breaking,Finish deprecation cycle for inplace view error checks (#56093)
03cc9fabd4,python_frontend,Untopiced,Added complex datatype support to sigmoid on cuda (#55975)
bb35b066af,releng,Untopiced,Put `env` before `run` or `with` in GHA workflows (#56268)
3e0744a1ae,skip,Untopiced,[sparsity] Moving only the C++ files from internal to OSS
7629477ff7,releng,Untopiced,Filter out more expected errors from sccache log (#56281)
26046b9110,caffe2,Untopiced,[caffe2][publish] Optimize metanetdef load
164bee1d09,autograd_frontend,Untopiced,"Return a CType instead of a string for returns, beef up CType (#55046)"
947c7a8215,caffe2,Untopiced,add C++ namespacing logic to ctypes (#55047)
eca98fedb5,autograd_frontend,Untopiced,split out NamedCType from CType. Remove direct string comparison from autograd codegen (#55334)
d79326ce7a,skip,Untopiced,Revert D27812204: [sparsity] Moving only the C++ files from internal to OSS
0dc6e7ae38,autograd_frontend,Untopiced,Move grad_mode.h/cpp to c10. (#56204)
8d7faa2af8,python_frontend,Untopiced,Update _torch_docs.py to close #56240. (#56242)
5f19385588,jit,Untopiced,[TensorExpr] Add aten::matmuls to TE fuser. (#54605)
1ec12fd491,skip,Untopiced,Add minidump collection via breakpad (#55647)
8d4e6c9570,package,Untopiced,[package] make GlobGroup a public concept (#56238)
164de39a11,jit,Untopiced,Fix build failure due to namespace change for log_out and tanh_out (#56278)
5a9b1ddf3b,skip,Untopiced,fix the readme link (#56269)
a6940aae37,distributed,Untopiced,[19/n][torch/elastic][upstream] Replace pytorch.distributed.launch with torchelastic launcher (#56214)
d4fad109e8,python_frontend,Untopiced,Add OpInfo tests for torch.inner (#55536)
1360980659,skip,Untopiced,Remove duplicate test due to rebasing mistake (#56287)
d30e31cfe6,distributed,Untopiced,[20/n][torch/elastic][upstream] Move torchelastic.distributed.tests to pytorch.distributed (#56215)
ce1380f9b5,jit,Untopiced,fixing Optional[Tensor] type in autodiff (#55565)
643dd26389,jit,Untopiced,Fix formatting for the new language reference (#56042)
83cfaf1a12,profiler,Untopiced,[kineto] deprecate pthreadid (#56209)
d312aeb6ac,autograd_frontend,Untopiced,Implement faster gradcheck but not enabled for most things (#54480)
8176ab6ca0,jit,Untopiced,[jit] Put explicit error message on class attribute accesses. (#55723)
cd780e1c6e,jit,Untopiced,Move graph iterator to seperate utility file (#56211)
98933866a9,quantization,Untopiced,[quant][graphmode][fx] Optimize cat (#54813)
5eadc243f3,fx,Untopiced,Preserve node meta info in split_module (#56212)
48e675ac75,quantization,Untopiced,fx quant: fix subtle bug in BinaryOpQuantizeHanlder logic in matching (#56294)
72a93a6337,jit,Untopiced,Fix warnings in ivalue test (#56303)
d02919dd50,fx,Untopiced,[FX] Make shape_prop handle targets with aggregate outputs (#56221)
a43483586d,jit,Untopiced,A heuristic to avoid perf incompatible MKLDNN formats for binary ops (#56089)
7636cb6bab,skip,Untopiced,clean up unused reduction functions in THC (#56293)
04e7891aab,jit,Untopiced,Add adaptive_avgpool2d to the set of fusible ops (#56180)
928a4733af,jit,Untopiced,[NNC] Only lower float conv2d's (#56289)
be2a0805d2,distributed,Untopiced,[TensorPipe] Update tensorpipe subodule + remove TP_NEW_API switch. (#56260)
50d4c63f46,composability,Untopiced,Allow inlining of more Tensor methods (#53905)
dd9ef529ba,jit,Untopiced,[TensorExpr] TensorExprKernel: switch type of tensors_ from Tensor to Buf. (#56318)
85126629a5,jit,Untopiced,[TensorExpr] Add support for constant tensors in tensorexpr kernel. (#56319)
36b476ccdd,python_frontend,devs,"Added OpInfos for eq, ne, ge, gt, le, and lt (#55709)"
8c74e1b840,performance_as_product,performance,Vectorize copysign on CPU (#51792)
b0e0841f98,python_frontend,devs,OpInfo porting for logsumexp operator (#55520)
29c5cb797d,jit,Untopiced,[NNC] Fuse loops that have the same bounds as expressions (#55997)
a24b17248f,distributed,Untopiced,Short circuits DistributedDataParallel._recursive_to's copy and stream syncs if input is already on the right device (#55624)
ce05b7a324,distributed,Untopiced,"[c10d] Remove deprecated use of torch.LongTensor, torch.ByteTensor (#55861)"
3e42da09df,python_frontend,devs,Porting logcumsumexp tests to OpInfo (#56135)
ffdecc1ac4,cuda,Untopiced,[CUDA graphs] Allows DeviceCachingAllocator to capture cross-stream memory use (#55860)
22d4d9f4a6,skip,Untopiced,[pytorch][PR] Automated submodule update: tensorpipe (#56348)
b387f7ca47,jit,Untopiced,[NNC] Make normalization transformation in-place (#56158)
2219286de4,linalg_frontend,Untopiced,Updated internal code for orgqr function (#56247)
0e106fce9c,python_frontend,Untopiced,add tests for torch.testing (#54784)
7513455c74,python_frontend,Untopiced,Make tensordot resize output tensor's size if out= argument is specified & make it safely cast & copy output (#56286)
1077f87269,skip,Untopiced,Support factory kwargs in torch.nn modules (#54508)
7d17559152,skip,Untopiced,[special] OpInfo `i0e`: fix missing check (#56232)
d05e7c163f,skip,Untopiced,Revert D27600457: [pytorch][PR] Support factory kwargs in torch.nn modules
92991d9533,python_frontend,devs,Add OpInfo for (nan)quantile (#55548)
b6b2fc7e3f,python_frontend,devs,Added OpInfos of add & mm (#55915)
d806b06167,python_frontend,Untopiced,Support int32 indices in torch.repeat_interleave (#55102)
98ac6f7cbc,distributed,Untopiced,Increase default rendezvous timeout to 15 minutes
838d3079ad,jit,Untopiced,Lazily initialize alias db in remove_mutation opt (#55949)
6409d34482,jit,Untopiced,Sort glob of files to ensure it is deterministic (#55850)
8881f504f1,skip,Untopiced,Remove the unused maximum and minimum functions in vec256_base (#56313)
98162cb0bb,autograd_frontend,Untopiced,Enable AutoGradMode in InferenceMode. (#56107)
5748cc0d11,jit,Untopiced,[Mobile GPU] Ban mutations in JIT passes (#56070)
48aaea3359,distributed,Untopiced,unified GlooStore and c10d store API (#56222)
d1b6383d65,quantization,Untopiced,Hide warnings for deprecated quantization APIs (#56291)
ca6e5c7fc9,jit,Untopiced,[NNC] added more python bindings for loopnest (#56213)
40483acc51,skip,Untopiced,Support factory kwargs in torch.nn modules (#54508)
7bcf95bbb6,mobile,Untopiced,[iOS GPU] Move the definition of `fp16_t` to MetalUtils.h (#54521)
e3900d2ba5,skip,Untopiced,Add lint for unqualified `noqa` (#56272)
2c9972facf,mobile,Untopiced,[iOS GPU][Kernel] Implement transpose in Metal shaders (#54522)
04607a58f1,nn_frontend,Untopiced,[pytorch] Fix compiler warnings from conv.h (#56181)
a14178ed5c,skip,Untopiced,Remove useless code (#56230)
638617f9f8,skip,Untopiced,Write mini dump on pybind exceptions (#55652)
2f5c352162,caffe2,Untopiced,Fix protobuf warnings in caffe2 (#56186)
34d0bd5b1d,python_frontend,Untopiced,Fix TestTypeHints.test_doc_examples (#56388)
fa7534788b,skip,Untopiced,Fix typo in gradcheck.py (#56368)
fe3f6f2da2,mobile,Untopiced,[iOS GPU][Kernel] Implement mean.dim using MPSReduce kernel (#56073)
0d94c04247,jit,Untopiced,[NNC] Change fuseLoops API to return bool flag and not throw any exceptions (#56353)
7adc04d7b5,distributed,Untopiced,Add more logging to debug test_reduce_sum_cuda_twice (#56406)
0917061f43,vulkan,Untopiced,[vulkan][jit_pass] Add optimized_for_vulkan attribute on vulkan pass (#56414)
31677c5fcb,releng,Untopiced,[reland] .github: Add initial linux CI workflow (#56280)
5b4c3a9da1,distributed,Untopiced,record Torch DP and DDP modules forward (#55578)
f096245610,autograd_frontend,Untopiced,AutoNonVariableTypeMode->InferenceMode in OSS. (#56421)
b1282bc109,jit,Untopiced,Use stack trace implementation in common/process on fbcode (#56400)
92d24e3060,skip,Untopiced,Revert D27855386: [pytorch][PR] Support factory kwargs in torch.nn modules
42f0fe1fe3,nn_frontend,Untopiced,fix misaligned access #56325 (#56403)
94406f77f6,quantization,Untopiced,[quant][graphmode][fx] Add support for keeping output quantized for list and dict (#56391)
023231a2ac,distributed,Untopiced,[torch/distributed] Fix pydoc for torch.distributed.elastic.multiprocessing (replace Redirect with Std)
07653b7fe0,nn_frontend,Untopiced,[SPMD] Remove ddp_gpu_size field from SyncBatchNorm (#55946)
513e9e0927,cuda,Untopiced,Fix cxx11 abi (#55984)
0d4394778e,structured_frontend,Untopiced,Port adaptive_max_pool2d to structured kernel (#56317)
85f4025ad7,structured_frontend,Untopiced,Port adaptive_max_pool3d to structured kernel (#56320)
7ae45403a1,jit,Untopiced,[static runtime] support aten::__getitem__ natively (#55310)
c5c5230890,distributed,Untopiced,Pytorch resolve bug around incorrect rdzv handler resolution (#56386)
a661e58731,linalg_frontend,Untopiced,Removed infos vector in torch.linalg.qr (#56248)
df8bb5a42b,python_frontend,devs,Add OpInfo for polygamma and remove torch_op_tests Infra (#51966)
0ea4eb745b,python_frontend,devs,[opinfo] torch.lerp: move remaining cases from tensor_methods to opinfo (#55665)
63dac82444,skip,Untopiced,Make grad mode error just a warning (#56401)
43c747859c,caffe2,Untopiced,Use c10 backtrace generation in caffe2 (#56198)
3d878dee45,linalg_frontend,Untopiced,Added out= variant for torch.linalg.lstsq (#54721)
c61778355c,releng,Untopiced,Upgrade ShellCheck to v0.7.2 (#56445)
eacf6f1b51,skip,Untopiced,Updated the tech docs to be consistent with other two descriptions (#56338)
4e0760f41a,skip,Untopiced,Remove `is_variable` from tests (#56305)
0e0a5471ef,caffe2,Untopiced,Remove an unused variable in SoftmaxWithLossOp (#56321)
b2dae294b6,distributed,Untopiced,Fix distributed.test_jit_c10d flaky tests (#56410)
f74a346213,python_frontend,Untopiced,"Fix torch.hub.load(""pytorch/vision"") fails to validate the master branch (#56138)"
e4faebca0d,skip,Untopiced,Automated submodule update: tensorpipe (#56259)
062e70590c,python_frontend,devs,"Add OpInfo tests for torch.{dot, vdot, bmm, mv} (#56409)"
75651e3cc4,releng,Untopiced,Add remaining ToCs to ToC lint (#56487)
59b61f912a,python_frontend,Untopiced,Switch assertWarnsOnceRegex logic to check any instead of all. (#56434)
04de24d10a,distributed,Untopiced,Separate profiling tests from p2p tests (#56412)
5017c5fcad,nn_frontend,Untopiced,[SPMD] Remove _specify_ddp_gpu_num method (#56425)
a8ea490f67,caffe2,Untopiced,Revert caffe2 print stack traces flag (#56496)
8868f9c8e3,distributed,Untopiced,[TensorPipe] Use targetDevice in tensorpipe_agent. (#56346)
ab20ba4427,composability,Untopiced,Fix issue with dispatch key: AutogradXPU (#56336)
43eb21bff3,releng,Untopiced,[skip ci] Add simple local actions runner (#56439)
ea4af1511c,skip,Untopiced,[Pytorch] Better error message for bundling inputs a second time (#56086)
6e1fc5cef8,quantization,Untopiced,[quant] added dq->op->q quantization patterns for GELU and softmax ops (#56004)
12b5e666b0,releng,Untopiced,add codegen subdirectories to mypy-strict.ini (#56523)
c65284aa07,jit,Untopiced,Remove caption for Lang Reference (#56526)
7d4e9bdba1,dataloader_frontend,Untopiced,Add type hint for SequentialSampler (#56374)
1e03a2505f,memory_format_frontend,Untopiced,add channels last for MaxPool2d (#56361)
17b8a4db1c,jit,Untopiced,[NNC] Support `pow` on CPU (#56308)
20e88401db,jit,Untopiced,Add monkey type config for JIT (#54513)
15734f5b6f,caffe2,Untopiced,Ignore warnings for record_function_ops (#56543)
8ae8fb7dd1,mobile,Untopiced,[iOS GPU][Stub] Move conv2d_prepack impl from MetalPrepackOpRegister.cpp to MetalConvolution.cpp (#56491)
af7775ba26,distributed,Untopiced,Types for caffe2/torch/testing/_internal/common_distributed.py (#55338)
3cc4dbb66d,quantization,Untopiced,Expose nbins and ratio (#50398)
1d8053655d,autograd_frontend,Untopiced,Rename AutoNonVariableTypeMode to AutoDispatchBelowAutograd and add a warning. (#56422)
13ac0019ae,jit,Untopiced,[NNC] Update loop-carried dependence check to handle all known dependences (#56354)
3d904b56ec,autograd_frontend,Untopiced,s/AutoNonVariableTypeMode/AutoDispatchBelowAutograd/ (#56423)
7fff71eb9a,cpp_frontend,Untopiced,Fix warnings in tensor_flatten.cpp (#55956)
594c546b69,mobile,Untopiced,[PyTorch Edge] Eliminate non-determinism when generating build YAML file (#56539)
a4626348bc,jit,Untopiced,fix unqualified noqa lint (#56548)
a2422cc243,jit,Untopiced,Add stricter check for function schemas with varargs (#56509)
19943aafe9,caffe2,Untopiced,[caffe2] Speed up remote net loading
75995e4bf6,onnx,Untopiced,[ONNX] Add support for hann_window operator. (#54587) (#56163)
9986b109d2,onnx,Untopiced,[ONNX] Fix assign input shape for tuple inputs & primitive type inputs (#54112) (#56164)
f804b65d4e,onnx,Untopiced,[ONNX] Update repeat_interleave symbolic (#54312) (#56165)
5a455dc717,onnx,Untopiced,[ONNX] Enable tensordot symbolic function. (#55654) (#56166)
a31fd7f453,onnx,Untopiced,Fix onnx/constant_fold.cpp compilation on Windows (#55770) (#56167)
90e63cc41f,onnx,Untopiced,[ONNX] Add support for prim::min (#55259) (#56168)
0b0fca3c59,onnx,Untopiced,[ONNX] Export mv op (#55470) (#56169)
1e449694a3,onnx,Untopiced,[ONNX] enable word_language_model GRU and LSTM scripting (#54310) (#56170)
88fbbb4165,onnx,Untopiced,[ONNX] Fix ComputeShapeFromReshape when input_shape_size < reshape_size (#56171)
33f206b865,jit,Untopiced,[StaticRuntime] Replace StorageImpl with TensorImpl in MemoryPlanner (#56447)
c91c4a081d,jit,Untopiced,[NNC] Horizontally fuse all loops (#56324)
4575028f6c,jit,Untopiced,Update script API to take example inputs (#55376)
7929bc76a0,caffe2,Untopiced,[shape inference] Fix dim type for Cast
b66a1e00a6,jit,Untopiced,[NNC] added skeleton for refactoring (#55371)
d168eae114,python_frontend,Untopiced,make torch.testing error messages more expressive (#55145)
46a1ac40d9,cpp_frontend,Untopiced,fix meta() calls for non-storage tensors (i.e. xla) (#56306)
87a1ebc9cd,structured_frontend,Untopiced,"fix RegistrationDeclarations.yaml, now that we codegen composite kernels for structured functional/inplace ops (#56307)"
75024e228c,skip,Untopiced,Add lint for unqualified `type: ignore` (#56290)
744360ce52,cpp_frontend,Untopiced,Fix missing definitions in Vec256 for VSX (#56486)
51d0212d0f,skip,Untopiced,generate xla codegen in-tree (#55050)
fe0e1c71a7,skip,Untopiced,Add type ignore lint to Makefile (#56587)
d43d6593cd,jit,Untopiced,[NNC] Handling conditionals in reorderAxis (#56063)
e51f73a03e,releng,Untopiced,Report test stats for macos_10_13 tests (#56429)
a583b9cd86,nn_frontend,Untopiced,"Fixing ""naive"" `forward` of `ModuleList` and `ModuleDict (#48785)"
2e8418025a,vulkan,Untopiced,[vulkan] safe_downcast for buck build (#56540)
096089abcb,quantization,Untopiced,[quant][graphmode][fx] Produce torch.cat instead of torch.ops.quantized.cat (#54924)
b7d5a0cf10,distributed,Untopiced,[c10d] sequence number in process group (#55319)
90e532f3ef,skip,Untopiced,Revert D27708346: generate xla codegen in-tree
3e55fc91fd,distributed,Untopiced,[pet] Remove additional @record in elastic_launch to fix file existing error
02c9d2dc90,distributed,Untopiced,Release GIL before destructing ProcessGroup classes (#56381)
e691f24079,cpp_frontend,Untopiced,[sparsity] Moving only the C++ files from internal to OSS (#56553)
8a81c4dc27,nn_frontend,Untopiced,Update padding_idx docs for EmbeddingBag to better match Embedding's (#56065)
7660cb880f,releng,Untopiced,Rename job to be py2-setup-validate-errormsg (#56593)
4230040470,distributed,Untopiced,torch: Fix flake8 errors from leftover import (#56614)
8ee1347c3f,fx,Untopiced,Changes to support strides in addition to shape and dtype. (#56567)
11e26e7246,quantization,Untopiced,"[sparsity][refactor] Remove ""Sparsity"" from the function names (#56555)"
5a09def9b0,skip,Untopiced,Support factory kwargs in torch.nn modules (#54508)
284e735b3f,releng,Untopiced,Set show_error_codes = True in mypy-strict.ini (#56616)
12b2bc94d7,skip,Untopiced,Revert D27909732: [pytorch][PR] Support factory kwargs in torch.nn modules
5e4dfd0140,releng,Untopiced,Add quicklint make target (#56559)
3e0c226eed,jit,Untopiced,Raise TypeErrors when IValue::getSubValues fails (#56510)
af23822112,jit,Untopiced,Gracefully handle failure of DataPtr extraction in CUDAFuture (#56511)
5ddc2691d0,jit,Untopiced,Merge ivalue::Future's markCompleted and markCompletedWithDataPtrs (#56512)
7dec14a491,distributed,Untopiced,Avoid defining RpcCUDAFuture subclass in TensorPipe agent (#56513)
0911ee9108,build_frontend,Untopiced,Split CUDAFuture into a .h and a .cpp file (#56514)
eac082891f,package,Untopiced,[package] Massage exporter docstrings (#56547)
3ec6bf5d26,nn_frontend,Untopiced,Fix cuda launch error in reflection_pad2d (#56451)
27a0d6f1df,autograd_frontend,Untopiced,AutoDispatchBelowAutograd takes no arguments. (#56424)
772ca1a2c3,vulkan,Untopiced,[vulkan] Add Vulkan registrar for internal build (#56620)
5e695b1271,releng,Untopiced,Use absolute path for local linter (#56633)
1211bccc65,cpp_frontend,bc_breaking,[PyTorch] Fix const correctness for resize native functions (#55351)
26fc27cb4f,structured_frontend,Untopiced,[PyTorch] Format generated structured kernels code better (#55258)
b79901f932,composability,Untopiced,[PyTorch] Remove non-const TensorIterator::tensor() method (#55420)
7e8f078a3d,cpp_frontend,Untopiced,[PyTorch] Always update op.current_dtype in TensorIteratorBase::set_output (#55940)
01842d2bb0,cpp_frontend,Untopiced,[PyTorch] Support borrowing in/out Tensors in TensorIterator (#55690)
6032ea0313,cpp_frontend,Untopiced,[PyTorch] Migrate add operators to borrow in TensorIteratorBase (#55691)
28f52649d8,profiler,Untopiced,add dtype information for input (#55358)
c244d1c540,package,Untopiced,[package] resolve `__import__` calls on export (#55153)
76ca1eeeb8,distributed,Untopiced,[4/n] [torch/elastic] Fix the finalizer of PeriodicTimer (#56532)
df91eb924c,distributed,Untopiced,[5/n] [torch/elastic] Introduce the delay utility function (#56533)
21d9bc246b,distributed,Untopiced,[6/n] [torch/elastic] Reorder type definitions in dynamic_rendezvous.py (#56534)
853112bbfc,distributed,Untopiced,[7/n] [torch/elastic] Rename _Rendezvous to _RendezvousState (#56535)
d83ae5d1b7,distributed,Untopiced,Add devices to TensorPipe options (#56405)
e0be76fb9b,jit,Untopiced,[static_runtime] fix num args for to_copy (#56441)
73eaa0a5f5,jit,Untopiced,Fixing error in jit cuda on ROCm: non-constant-expression cannot be n (#55243)
5dcc7ac35c,releng,Untopiced,Add new scheduled job to circle-ci workflow (#55182)
6d7d36d255,nn_frontend,Untopiced,"s/pad/""pad""/ in files introduced by #56065 (#56618)"
a970e525fd,distributed,Untopiced,make ProcessGroup.Options.timeout argument private in python (#56531)
43ad172c54,distributed,Untopiced,make ProcessGroupDefaultTimeout the same as python (#56549)
818ce1d0d2,onnx,Untopiced,Add standardOps match more input type in ORT (#53813) (#56172)
24ff92f76d,onnx,Untopiced,[ONNX] Redesign inplace conversion (#55033) (#56173)
0cc42809ce,skip,Untopiced,Enable skipped test for c10::complex on CUDA >= 11.2 (#50227)
76fbd755c1,composability,Untopiced,"Reland of ""D27708346: generate xla codegen in-tree"" (#56601)"
df1dfd879e,nn_frontend,Untopiced,Fix errors when initializing Linear with 0 in_features (#56505)
a1299a2802,releng,Untopiced,Disable Windows GPU testing (#56655)
36828aa0ff,skip,Untopiced,Revert D27866138: [ONNX] Redesign inplace conversion (#55033)
1b87274460,mobile,Untopiced,[iOS GPU][Design] Support multiple tensors as outputs (#56072)
d24314bd2c,skip,Untopiced,Update Kineto submodule and use new metadata api (#56432)
5cc75e46fa,distributed,Untopiced,"Split test_c10d.py to test_c10d_common.py, test_c10d_gloo.py, test_c10d_nccl.py (#56598)"
426852b4f0,releng,Untopiced,"Split test_c10d_spawn.py to test_c10d_spawn_gloo.py,test_c10d_spawn_nccl.py (#56599)"
57cba8e601,skip,Untopiced,Use at::cpu in bench_approx (#56563)
81b59211d4,benchmark,Untopiced,[static runtime] binding for aten::div_out (#56653)
0df239e550,fx,Untopiced,[FX] Make arg normalization a method on Node and not a pass (also augment tests to be exhaustive) (#55992)
49df8993c4,python_frontend,devs,Port `scatter` and `scatter_add` to `OpInfo` (#56140)
76214bb464,python_frontend,devs,Add OpInfo for torch.baddbmm (#56502)
1f0223d6bb,nn_frontend,Untopiced,Fix bug in gaussian_nll_loss (#56469)
bdb421895a,releng,Untopiced,Remove some wildcards from mypy configs (#56645)
47d2edd597,fx,Untopiced,Fix quick-checks for operator-schemas (#56692)
3355c30f91,releng,Untopiced,Always run all the grep-based quick-checks steps (#56700)
690c8b434f,benchmark,Untopiced,[static runtime] binding for aten::sub_out (#56656)
9be2cabc45,nn_frontend,Untopiced,Pass contiguous weight to NNPACK convolution (#56569)
78022aa62c,fx,Untopiced,Add more model symbolic tracing tests from torchvision (#55744)
21fd5f4b79,build_frontend,Untopiced,Document current deploy cpython build #56490 (#56600)
bc3d892c20,build_frontend,Untopiced,README: Minor improvements (#56193)
aec83ff45e,dataloader_frontend,Untopiced,[DataLoader] Add Numpy seeding to worker of DataLoader (#56488)
8cf85a1152,dataloader_frontend,Untopiced,[DataLoader][doc] Randomness for base_seed generator and NumPy seed (#56528)
dfb65146e5,releng,Untopiced,Add RELEASE.md (#56520)
86ae22d85d,package,Untopiced,[torch.Package] Folder has_file() method (#56584)
c6d004125e,structured_frontend,Untopiced,Port all non-float unary operators to structured (and rsqrt) (#56151)
036becf29c,nn_frontend,Untopiced,Disable TestComplexity.test_nn_module_test in fbcode (#56677)
f0958f4748,distributed,Untopiced,[c10d] Add requires_gloo decorator to test_logging_init (#56682)
1dbbbbe904,quantization,Untopiced,[doc] FX Graph Mode Quantization - fix preamble (#52192)
187a524249,releng,Untopiced,Re-order tests based on changed files (#56666)
614dce54a6,mobile,Untopiced,[iOS GPU] Fix Shader compilation errors for Metal 1.2 (iOS 12) (#56670)
0c544ebd24,mobile,Untopiced,Revert to ANVTM in jni_lite due to Oculus failure.
b85b89d246,distributed,Untopiced,Re-enable test_device_maps_gpu (#56415)
8b3bf98cb8,composability,Untopiced,Tell codegen that SparseCsrCUDA is cuda (#56602)
048087d942,nn_frontend,Untopiced,make beg_size output deterministic for EmbeddingBag (#56661)
2ee3f5f812,releng,Untopiced,"Copy over test reports before running ""report results"" for linux test jobs (#56725)"
679cc7eb13,nn_frontend,Untopiced,Re-enable fast winograd conv on IOS (#56021)
2128a84a69,autograd_frontend,Untopiced,Fix grad_fn bindings when saved variable freed (#56499)
5b01b3e8e8,releng,Untopiced,Introducing JitPlugin (#56708)
31fe2bbb30,releng,Untopiced,Remove extraneous variables in windows report stats step (#56596)
375687839e,python_frontend,Untopiced,[sparsity] Moving the sparsity python files to OSS (#56617)
3a44d269ac,releng,Untopiced,Add periodic_ prefix to all jobs run by cron (#56695)
1719cb82f3,quantization,Untopiced,[quant][graphmode][fx] Support preserving attributes in deepcopy of observed/quantized graphmodule (#56550)
3a4344a717,distributed,Untopiced,Create helper function for RPC profiling in _invoke_rpc and remote (#56643)
febff45900,skip,Untopiced,Support factory kwargs in torch.nn modules (#54508)
bac4cfd54d,nn_frontend,Untopiced,Fix mp serialization for integer nn.Parameter on CUDA (#56529)
08ce2300bf,build_frontend,Untopiced,torch: Add cpython as a dependency for torch_python_obj (#56740)
5c752ead3e,releng,Untopiced,Print non-breaking space directly in lint.yml (#56726)
2ea3c24c06,skip,Untopiced,Disable flaky tests (#56279)
d01302431c,autograd_frontend,Untopiced,Enable fast gradcheck for real inputs and outputs (#55237)
2078836005,autograd_frontend,Untopiced,Clean up raise exception logic (#55656)
29491f7954,jit,Untopiced,[NNC] Add unroll and flatten APIs which not require return stmt pointer (#56420)
f84a50109f,releng,Untopiced,Move windows testers to previous image (#56626)
461e887d92,benchmark,Untopiced,CPU Convolution benchmark harness for some popular models (#56455)
913f1f75b3,onnx,Untopiced,"Revert ""Revert [ONNX] Redesign inplace conversion"" (#56675)"
88deea4e29,package,Untopiced,[torch.package] is_from_package check (#56729)
1f04494c0e,skip,Untopiced,Consolidate nondeterministic error tests (#55631)
7c50852a60,jit,Untopiced,moved more lowerings over (#55372)
a4e47ea152,jit,Untopiced,static runtime support for fb::equally_split (#56565)
0a72904ab4,distributed,Untopiced,Torchelastic: make process failure init error non-fatal (#56739)
83c23703b7,jit,Untopiced,Some simple optimizations (#51831)
e5fda07e80,nn_frontend,Untopiced,Fix: Compare input against beta * threshold in softplus backwards (#56484)
02c3e6d98a,nn_frontend,Untopiced,addmm CPU inplace implementation shouldn't resize an input tensor (#56452)
f2fd91ccfd,composability,Untopiced,[PyTorch] Add & document borrow_from_optional_tensor (#56647)
7b7a4750a9,composability,Untopiced,[PyTorch] Migrate hacky wrapper removal to borrow_from_optional_tensor (#56648)
d6a25a58f5,jit,Untopiced,"add hardtanh(0,6) to the set of MKLDNN fusible ops for mobilenetv2 (#56203)"
58d12eb75e,cuda,Untopiced,Allow to specify a set of device for CUDAFuture (#56515)
15ca379bde,jit,Untopiced,Add CUDA support to a user-created torch.futures.Future (#56517)
369e8bc4bc,linalg_frontend,Untopiced,Added support for uppercase letters in torch.einsum (#56475)
acca89e25f,distributed,Untopiced,Add more RRef CUDA RPC tests (#56757)
22b151a3ba,nn_frontend,bc_breaking,Make sure full backward hook fire when no input requires grad (#56693)
88bd0510ef,jit,Untopiced,Use JIT Plug-in for coverage to cover JIT'd functions and methods (#56310)
d1fe68e70b,python_frontend,Untopiced,To add single and chained learning schedulers to docs (#56705)
ed0a0c3578,skip,Untopiced,Revert D27902824: static runtime support for fb::equally_split
7ff1990caf,distributed,Untopiced,[c10d] Increment sequence numbers on collectives. (#55718)
7e9f7fb980,jit,Untopiced,[Pytorch Edge] Prepack folding for functions besides forward (#56081)
7d2a9f2dc9,nn_frontend,Untopiced,Fix instance norm input size validation + test (#56659)
798dd4665d,fx,Untopiced,Add a new API replace_input_with to node.py (#55887)
2e4c68a727,skip,Untopiced,[PyTorch][Edge] Add v4 and v5 models and remove unused model (#56751)
6de1d9b2d0,jit,Untopiced,Fix bug in emitUse to drop all values that are marked as drop (#56652)
0424f6af93,releng,Untopiced,"Local lint fixes - missing steps, pin to bash (#56752)"
ed2104fe5c,releng,Untopiced,Fixing MAGMA with HIP issues (#56448)
10fd7d8be6,python_frontend,devs,Add option to OpInfo to skip gradgrad check and empty cdist OpInfo (#56603)
3ddcc8d833,skip,Untopiced,Add more test cases for cdist OpInfo and TODOs (#56604)
0d7e780eff,python_frontend,Untopiced,Fix broadcasting of cdist backward (#56605)
e098515b89,python_frontend,devs,Fix cdist backward for empty inputs (#56606)
5b7317b562,jit,Untopiced,[NNC] API for Buffer Compression (#55853)
c37095760d,distributed,Untopiced,[torch distributed] Implementing all_gather_base (#56315)
5288d05cfd,skip,Untopiced,Revert D27958477: [PyTorch][Edge] Add v4 and v5 models and remove unused model
375ebd634a,composability,Untopiced,[PyTorch] Break up generated tag in source (#56503)
be7a943bb8,autograd_frontend,Untopiced,s/AutoDispatchBelowAutograd/AutoDispatchBelowInplaceOrView. (#56657)
2041cd6707,jit,Untopiced,Enable forward/backward compatibility in TS mobile (#56079)
5d940e2fbc,autograd_frontend,Untopiced,[TSAN] Fix PythonEngine data-race-on-vptr. (#56808)
bd3dda95fd,cuda,Untopiced,Make old_gpu warning dynamic (#56621)
060e4c96ee,distributed,Untopiced,Torchelastic: forbid mp tests running with *san (#56827)
b2b9efb33a,releng,Untopiced,.github: Add initial Linux CI for CUDA (#56494)
34eb6c8589,caffe2,Untopiced,[caffe2] ScriptModuleOp support pass_inputs_as_tensor_list (#56813)
e4efc0c948,jit,Untopiced,[Static Runtime] Enable check_for_memory_leak in StaticRuntime::benchmark (#56839)
a688b29750,jit,Untopiced,Support custom Python classes in CUDAFuture (#56516)
c416167fb7,distributed,Untopiced,Add tests for CUDAFuture (#56518)
3fbc15410a,jit,Untopiced,Revert D27967517: [pytorch][PR] Use JIT Plug-in for coverage to cover JIT'd functions and methods
4ef8205104,fx,Untopiced,[FX][normalize] Allow for args to be left as args (#55995)
51bca2ca4d,onnx,Untopiced,[caffe2] fix -Wrange-loop-construct in onnx_exporter.cc (#56759)
45692fbef0,fx,Untopiced,"[fx splitter][fx net_min] Move Splitter, Minimizer and necessary deps to OSS (#56201)"
6e5ce569bd,python_frontend,Untopiced,DOC: add note for torch.clamp() special case min > max See #45664 (#56367)
710288e413,python_frontend,Untopiced,torch.fft: Document out argument (#56732)
bcef7ebd60,jit,Untopiced,[NNC] Added matmul for NNC lowering/unified dtypes (#56456)
dbf3451c6e,python_frontend,Untopiced,Add support for checking tensor containers in `torch.testing` (#55385)
27148db5df,python_frontend,Untopiced,Add support for scalars and numpy in torch.testing (#55786)
edfbc989d1,python_frontend,Untopiced,add support for equal_nan in torch.testing.assert_close (#55788)
805129f957,python_frontend,Untopiced,enable support for custom error messages in `torch.testing` (#55890)
58fcf77712,cpp_frontend,Untopiced,Port CPU torch.geqrf to ATen (#56249)
d5ff432615,linalg_frontend,Untopiced,Add torch.linalg.svdvals (#56684)
e97c17afa0,cpp_frontend,Untopiced,Update internal code for torch.geqrf (#56250)
d4707e260b,jit,Untopiced,Infer types (#56832)
70d9be0f42,skip,Untopiced,Replace duplicative s with alpha (#56804)
2d2370bb61,distributed,Untopiced,[Dist profiling] Fix ProcessGroupNCCL collective profiling (#55204)
7b74c3c70a,distributed,Untopiced,Enable tests for dist profiling with torch.profiler (#56216)
dde2bc4818,build_frontend,Untopiced,Add OPENSSL_ROOT_DIR to cmake.py (#56846)
267b554b6f,fx,Untopiced,fx: Fix type_matches for Optional[List[int]] arguments (#56790)
298db67220,python_frontend,Untopiced,[OpInfo] Add Function Variant and Opinfo for permute (#56125)
9e027d7ea3,python_frontend,devs,[OpInfo] Add opinfo for `transpose` and its aliases (#56122)
9eee14704a,skip,Untopiced,OpInfo: roll and rot90 (#56770)
7b31ba4708,nn_frontend,Untopiced,Fix cudnn ctc loss backward (#56639)
1faf1f96aa,jit,Untopiced,[TensorExpr] Fuser: don't lift tensor constants from fusion groups. (#56756)
441c835733,jit,Untopiced,[TensorExpr] Remove unused field from TensorExprKernel. (#56761)
f3743f097f,jit,Untopiced,[TensorExpr] Nuke tensorexpr::ScalarType and instead use c10::ScalarType directly. (#56825)
f27513e951,python_frontend,Untopiced,Fix bug in torch.sparse.addmm on CUDA when beta != 0 or 1 (#56160)
b3f56ec0e0,skip,Untopiced,Automated submodule update: tensorpipe (#56495)
ed9c7e187b,skip,Untopiced,Added OpInfo for addmm (#55920)
689d3a70aa,quantization,Untopiced,Fix broken link to fx graph quant guide in quantization.rst (#56776)
1e51c05b71,jit,Untopiced,Name .coverage.jit with timestamp to prevent loss of stats (#56829)
a90a3acbee,jit,Untopiced,Use JIT Plug-in for coverage to cover JIT'd functions and methods (#56310)
6ba9fd5963,linalg_frontend,Untopiced,"Added ""Tensor tol"" overload of torch.linalg.matrix_rank (#54157)"
3e006fc57e,python_frontend,Untopiced,"Adding hsplit,vsplit and dsplit methods (#53536)"
5854e93bc9,python_frontend,Untopiced,Fix derivative of sinc at x=0 (#56763)
f84f2063b4,cpp_frontend,Untopiced,Port CUDA torch.geqrf to ATen (#56251)
27a8ece805,cuda,Untopiced,Add cuSOLVER path for torch.geqrf (#56252)
5b1f0ef622,linalg_frontend,Untopiced,Add cuBLAS path for batched torch.geqrf (#56253)
28a9483e36,distributed,Untopiced,fix ddp logging test (#56640)
2f598b53dd,releng,Untopiced,catch xml parser error during report test result phase in CI (#56864)
2639c4e6b3,python_frontend,devs,fix bug in rocm device type (#56646)
6155b0d9fa,releng,Untopiced,[reland] Trigger azure pipeline for multi gpu tests (#56128)
7989f2ac87,distributed,Untopiced,Clang format dist_utils.py and rpc/__init__.py (#56853)
cb1e78038f,releng,Untopiced,.github: Add options to force unzip artifacts (#56929)
72c3ee073f,python_frontend,Untopiced,add deterministic path for index_add_cuda (#56521)
e1a7ec3c4f,caffe2,Untopiced,[caffe2] fix -Wrange-loop-construct
d1088de522,distributed,Untopiced,Let RRef getValue() synchronize CUDA streams (#56895)
9b46b6b37a,releng,Untopiced,Added sm_75 to CUDA Arch List for Linux CI GPU builds (#56619)
e810bed63f,benchmark,Untopiced,[Static Runtime] Clean up op implementations (#56841)
16710e5d93,autograd_frontend,Untopiced,Add reasons in TODO for the unblocked AVNTM -> InferenceMode cases. (#56823)
d221be6fb4,mobile,Untopiced,[iOS GPU] Use thread buffer to store indices for transpose (#56706)
0888b8726a,jit,Untopiced,[static runtime] binding for aten::clamp_min_out (#56635)
f5c24cc891,python_frontend,Untopiced,add deterministic path for index_copy_cpu (#56900)
d405d41a7c,quantization,Untopiced,ns for fx: enable user defined functions for graph matching (#56283)
8dbf6ae8fa,quantization,Untopiced,ns for fx: handling for user functions in weight and unshadowed act APIs (#56292)
93de80203d,quantization,Untopiced,ns for fx: move node I/O dtype mapping to be local instead of global (#56296)
1917350977,quantization,Untopiced,ns for fx: allow user functions in shadowing (#56301)
96a9eafcfb,quantization,Untopiced,ns for fx: add fp16 function shadowing (#56311)
f35540be38,quantization,Untopiced,ns for fx: bug fix for shadowing fp16 emulation patterns (#56384)
c004346c88,quantization,Untopiced,ns for fx: support binary ops when adding unshadowed loggers for inputs (#56408)
92c7aec5f5,quantization,Untopiced,ns for fx: add option to skip matching classes and functions (#56493)
502c58ad84,quantization,Untopiced,ns for fx: allow comparing int8 to int8 for functionals (#56742)
9bd14da6e4,quantization,Untopiced,ns for fx: additional bugfix for user defined functions (#56762)
e909ad2dc4,jit,Untopiced,[static runtime] binding for aten::argmin_out (#56638)
8a0eb7fb2d,jit,Untopiced,[TensorExpr] Docs: checkin 'Conditionals in TE' doc. (#56949)
e7c79cb158,mobile,Untopiced,Add type annotations to nnapi (#48142)
77e3f5d73d,structured_frontend,Untopiced,Port adaptive_max_pool2d_backward to structured kernel (#56799)
3721e01d60,structured_frontend,Untopiced,Port adaptive_max_pool3d_backward to structured kernel (#56800)
35f3feca28,distributed,Untopiced,[RPC Framework] Supporting reading the input from the remote worker (#56943)
a09bbe73fd,jit,Untopiced,static runtime support for fb::equally_split (#56812)
6ed5bbfb46,distributed,Untopiced,[TensorPipe] Give higher priority to CPU-only channels. (#56908)
dc8a8cea79,caffe2,Untopiced,Move caffe2 signal_handler to c10. (#56717)
38bb0ac3e8,profiler,Untopiced,[profiler] Add cuda synchronization points (#56651)
c42dd8b257,jit,Untopiced,"Revert ""Use at::cpu in bench_approx (#56563)"" (#56816)"
780f454297,amd,Untopiced,Add some functions for manipulating mkldnn tensors to TORCH_API (#56954)
a0483cd06b,fx,Untopiced,"Back out ""fx: Fix type_matches for Optional[List[int]] arguments"" (#56991)"
5db03b4109,skip,Untopiced,Revert D27960766: ns for fx: additional bugfix for user defined functions
5dc7a6b050,skip,Untopiced,Revert D27960767: ns for fx: allow comparing int8 to int8 for functionals
cc8c5c1447,skip,Untopiced,Revert D27886107: ns for fx: add option to skip matching classes and functions
abb8b6c1c1,skip,Untopiced,Revert D27864296: ns for fx: support binary ops when adding unshadowed loggers for inputs
90d554bd86,skip,Untopiced,Revert D27857735: ns for fx: bug fix for shadowing fp16 emulation patterns
982c72ac33,skip,Untopiced,Revert D27836064: ns for fx: add fp16 function shadowing
45e96b5410,skip,Untopiced,Revert D27833189: ns for fx: allow user functions in shadowing
1145e2c6e2,skip,Untopiced,Revert D27831996: ns for fx: move node I/O dtype mapping to be local instead of global
f2acdff73d,skip,Untopiced,DOC: Add note to mutating methods (#56877)
f7fba854bf,nn_frontend,Untopiced,Implement module.to_empty() (#56610)
0d777a808c,python_frontend,Untopiced,Make test_randperm work with meta device (#56976)
ab1457ad14,cuda,Untopiced,Remove C++17 only optional include (#56782)
57e37080cd,skip,Untopiced,Added OpInfo for torch.einsum (#56276)
268cc117a8,skip,Untopiced,"Add OpInfos for torch.{complex, view_as_real, view_as_complex} (#56524)"
7fe6e8e5a2,autograd_frontend,bc_breaking,Refactor C->C to C->R twice (#55692)
201ad938b2,autograd_frontend,Untopiced,Enable fixed fast_mode for complex (#55699)
759cfb7495,skip,Untopiced,add missing comma to `run_test.py` (#57010)
3b977a0d28,dataloader_frontend,Untopiced,[DataLoader] Add `generate_state` for NumPy seeding (#56797)
6bbd8ba658,jit,Untopiced,[NNC] removed the second run of llvm passmanager - it is repeated and caused a slowdown in the generated code (#56837)
e138987818,releng,Untopiced,.github: Build test binaries in build/ directory (#56941)
8d29ac2033,releng,Untopiced,.github: Bump linux.2xlarge runners to 500 (#56945)
cfbd06d7a1,jit,Untopiced,"add all pools, Batchnorm and Tanh (i.e. all ideeped MKLDNN ops) to MKLDNNFuser (#56541)"
338a600e78,vmap_frontend,Untopiced,Add dispatch keys for out-of-tree grad+vmap prototype (#56824)
ed617a61ce,linalg_frontend,Untopiced,Adjust computeLRWorkDim() to work with Accelerate.framework (#56847)
11d455fa8b,releng,Untopiced,.github: Enable Linux CPU GHA on PRs (#56942)
a93ceb333d,build_frontend,Untopiced,Workaround intermittent gcc-7.5 ICE in cpp tests (#57016)
c203c921bc,skip,Untopiced,Revert D27926270: [pytorch][PR] [profiler] Add cuda synchronization points
9d54475032,fx,Untopiced,Hide module paths leaking in the documentation. (#54585)
d578e8cfa2,linalg_frontend,Untopiced,Improved docs for `torch.linalg` (#56265)
6c37788cb1,cuda,Untopiced,[torch] Add cuda support for segment reduction 'max' (#56704)
6e91e90b4d,skip,Untopiced,Use OpInfo for unsqueeze test (#56924)
cf17fd6dd5,cuda,Untopiced,Fix multinomial CUDA misalignment and non-deterministic behavior (#55364)
a18f3aacee,cpp_frontend,Untopiced,Vectorize floating point floor_divide (#55380)
6c602eb099,composability,Untopiced,Don't hold ThreadPool lock when destructing task (#56817)
3de86b951d,cuda,Untopiced,Migrate thrust->cub for index put (#55693)
cea265b8d8,jit,Untopiced,Support layer_norm for static runtime (#56444)
f9e7e2e20e,distributed,Untopiced,Remove unnecessary noCuda arg from AtomicJitFuture (#56973)
5b3c0ae563,distributed,Untopiced,Use a FutureFactoryRegistry to allow libtorch_cpu files to create CUDAFuture (#56984)
9da0f2e95e,python_frontend,Untopiced,Support `__pos__` and `positive` (#55891)
092eeedcb7,profiler,Untopiced,[profier] Fix double printing of FLOPs (#56974)
26ed4b4756,skip,Untopiced,OpInfo : index_fill (port remaining method_tests) (#57009)
dd84224edc,releng,Untopiced,.github: Switch alpine to ECR image instead (#57060)
d16ed1ee8a,autograd_frontend,Untopiced,Add first draft of gradcheck note (#55966)
daef60c3b7,skip,Untopiced,Initial support for sparse complex tensors constructors for CPU/CUDA (#54153)
4a899bb3c4,skip,Untopiced,Fix: Incorrect example output in sparse_csr_tensor doc-string (#56722)
ecaa208fd6,python_frontend,Untopiced,Fix: sparse_csr_tensor segfaults when crow_indices or col_indices are non-tensors (#56723)
522dca4ab0,cpp_frontend,Untopiced,"Port `topk` from THC to ATen, migrate most of sort as well (#55392)"
7b160e29a4,distributed,Untopiced,[DDP] remove backend constraints on uneven input tests (#56754)
60a5ebfac2,mobile,Untopiced,[Pytorch Edge] Remove methods_to_optimize arg (#57045)
09feb5f579,composability,Untopiced,Delete grandfathered Caffe2 dispatch keys. (#56939)
18c89a904b,python_frontend,devs,Modernize test-suite in sparse tensor CSR (#56392)
0d41122e61,python_frontend,Untopiced,Eliminate global usage of torch.set_default_dtype in sparse test (#56393)
fa57191b16,python_frontend,Untopiced,fix #56822 (#56967)
7bcce2acb9,skip,Untopiced,Revert D27765618: Initial support for sparse complex tensors constructors for CPU/CUDA
c307379170,linalg_frontend,Untopiced,Output tensor specified via out= must be on the same device as inputs for dot & vdot (#56334)
c4bec76bec,quantization,Untopiced,ns for fx: move node I/O dtype mapping to be local instead of global (#57021)
782a0a1469,quantization,Untopiced,ns for fx: allow user functions in shadowing (#57022)
2acc19eca1,quantization,Untopiced,ns for fx: add fp16 function shadowing (#57023)
ddedeab66d,quantization,Untopiced,ns for fx: bug fix for shadowing fp16 emulation patterns (#57024)
e8a5490c0a,quantization,Untopiced,ns for fx: support binary ops when adding unshadowed loggers for inputs (#57025)
a359cfac22,quantization,Untopiced,ns for fx: add option to skip matching classes and functions (#57026)
da2cef6a40,quantization,Untopiced,ns for fx: allow comparing int8 to int8 for functionals (#57027)
9fe2673d1c,quantization,Untopiced,ns for fx: additional bugfix for user defined functions (#57028)
e8c268746b,skip,Untopiced,Remove sync for randperm on small tensors. (#54113)
0319b64ea0,composability,Untopiced,[aten][simple] Optimize atrepeat (#56994)
6e826cac67,python_frontend,Untopiced,To fix inconsistency of digamma with SciPy (#56689)
808850b6de,nn_frontend,Untopiced,[ARM] Do not use depthwise3x3 conv in grad mode (#56889)
1c0617bb54,skip,Untopiced,Fix clang-tidy for native CPU ops (#57037)
786b0a8091,fx,Untopiced,[FX] fix normalization issues with lists of tensors (#57004)
c91ea7d488,mobile,Untopiced,[PyTorch][Edge] Add binarires for unittests (#57039)
51e6ebb5b7,performance_as_product,Untopiced,Add missing vec256<>::isnan() for VSX float and double vectors (#56658)
882e273663,caffe2,Untopiced,[caffe2] fix bug when weight_decay is used with fused rowwise + SLWS grad (#57090)
0df574017d,distributed,Untopiced,Torchelastic: add support for the new error file format (#57084)
8134806e23,mobile,Untopiced,[iOS GPU][Kernel] Implement channel split in Metal shaders (#56074)
77721ee318,profiler,Untopiced,[profiler] Add cuda synchronization point (ci-all) (#57036)
5536cda19a,python_frontend,bc_breaking,Update floor_divide behavior in line with NumPy 1.20 (#56893)
3115728cba,profiler,Untopiced,[profiler] Support for trace metadata (#56575)
1e77ba36db,distributed,Untopiced,change ddpLoggingData struct to map or dict (#56641)
89377e3e45,mobile,Untopiced,model_dump tool for model inspection (#56868)
4638bd0f0f,distributed,Untopiced,"Fix ProcessGroupMPITest.cpp Gather, Scatter and SendRecv. Enable ProcessGroupMPITest (#56709)"
46321cb937,jit,Untopiced,[static runtime] binding for aten::norm_out (#56636)
ef2bb784da,cuda,Untopiced,Replace raw cudaMalloc calls with CUDACachingAllocator (#57083)
5d7e48c9fc,skip,Untopiced,Disable one test in rocm (#56951)
4d72538f80,python_frontend,bc_breaking,Give Tensor a trivial (for now) metaclass _TensorMeta (#56147)
e362ee6f8a,composability,Untopiced,Make it illegal to directly construct _TensorBase (#56150)
6ee5e490d4,distributed,Untopiced,[BE][SyncBN] Avoid sync stats in eval mode (#56982)
fe09d54120,distributed,Untopiced,[c10d] Add debug level field in ProcessGroup (#56530)
ec0fa40f0f,distributed,Untopiced,Release GIL before destructing RPCAgent subclasses. (#57029)
4b8ccc6a0f,releng,Untopiced,.circleci: Add /opt/openssl to CI images (#57071)
18337fec7e,skip,Untopiced,Remove glaringlee from C++ frontend codeowners (#57130)
911852ffe2,releng,Untopiced,.github: Only add @generated on generated workflows (#57063)
ce79bd255d,skip,Untopiced,Fix doc issues (#57153)
efd451385c,profiler,Untopiced,Add gzip format support for chrome tracing (#56554)
610c984d2e,cuda,Untopiced,[CUDA graphs] Avoid sync errors when graph capturing cudnn rnn calls that use cudnn dropout (#56433)
31e59c3869,package,Untopiced,torch.package change `Folder` to `Directory` and add doc strings (#56925)
6ec01b1610,dataloader_frontend,Untopiced,[DataLoader] Add mode to LoadFilesFromDisk (#57056)
5a10ee71d6,distributed,Untopiced,[Reland] TCPStore add watchKey method and new listener thread (#56217)
4cb534f92e,skip,Untopiced,Make PyTorch code-base clang-tidy compliant (#56892)
0a30d64c83,skip,Untopiced,Revert D27966444: [pytorch][PR] [CUDA graphs] Avoid sync errors when graph capturing cudnn rnn calls that use cudnn dropout
28fc59d13d,mobile,Untopiced,Add xnnpack hardswish op (#56714)
aac2e68515,mobile,Untopiced,Add inplace hardswish xnnpack op (#56715)
3483049d58,mobile,Untopiced,Add xnnpack global average pool op (#55791)
c69386ccee,jit,Untopiced,[torch/deploy] remove usage of fbcode_dir (#57102)
63d54874e7,jit,Untopiced,[torch/deploy] smol cleanups to generate_packages
78736a72a5,jit,Untopiced,"Fix default dtype for randperm, triu/tril_indices inside TorchScript (#57105)"
73453f1de1,releng,Untopiced,Swap CUDA-10.2 and CUDA-11.1 master-only status (#57207)
4049732811,releng,Untopiced,Enable clang-tidy on master (#57213)
6ff0002b12,distributed,Untopiced,Pytorch: enable many torchelastic tests (#56970)
2dc3dc2324,jit,Untopiced,Enhance error message for Future.setErrorIfNeeded. (#56631)
dd6b9665bf,profiler,Untopiced,[profiler] Add sequenceNr and fwdThreadId to the trace (#57182)
1ee54cc7b4,distributed,Untopiced,Add devices argument to RRef constructor (#57085)
d0ea3183c1,skip,Untopiced,Remove debugging print in randperm (#57218)
54eee04226,python_frontend,Untopiced,support discontiguous tensors only for contiguous output format (#57177)
565b034237,fx,Untopiced,changed parametric type error in normalize to a warning (#57183)
eac02f85cf,skip,Untopiced,Fix more clang-tidy errors (#57235)
e903e16d40,skip,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
2aadeac0ff,jit,Untopiced,Remove duplicate entry for filter in language ref v2 (#57154)
ca814904b4,distributed,Untopiced,Handle error reporting when reply file already exists (#57217)
3a923a555a,jit,Untopiced,[NNC] moved lowerings out of the TensorExprKernel and into independent functions (#56679)
5c8ceefe46,distributed,Untopiced,Pytorch add agent api tests (#56985)
17b961b8bc,mobile,Untopiced,[PyTorch][Edge] Fix mypy error (#56999)
762b3aa7ba,skip,Untopiced,Revert D28078846: [pytorch][PR] Enable clang-tidy on master
82e50f4757,autograd_frontend,Untopiced,Update test_overrides for gradcheck (#57155)
fda8561944,skip,Untopiced,Adding vector_norm to the C++ API (#57055)
b8e1be1a13,skip,Untopiced,Revert D28041140: [pytorch][PR] Adding vector_norm to the C++ API
36ebd0f65d,skip,Untopiced,Improve LeftRight documentation (#57164)
5a02f72fcf,linalg_frontend,Untopiced,Modified batched residuals return of torch.linalg.lstsq (#54722)
03962bc7f1,linalg_frontend,Untopiced,Updated linalg.lstsq with NumPy compatible kwarg rcond (#54723)
b232659765,composability,Untopiced,Replaced _lstsq_helper with internal dispatch (#54724)
63533478bd,distributed,Untopiced,Fix misleading messages in test_jit_c10d (#57256)
6fdf092cad,composability,Untopiced,Add getStreamFromPool to DeviceGuardImplInterface (#57046)
ea64c90ecc,composability,Untopiced,Add recordDataPtrOnStream to DeviceGuardImplInterface (#57047)
381698f900,cuda,Untopiced,Simplify CUDAMultiStreamGuard (#57048)
682476022f,distributed,Untopiced,Introduce generic MultiStreamGuard (#57049)
cf1595c48b,cuda,Untopiced,Use only generic helpers in CUDAFuture (#57050)
71c2f88b90,cuda,Untopiced,Make CUDAFuture handle any kind of device type (#57051)
311ad5e3af,cuda,Untopiced,Merge CUDAFuture into ivalue::Future (#57052)
e96667175e,releng,Untopiced,.circleci: Switch libtorch builds to use smaller image (#56937)
2c8ea63cbb,distributed,Untopiced,add a test for grad view with torch amp (#56730)
9486fc3229,mobile,Untopiced,[PyTorch][Edge] share readArchiveAndTensors between mobile and jit (#57098)
ecacb8c78b,quantization,Untopiced,[quant][graphmode][fx] Fix getitem for unmatched nodes (#57173)
ee71584236,distributed,Untopiced,Update compare_set implementation for FileStore and HashStore (#57175)
c72f01ab6b,releng,Untopiced,Add CI workflow and script to test torchbench. (#56957)
8a949f9e51,distributed,Untopiced,[23/n][torch/elastic][upstream] Rename torch.distributed.elastic_launch to torch.distributed.run (#56831)
2e2c0099eb,jit,Untopiced,Support type inference of nn.Module methods using PDT (#57165)
fd67088a57,distributed,Untopiced,[Distributed test]Enable ddp_control_flow tests for ROCm (#57159)
ec86f96e91,autograd_frontend,Untopiced,Fix for derivative of sinc(x) when x is positive but very very small (#56986)
ac86e0a0e5,python_frontend,Untopiced,fix: index_fill_ formula to support duplicate indices (#57101)
a1d2bd56a0,composability,Untopiced,[PyTorch] Make as_strided_ use_const_ref_for_mutable_tensors (#55875)
fb2f3cd172,cpp_frontend,Untopiced,[PyTorch] Migrate copy_ to borrow input/output (#56031)
dd9f4c8cc9,jit,Untopiced,[PyTorch] Reduce move overhead in inferExpandGeometry (#56032)
d3ffe9ab6b,linalg_frontend,Untopiced,[PyTorch] Allocate correctly-sized output tensor in addmm_cuda (#56033)
21be40b390,releng,Untopiced,Add torch_cpu specific flag for debug info (#57190)
4b96fc060b,releng,Untopiced,Remove distutils (#57040)
be0ca00c5c,jit,Untopiced,[torch/deploy] Minor housekeeping in interpreter_impl
95f393f212,distributed,Untopiced,"Add compare_set to trampoline class, add typing and formatting (#57191)"
a6fa6a6cda,fx,Untopiced,[fx minimizer] Add an option to minimizer to allow return all intermediate results (#57279)
e31265dfb3,distributed,Untopiced,Fix path handling on Win32 in rendezvous.py (#57000)
149000c3f0,distributed,Untopiced,Update compare_set docs (#57203)
6ed90ed1ac,skip,Untopiced,Added OpInfos for sub & mul (#56227)
2c6f5e8a12,package,Untopiced,[package] PackageExporter `__import__` logic to not parse dynamic cases (#57283)
c2fbd96735,distributed,Untopiced,[RPC Framework] Expose a Python API for device map getter (#57179)
d1def93166,caffe2,Untopiced,[torch/debuggability] use log.info() in addition to print() in timeoutguard (#57296)
e27740b38e,autograd_frontend,Untopiced,[torch] Add backward support for segment reduce (CPU only)
995161203b,skip,Untopiced,Fix sort for slow gradcheck (#57192)
16fc18bf82,structured_frontend,Untopiced,port neg to structure kernel (#57212)
49dbe1798f,profiler,Untopiced,[kineto] Deprecate ClientTraceActivity and merge it with GenericTraceActivity (#56743)
65968ab817,cuda,Untopiced,"Revert ""Remove sync for randperm on small tensors. (#54113)"" (#57299)"
c44cbc63cc,distributed,Untopiced,"Ignore more compiler warnings, unify WERROR options (#56630)"
ac72881f3f,cuda,Untopiced,Fix a numerical issue of CUDA channels-last SyncBatchNorm (#57077)
e31b67f550,jit,Untopiced,[torch/deploy] opt torch/csrc/depoy into autofromatting
b3e1802439,jit,Untopiced,Static runtime support for fb::expand_dims (#57282)
54469e157b,skip,Untopiced,Automated submodule update: FBGEMM (#55347)
264db1959e,skip,Untopiced,Automated submodule update: FBGEMM (#57342)
df69b0d060,distributed,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
db32b69591,skip,Untopiced,quote str kwarg values in `test_ops.py::TestCommon::test_jit_alias_remapping` (#57120)
5b3e7638ca,profiler,Untopiced,Expand Kineto profiler support (part 1) (#57333)
d4ddb47719,python_frontend,Untopiced,[special] Add `xlog1py` (#55138)
6fa1d880b6,composability,Untopiced,make external codegen aware of autogen'd composite kernels (#56960)
c91bd25e90,autograd_frontend,Untopiced,Fix use of allow_tensor_metadata in view variable creation (#57069)
b016bc1c91,autograd_frontend,Untopiced,fix InplaceOrView implementation for manual functions (#57152)
83f186717b,autograd_frontend,Untopiced,Improve perf for forward AD view handling (#57057)
95dc2b6e9b,autograd_frontend,Untopiced,Remove unused forward AD flag (#57058)
0dddfbf346,skip,Untopiced,Revert D28114231: [pytorch][PR] Automated submodule update: FBGEMM
e08303c740,skip,Untopiced,Revert D27582224: [pytorch][PR] Automated submodule update: FBGEMM
095c328d9f,skip,Untopiced,Add supported backward_dtype to OpInfo (#56156)
731cc472c5,composability,Untopiced,refactor autocast to be extensible for devices (#57104)
c971401696,jit,Untopiced,[jit] Disable conv-add-relu fusion for cuDNN7 when model uses fp16 (#56579)
52805a0f4f,amd,Untopiced,[PyTorch] Include hip_runtime.h in macros.h (#57070)
b49e079a2a,composability,Untopiced,Fix string_view::equals_ compilation by CUDA-11.3 (#57322)
e795f88d6b,jit,Untopiced,[NNC] Make flatten transform in-place (#56629)
d50a969f2a,jit,Untopiced,reduce inline autodiff threshold so we can caputre smaller fusions (#57062)
7c8a7efe3f,jit,Untopiced,[nnc] Enable all fuser tests for cpu (#57332)
d896d1f4ce,fx,Untopiced,[fx splitter] Fix fusion group utility (#57280)
b87d3fa432,jit,Untopiced,[PyTorch][jit] Don't allow create() on singleton types (#56807)
0a9c9cc674,mobile,Untopiced,Update DLPack to 0.4 (#55365)
e62cdae469,jit,Untopiced,Static Runtime support for aten::matmul (#57291)
81ef82e5f4,quantization,Untopiced,Add pybind interface to caffe2 quantization server (#57330)
5f2b9b1df9,distributed,Untopiced,refactor autograd_hook (#54981)
3f81912885,distributed,Untopiced,static graph api skeleton (#54995)
788aefd7cc,python_frontend,Untopiced,Propagate information on torch_shm_manager failures to parent process (#57307)
7eed5410cd,composability,Untopiced,Make c10::TempFile non-copyable but movable (#57308)
2c2aa9e030,python_frontend,Untopiced,Address temp file/bind race condition in torch_shm_manager (#57309)
e68c46bb3a,python_frontend,Untopiced,Propagate information on torch_shm_manager execl failure to parent process (#57310)
d5e1cac6e1,linalg_frontend,Untopiced,Add non-allocating helper function for torch.linalg.qr (#56254)
6cb9abfd20,linalg_frontend,Untopiced,Remove size arguments for internal orgqr and geqrf calls (#56255)
ff59039a24,linalg_frontend,Untopiced,Add cuSOLVER path for torch.linalg.qr (#56256)
f54aa85a6c,linalg_frontend,Untopiced,Fix MAGMA qr for empty batched inputs (#56257)
b9b768c0e7,skip,Untopiced,Revert D28011862: Add pybind interface to caffe2 quantization server
3a777b6792,composability,Untopiced,[PyTorch] Optimize intrusive_ptr(TTarget*) ctor (pybind) (#57053)
bbc3cc6718,cuda,bc_breaking,[CUDA graphs] [BC-breaking] Makes torch.cuda.amp.GradScaler scale updates in-place for better composability with graph capture (#55562)
72b1faa2d2,distributed,Untopiced,[8/n] [torch/elastic] Add unit tests for _RendezvousState (#56536)
42b3fc29f4,cuda,Untopiced,"Fix NVRTC versioning for CUDA 11.X (X>=3), CUDA 12 and later (#57204)"
5e422fa170,quantization,Untopiced,per_channel fake quant fp16 and fp64 support (#56894)
4c3283da0d,releng,Untopiced,Fix binary_checkout to use master (#57389)
c9ab384af7,jit,Untopiced,[TensorExpr] Add `CodeGen::call_raw` method. (#55113)
f219ed6627,jit,Untopiced,[TensorExpr] Add `TensorExprKernel::runFast` method. (#57328)
400ca7677c,skip,Untopiced,[StaticRuntime] Use NNC's call_raw API to reduce call overheads. (#57329)
c1a442248b,jit,Untopiced,[jit] Enable conv-add-relu fusion as a part of frozen graph optimization (#56580)
293830bc19,python_frontend,Untopiced,Fix min() and max() for empty tensors (#52565)
208f81b787,composability,Untopiced,[PyTorch] ifdef out ATen tests that fail with static dispatch (#57379)
3a5f85465b,cuda,Untopiced,[pytorch] fewer cuda sync in unique by using cub instead of thrust (#57323)
233f2cd29f,fx,Untopiced,Maintain submodule references during subgraph rewriting (#55463)
47e9ec401a,jit,Untopiced,[NNC] ported some more ops + added vectors to argvalue (#56766)
bbdadab306,autograd_frontend,Untopiced,Refactor fast gradcheck (#55871)
2b54cec7e8,autograd_frontend,Untopiced,Clean up naming and comments (#56964)
bd347012ec,releng,Untopiced,Added sm_75 support for CI Xenial CUDA 11.1 cuDNN 8 builds (#57320)
20eac093a7,python_frontend,Untopiced,[torch][segment_reduce] Add support for initial value (#56923)
13dbb77b7a,distributed,Untopiced,[RPC Framework] Enable RemoteModule to directly send GPU tensors over the wire on TensorPipe RPC backend if a device map is provided (#57288)
b11a24209f,composability,Untopiced,[PyTorch] Take advantage of string literals in TORCH_WARN (#54032)
3c4d57c18b,jit,Untopiced,[pytorch][nnc] update external functions for mobile build (#56850)
44cc873fba,skip,Untopiced,[PyTorch] Autoformat c10 (#56830)
f7f8540794,python_frontend,Untopiced,Fix tensor device in test_kthvalue_overlap (#56869)
183320df96,composability,Untopiced,Add device_check place holder for functions (#56870)
22ecb8885f,foreach_frontend,Untopiced,Disable device check for foreach kernels (#56871)
20085f6d23,python_frontend,Untopiced,Support auto generation of device check (#56872)
3315f14280,skip,Untopiced,Revert D28110358: [StaticRuntime] Use NNC's call_raw API to reduce call overheads.
d536e6c684,python_frontend,Untopiced,Fix variable names in torch.fft examples (#57290)
2dffa8cdf8,distributed,Untopiced,Fix CUDA Stream synchronization when arguments contains RRefs (#57394)
58bc003487,composability,Untopiced,Add pybind type caster for c10::Device (#57292)
6697ef51b2,jit,Untopiced,Add device() method to c10::Event (#57293)
0c3e79b5b9,distributed,Untopiced,Rename DeviceGuardImplInteface's getStreamFromPool method (#57345)
0422e67336,distributed,Untopiced,Use Devices instead of DeviceIndexes in TensorPipe agent (#57294)
fb7469fb7f,jit,Untopiced,Use Devices instead of DeviceIndexes in Future (#57353)
82d245faef,jit,Untopiced,Inline hooks in ivalue::Future (#57354)
3018093066,skip,Untopiced,Revert D28110359: [TensorExpr] Add `TensorExprKernel::runFast` method.
4350d4af77,mobile,Untopiced,Immediately mark DLPack capsule as used after stealing the ownership (#56789)
6d681d064f,linalg_frontend,Untopiced,ROCM: Re-enable test_norm_fro_2_equivalence_old (#57170)
a5288a0244,python_frontend,Untopiced,Sparse support for division rounding_mode argument (#51989)
7c8d0069c4,autograd_frontend,Untopiced,grad_fn getter for optional strings (#55225)
2be115336b,linalg_frontend,Untopiced,Fix torch.ormqr for non Fortran-contiguous inputs (#57314)
afe6b4c8ee,jit,Untopiced,[NNC] Add logical Operators '&&' and '||' (#56947)
75a2a92b02,linalg_frontend,Untopiced,Add torch.linalg.cholesky_ex without checking for errors by default (#56724)
05b255c543,skip,Untopiced,Revert D27487549: [TensorExpr] Add `CodeGen::call_raw` method.
41099ef71c,skip,Untopiced,OpInfo: mvlgamma (#56907)
0ecdbfebff,autograd_frontend,Untopiced,s/InplaceOrView/ADInplaceOrView/g (#57372)
bb640efa40,quantization,Untopiced,ns for fx: add missing add_relu and mul_relu patterns (#56927)
7fe4c1d0e7,distributed,Untopiced,Torchelastic: add multiprocessing tests to ci/cd (#56842)
57f72b8433,distributed,Untopiced,[DDP] Uneven inputs: option to throw early (#56755)
ce4449918a,skip,Untopiced,Port reverse binary ops to `OpInfo` (#56471)
eaf00bf7d4,linalg_frontend,Untopiced,Skip linalg.qr saved mode check if compiled without LAPACK (#56284)
5c68072ee8,python_frontend,devs,add support for complex input to `torch.testing.assert_(equal|close)` (#57162)
4a872f8539,skip,Untopiced,Add cross OpInfo (#55483)
46a32e075c,nn_frontend,Untopiced,Improve BatchNorm1d training performance (CPU) (#57033)
db6cd42434,quantization,Untopiced,fx quant: clean up nit in insert_observer (#57367)
fe23881e76,quantization,Untopiced,fx quant: readability improvements on observer functions (#57368)
1b20eeb138,quantization,Untopiced,fx quant: move output obs logic to QuantizeHandler (#57377)
2bd158386a,quantization,Untopiced,fx quant: move input_output_observed to qhandler (#57388)
643f41be61,quantization,Untopiced,fx quant: remove FixedQParamsOpQuantizeHandler from quantize.py (#57393)
d6563bc153,quantization,Untopiced,fx quant: remove unnecessary quants arguments (#57399)
da51fd31a5,quantization,Untopiced,fx quant: remove `find_quants` from convert (#57402)
e845158b1a,cpp_frontend,Untopiced,Assert that GIL is not held in blocking destructors (#57030)
154eca0309,skip,Untopiced,"OpInfo: ravel, view, view_as (#56910)"
87242d2393,autograd_frontend,Untopiced,Eliminate global usage of torch.set_default_dtype in test_autograd (#56446)
7e12c3e10a,skip,Untopiced,Automated submodule update: tensorpipe (#56916)
0a0e024648,python_frontend,Untopiced,use importlib instead of imp as it support python 3.5+ (#57160)
f332a8bdff,distributed,Untopiced,Implement result() function in MPI Work classes (#57168)
c7d8d8f925,amd,Untopiced,[BE] Improve has_bf16_support (#57408)
6bc3ad28a3,skip,Untopiced,Revert D28143091: [pytorch][PR] Add cross OpInfo
52b389259c,structured_frontend,Untopiced,Port max_pool2d_with_indices to structured kernel (#56459)
375c8a81dc,distributed,Untopiced,[DDP] Profile search_unused_parameters (#57376)
c0d39ba680,releng,Untopiced,Replace 11.2 linux CI with 11.3 (#57222)
264d87985a,releng,Untopiced,Use ld.gold by default to link in CI (#57061)
945c93b8bd,quantization,Untopiced,[quant][graphmode][fx] Skip observering boolean Tensors (#57375)
ac71432c54,mobile,Untopiced,[PyTorch][Edge] Add api to get bytecode version from runtime (#56948)
6bf8df6b3b,distributed,Untopiced,[9/n] [torch/elastic] Introduce RendezvousSettings (#56537)
6876e15dbe,distributed,Untopiced,[10/n] [torch/elastic] Add comparison operators to _NodeDesc (#57139)
3209364724,distributed,Untopiced,[11/n] [torch/elastic] Add heartbeat timeout to RendezvousTimeout (#57140)
a6f60cf4f0,distributed,Untopiced,[12/n] Rename last_keep_alives to last_heartbeats in _RendezvousState (#57141)
233004b4c8,distributed,Untopiced,[13/n] Extend the return type of RendezvousBackend's set_state method (#57142)
1b745efbe8,distributed,Untopiced,[14/n] Introduce a name attribute to _PeriodicTimer (#57143)
e841f335aa,cuda,Untopiced,[RELAND] [CUDA graphs] Avoid sync errors when graph capturing cudnn rnn calls that use cudnn dropout (#57373)
160304a81d,cuda,Untopiced,fix comments in ATenNVRTC.h (#57318)
76bccfb2e0,distributed,Untopiced,[15/n] [torch/elastic] Introduce _RendezvousStateHolder (#56538)
1a6f827ae6,distributed,Untopiced,[16/n] [torch/elastic] Introduce _RendezvousOpExecutor (#57144)
c328bb6d79,structured_frontend,Untopiced,Port trunc to structured (#57350)
33eea146ee,python_frontend,Untopiced,torch.clamp with tensor min and max (#52695)
d68ad3cb1e,releng,Untopiced,Add a shortcut to test all torchbench models. (#57311)
589072afa1,distributed,Untopiced,Fix return type of getDeviceMap (#57487)
6d3bb01b1a,caffe2,Untopiced,Sequence Blob NVM Reader to Selectively NVMify Ads Embeddings in A*
2a178d34cd,quantization,Untopiced,[Redo] Add pybind interface to caffe2 quantization server (#57378)
aa5d35e1d7,distributed,Untopiced,[17/n] [torch/elastic] Introduce _DistributedRendezvousOpExecutor (#57145)
3e024fcfc9,distributed,Untopiced,[18/n] [torch/elastic] Introduce _RendezvousCloseOp (#57146)
baf8f4c0a6,distributed,Untopiced,[19/n] [torch/elastic] Introduce _RendezvousKeepAliveOp (#57147)
81ef683cb3,distributed,Untopiced,[20/n] [torch/elastic] Introduce _RendezvousExitOp (#57148)
4a10bd3b58,distributed,Untopiced,[21/n] [torch/elastic] Introduce _RendezvousJoinOp (#57149)
a357fc8a4b,distributed,Untopiced,[22/n] [torch/elastic] Introduce a new from_backend static constructor for DynamicRendezvousHandler (#57150)
bf6e3425b0,distributed,Untopiced,[23/n] [torch/elastic] Introduce the implementation of DynamicRendezvousHandler (#57151)
c0309af1f3,releng,Untopiced,Actually report mac stats (#57511)
15975cf6a6,python_frontend,Untopiced,"To add priority of int/int? over int[] on signature matching and adding {h,v,d}split methods (#57346)"
4143483d95,distributed,Untopiced,[RPC Framework] Create a separate remote module template when moving CPU tensors to a cuda device is not enabled (#57413)
1d3a9bff3c,releng,Untopiced,Swap CUDA 10.1 and CPU CI for windows (#57493)
75f6dcf8b5,autograd_frontend,Untopiced,protect destructors of python bindings that can be kept alive by c++ objects (#57488)
74a4868d9a,autograd_frontend,Untopiced,Add docs for c10::InferenceMode. (#57480)
3ad3d8bd3f,jit,Untopiced,[jit] Add a pass for annotating graph with input types derived from sample inputs. (#57076)
839d549f8f,jit,Untopiced,[jit] Add a pass for removing a first (self) argument from a graph if it is unused. (#57169)
030692cf9e,jit,Untopiced,[TensorExpr] Remove `dtype_` and add `buf_` fields to `CodeGen::BufferArg`. (#57382)
6b2cb939c5,jit,Untopiced,[TensorExpr] Add methods for inspecting generated code in `TensorExprKernel`. (#57074)
5c7e35c689,distributed,Untopiced,[RPC Framework] Clang-format remote_module.py and instantiator.py (#57414)
67f874de8f,cuda,Untopiced,[resubmit] Remove sync for randperm on small tensors. (#54113) (#57364)
3cc733e451,profiler,Untopiced,fix for nvtxstring not printing name for aten kernels (#57407)
3db45bcb91,distributed,Untopiced,Compilation error fix for torch/csrc/distributed/rpc/init.cpp (#57500)
a80b215a9a,distributed,Untopiced,[1/n][torch/elastic] Move torchelastic docs *.rst (#148)
5439977352,benchmark,Untopiced,[Static Runtime] Revamp op schema check (#57521)
dc49299078,distributed,Untopiced,Allow passing cpu to CUDA RPC device maps (#57019)
03b5d87980,skip,Untopiced,fix(docs): `torch.add` and `torch.mul` (#54672)
01e4444211,skip,Untopiced,Tiny typo fix (#57113)
aa5ff7cc91,cuda,Untopiced,irange for Indexing.cu (#57479)
f4a921600a,mobile,Untopiced,"[PyTorch, Mobile] Serialization format change for source range (#54284)"
e0fc473e47,mobile,Untopiced,"[Pytorch, Mobile] Serialize inlined callstack pointer with debug handle. (#55062)"
bb3c6699a5,mobile,Untopiced,[Pytorch Mobile DebugInfo Serialization] Save debug handles for all instructions. (#55252)
5326ec60e6,jit,Untopiced,[Inlined Callstack Fix] Fix inlined callstack for blocks of the node. (#56562)
34d853a524,fx,Untopiced,[fx2trt] example for lowering model to trt with FX based tooling (#57298)
42d073a7e9,releng,Untopiced,"Look for unqualified ignore in .pyi, not just .py (#57468)"
b3c0ef4a40,autograd_frontend,Untopiced,Revert back to old assert behavior in as_view (#57499)
1461859fde,skip,Untopiced,Revert D28048289: [TensorExpr] Add methods for inspecting generated code in `TensorExprKernel`.
28c24ec3e8,python_frontend,Untopiced,[numpy] polygamma: int -> float promotion (#57462)
bca1949dc9,caffe2,Untopiced,[typing] suppress errors in `fbcode/caffe2` - batch 2
383e451036,cuda,Untopiced,Implement torch.sort with cub::DeviceSegmentedRadixSort (#56821)
1fc89d9ffc,python_frontend,Untopiced,Use proper Google Analytics id (#56578)
76d9070d10,releng,Untopiced,Replace windows CUDA 11.2 CI with 11.3 (#57223)
9c5478588e,mobile,Untopiced,[iOS GPU] [easy] Rename APIs in MPSImageWrapper
00d6472b4d,releng,Untopiced,tools: Add render_junit script (#57327)
8c9e42baaf,releng,Untopiced,.github: Add render_test_results job (#57472)
2b6c09c11e,distributed,Untopiced,Add futures to ProcessGroupMPI work (but not including Send/Recv) and python DDP comm hook testing (#57214)
7c3a30fd79,quantizations,Untopiced,fx quant: remove matching hack for binary qhandler (#57470)
151e81b7bc,jit,Untopiced,[NNC][tests] Skip long running tests when using TE interpreter (#57568)
7175d49122,profiler,Untopiced,[Dist profiling] Add is_async field (#57253)
eb39da6b52,releng,Untopiced,Always run as many quick-checks steps as possible (#57572)
d728491fc1,mobile,Untopiced,[RFC] [PyTorch Edge] Simplify error logging in mobile/import.cpp (#55711)
45a3231bb8,caffe2,Untopiced,[codemod] Enforce proper use of emplacy functions
cd9995ae14,skip,Untopiced,Update Gloo submodule (#57586)
133d8abbfc,build_frontend,Untopiced,Compute nvrtc during libtorch build (#57579)
0142fd0b57,jit,Untopiced,[jit][NNC] add hardswish symbolic gradient and NNC lowering (#57383)
aeaa91bff6,amd,Untopiced,mkldnn gelu (#53615)
9ec6883442,skip,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
a9dc9535f6,quantization,Untopiced,ns for fx: move relatedness mapping to mappings file (#57171)
44bb15cfd3,quantization,Untopiced,ns for fx: add more type to relationship mapping (#57184)
76f29d53bf,quantization,Untopiced,ns for fx: change matching to only match known types (#57186)
49adac65c4,quantization,Untopiced,ns for fx: clean up manual string names of related ops (#57210)
0787d781c5,nn_frontend,Untopiced,Fix compatibility problem with LSTMs and torch.save (#57558)
887d0e5657,skip,Untopiced,Revert D28197820: [JIT][NNC] add hardswish symbolic gradient and NNC lowering
c65a1da90a,linalg_frontend,Untopiced,Fixed C++ linalg API (#57464)
da8cc355a3,autograd_frontend,Untopiced,Relax tp_new so that it is OK to call (#57544)
0bf69278f7,jit,Untopiced,Reland: [TensorExpr] Add `CodeGen::call_raw` method. (#57551)
e686c66fe7,jit,Untopiced,Reland: [TensorExpr] Add `TensorExprKernel::runFast` method. (#57552)
9e7814d539,jit,Untopiced,Reland: [StaticRuntime] Use NNC's call_raw API to reduce call overheads. (#57553)
dedaf4fad7,jit,Untopiced,Reland: [TensorExpr] Add methods for inspecting generated code in `TensorExprKernel`. (#57560)
fb9a32b7b4,mobile,Untopiced,[PyTorch][Edge] Add api to get bytecode model version (#56801)
17035f6aab,releng,Untopiced,Speedup render_junit (#57641)
a948e279ac,distributed,Untopiced,[c10d] Profiler support for nccl p2p collectives (#56427)
7115a4b870,distributed,Untopiced,Clang format ProcessGroupNCCL.cpp (#56840)
15c092b888,skip,Untopiced,"Revert ""Make grad mode error just a warning (#56401)"" (#57640)"
534c457d3d,skip,Untopiced,add a standalone extra file loader for pytorch model (#57591)
babae61f2f,linalg_frontend,Untopiced,Make torch.linalg.svdvals differentiable (#57188)
049152faa9,linalg_frontend,Untopiced,Make torch.linalg.eigvalsh differentiable (#57189)
28cd04ea64,mobile,Untopiced,NNAPI: add flexible size support for conv2d (#57561)
4c609a9782,mobile,Untopiced,NNAPI: Add qadd flexible size support (#57562)
c4bb6a5781,mobile,Untopiced,NNAPI: flex size support for upsample_nearest2d op (#57563)
69e64b2632,distributed,Untopiced,[Flaky tests] Fix flaky rpc profiling tests (#57517)
30c96c9419,mobile,Untopiced,[iOS GPU] Add Metal API availability check (#57663)
65fad0ebd2,releng,Untopiced,Expand Kineto platform support (ci-all) (#56323)
e5179e960e,releng,Untopiced,Share VS Code settings/extensions nicely (#57671)
cd22bdf236,composability,Untopiced,"[PyTorch] Autoformat c10, round 2 (#57645)"
0b51ee311d,autograd_frontend,Untopiced,Add missing return statement from 57057 (#57669)
56211524a7,jit,Untopiced,[NNC] ported over sum and softmax to new scheme (#56775)
7627dd568a,jit,Untopiced,hardswish reland (#57652)
dedf9fbe81,package,Untopiced,[package] factor out `PackageExporter._get_dependencies` (#57335)
a39c685ace,package,Untopiced,[package] make extern a dict (#57336)
53c21172c0,package,Untopiced,[package] add simple graph data structure (#57337)
f326f7dda8,package,Untopiced,[package] use digraph to back dependency visualization (#57338)
a3cba770b5,package,Untopiced,[package] remove PackageExporter.file_structure (#57339)
44b021d21b,package,Untopiced,[package] remove save_source_file API (#57340)
0d813bbca5,skip,Untopiced,Revert D28177176: [iOS GPU] Add Metal API availability check
ba500c5c90,jit,Untopiced,"Add call_kwargs(args, kwargs) method to torch::deploy api (#57484)"
27af9b0462,distributed,Untopiced,Fix flaky test_rref_context_debug_info (#57526)
866b19e95d,distributed,Untopiced,[paramcomms] support for in and out split sizes
c27428b5e9,jit,Untopiced,[NNC] ported conv2d lowering over (#56875)
86b061c80e,fx,Untopiced,[FX] Changes in order to move python key out of tree (#57427)
ccbbb2d6f8,skip,Untopiced,Revert D28052211: [paramcomms] support for in and out split sizes
ba78bf1363,jit,Untopiced,[standaloneRunner] fix another GIL mutithreading issue exposed by torch::jit::toIValue() (#57688)
126ea1ccad,python_frontend,Untopiced,relax type equality constraint for scalars (#57532)
8bbe383877,benchmark,Untopiced,[Static Runtime] Fix bugs in logit (#57578)
fc657b547a,profiler,Untopiced,[kineto] set the correct device id for GenericTraceActivity
7870450706,composability,Untopiced,[PyTorch] Use c10::ThreadLocal instead thread_local in record_function.cpp for specific __GLIBCXX__ on Android (#57689)
3fb5be05ba,mobile,Untopiced,[iOS GPU] Add Metal API availability check (#57663)
95fbc158d4,jit,Untopiced,[NNC] Add a method to compute conv without bias (#57512)
eef72f3f8a,jit,Untopiced,[NNC] Update Buf on mutation instead of creating new ones (#57513)
1f178de800,jit,Untopiced,[NNC] Add support for computing conv with dynamic shapes (#57514)
1292602375,jit,Untopiced,Avoid re-extracting DataPtrs when forwarding values between Futures (#57433)
69de4940f3,distributed,Untopiced,Ensure devices are preserved when forwarding between futures (#57432)
8e9bbd3113,jit,Untopiced,Make DataPtr extraction in CUDAFuture faster for Python values (#56918)
7ffadf6e46,distributed,Untopiced,Replace DeviceIndexes with Devices in RRefs (#57442)
7d4121d1d2,distributed,Untopiced,Make RRefContext get devices from RPC agent when creating OwnerRRef (#57443)
db7b31358f,cuda,Untopiced,Fix internal assert in CUDA caching allocator when trying to allocate ~2^64 memory (#57571)
d82333e92a,jit,Untopiced,[pytorch][nnc] protocol classes to persist the context for compiled functions (#56851)
b4a098f1fb,jit,Untopiced,[pytorch][nnc] mobile nnc backend skeleton (#56852)
59d794b2c3,linalg_frontend,Untopiced,Port CPU torch.ormqr to ATen (#57315)
35fab44eaf,linalg_frontend,Untopiced,Add CUDA support for torch.ormqr (#57316)
7b31d4262b,linalg_frontend,Untopiced,Add cuSOLVER path for torch.linalg.lstsq (#57317)
40cb55f978,skip,Untopiced,"Revert D28154522: Add call_kwargs(args, kwargs) method to torch::deploy api"
f1a62264f3,jit,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
52ac015d76,vmap_frontend,Untopiced,Add note about improved vmap prototype to vmap docstring (#57677)
ad31aa652c,nn_frontend,Untopiced,Fixed the error in conv1d example (#57356)
cb7197ce3f,distributed,Untopiced,Torchelastic: populate __init__.py with failover documentation
a7ba0f08f3,linalg_frontend,Untopiced,Update internal code for torch.lu_solve (#56611)
dc06f52480,distributed,Untopiced,Add result() to ProcessGroupGloo::AsyncWork's (#57565)
72ebdd68e1,skip,Untopiced,Revert D28242069: Add cuSOLVER path for torch.linalg.lstsq
d83d1d3741,cpp_frontend,Untopiced,TensorIterator: documentation on the order of creation (#57550)
3c0d22fab3,structured_frontend,Untopiced,Port floor to structured (#57587)
ccbaa5fbe5,structured_frontend,Untopiced,Port sign to structured (#57588)
ebd2c0a4ed,structured_frontend,Untopiced,Port ceil to structured (#57589)
1101a5f6e9,distributed,Untopiced,[paramcomms] support for in and out split sizes (#57709)
b2936ad8fa,skip,Untopiced,Improve BatchNorm1d performance (CUDA) (#57034)
eb6445a92a,jit,Untopiced,[jit] Lazily initialize aliasDb in DCE (#56649)
da06ae73a3,caffe2,Untopiced,[c2] Fix flaky test_spatial_bn_multi_batch_grad
2370d8c41f,profiler,Untopiced,[profiler] Add profiler fallback (#57612)
cb234e606d,package,Untopiced,[package] fix corner case in PacakgeImporter.whichmodule (#57651)
3948ce2fd9,caffe2,Untopiced,[caffe2] Introduce c10::CudaError for CUDA Exceptions (#57609)
2992ff3fb8,skip,Untopiced,Revert D28142447: Improve BatchNorm1d performance (CUDA)
52d1b91d38,releng,Untopiced,Give Python sub-version in GHA CUDA workflow name (#57770)
aedcff7275,releng,Untopiced,fix codegen for lite_interpreter (#57761)
241c2f4496,jit,Untopiced,Add Gelu To NNC (#57753)
78fb9c2f5b,releng,Untopiced,Reorder gc.py imports (#57779)
2787f01455,releng,Untopiced,Catch KeyboardInterrupt in tools/test_history.py (#57780)
8b38458011,jit,Untopiced,[jit] Break interpreter.cpp into smaller files. (#56546)
cb1272a846,build_frontend,Untopiced,update doc in build section (#56686)
1f1e2dab6b,linalg_frontend,Untopiced,Remove optional type for ord parameter in vector_norm (#57662)
cb95c9db9f,skip,Untopiced,Automated submodule update: FBGEMM (#57485)
e5e095cbe4,distributed,Untopiced,[torch/elastic] Rename etcd-/c10d-experimental to etcd-v2 and c10d (#57764)
ca8090f81b,jit,Untopiced,[Pytorch Edge] Enable eager symbolication in benchmarking binary (#57705)
f2fdb61e2d,mobile,Untopiced,[iOS GPU][Perf][1/n] Use aten::contiguous instead of permuting weights manually (#57664)
319b08be59,jit,Untopiced,"Add call_kwargs(args, kwargs) method to torch::deploy api (#57748)"
ee79413b6a,skip,Untopiced,[testing] change unaryufunc default dtypes (#57616)
159a2404bd,python_frontend,Untopiced,fft: Increase tolerance for nd-fft tests (#57576)
6eec730a73,skip,Untopiced,[testing] atan2: Enable cases where self broadcasts (#57608)
4cb3c60c20,skip,Untopiced,OpInfo: float_power (#57648)
1f7309dfe3,skip,Untopiced,[testing] clean-up test_unary_ufuncs.py (#57615)
9e6b7e6e6e,skip,Untopiced,OpInfo: expand and expand_as (#57606)
adaf80bcbe,linalg_frontend,Untopiced,Update internal code for at::_lu_with_info (#56612)
5f2925074b,linalg_frontend,Untopiced,Update internal code for torch.linalg.solve (#56613)
9aa1461a68,composability,Untopiced,Make wrapPropagateTLSState more generic (#57634)
36e47af58b,cpp_frontend,Untopiced,Pass reference to parent future in callbacks (#57635)
45012da298,distributed,Untopiced,Migrate from shared_ptr to intrusive_ptr for Future (#57636)
8d363d37da,fx,Untopiced,[FX] Adds PyTree support to FX through `concrete_args` (#55888)
a911c4fc1c,complex_frontend,Untopiced,New: Initial support for sparse complex tensors constructors for CPU/CUDA (#57125)
6f2c0cccdd,complex_frontend,Untopiced,"New: sparse complex: add linear algebra, addmm (#57129)"
023ecc40ad,skip,Untopiced,Revert D28248766: Update internal code for torch.linalg.solve
2901d2e694,quantization,Untopiced,make quantizeable MHA work with torch.jit.script (#57774)
27f672a0fc,releng,Untopiced,Fix test reporting regression (#57795)
0dd0151c64,python_frontend,Untopiced,add `torch.testing` to docs (#57247)
161ea537f0,releng,Untopiced,[reland] Remove unused code in windows_build_definition.py (#57107)
b5b158a6c6,releng,Untopiced,Be more lenient with network exceptions in trigger_azure_pipeline.py (#57714)
626ae7f036,jit,Untopiced,Copy edit of TorchScript Language Reference (#57694)
c07babbcf1,distributed,Untopiced,[Gradient Compression] Divide by world size before all_reduce to avoid overflow (#57410)
5044d9dc51,quantization,Untopiced,Fixing quantize_per_tensor on cuda (#57703)
7e51ac5ea7,structured_frontend,Untopiced,Port gcd to structured (#57624)
3a1dc60da5,structured_frontend,Untopiced,Port nextafter to structured (#57625)
3dd88d6792,structured_frontend,Untopiced,Port igamma and igammac to structured (#57626)
470c7af749,structured_frontend,Untopiced,Port hypot to structured (#57627)
223a362f63,structured_frontend,Untopiced,Port lcm to structured (#57628)
0503105bc2,structured_frontend,Untopiced,Port logaddexp and logaddexp2 to structured (#57629)
64dc10e268,jit,Untopiced,[jit] Also fold NaiveSyncBatchNorm when folding batch norm (#57823)
731dcd75f5,distributed,Untopiced,[torch/elastic] Revise the note section of RendezvousHandler doc (#57723)
96fce78ac4,vulkan,Untopiced,[Vulkan] Add -Os flag to shader compilation (#57199)
96e1a83fb2,releng,Untopiced,Add Gloo TCP_TLS transport (#56442)
9234d7fc27,linalg_frontend,Untopiced,[PyTorch] Use MaybeOwned and avoid resize in bmm_cuda (#56115)
3d2ce60539,composability,Untopiced,[PyTorch] Remove dead get/setTLSCallbacks APIs (#56492)
2043093217,python_frontend,Untopiced,Add correction parameter to std/var (#50903)
db412a6885,distributed,Untopiced,Avoid 2 extra copies when reducing sparse tensors and fix result() vs inplace output discrepancy (#57822)
58f32fa5fd,linalg_frontend,Untopiced,Remove compute_uv flag from torch.linalg.svd (#57180)
18fed3dfbe,linalg_frontend,Untopiced,Change name for namedtuple return of torch.linalg.svd (#57181)
c88167d2ed,releng,Untopiced,Respect .ini for flake8 and mypy (#57752)
b38f153d91,jit,Untopiced,[NNC] Added NNC lowerings for t/transpose/permute/expand + other cleaning (#57426)
b0c27b44cf,jit,Untopiced,Enable backward/forward compatibility for TS runtime (#57498)
bc0965ac85,vulkan,Untopiced,[Vulkan] Use more optimal command buffer submission rate (#57196)
4fad8d1a2c,autograd_frontend,Untopiced,Update the default detach semantic for forward mode AD (#57820)
ee4be5322b,jit,Untopiced,Fix lint in test_tensorexpr_pybind (#57869)
73f22bcbf9,fx,Untopiced,"[fx ir] Handle cases in GraphDrawer when shape, type or stride are not present (#57845)"
e9c3ce30d4,distributed,Untopiced,Fix flaky test_barrier_timeout_global. (#57523)
8c04593c0a,mobile,Untopiced,[PyTorch Edge] Add backport to export old bytecode models (#56802)
74d493cc07,distributed,Untopiced,[RPC Framework] Support passing RemoteModule as an arg (#57695)
4db88307d9,distributed,Untopiced,[RPC Framework] Add a link to the tutorial in RemoteModule docstring (#57875)
94080f45ab,distributed,Untopiced,[RPC Framework] Update rpc.rst (#57876)
bc2540f0be,distributed,Untopiced,benchmark rpc ps (#57454)
3a66a1cb99,releng,Untopiced,[clang-tidy] Exclude cppcoreguidelines-avoid-magic-numbers (#57841)
8639fd104e,profiler,Untopiced,[profiler][kineto] Support for memory allocs/deallocs in the traces (#57835)
f51798d0dc,jit,Untopiced,[TensorExpr] Fix UB in LoopNest::distribute. (#57883)
a46e927b1a,nn_frontend,Untopiced,[torch] handle embedding bag with empty bag (#57446)
88a1e8eb01,caffe2,Untopiced,Add EMA to DecayAdagrad (#57866)
737f48dfc5,mobile,Untopiced,Remove _save_data() and _load_data() from mobile (#57879)
e8fb167b17,jit,Untopiced,[PyTorch Edge] Reuse constant table from ts in bytecode (#56002)
0c2d38264a,performance_as_product,Untopiced,Improve BatchNorm1d performance (CUDA) (#57786)
9ad19af935,jit,Untopiced,[TensorExpr] Fix a condition when we use a native depthwise conv2d lowering. (#57906)
4cf2c646c2,linalg_frontend,Untopiced,Added torch.linalg.matrix_norm (#57127)
14282232d9,python_frontend,devs,Fix `generate_not_implemented_tests` not testing unknown types correctly (#56997)
fc55290e5b,distributed,Untopiced,Fix distributed autograd gradients synchronization (#57792)
5c67d8dfd3,skip,Untopiced,ATen lu_unpack. Required for making `torch.lu_solve` differentiable. (#46913)
50e22e1e08,cpp_frontend,Untopiced,Remove tmp folder when run unit test (#57800)
300363b54f,nn_frontend,Untopiced,CLN Removes unused RReLU code (#57672)
d11cce4f5e,linalg_frontend,Untopiced,Add cuSOLVER path for torch.linalg.lstsq (#57317)
e7e73192f6,linalg_frontend,Untopiced,Added cuBLAS path for torch.linalg.lstsq (#54725)
259d19a733,jit,Untopiced,[jit] Adding a concat optimization pass (#55474)
3c87fe9b14,skip,Untopiced,Revert D28117714: [pytorch][PR] ATen lu_unpack. Required for making `torch.lu_solve` differentiable.
b84a28b50a,linalg_frontend,Untopiced,tweak sync note wording for linalg docs (#57924)
cbfce376a8,skip,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
ece15f6902,dataloader_frontend,Untopiced,[DataLoader] Change Decoder signature and add MatHandler (#57391)
bc798cdc1d,releng,Untopiced,Add run_master_build workflow (#57899)
807bea1c4e,jit,Untopiced,[jit] initial support for PEP-585 types (#57363)
727c1d69d7,autograd_frontend,Untopiced,Remove unnecessary indirection through torch::autograd::impl::pyobj/set_pyobj (#57733)
4d181ba51c,structured_frontend,Untopiced,Port maximum and minimum to structured (#57630)
d115e81a32,distributed,Untopiced,Fix document around DDP uneven inputs (#57448)
710a83d09f,autograd_frontend,deprecations,Remove code and logic for old style custom autograd Function (#57357)
29753339b7,releng,Untopiced,Do not download slow test when on sandcastle (#57953)
b587354e4c,releng,Untopiced,Add Python-3.9 CI testing (#50992)
fe3c63d9d3,distributed,Untopiced,[DDP] fix param to name mapping (#57771)
fea3824214,jit,Untopiced,Ensure torch.save() deterministic output (#57536)
bf053a1296,jit,Untopiced,Fix hasattr support type (#57950)
e1cbc43f50,releng,Untopiced,Use tools/print_test_stats.py in GHA (#57647)
478f639779,vulkan,Untopiced,[Vulkan] Fix seg fault during descriptor set allocation on some platforms (#57825)
481806be97,autograd_frontend,Untopiced,Fix creation_meta for multi view outputs in NoGradMode/InferenceMode. (#57842)
19706d91cd,vulkan,Untopiced,[vulkan] Add sigmoid activation functions (#57867)
ba07aaf211,skip,Untopiced,Fix typo in warning for spawn method (#57927)
98fcdb8005,skip,Untopiced,add cuda memory and distributed metadata (#57252)
ebb1b74f65,profiler,Untopiced,Fix json parse error for profiler call stack (#57099)
f0f69c5dc1,skip,Untopiced,torch.where is now mentioning Bool rather than Byte when given wrong dtype mask (#57942)
f1d01b9488,skip,Untopiced,Disable test for quicklint (#57968)
36172f347a,mobile,Untopiced,[iOS GPU][Perf][2/n] Prepack linear + Fuse relu/hardtanh (#57665)
036167111d,skip,Untopiced,Revert D28294662: [pytorch][PR] add cuda memory and distributed metadata
747312bf61,fx,Untopiced,Support for accumulate nodes traversal and to access op names in the compare function (#57685)
38500d5d7b,distributed,Untopiced,[RPC Framework] Move the annotation w/ bold effect out of the quotes (#57965)
fc9c486044,jit,Untopiced,Add enabling default instructions flag for mobile (#57778)
b8ca1219de,jit,Untopiced,Add tests for custom state_dict save/load methods in TorchScript (#57886)
f97650e70b,jit,Untopiced,[NNC] Fix float->bool conversion on cpu (#57798)
c714596027,profiler,Untopiced,"[kineto] Update Kineto submodule, cupti library paths (#57789)"
71ca3e99af,python_frontend,devs,Only use actually mismatched elements for reporting in `torch.testing` (#57923)
e90fcffb65,distributed,Untopiced,[c10d] Log when store based barrier succeeds (#57711)
a0d686c9cd,skip,Untopiced,OpInfo: select (#57731)
5840c8cfd8,distributed,Untopiced,[nccl] log rank when communicator is aborted (#57974)
ba84c91197,linalg_frontend,Untopiced,Deprecate torch.lstsq (#57743)
a93314dec3,linalg_frontend,Untopiced,"Alias det, slogdet, matrix_power, inverse, pinverse (#57821)"
36a22967b7,fx,Untopiced,[fx ir] Handle the case when output consumes get_attr directly (#57844)
f3e014f37b,mobile,Untopiced,[iOS GPU][Perf][3/n] Cache the compuation pipeline state object (#57666)
4fef1c1d74,linalg_frontend,deprecations,Deprecate torch.cholesky (#57725)
24087d07ca,linalg_frontend,deprecations,Deprecate QR (#57745)
3ec16035f2,nn_frontend,Untopiced,TST Migrates some of test_nn.py from assertEqualIgnoreTypes to assertEqual (#57642)
ee48bd089c,nn_frontend,Untopiced,Support mix of int32 and int64 offsets/indices for EmbeddingBag and its variants (#55189)
415ae54c31,linalg_frontend,bc_breaking,Deprecate torch.eig (#57727)
7707efed8f,linalg_frontend,Untopiced,Deprecate matrix_rank (#57734)
43f6deb6e4,linalg_frontend,bc_breaking,Deprecate chain_matmul (#57735)
0d564904b5,mobile,Untopiced,[iOS GPU][Perf][4/n] Reuse the same command buffer when copying results to CPU (#57667)
cf7a0e5af4,distributed,Untopiced,Use RPC context streams to cover serde ops (#57926)
9e94921a55,distributed,Untopiced,combine consecutive layes on the same device (#55973)
3e46d6c9e4,python_frontend,Untopiced,Update docs to mention CUDA support for Future (#50048)
dc55ab3f77,quantization,Untopiced,[fbgemm] fix bug handling bias in rowwise quantization of FC (#58022)
565550d89a,mobile,Untopiced,[iOS GPU][perf][5/n] Replace std:vector with IntArrayRef and SmallVector (#57668)
dbedb1fa1c,cuda,Untopiced,[CUDA graphs] Sync after replay (#57556)
fa318911be,python_frontend,Untopiced,"Enable geometric ops, exp2, expm1, rsqrt & erfc for BFloat16 on CUDA (#57913)"
067147ac7d,python_frontend,Untopiced,Enable BFloat16 for `logaddexp` & `logaddexp2` on CUDA (#57908)
4fb8676cea,cuda,Untopiced,Add dot implementation for BFloat16 on CUDA (#57903)
90f05c005d,nn_frontend,Untopiced,refactor multi_head_attention_forward (#56674)
502eb664ae,skip,Untopiced,OpInfo: chunk (#57935)
ea421fb249,distributed,Untopiced,enable static graph training in DDP (#55248)
7faac089ca,cuda,Untopiced,Enable cusolver potrf batched for Cholesky decomposition when cuda >= 11.3 (#57788)
e0539b0ba6,dataloader_frontend,Untopiced,[DataLoader] Remove redundant len >= 0 (#57951)
ac44569b0d,skip,Untopiced,make ddp logging api to be private (#57999)
18edb77a28,nn_frontend,Untopiced,Add `pad_sequence` as a native function (#57868)
e385aa863a,releng,Untopiced,Add tools/ script to limit circleci to a set of jobs (#58001)
0da5421837,linalg_frontend,Untopiced,Doc deprecate norm and add seealso to linalg.norm (#57986)
a02305925c,releng,Untopiced,[local lint] Force color output on mypy (#58071)
ad4cd6ef89,skip,Untopiced,Revert D28338485: make ddp logging api to be private
698be31262,jit,Untopiced,Adding support for normalization of __is__ op (#57862)
eb1ffa91d8,jit,Untopiced,[pyper] allow static runtime on and glow on simultaneously (#57972)
86b7ae181a,skip,Untopiced,Automated submodule update: FBGEMM (#57983)
dd876120f9,benchmark,Untopiced,Out version for aten::repeat (#57683)
b58a7c95aa,dataloader_frontend,Untopiced,[DataLoader] Raise detailed Error for ForwardRef type (#57824)
1d4d9ffca0,distributed,Untopiced,[torch/elastic] Refactor rendezvous store initialization logic (#58057)
d49f6d556b,dataloader_frontend,Untopiced,[DataLoader] Fix tempfile binding and removing for torch_shm_manager (#57566)
111c99cdfd,vulkan,Untopiced,[vulkan] Fix glslc path for desktop build (#56507)
4ef94265e9,distributed,Untopiced,Add Futures to ProcessGroupGloo (#57818)
8b12c8e8b3,nn_frontend,Untopiced,Fixes: register_full_backward_hook crash if first argument don't require a gradient (#57944) (#57945)
e4418b67c7,distributed,Untopiced,[torch/elastic] Update the rendezvous docs (#57973)
a13718b69f,fx,Untopiced,[FX] Make stack trace testing less strict (#58088)
f9c8b7f1a8,fx,Untopiced,[FX][docs] minor fixes (#58085)
c36055bb42,releng,Untopiced,Make mypy_wrapper.py accept multiple filenames (#57998)
a1f9a3c643,cpp_frontend,Untopiced,Fix UB in library.h (#57962)
a90c229900,linalg_frontend,Untopiced,Remove the BETA status for torch.linalg (#58043)
1f83d8eec2,jit,Untopiced,[Static Runtime] Return nullptr if the number of input args doesn't match (#58018)
d9ea93181b,distributed,Untopiced,Some types for remote_module (#58012)
29cfcf70be,package,Untopiced,[package] add mock/extern hooks (#58000)
7a23a5e8e9,releng,Untopiced,Shut up sccache couldn't connect error (#58047)
e573987bea,nn_frontend,Untopiced,remove syncs in one_hot (#57902)
aaca12bcc2,linalg_frontend,Untopiced,Deprecate in docs torch.svd and change svd -> linalg_svd (#57981)
b7d674eb21,skip,Untopiced,Revert D28331386: [pytorch][PR] [torch/elastic] Update the rendezvous docs
0d4dc6cb39,fx,Untopiced,Let submodules be collected as args/kwargs (#57840)
8b816e9010,python_frontend,Untopiced,To implement gradient for Pytorch (#54617)
8824f49e68,python_frontend,Untopiced,Split `test_testing.py::TestAsserts` for multiple devices (#56365)
e9e125475e,jit,Untopiced,[Static Runtime] Add schema check to aten::repeat and fb::fast_gather (#58106)
8c91acc161,structured_frontend,Untopiced,port topk to structured (#57790)
32acc96f78,benchmark,Untopiced,[Static Runtime] Fix bug in aten::clone (#58100)
c790fd2bf8,linalg_frontend,Untopiced,ATen lu_unpack. Required for making `torch.lu_solve` differentiable. (#46913)
c3d40fdf56,cpp_frontend,Untopiced,[ATen] Use expect_contiguous in layer_norm (#58067)
d623fb7e04,distributed,Untopiced,Add a disclaimer about limited CUDA support in RPC (#58023)
a07a0190f9,composability,Untopiced,enable deterministic path for index_put with accumulate=False on CPU and CUDA (#57839)
14badd9929,skip,Untopiced,enable deterministic path for index_copy_cuda with index_put (#57870)
f1defeaea4,profiler,Untopiced,[profiler][resend] Add cuda memory and distributed metadata (#58010)
bf2ebfc9f6,profiler,Untopiced,[profiler][small] Handle empty trace (#58013)
cdf161c382,profiler,Untopiced,[profiler][small] Speed up postprocessing (#58021)
e18f5f1d13,profiler,Untopiced,[profiler][small] Add skip_first parameter to the default schedule (#58025)
db13119fc4,linalg_frontend,deprecations,Deprecate symeig (#57732)
e1078d42f0,complex_frontend,Untopiced,std/var: Return real results for complex input (#58066)
c7fb0a0e82,python_frontend,Untopiced,Remove beta warning for use_deterministic_algorithms (#58074)
c911c30520,skip,Untopiced,Revert D28291041: enable deterministic path for index_copy_cuda with index_put
ff982ef73d,skip,Untopiced,"OpInfo: reshape, reshape_as and minor clean-up (#57460)"
5ea87f9c24,skip,Untopiced,Grammatically updated the tech docs (complex_numbers.rst) (#57540)
30f26c5893,python_frontend,Untopiced,Reimplement torch::flip based on advanced indexing (#56713)
4faa427383,distributed,Untopiced,Remove printout from distributed tests (#58095)
c52700dbcd,distributed,Untopiced,[wip] enhance DDPSink to work for general outputs (#57073)
d212bf1863,python_frontend,Untopiced,Enable `BFloat16` for `nan_to_num` on CUDA (#58063)
16d617c3e5,distributed,Untopiced,test experiment script (#57925)
94bb1150a7,releng,Untopiced,[ROCm] ubuntu version check in install_rocm.sh (#57751)
8f83bfeb98,releng,Untopiced,Update CI images for rocm4.2 (#58017)
3603ba24d5,releng,Untopiced,Trigger Windows multi gpu tests on master (#57817)
bfd0a46156,fx,Untopiced,[FX] Arg normalization not save output node in the node_map (#58058)
9d56176034,fx,Untopiced,Fix splitter and add a unittest (#58075)
6404184700,skip,Untopiced,Revert D28385479: [pytorch][PR] [ROCm] ubuntu version check in install_rocm.sh
35521a2629,skip,Untopiced,Fix some tensor operators to return `NotImplemented` for invalid inputs (#57934)
87afcea0cc,cuda,Untopiced,T90561249: Enforce kernel launch checks (#58116)
a0ac80ec76,distributed,Untopiced,[DDP] Don't find tensors if static graph (#58105)
5c696443c7,dataloader_frontend,Untopiced,[DataLoader] Modfity construct_time_validation to argument_validation (#55836)
3b977b3b4d,dataloader_frontend,Untopiced,[DataLoader] Add context manager for runtime type validation (#55936)
7156168f71,structured_frontend,Untopiced,Port max_pool2d_with_indices_backward to structure (#57797)
53bc6f79f3,releng,Untopiced,Added DevOps PR and Nightly Build logic (#58007)
af36d084fd,releng,Untopiced,reland [ROCm] ubuntu version check in install_rocm.sh (#58164)
ab6b5fa036,amd,Untopiced,Add HIP (ROCm) semantics doc (#57871)
a88673e93e,jit,Untopiced,Enable cat wo conditionals iff cpu (#58026)
6955d4d0f7,jit,Untopiced,[NNC] Handle only the first argument of aten::to (#58028)
c9eb381aac,releng,Untopiced,Allow zero jobs in tools/explicit_ci_jobs.py (#58176)
3c973de543,composability,Untopiced,HABANA Device registration key and Autograd key addition (#57094)
cbd1227809,nn_frontend,Untopiced,Add a note in the parametrize doc about the naming choice (#58142)
0bfcc3e3f4,python_frontend,Untopiced,fix topk with k=0 on cuda (#58086)
614437751f,distributed,Untopiced,make remote model instantiation async when possible (#58052)
46e4b2dbda,nn_frontend,Untopiced,Convert assert -> cast. (#57458)
5e83c62a9e,skip,Untopiced,Revert D28351931: [pytorch][PR] Fix some tensor operators to return `NotImplemented` for invalid inputs
cbba3db21b,jit,Untopiced,[TensorExpr] Minor cleanup in IREval. (#57881)
c751e53800,jit,Untopiced,[TensorExpr] Implement 'call_raw' in IREval. (#57882)
4c24d820ff,jit,Untopiced,[TensorExpr] Implement 'call_raw' in CUDA codegen. (#57901)
581bf01074,distributed,Untopiced,[Gradient Compression] Remove unnecessary warning on the rst file and the check on C++ version (#58170)
2073e866ad,releng,Untopiced,Switch GHA test stats S3 upload token (#58156)
9bfc1c4e0e,distributed,Untopiced,[Gradient Compression] Update the docstring of fp16_compress_hook (#58168)
82b2013eac,composability,Untopiced,Delete move constructor on TensorImpl (#58048)
85d64648d3,structured_frontend,Untopiced,Port threshold to structure (#57810)
3d5bb71020,skip,Untopiced,"Back out ""[PyTorch Edge] Reuse constant table from ts in bytecode"" (#58099)"
1de3525ca8,onnx,Untopiced,[ONNX] Handle PackedParams inputs for _propagate_and_assign_input_shapes (#56449) (#57079)
9063cb0a3c,jit,Untopiced,Infer types for arguments of methods not invoked directly by monkeytype (#57202)
9148f19e85,python_frontend,Untopiced,enable support for nested containers in `torch.testing.assert(equal|close)` (#57270)
d09abf004c,skip,Untopiced,OpInfo: narrow (#58082)
d230045fde,build_frontend,Untopiced,Combine backtrace print into one string to avoid interleaving. (#56961)
01d0eb9dac,package,Untopiced,[package] Add an intern keyword (#57341)
8a45006765,cuda,Untopiced,enable deterministic path for index_copy_cuda with index_put (#58144)
166a8df65f,distributed,Untopiced,[reland] make ddp logging api to be private (#58089)
ae63b1d1c6,distributed,Untopiced,[torch/elastic] Revise distributed run script (#58159)
028f2f62ac,distributed,Untopiced,[torch/elastic] Update the rendezvous docs (#58160)
f1ac9b6598,package,Untopiced,fix lint (#58203)
645a5f706a,cpp_frontend,Untopiced,move `flatten_dense_tensors` and `unflatten_dense_tensors` to Native (#58006)
bc30c3165c,distributed,Untopiced,Update docs for get_future support (#58107)
647282cb0c,autograd_frontend,Untopiced,Add forward AD gradcheck (#57633)
26b6d044cd,autograd_frontend,Untopiced,Add forward AD test for op info (#57701)
2279962162,autograd_frontend,Untopiced,Codegen inplace forward AD formula from out of place one if needed (#57767)
f0a5500722,distributed,Untopiced,[torch/elastic] Add logging to the sanitize function of RendezvousStateHolder (#58169)
f4a5730a6b,jit,Untopiced,Add LowerSimpleTuples for freeze tuples (#57915)
c4a486f4b1,python_frontend,Untopiced,Enable atan2 & hypot for BFloat16 on CUDA (#57905)
e6d8f45523,python_frontend,Untopiced,"Enable `ceil`, `floor`, `frac`, `round` & `trunc` for BFloat16 on CUDA (#57910)"
f9aa6b2432,python_frontend,Untopiced,Enable lerp for BFloat16 on CUDA (#57907)
ce1a8620d9,python_frontend,Untopiced,Enabled `roll` & `diag` for BFloat16 dtype on CUDA (#57916)
066e7699eb,skip,Untopiced,Revert D28387764: Codegen inplace forward AD formula from out of place one if needed
87f7fdfd5c,benchmark,Untopiced,Allow instruction counting to use shared memory as a staging ground. (And a couple other tweaks.) (#56711)
f88297c66b,skip,Untopiced,Revert D28387767: Add forward AD test for op info
2d7d6922b6,skip,Untopiced,Revert D28387765: Add forward AD gradcheck
a31daf381f,releng,Untopiced,Move libtorch builds to be master-only (#58183)
6b1eeef601,skip,Untopiced,OpInfo: squeeze (#58080)
ad4b2571b6,releng,Untopiced,Fix multi gpu test break on Windows (#58213)
8a1dab3d26,distributed,Untopiced,[tsm] add support for jetter to Role (base_image) for mast launches
e554731b32,skip,Untopiced,Hide set_enabled since it's not public facing. (#58078)
c8644326a7,skip,Untopiced,Revert D28177553: [tsm] add support for jetter to Role (base_image) for mast launches
7a95cccbc7,skip,Untopiced,"Revert D28393469: [pytorch][PR] Enable `ceil`, `floor`, `frac`, `round` & `trunc` for BFloat16 on CUDA"
82d714935e,complex_frontend,Untopiced,[TS] Add complex support for more ops (#54541)
fee7e8b91d,jit,Untopiced,Striding for lists Part 2 (#49352)
2b99bce1d7,profiler,Untopiced,[profiler] CUDA event fallback (#58133)
6997e7bd39,skip,Untopiced,Update Kineto submodule (#58179)
cf7d56d8f2,autograd_frontend,Untopiced,Gradgradcheck to runs successfully with unrelated inputs (#58049)
ab5c273950,skip,Untopiced,Remove the matmul complex backward skip (#58138)
e8574b84bf,python_frontend,bc_breaking,Fix legacy tensor constructor/new matching incorrect signature with d (#58108)
52e9a192b1,releng,Untopiced,[ROCm] add 4.2 to nightly builds (#58143)
002ce5c1df,structured_frontend,Untopiced,port addmm to structure kernel (#57417)
e71b526e7e,autograd_frontend,Untopiced,Add inference mode python bindings and tests (#58045)
dd3bd0286b,onnx,Untopiced,T89509943 - Improve error message during Glow ONNXIFI (#58069)
a0f4b7cd48,jit,Untopiced,"[TensorExpr] Re-enable skipped tests, they seem to be working now. (#58206)"
470cd64514,jit,Untopiced,[TensorExpr] Remove disabled tests that we do not plan to re-enable. (#58207)
e507771294,distributed,Untopiced,[RPC Framework] Replace Python Pickler with internal RPC pickler for RemoteModule (#58019)
2afcb7e8fd,releng,Untopiced,Move Azure MultiGPU tests back to nightly (#58242)
9e156b01e5,linalg_frontend,Untopiced,linalg.eig backwards and linalg.eigvals (#57276)
c1430c3425,linalg_frontend,Untopiced,Add torch.linalg.inv_ex without checking for errors by default (#58039)
a49406b331,linalg_frontend,Untopiced,Fixed batched version of torch.linalg.cond for singular inputs (#58040)
5e65428503,linalg_frontend,Untopiced,Fix NumPy compatibility issue for torch.linalg.cond (#58041)
020e2ff115,jit,Untopiced,Add tests for PDT (#58211)
d8c6b74b0b,linalg_frontend,bc_breaking,Deprecate torch.solve (#57741)
2294fd61c6,releng,Untopiced,.github: Add windows.4xlarge to scale-config.yml (#58198)
1de9f51782,mobile,Untopiced,[Pytorch Edge] Runtime ops compatibility api (#57570)
8888565597,linalg_frontend,Untopiced,T90561249: Enforce kernel launch checks (#58178)
770f8cea2d,complex_frontend,Untopiced,Add support for real and imag tensor attributes (#54692)
098d9975a7,structured_frontend,Untopiced,Port heaviside to structured kernel (#57933)
3c4a90ce38,autograd_frontend,Untopiced,"Revert ""Revert D28387764: Codegen inplace forward AD formula from out of place one if needed"" (#58231)"
9b95568dc3,autograd_frontend,Untopiced,update abs forward ad formula (#58235)
061c7a1e17,releng,Untopiced,Overwrite with `ln` if libc10.so already exists (#58243)
3bc8a2264d,onnx,Untopiced,[ONNX] Support .item() export & NumberType to tensor conversion (#55697) (#57594)
6d7fe76317,onnx,Untopiced,[ONNX] Warning when using __len__ to calculate tensor shape (#55151) (#57595)
ac9e79e561,onnx,Untopiced,Add a new operator for fill_() function. (#56859) (#57596)
dc0071dfa5,onnx,Untopiced,[ONNX] Special post process for onnx::Cast and onnx::ConstantOfShape shape type inference (#55962) (#57597)
9e56314d2c,onnx,Untopiced,onnx.symbolic_helper.parse_args: document and clean up (#56956) (#57598)
2b0f481d3f,onnx,Untopiced,Add support to to(device) op. (#56857) (#57599)
346dc88bfa,onnx,Untopiced,[ONNX] Support registering custom export for prim::PythonOp from torch.autograd.Function (#55630) (#57600)
bfe7728f18,onnx,Untopiced,[ONNX] Process const folding progressively when converts to ONNX (#54569) (#57601)
8e29863a0d,onnx,Untopiced,[ONNX] Handle NoneType in Assign Output Shapes (#54623) (#57602)
01374d69e4,onnx,Untopiced,[ONNX] ListUnpack on dynamic tensor list (#56592) (#57603)
51cd89ecc6,onnx,Untopiced,"[ONNX] Handle mixed mask, index input for index_put (#57604)"
e1bb9d2d99,nn_frontend,Untopiced,Reimplement spectral_norm using new parametrization functionality (#57784)
d833caaf6b,jit,Untopiced,[PyTorch Mobile][Forward/backward compatibility] Number of arguments for operators (#56845)
26aeec35a1,skip,Untopiced,Disable more of quicklint test (#58257)
f6532468c8,linalg_frontend,Untopiced,Make norm and vector_norm use the same kernels. (#58214)
3f9126f399,skip,Untopiced,Only quicklint files that exist (#58261)
7756cb6a5b,releng,Untopiced,Migrate pytorch_python_doc_build to github action (#57371)
3a898c26c0,releng,Untopiced,Print stderrs in tools/mypy_wrapper.py (#58265)
d304bb070a,skip,Untopiced,"Gelu Backward, Contribution from Kevin Stephano (#58249)"
b0833533a7,linalg_frontend,Untopiced,Update internal code for torch.linalg.solve (#56613)
1f3807ce5d,linalg_frontend,Untopiced,More stable and faster implementation of the gradient of torch.linalg.eigh (#55049)
993a35a8cb,benchmark,Untopiced,[Static Runtime] Support clamp.Tensor (#58191)
fd3d3ef900,distributed,Untopiced,[RPC Framework] Add _script_module_reducer unconditionally for RecursiveScriptModule in RPC pickler (#58020)
8ac0917cc7,nn_frontend,Untopiced,add channels last support for AvgPool2d on CPU (#48918)
047ae6b713,profiler,Untopiced,"[profiler][small] CUDA synchronize guard, minor fix (#58254)"
c524448dd1,fx,Untopiced,init hardshrink (#57749)
f3ead05d77,jit,Untopiced,hardtanh (#57750)
3072c97017,jit,Untopiced,"Gelu Backward, Contribution from Kevin Stephano (#58249)"
64d23cc040,skip,Untopiced,Revert D28379394: Update internal code for torch.linalg.solve
04970057d8,python_frontend,Untopiced,Code-dedup in PowKernel (#57873)
31607ad41d,jit,Untopiced,[NNC] Started codegenning some external calls (#58118)
f6408c0dc1,quantization,Untopiced,[ATen][quant] Use expect_contiguous in quantized::linear fbgemm version (#58221)
452569dffb,complex_frontend,Untopiced,cfloat and cdouble functions (#58137)
38e606d056,distributed,Untopiced,[RFC] Add method torch.jit._clone_module_with_class (#56152)
a8122062c0,mobile,Untopiced,[PyTorch Mobile]Add light version of RandomSampler (#58201)
cb7c6a536b,distributed,Untopiced,[doc] update distributed optimizer doc (#58084)
6b8b591a84,jit,Untopiced,[NNC] Fix output restriding of size-1 dimensions (#58256)
ac04cc775b,jit,Untopiced,[NNC] Enable CPU fusion inside Facebook (#58029)
03398b7edb,structured_frontend,Untopiced,Port elu to structured (#57619)
9dba26eed1,structured_frontend,Untopiced,Port softplus to structured (#57620)
401d0fe8c5,structured_frontend,Untopiced,Port leaky_relu to structured (#57621)
d65dff463a,structured_frontend,Untopiced,Port hardsigmoid to structured (#57622)
f23e10f27b,structured_frontend,Untopiced,Port softshrink to structured (#57623)
cf1daf571d,structured_frontend,Untopiced,Port silu to structured (#58050)
88ff651e90,jit,Untopiced,torch.jit.ignore as a context manager (#55172)
ccd7141919,composability,Untopiced,Modify DispatchKeyExtractor to also work for optional Tensors (#58283)
4f28c0b590,skip,Untopiced,"Revert ""Revert D28387767: Add forward AD test for op info"" (#58230)"
72a90c3ea5,mobile,Untopiced,[metal] Add reflection_pad2d for metal (#58263)
1f5ed1ff69,mobile,Untopiced,[metal] Fix binary elementwise ops to handle inputs with mismatched dim() (#58262)
2ead01f796,releng,Untopiced,Build and push Docker images in GitHub Actions (#58174)
07de11c26d,package,Untopiced,[torch.Package/TorchScript] TS serialization importer to handle unified format (#54891)
8ab3aa464a,package,Untopiced,[torch.Package/TorchScript] refactor ScriptModuleSerializer Exporter (#55958)
3ad11803f7,package,Untopiced,[torch.Package/TorchScript] ScriptModuleSerializer add unified format (#56299)
307375a88e,package,Untopiced,[torch.Package/TorchScript] torch.Package python logic to save TorchScript (#54893)
9403fe17ce,package,Untopiced,[torch.package/TorchScript] logic to enable sharing of tensors on load (#57573)
e27f861db7,package,Untopiced,[torch.Package/TorchScript] TS into torch.Package test cases (#54894)
76d2cb3b8e,package,Untopiced,[torch.package/TorchScript] flag to gate allowance of TS serializaiton in torch.package (#57678)
e6adc06221,skip,Untopiced,Revert D28425179: Build and push Docker images in GitHub Actions
2e26976ad3,releng,Untopiced,Disallow versionless Python shebangs (#58275)
4bcaa5ae20,autograd_frontend,Untopiced,"Revert D28412496: Revert ""Revert D28387767: Add forward AD test for op info"""
6e1718277c,releng,Untopiced,Make GHA test-reports upload regex more permissive (#58250)
c711c30c74,autograd_frontend,Untopiced,"Revert ""Revert D28387764: Codegen inplace forward AD formula from out of place one if needed"" (#58231)"
064923e635,nn_frontend,Untopiced,Improve native_batch_norm_backward performance (CUDA) (#58240)
52bb8120b8,distributed,Untopiced,Mention distributed profiling in documentation (#58286)
520f90f359,onnx,Untopiced,[ONNX] Handling incorrect format for example_outputs (#55802) (#57829)
0d11dbf511,onnx,Untopiced,[ONNX] Support index_add_ function. (#56867) (#57830)
0be334a1ba,skip,Untopiced,optimize channels last for BatchNorm2d on CPU (#48919)
94ef2b9b48,skip,Untopiced,[Pytorch] Better doc strings for bundled inputs (#56591)
0caec739a3,skip,Untopiced,Revert D25399468: optimize channels last for BatchNorm2d on CPU
49a8942a77,skip,Untopiced,Revert D25399466: add channels last support for AvgPool2d on CPU
73d51406fa,mobile,Untopiced,[PyTorch Mobile]Move train related files to their own folder (#58205)
623d63d9da,releng,Untopiced,[reland] Build and push Docker images in GitHub Actions (#58299)
34ac28b5ff,releng,Untopiced,Bump Ubuntu/Python versions in ECR GC Docker image (#58309)
0a561f83ca,jit,Untopiced,[PyTorch Mobile]Fix unit test (#58202)
c034bce979,onnx,Untopiced,"Back out ""[ONNX] Process const folding progressively when converts to ONNX (#54569)"""
d3fbb41c61,jit,Untopiced,[PyTorch Edge] share tensors in mobile with new api (#58182)
00156d4845,fx,Untopiced,[FX][WIP] Proxyable classes (#56737)
84d8e3b0f6,fx,Untopiced,[FX] Finished prepare_for_inference API for release (#58293)
3dc70d8f78,mobile,Untopiced,[iOS][Metal] Add target for testing metal ops (#57832)
a4075fca9a,composability,Untopiced,extract dispatch keys from optional Tensors (unboxed) (#58296)
c4c2039fb2,skip,Untopiced,Revert D27652484: [nnc] Enable CPU fusion inside Facebook
00a46a5eb4,python_frontend,Untopiced,Fix incorrect inplace sort in `topk` (#58314) (#58318)
67583122f0,releng,Untopiced,Use pip3 instead of pip when building ECR GC image (#58334)
b0819b0b73,releng,Untopiced,[CircleCI] s/ubuntu-1604:202007-01/ubuntu-2004:202104-01/ (#58308)
998374a702,distributed,Untopiced,[tsm] add support for jetter to Role (base_image) for mast launches (#58252)
bcacf91a71,fx,Untopiced,[fx_glow]Add Support for importing quantized linear in FXIRImporter (#57483)
9def776cd6,quantization,Untopiced,[fx_acc] e2e quantized resnet18 (#58204)
2436377a7d,distributed,Untopiced,Remote the list for the attributes that will be ignored for pickling (#58345)
4f50fdc2a3,quantization,Untopiced,fx quant: refactor observer insertion
fad2ce439e,jit,Untopiced,[NNC] Link all available LLVM targets (#58312)
211bac53ef,jit,Untopiced,[jit] Add optimize_for_inference API (#58193)
1a91892f90,jit,Untopiced,Added fix for missing ops aten::sorted.str (#58339)
71f4c5c1f4,releng,Untopiced,"Fix ""ci/master"" workflow (#58335)"
6060684609,skip,Untopiced,Automated submodule update: tensorpipe (#57613)
9c7d5ed9b0,linalg_frontend,Untopiced,Clarifies cholesky_ex role and makes batched support a common string (#58217)
ee93a348de,nn_frontend,Untopiced,ENH Raises nicer error when calling module.train with invalid modes (#58247)
b1b9fb0147,releng,Untopiced,Specify the exact commit when triggering multi-gpu pipeline (#58219)
1ad06ba3f5,jit,Untopiced,Wrap torch::deploy API functions in safe rethrow macros (#58192)
432676599c,releng,Untopiced,Stop installing libuv on Windows (#51936)
4454b18e14,skip,Untopiced,Revert D28371127: Wrap torch::deploy API functions in safe rethrow macros
bef0e07e09,releng,Untopiced,Remove unused Dockerfile_runtime (#58333)
eab59bae15,build_frontend,Untopiced,Fix cmake_minimum_require in libshm (#58306)
5a238eb96e,jit,Untopiced,Fix deadlock in Future due to lock inversion with GIL (#58382)
affed3b04d,jit,Untopiced,Prevent lock inversions with GIL in Future (#58391)
ae9b66dd94,distributed,Untopiced,Fix TP agent not recording outgoing tensors with caching allocator (#58384)
a3b33139da,python_frontend,Untopiced,[Pytorch] Add non mutator bundled inputs method (#58408)
95fd1e9045,cuda,Untopiced,reduce number of randperm template instantiations (#58362)
2879f0f780,vulkan,Untopiced,[Vulkan] Use 2D tensor views when possible (#57198)
c29e6d37e8,vulkan,Untopiced,[Vulkan] Switch to Image2D for Convolution biases (#57201)
cce156ac94,releng,Untopiced,.github: Make on_pull_request a conditional block (#58363)
5f0bbb38ec,releng,Untopiced,ci: Release branch specific changes
