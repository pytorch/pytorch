# Template is at:    .github/templates/windows_ci_workflow.yml.j2
# Generation script: .github/scripts/generate_ci_workflows.py
name: Windows CI (!{{ build_environment }})

on:
{%- if on_pull_request %}
  pull_request:
{%- endif %}
  push:
    branches:
      - master
      - release/*
  workflow_dispatch:

env:
  BUILD_ENVIRONMENT: !{{ build_environment }}
  BUILD_WHEEL: 1
  CUDA_VERSION: "!{{ cuda_version }}"
  IN_CI: 1
  INSTALL_WINDOWS_SDK: 1
  JOB_BASE_NAME: test
  PYTHON_VERSION: "3.6"
  SCCACHE_BUCKET: "ossci-compiler-cache"
  VC_PRODUCT: "BuildTools"
  VC_VERSION: ""
  VC_YEAR: "2019"
{%- if cuda_version != "cpu" %}
  TORCH_CUDA_ARCH_LIST: "7.0"
  USE_CUDA: 1
{%- endif %}

concurrency:
  group: !{{ build_environment }}-${{ github.event.pull_request.number || github.sha }}
  cancel-in-progress: true

jobs:
  build:
    runs-on: "windows.4xlarge"
    steps:
      - name: Checkout PyTorch
        uses: actions/checkout@v2
        with:
          submodules: recursive
      - name: Install Visual Studio 2019 toolchain
        shell: powershell
        run: |
          .\.circleci\scripts\vs_install.ps1
{%- if cuda_version != "cpu" %}
      - name: Install Cuda
        shell: bash
        run: |
          .circleci/scripts/windows_cuda_install.sh
      - name: Install Cudnn
        shell: bash
        run: |
          .circleci/scripts/windows_cudnn_install.sh
{%- endif %}
      - name: Build
        shell: bash
        run: |
          .jenkins/pytorch/win-build.sh
      # Upload to github so that people can click and download artifacts
      - name: Upload artifacts to Github
        if: always()
        uses: actions/upload-artifact@v2
        # Don't fail on upload to GH since it's only for user convenience
        continue-on-error: true
        with:
          retention-days: 14
          if-no-files-found: error
          name: ${{ env.BUILD_ENVIRONMENT }}
          path: C:\w\build-results
      - name: Upload artifacts to s3
        if: always()
        uses: seemethere/upload-artifact-s3@9d7ceb0ab39c2c88d93ef7792b27425b27d59162
        with:
          retention-days: 14
          if-no-files-found: error
          name: ${{ env.BUILD_ENVIRONMENT }}
          path: C:\w\build-results

  test:
    runs-on: !{{ test_runner_type }}
    env:
      JOB_BASE_NAME: !{{ build_environment }}-test
    needs:
      - build
    steps:
      - name: Checkout PyTorch
        uses: actions/checkout@v2
        with:
          submodules: recursive
      - name: Install Visual Studio 2019 toolchain
        shell: powershell
        run: |
          .\.circleci\scripts\vs_install.ps1
{%- if cuda_version != "cpu" %}
      - name: Install Cuda
        shell: bash
        run: |
          .circleci/scripts/windows_cuda_install.sh
      - name: Install Cudnn
        shell: bash
        run: |
          .circleci/scripts/windows_cudnn_install.sh
{%- endif %}
      - uses: seemethere/download-artifact-s3@0504774707cbc8603d7dca922e8026eb8bf3b47b
        name: Download PyTorch Build Artifacts
        with:
          name: ${{ env.BUILD_ENVIRONMENT }}
          path: C:\${{ github.run_id }}\build-results
      - name: Check build-results folder
        shell: powershell
        run: |
          tree /F C:\$Env:GITHUB_RUN_ID\build-results
      # Needed for coverage in win-test.sh
      - uses: actions/setup-python@v2
        name: Setup Python3
        with:
          python-version: '3.x'
      - name: Run test scripts
        shell: bash
        env:
          PYTORCH_FINAL_PACKAGE_DIR: /c/${{ github.run_id }}/build-results/
        run: |
            .jenkins/pytorch/win-test.sh
      - uses: actions/upload-artifact@v2
        name: Store PyTorch Test Reports
        if: always()
        with:
          name: test-reports
          retention-days: 14
          if-no-files-found: error
          path:
            test/**/*.xml

  # this is a separate step from test because the log files from test are too
  # long: basically, GitHub tries to render all of the log files when you click
  # through an action causing extreme slowdown on actions that contain too many
  # logs (like test); we can always move it back to the other one, but it
  # doesn't create the best experience
  render_test_results:
    if: always()
    needs:
      - test
    runs-on: ubuntu-18.04
    # TODO: Make this into a composite step
    steps:
      - name: Checkout PyTorch
        uses: actions/checkout@v2
        with:
          # deep clone, to allow tools/print_test_stats.py to use Git commands
          fetch-depth: 0
      - uses: actions/download-artifact@v2
        name: Download PyTorch Test Reports
        with:
          name: test-reports
          path: test/test-reports
      - uses: actions/setup-python@v2
        with:
          python-version: 3.9
      - name: Install dependencies
        # boto3 version copied from .circleci/docker/common/install_conda.sh
        run: |
          pip install -r requirements.txt
          pip install boto3==1.16.34 junitparser rich
      - name: Output Test Results (Click Me)
        run: |
          python tools/render_junit.py test
      - name: Parse ref
        id: parse-ref
        run: .github/scripts/parse_ref.py
      - name: Display and upload test statistics (Click Me)
        # temporary hack: set CIRCLE_* vars, until we update
        # tools/print_test_stats.py to natively support GitHub Actions
        env:
          SCRIBE_GRAPHQL_ACCESS_TOKEN: ${{ secrets.SCRIBE_GRAPHQL_ACCESS_TOKEN }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_OSSCI_METRICS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_OSSCI_METRICS_SECRET_ACCESS_KEY }}
          CIRCLE_BRANCH: ${{ steps.parse-ref.outputs.branch }}
          CIRCLE_JOB: !{{ build_environment }}
          CIRCLE_PR_NUMBER: ${{ github.event.pull_request.number }}
          CIRCLE_SHA1: ${{ github.event.pull_request.head.sha || github.sha }}
          CIRCLE_TAG: ${{ steps.parse-ref.outputs.tag }}
          CIRCLE_WORKFLOW_ID: ${{ github.run_id }} # dunno if this corresponds
        run: |
          export PYTHONPATH=$PWD
          python tools/print_test_stats.py --upload-to-s3 --compare-with-s3 test
