name: A TEST - 8 AMD GPU Integration Test

on:
  push:
    branches: [ main ]
  pull_request:
  schedule:
    # Runs every 6 hours
    - cron: '0 */6 * * *'
concurrency:
  group: unit-test${{ github.workflow }}-${{ github.ref == 'refs/heads/main' && github.run_number || github.ref }}
  cancel-in-progress: true

defaults:
  run:
    shell: bash -l -eo pipefail {0}

jobs:
  build-test:
    uses: pytorch/test-infra/.github/workflows/linux_job_v2.yml@main
    with:
      runner: linux.rocm.gpu.mi300.2
      gpu-arch-type: rocm
      gpu-arch-version: "6.3"
      upload-artifact: outputs
      script: |
        set -eux
        # The generic Linux job chooses to use base env, not the one setup by the image
        CONDA_ENV=$(conda env list --json | jq -r ".envs | .[-1]")
        conda activate "${CONDA_ENV}"
        pip config --user set global.progress_bar off
        python -m pip install --force-reinstall --pre torch --index-url https://download.pytorch.org/whl/nightly/cu126
        USE_CPP=0 python -m pip install --pre torchao --index-url https://download.pytorch.org/whl/nightly/cu126
        mkdir artifacts-to-be-uploaded
        python ./tests/integration_tests.py artifacts-to-be-uploaded --ngpu 2


  linux-jammy-rocm-py3_10-build:
    name: linux-jammy-rocm-py3.10-mi300
    uses: ./.github/workflows/_linux-build.yml
    with:
      runner_prefix: ""
      runner: "linux.rocm.gpu.mi300.2"
      build-environment: linux-jammy-rocm-py3.10-mi300
      docker-image-name: ci-image:pytorch-linux-jammy-rocm-n-py3
      test-matrix: |
        { include: [
          { config: "default", shard: 1, num_shards: 6, runner: "linux.rocm.gpu.mi300.2" },
        ]}
    secrets: inherit