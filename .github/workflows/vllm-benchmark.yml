name: vLLM Benchmark

on:
  # DEBUG, TO BE REMOVED BEFORE LANDING
  pull_request:
  workflow_dispatch:
    inputs:
      pytorch_branch:
        description: |
          PyTorch branch (main, nightly, or refs/pull/PR_NUMBER/head for pull request)
        required: true
        type: string
        default: main
      pytorch_commit:
        description: |
          PyTorch commit (optional, default to use the latest commit from the branch)
        required: false
        type: string
      models:
        description: |
          A comma-separated list of models from pytorch-integration-testing repo (optional, default to run everything)
        required: false
        type: string
        # DEBUG: TO BE REMOVED BEFORE LANDING
        default: 'facebook/opt-125m'
      runners:
        description: |
          A comma-separated list of runners from .github/scripts/generate_vllm_benchmark_matrix.py to run the benchmark (optional, default to run everything)
        required: true
        type: string
        default: h100,b200
  schedule:
    # Run daily at 5:15 AM PST
    - cron: '15 13 * * *'

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.sha }}-${{ github.event_name == 'workflow_dispatch' }}-${{ github.event_name == 'schedule' }}
  cancel-in-progress: true

jobs:
  set-parameters:
    if: ${{ !github.event.pull_request.head.repo.fork && github.repository_owner == 'pytorch' }}
    runs-on: linux.2xlarge
    outputs:
      benchmark_matrix: ${{ steps.set-parameters.outputs.benchmark_matrix }}
      build-docker-image: ${{ steps.calculate-docker-image.outputs.docker-image }}
      torch-cuda-arch-list: '8.0 8.9 9.0'
      build-environment: linux-jammy-cuda12.9-py3.12-gcc11
    steps:
      - uses: astral-sh/setup-uv@681c641aba71e4a1c380be3ab5e12ad51f415867 # v7.1.6
        with:
          python-version: 3.12
          activate-environment: true
          ignore-empty-workdir: true

      - name: Checkout pytorch-integration-testing repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          repository: pytorch/pytorch-integration-testing
          path: pytorch/pytorch-integration-testing
          ref: main

      - name: Set parameters
        working-directory: pytorch/pytorch-integration-testing
        id: set-parameters
        shell: bash
        env:
          # DEBUG: TO BE REMOVED BEFORE LANDING
          MODELS: ${{ inputs.models || 'facebook/opt-125m' }}
          # Only need CUDA for now, we can add ROCm later if needed
          RUNNERS: ${{ inputs.runners || 'h100,b200' }}
        run: |
          set -eux

          # The generated matrix is grouped by model and runner
          python .github/scripts/generate_vllm_benchmark_matrix.py \
            --benchmark-configs-dir vllm-benchmarks/benchmarks \
            --models "${MODELS}" \
            --runners "${RUNNERS}"

      - name: Checkout PyTorch
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          path: pytorch/pytorch
          ref: ${{ inputs.pytorch_commit || inputs.pytorch_branch }}
          show-progress: false

      - name: Calculate docker image
        id: calculate-docker-image
        uses: pytorch/test-infra/.github/actions/calculate-docker-image@main
        with:
          working-directory: pytorch/pytorch
          docker-image-name: ci-image:pytorch-linux-jammy-cuda12.9-cudnn9-py3.12-gcc11-vllm

  # TODO (huydhn): Move this to a generic GHA, also this only works for CUDA in
  # the current state. I intentionally don't use _linux-build here as we'll need
  # to refactor it in the new world of open source developer cloud ARC runner.
  # And this serves as an early example using GHA container directive
  build:
    name: Build PyTorch and vLLM
    needs:
      - set-parameters
    # TODO: TURN IT OFF BY DEFAULT WHEN BRANCH IS NOT SET
    # if: ${{ inputs.pytorch_commit != '' || inputs.pytorch_branch != '' }}
    runs-on: linux.24xlarge.memory
    container:
      image: ${{ needs.set-parameters.outputs.build-docker-image }}
      options: --ipc=host --tty
      # The env inside and outside the container are different
      env:
        SKIP_SCCACHE_INITIALIZATION: 1
        SCCACHE_BUCKET: ossci-compiler-cache-circleci-v2
        SCCACHE_REGION: us-east-1
        TORCH_CUDA_ARCH_LIST: ${{ needs.set-parameters.outputs.torch-cuda-arch-list }}
        BUILD_ENVIRONMENT: ${{ needs.set-parameters.outputs.build-environment }}
        RUNNER: linux.24xlarge.memory
    steps:
      - name: Install system dependencies
        shell: bash
        run: |
          set -eux
          apt-get update
          apt-get install -y git zip unzip

      - name: Checkout PyTorch
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          ref: ${{ inputs.pytorch_commit || inputs.pytorch_branch }}
          submodules: recursive
          show-progress: false

      - name: Get vLLM pinned commit
        id: vllm-pinned-commit
        run: |
          VLLM_PINNED_COMMIT=$(cat .github/ci_commit_pins/vllm.txt)
          echo "commit=${VLLM_PINNED_COMMIT}" >> "${GITHUB_OUTPUT}"

      - name: Build PyTorch
        shell: bash
        env:
          BUILD_ADDITIONAL_PACKAGES: 'vision audio'
        run: |
          set -eux
          bash .ci/pytorch/build.sh

      - name: Checkout vLLM
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          repository: vllm-project/vllm
          path: vllm-project/vllm
          ref: ${{ steps.vllm-pinned-commit.outputs.commit }}
          submodules: recursive
          show-progress: false

      # TODO (huydhn): Lumen CLI won't work inside the container, need to revisit
      # the approach later. So, this is the bare minimum to build vLLM wheel
      - name: Build vLLM
        working-directory: vllm-project/vllm
        shell: bash
        run: |
          set -eux

          python use_existing_torch.py
          pip install -r requirements/build.txt

          sccache --show-stats
          python setup.py bdist_wheel --dist-dir=dist --py-limited-api=cp38
          sccache --show-stats

      - name: Copy vLLM wheel
        run: |
          mkdir -p dist/vllm
          mv vllm-project/vllm/dist dist/vllm

      - name: Archive artifacts into zip
        run: |
          zip -1 -r artifacts.zip dist/

      - name: Store the build artifacts on S3
        uses: seemethere/upload-artifact-s3@baba72d0712b404f646cebe0730933554ebce96a # v5.1.0
        with:
          name: ${{ needs.set-parameters.outputs.build-environment }}
          retention-days: 14
          if-no-files-found: error
          path: artifacts.zip
          s3-bucket: gha-artifacts

  benchmarks:
    name: Run vLLM benchmarks
    needs:
      - set-parameters
      - build
    # if: always()
    strategy:
      matrix: ${{ fromJson(needs.set-parameters.outputs.benchmark_matrix) }}
      fail-fast: false
    runs-on: ${{ matrix.runner }}
    permissions:
      id-token: write
      contents: read
    container:
      image: nvidia/cuda:12.9.1-cudnn-devel-ubuntu22.04
      options: --gpus all --ipc=host --tty
    steps:
      - name: Install system dependencies
        shell: bash
        run: |
          set -eux
          apt-get update
          apt-get install -y git zip unzip

      - name: Checkout PyTorch
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          ref: ${{ inputs.pytorch_commit || inputs.pytorch_branch }}
          submodules: recursive
          show-progress: false

      - uses: astral-sh/setup-uv@681c641aba71e4a1c380be3ab5e12ad51f415867 # v7.1.6
        with:
          python-version: 3.12
          activate-environment: true

      - name: Install benchmark dependencies
        shell: bash
        run: |
          set -eux
          uv pip install pip

      - name: Get vLLM pinned commit
        id: vllm-pinned-commit
        run: |
          VLLM_PINNED_COMMIT=$(cat .github/ci_commit_pins/vllm.txt)
          echo "commit=${VLLM_PINNED_COMMIT}" >> "${GITHUB_OUTPUT}"

      - name: Checkout vLLM
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          repository: vllm-project/vllm
          path: vllm-project/vllm
          ref: ${{ steps.vllm-pinned-commit.outputs.commit }}
          submodules: recursive
          show-progress: false

      #- name: Install nightly
      #  if: inputs.pytorch_commit == '' && inputs.pytorch_branch == ''
      #  shell: bash
      #  run: |
      #    uv pip install vllm --pre --extra-index-url https://download.pytorch.org/whl/nightly/cu129

      - name: Authenticate with AWS
        if: ${{ always() && contains(matrix.runner, 'b200') }}
        uses: aws-actions/configure-aws-credentials@ececac1a45f3b08a01d2dd070d28d111c5fe6722 # v4.1.0
        with:
          role-to-assume: arn:aws:iam::308535385114:role/gha_workflow_upload-benchmark-results
          # The max duration enforced by the server side
          role-duration-seconds: 18000
          aws-region: us-east-1

      - name: Download build artifacts
        # if: inputs.pytorch_commit != '' || inputs.pytorch_branch != ''
        uses: ./.github/actions/download-build-artifacts
        with:
          name: ${{ needs.set-parameters.outputs.build-environment }}
          s3-bucket: gha-artifacts

      - name: Install build artifacts
        # if: inputs.pytorch_commit != '' || inputs.pytorch_branch != ''
        shell: bash
        run: |
          set -eux

          # DEBUG
          ls -laR dist

          uv pip install \
            dist/torch-*.whl \
            dist/vision/torchvision-*.whl \
            dist/audio/torchaudio-*.whl \
            dist/vllm/vllm-*.whl \
            --extra-index-url https://download.pytorch.org/whl/cu129

      - name: DEBUG
        run: |
          uv pip list

      - name: Gather benchmark metadata
        id: gather-benchmark-metadata
        uses: pytorch/test-infra/.github/actions/gather-benchmark-metadata@main
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}

      - name: Gather runners info
        id: gather-runners-info
        uses: pytorch/test-infra/.github/actions/gather-runners-info@main

      - name: Gather dependencies
        id: gather-dependencies
        uses: pytorch/test-infra/.github/actions/gather-dependencies@main
