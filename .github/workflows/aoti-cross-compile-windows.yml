name: aoti-cross-compile-windows

on:
  push:
    tags:
      - ciflow/inductor/*
  workflow_dispatch:
  schedule:
    # Run every 12 hours
    - cron: 30 2,14 * * *

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}
  cancel-in-progress: true

permissions:
  id-token: write
  contents: read

jobs:
  get-default-label-prefix:
    name: get-default-label-prefix
    uses: pytorch/pytorch/.github/workflows/_runner-determinator.yml@main
    if: ${{ (github.event_name != 'schedule' || github.repository == 'pytorch/pytorch') && github.repository_owner == 'pytorch' }}
    with:
      triggering_actor: ${{ github.triggering_actor }}
      issue_owner: ${{ github.event.pull_request.user.login || github.event.issue.user.login }}
      curr_branch: ${{ github.head_ref || github.ref_name }}
      curr_ref_type: ${{ github.ref_type }}
      opt_out_experiments: lf

  # Step 1: Cross-compile models on Linux
  cross-compile-linux-build:
    name: cross-compile-linux-build
    uses: ./.github/workflows/_linux-build.yml
    needs: get-default-label-prefix
    with:
      build-environment: linux-jammy-cuda12.8-py3.10-gcc9-sm86
      docker-image-name: ci-image:pytorch-linux-jammy-cuda12.8-cudnn9-py3-gcc9-inductor-benchmarks
      cuda-arch-list: '8.6'
      runner_prefix: "${{ needs.get-default-label-prefix.outputs.label-type }}"
      test-matrix: |
        { include: [
          { config: "aoti_cross_compile", shard: 1, num_shards: 1, runner: "linux.g5.4xlarge.nvidia.gpu" },
        ]}
    secrets: inherit

  # Step 2: Use Windows build from trunk
  win-vs2022-cuda12_8-py3-build:
    name: win-vs2022-cuda12.8-py3
    uses: ./.github/workflows/_win-build.yml
    needs: get-default-label-prefix
    with:
      build-environment: win-vs2022-cuda12.8-py3
      cuda-version: "12.8"
      runner: "${{ needs.get-default-label-prefix.outputs.label-type }}windows.4xlarge.nonephemeral"
      upload-win-torch-libs-for-cross-compile: true
    secrets: inherit

  # Custom test job for cross-compilation
  cross-compile-linux-test:
    name: cross-compile-linux-test
    uses: ./.github/workflows/_linux-test.yml
    needs:
      - cross-compile-linux-build
      - get-default-label-prefix
      - win-vs2022-cuda12_8-py3-build
    with:
      build-environment: linux-jammy-cuda12.8-py3.10-gcc9-sm86
      docker-image: ${{ needs.cross-compile-linux-build.outputs.docker-image }}
      test-matrix: |
        { include: [
          { config: "aoti_cross_compile_for_windows", shard: 1, num_shards: 1, runner: "${{ needs.get-default-label-prefix.outputs.label-type }}linux.g5.4xlarge.nvidia.gpu", win_torch_libs_artifact: "win-vs2022-cuda12.8-py3-win-torch-libs" },
        ]}
    secrets: inherit

  # TODO: Test compiled packages on Windows
