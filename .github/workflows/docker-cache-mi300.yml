name: docker-cache-mi300

on:
  # TEMPORARY TO TRIGGER WORKFLOW ON PR
  pull_request:
  # run every 6 hours
  schedule:
    - cron: 0 0,6,12,18 * * *
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}
  cancel-in-progress: true

permissions:
  id-token: write
  contents: read

jobs:
  docker-cache:
    runs-on: rocm-docker
    steps:
      - name: Checkout PyTorch
        uses: pytorch/pytorch/.github/actions/checkout-pytorch@main
        with:
          no-sudo: true

      - name: configure aws credentials
        id: aws_creds
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::308535385114:role/gha_workflow_s3_and_ecr_read_only
          aws-region: us-east-1
          role-duration-seconds: 18000

      - name: Login to Amazon ECR
        id: login-ecr
        continue-on-error: false
        uses: aws-actions/amazon-ecr-login@v2

      - name: Calculate docker image
        id: calculate-docker-image
        uses: pytorch/test-infra/.github/actions/calculate-docker-image@main
        with:
          docker-image-name: pytorch-linux-focal-rocm-n-py3
          push: false

      - name: Pull docker image
        uses: pytorch/test-infra/.github/actions/pull-docker-image@main
        with:
          docker-image: ${{ steps.calculate-docker-image.outputs.docker-image }}

      - name: Tar and upload to S3 bucket
        run: |
          sudo docker save -o docker-data/pytorch/pytorch_docker_image.tar ${{ steps.calculate-docker-image.outputs.docker-image }}
          sudo rclone copy -P --s3-upload-concurrency 64 --s3-chunk-size 200M --s3-upload-cutoff 300M docker-data/pytorch/pytorch_docker_image.tar oci:pytorchbucket0002 --progress
