name: Download PyTest cache

description: Downloads the pytest cache to S3

inputs:
  cache_dir:
    description: Path to the pytest cache directory, relative to $GITHUB_WORKSPACE. This is where the merged cache will be placed.
    required: true
  job_identifier:
    description: Text that uniquely identifies a given job type within a workflow. All shards of a job should share the same job identifier.
    required: true
  s3_bucket:
    description: S3 bucket to download PyTest cache
    required: false
    default: "gha-artifacts"

runs:
  using: composite
  steps:
    - name: Setup uv
      uses: astral-sh/setup-uv@f0ec1fc3b38f5e7cd731bb6ce540c5af426746bb # v6.1.0
      with:
        python-version: 3.12

    - uses: nick-fields/retry@v3.0.0
      name: Setup dependencies
      with:
        shell: bash
        timeout_minutes: 5
        max_attempts: 5
        retry_wait_seconds: 30
        command: |
          set -eu
          # Pre-fetch dependencies to cache them for later uv run calls
          uv run --no-project --with boto3==1.35.42 python -c "import boto3; print('Dependencies ready')"

    - name: Download the cache
      shell: bash
      env:
        CACHE_DIR: ${{ inputs.cache_dir }}
        JOB_IDENTIFIER: ${{ inputs.job_identifier }}
        REPO: ${{ github.repository }}
        BUCKET: ${{ inputs.s3_bucket }}
      run: |
        uv run --no-project --with boto3==1.35.42 python .github/scripts/pytest_cache.py \
          --download \
          --cache_dir "$GITHUB_WORKSPACE/$CACHE_DIR" \
          --pr_identifier "$GITHUB_REF" \
          --job_identifier "$JOB_IDENTIFIER" \
          --temp_dir "$RUNNER_TEMP" \
          --repo "$REPO" \
          --bucket "$BUCKET"
