[
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M1_N1_K1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.81
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M1_N1_K1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M1_N1_K1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006629411832232129
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        54.159
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        58.08355178927329
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K128_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        54.596
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K128_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K128_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        115.2375107450138
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M1_N1_K1_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        39.169
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M1_N1_K1_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M1_N1_K1_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0003063685354039044
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M1_N1_K1_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        38.997
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M1_N1_K1_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M1_N1_K1_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00030771795331966143
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M1_N1_K1_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        39.124
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M1_N1_K1_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M1_N1_K1_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00030671377279062773
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K64_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        217.894
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K64_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K64_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        14.43693411895853
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K64_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        219.386
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K64_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K64_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        14.338762919028685
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K64_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        219.521
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K64_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K64_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        14.329965018238239
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K128_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        243.932
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K128_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K128_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        25.791831733435863
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K128_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        243.525
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K128_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K128_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        25.83497464488859
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K128_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        244.912
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K128_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K128_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        25.688631842458523
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "start: 0, end: 1000, step: 2.5, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "arange"
      }
    },
    "model": {
      "name": "arange_start0_end1000_step2.5_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "arange"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.468
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "start: 0, end: 1000, step: 2.5, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "arange"
      }
    },
    "model": {
      "name": "arange_start0_end1000_step2.5_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "arange"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "start: 0, end: 1000, step: 2.5, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "arange"
      }
    },
    "model": {
      "name": "arange_start0_end1000_step2.5_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "arange"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        null
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "start: -1024, end: 2048, step: 1, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "arange"
      }
    },
    "model": {
      "name": "arange_start-1024_end2048_step1_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "arange"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.125
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "start: -1024, end: 2048, step: 1, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "arange"
      }
    },
    "model": {
      "name": "arange_start-1024_end2048_step1_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "arange"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "start: -1024, end: 2048, step: 1, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "arange"
      }
    },
    "model": {
      "name": "arange_start-1024_end2048_step1_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "arange"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        null
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 8, N: 8, size: (2, 2), stride: (1, 1), storage_offset: 0, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "as"
      }
    },
    "model": {
      "name": "as_strided_M8_N8_size(2,2)_stride(1,1)_storage_offset0_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "as"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.764
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 8, N: 8, size: (2, 2), stride: (1, 1), storage_offset: 0, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "as"
      }
    },
    "model": {
      "name": "as_strided_M8_N8_size(2,2)_stride(1,1)_storage_offset0_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "as"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 8, N: 8, size: (2, 2), stride: (1, 1), storage_offset: 0, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "as"
      }
    },
    "model": {
      "name": "as_strided_M8_N8_size(2,2)_stride(1,1)_storage_offset0_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "as"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.2902636904992428
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 256, N: 256, size: (32, 32), stride: (1, 1), storage_offset: 0, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "as"
      }
    },
    "model": {
      "name": "as_strided_M256_N256_size(32,32)_stride(1,1)_storage_offset0_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "as"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.764
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 256, N: 256, size: (32, 32), stride: (1, 1), storage_offset: 0, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "as"
      }
    },
    "model": {
      "name": "as_strided_M256_N256_size(32,32)_stride(1,1)_storage_offset0_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "as"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 256, N: 256, size: (32, 32), stride: (1, 1), storage_offset: 0, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "as"
      }
    },
    "model": {
      "name": "as_strided_M256_N256_size(32,32)_stride(1,1)_storage_offset0_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "as"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        297.2469084837732
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, size: (64, 64), stride: (2, 2), storage_offset: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "as"
      }
    },
    "model": {
      "name": "as_strided_M512_N512_size(64,64)_stride(2,2)_storage_offset1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "as"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.767
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, size: (64, 64), stride: (2, 2), storage_offset: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "as"
      }
    },
    "model": {
      "name": "as_strided_M512_N512_size(64,64)_stride(2,2)_storage_offset1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "as"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, size: (64, 64), stride: (2, 2), storage_offset: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "as"
      }
    },
    "model": {
      "name": "as_strided_M512_N512_size(64,64)_stride(2,2)_storage_offset1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "as"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1186.6254039490218
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 256, K: 3136, device: cpu, training: True, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_M1_N256_K3136_cpu_trainingTrue_cudnnFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        324.232
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 256, K: 3136, device: cpu, training: True, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_M1_N256_K3136_cpu_trainingTrue_cudnnFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 256, K: 3136, device: cpu, training: True, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_M1_N256_K3136_cpu_trainingTrue_cudnnFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        19.82105490591947
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 256, K: 3136, device: cpu, training: False, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_M1_N256_K3136_cpu_trainingFalse_cudnnFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        89.386
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 256, K: 3136, device: cpu, training: False, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_M1_N256_K3136_cpu_trainingFalse_cudnnFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 256, K: 3136, device: cpu, training: False, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_M1_N256_K3136_cpu_trainingFalse_cudnnFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        71.89770595083952
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 256, K: 3136, device: cpu, training: True, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_M1_N256_K3136_cpu_trainingTrue_cudnnFalse_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        320.047
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 256, K: 3136, device: cpu, training: True, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_M1_N256_K3136_cpu_trainingTrue_cudnnFalse_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 256, K: 3136, device: cpu, training: True, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_M1_N256_K3136_cpu_trainingTrue_cudnnFalse_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        20.080261771381927
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 256, K: 3136, device: cpu, training: True, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_M1_N256_K3136_cpu_trainingTrue_cudnnFalse_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        317.767
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 256, K: 3136, device: cpu, training: True, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_M1_N256_K3136_cpu_trainingTrue_cudnnFalse_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 256, K: 3136, device: cpu, training: True, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_M1_N256_K3136_cpu_trainingTrue_cudnnFalse_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        20.22433719618258
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 256, K: 3136, device: cpu, training: False, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_M1_N256_K3136_cpu_trainingFalse_cudnnFalse_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        309.222
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 256, K: 3136, device: cpu, training: False, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_M1_N256_K3136_cpu_trainingFalse_cudnnFalse_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 256, K: 3136, device: cpu, training: False, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_M1_N256_K3136_cpu_trainingFalse_cudnnFalse_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        20.78317111434188
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 256, K: 3136, device: cpu, training: False, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_M1_N256_K3136_cpu_trainingFalse_cudnnFalse_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        308.115
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 256, K: 3136, device: cpu, training: False, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_M1_N256_K3136_cpu_trainingFalse_cudnnFalse_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 256, K: 3136, device: cpu, training: False, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_M1_N256_K3136_cpu_trainingFalse_cudnnFalse_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        20.857873193897806
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 3136, C: 256, device: cpu, training: True, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_N3136_C256_cpu_trainingTrue_cudnnFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.664
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 3136, C: 256, device: cpu, training: True, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_N3136_C256_cpu_trainingTrue_cudnnFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 3136, C: 256, device: cpu, training: True, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_N3136_C256_cpu_trainingTrue_cudnnFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        18.379447426130913
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 3136, C: 256, device: cpu, training: False, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_N3136_C256_cpu_trainingFalse_cudnnFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.346
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 3136, C: 256, device: cpu, training: False, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_N3136_C256_cpu_trainingFalse_cudnnFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 3136, C: 256, device: cpu, training: False, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_N3136_C256_cpu_trainingFalse_cudnnFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        58.240649977401276
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 3136, C: 256, device: cpu, training: True, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_N3136_C256_cpu_trainingTrue_cudnnFalse_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        473.657
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 3136, C: 256, device: cpu, training: True, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_N3136_C256_cpu_trainingTrue_cudnnFalse_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 3136, C: 256, device: cpu, training: True, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_N3136_C256_cpu_trainingTrue_cudnnFalse_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        13.568086379015678
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 3136, C: 256, device: cpu, training: True, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_N3136_C256_cpu_trainingTrue_cudnnFalse_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        471.224
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 3136, C: 256, device: cpu, training: True, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_N3136_C256_cpu_trainingTrue_cudnnFalse_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 3136, C: 256, device: cpu, training: True, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_N3136_C256_cpu_trainingTrue_cudnnFalse_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        13.63815074969864
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 3136, C: 256, device: cpu, training: False, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_N3136_C256_cpu_trainingFalse_cudnnFalse_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        426.553
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 3136, C: 256, device: cpu, training: False, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_N3136_C256_cpu_trainingFalse_cudnnFalse_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 3136, C: 256, device: cpu, training: False, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_N3136_C256_cpu_trainingFalse_cudnnFalse_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        15.066412925837446
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 3136, C: 256, device: cpu, training: False, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_N3136_C256_cpu_trainingFalse_cudnnFalse_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        427.713
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 3136, C: 256, device: cpu, training: False, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_N3136_C256_cpu_trainingFalse_cudnnFalse_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 3136, C: 256, device: cpu, training: False, cudnn: False",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "batchnorm"
      }
    },
    "model": {
      "name": "batchnorm_N3136_C256_cpu_trainingFalse_cudnnFalse_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "batchnorm"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        15.02556160022316
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add__M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.726
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add__M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add__M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006951150024217201
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add__M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        53.047
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add__M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add__M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        59.300448225193335
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add__M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        56.527
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add__M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add__M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        111.30005530650843
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub__M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.733
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub__M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub__M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006923837806023619
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub__M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        53.311
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub__M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub__M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        59.00666095550706
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub__M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        56.902
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub__M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub__M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        110.56579126286948
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul__M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.727
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul__M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul__M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006949273470531261
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul__M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        52.427
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul__M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul__M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        60.002163547805324
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul__M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        56.648
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul__M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul__M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        111.06307643821775
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "copy"
      }
    },
    "model": {
      "name": "copy__M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "copy"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.52
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "copy"
      }
    },
    "model": {
      "name": "copy__M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "copy"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "copy"
      }
    },
    "model": {
      "name": "copy__M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "copy"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.007895136093200989
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "copy"
      }
    },
    "model": {
      "name": "copy__M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "copy"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        47.15
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "copy"
      }
    },
    "model": {
      "name": "copy__M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "copy"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "copy"
      }
    },
    "model": {
      "name": "copy__M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "copy"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        66.71686992033182
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "copy"
      }
    },
    "model": {
      "name": "copy__M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "copy"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        47.588
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "copy"
      }
    },
    "model": {
      "name": "copy__M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "copy"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "copy"
      }
    },
    "model": {
      "name": "copy__M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "copy"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        132.2056101732962
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.float32, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div__M1_N1_K1_cpu_dtype_onetorch.float32_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.751
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.float32, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div__M1_N1_K1_cpu_dtype_onetorch.float32_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.float32, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div__M1_N1_K1_cpu_dtype_onetorch.float32_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006854791514468579
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.float32, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div__M64_N64_K64_cpu_dtype_onetorch.float32_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        59.248
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.float32, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div__M64_N64_K64_cpu_dtype_onetorch.float32_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.float32, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div__M64_N64_K64_cpu_dtype_onetorch.float32_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        53.094588440857855
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div__M64_N64_K128_cpu_dtype_onetorch.float32_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        59.533
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div__M64_N64_K128_cpu_dtype_onetorch.float32_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div__M64_N64_K128_cpu_dtype_onetorch.float32_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        105.68059201368878
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        53.417
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.6182267950994266
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        81.957
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.20147191606861536
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        57.656
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.1455602861311303
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        54.313
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.6080278242141868
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        82.541
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.20004717369910283
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        57.479
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.1490855847118702
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        56.206
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.5875505259679029
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        66.832
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.24706828055785948
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        80.451
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.8209720008408421
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        52.643
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.6273226421796329
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        64.655
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.2553879042373551
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        55.231
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.1958543516682834
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.826
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006572367379717735
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.976
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.003024185450629021
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.969
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0020206370832422
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.816
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0016521464532634508
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        54.21
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        58.028539560445765
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.333
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        23.514579293677745
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.846
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        15.596629476226141
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        50.322
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        15.628096652397454
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        54.813
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        114.77939187648671
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.174
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        46.181808281163285
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.221
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        30.77390013203528
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        49.471
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        31.79395332531052
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.857
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006463651753234356
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.017
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002983137118236842
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.046
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00196952811705315
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.854
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00161838359167798
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        54.638
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        57.57351403999148
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.121
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        23.564523143605268
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.148
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        15.705426324674557
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        49.773
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        15.800394330713438
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        54.959
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        114.47557551501171
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.969
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        46.27483898942752
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.005
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        30.838810628312668
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        50.221
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sub"
      }
    },
    "model": {
      "name": "sub_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sub"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        31.318635922054977
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.886
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0030882565822201546
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.95
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002278209089744641
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.997
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0015010282040617278
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.863
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.000776643011545632
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        153.433
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        20.5022589996177
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        153.077
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        15.412468870403979
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        155.064
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.143309795001812
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        153.698
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.116720949035452
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        156.2
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        40.27817249397464
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        154.719
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        30.497841047984615
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        156.892
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        20.050278859868286
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        154.705
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "div"
      }
    },
    "model": {
      "name": "div_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "div"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.166859224423586
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.827
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006568609289718411
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.971
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.003029674079676625
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.972
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002018889723294112
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.816
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0016520110911695833
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        52.295
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        60.1530571193641
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.022
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        23.354330703563516
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.154
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        15.70442042196961
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        46.963
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        16.745604763591395
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        53.522
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        117.54966063137776
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.123
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        46.662038801469365
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.428
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        31.014299859671873
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        46.47
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        33.84703965785891
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.931
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006215397647912735
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        5.137
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0017520951986216584
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        5.133
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0011688718291090253
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.943
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.001544274279984853
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        56.178
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        55.99575839051154
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.969
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        23.366436662796676
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.209
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        15.540729691870997
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        52.466
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        14.989472392073024
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        56.31
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        111.72883985548111
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.509
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        46.03087053021978
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.422
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        30.713523404829786
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        52.207
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asr"
      }
    },
    "model": {
      "name": "asr_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asr"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        30.1275222500117
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.95
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006153951940273812
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.852
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0018548659493929963
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.95
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0012121784921478355
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.942
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0015451796729300726
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        56.116
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        56.05762494964277
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.515
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        23.472141479305066
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.284
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        15.684071566320162
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        50.16
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        15.678601840196519
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        56.634
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        111.08957715967846
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.313
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        46.11898273555897
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.937
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        30.8594118049488
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        50.683
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lsl"
      }
    },
    "model": {
      "name": "lsl_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lsl"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        31.03314400816188
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.943
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006176306299202806
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        5.791
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M1_N1_K1_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.001554037872999806
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        6.113
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0009814734960641772
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.934
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M1_N1_K1_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0015514564738461855
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        55.809
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        56.36626152947507
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.603
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M64_N64_K64_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        23.220840533652165
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.375
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        15.515364251289967
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        47.7
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M64_N64_K64_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        16.4868749871563
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        56.23
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        111.88807308640735
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.099
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M64_N64_K128_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        46.2158105278409
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.638
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        30.648752115285298
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        47.616
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "xor"
      }
    },
    "model": {
      "name": "xor_M64_N64_K128_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "xor"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        33.032473119413034
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bool",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "logical"
      }
    },
    "model": {
      "name": "logical_and_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "logical"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        76.379
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bool",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "logical"
      }
    },
    "model": {
      "name": "logical_and_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "logical"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bool",
      "extra_info": {
        "input_config": "in_one: [64, 1, 64], in_two: [1, 64, 1], device: cpu, dtype: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "logical"
      }
    },
    "model": {
      "name": "logical_and_in_one[64,1,64]_in_two[1,64,1]_cpu_dtypetorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "logical"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.1080923970026901
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.bool, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "logical"
      }
    },
    "model": {
      "name": "logical_and_M1_N1_K1_cpu_dtype_onetorch.bool_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "logical"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.122
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.bool, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "logical"
      }
    },
    "model": {
      "name": "logical_and_M1_N1_K1_cpu_dtype_onetorch.bool_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "logical"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype_one: torch.bool, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "logical"
      }
    },
    "model": {
      "name": "logical_and_M1_N1_K1_cpu_dtype_onetorch.bool_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "logical"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0014138342059641302
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.bool, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "logical"
      }
    },
    "model": {
      "name": "logical_and_M64_N64_K64_cpu_dtype_onetorch.bool_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "logical"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        52.275
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.bool, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "logical"
      }
    },
    "model": {
      "name": "logical_and_M64_N64_K64_cpu_dtype_onetorch.bool_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "logical"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype_one: torch.bool, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "logical"
      }
    },
    "model": {
      "name": "logical_and_M64_N64_K64_cpu_dtype_onetorch.bool_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "logical"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        15.044063285145329
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "logical"
      }
    },
    "model": {
      "name": "logical_and_M64_N64_K128_cpu_dtype_onetorch.bool_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "logical"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        51.375
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "logical"
      }
    },
    "model": {
      "name": "logical_and_M64_N64_K128_cpu_dtype_onetorch.bool_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "logical"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "logical"
      }
    },
    "model": {
      "name": "logical_and_M64_N64_K128_cpu_dtype_onetorch.bool_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "logical"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        30.615322281660696
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "B: 2, M: 1, N: 8, K: 2, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "bmm"
      }
    },
    "model": {
      "name": "bmm_B2_M1_N8_K2_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "bmm"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.731
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "B: 2, M: 1, N: 8, K: 2, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "bmm"
      }
    },
    "model": {
      "name": "bmm_B2_M1_N8_K2_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "bmm"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "B: 2, M: 1, N: 8, K: 2, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "bmm"
      }
    },
    "model": {
      "name": "bmm_B2_M1_N8_K2_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "bmm"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.12016661156671836
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "B: 2, M: 1, N: 8, K: 2, device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "bmm"
      }
    },
    "model": {
      "name": "bmm_B2_M1_N8_K2_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "bmm"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.767
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "B: 2, M: 1, N: 8, K: 2, device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "bmm"
      }
    },
    "model": {
      "name": "bmm_B2_M1_N8_K2_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "bmm"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "B: 2, M: 1, N: 8, K: 2, device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "bmm"
      }
    },
    "model": {
      "name": "bmm_B2_M1_N8_K2_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "bmm"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.05885508706549527
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "B: 128, M: 64, N: 32, K: 64, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "bmm"
      }
    },
    "model": {
      "name": "bmm_B128_M64_N32_K64_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "bmm"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        194.359
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "B: 128, M: 64, N: 32, K: 64, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "bmm"
      }
    },
    "model": {
      "name": "bmm_B128_M64_N32_K64_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "bmm"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "B: 128, M: 64, N: 32, K: 64, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "bmm"
      }
    },
    "model": {
      "name": "bmm_B128_M64_N32_K64_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "bmm"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        21.5801351091582
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "B: 128, M: 64, N: 32, K: 64, device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "bmm"
      }
    },
    "model": {
      "name": "bmm_B128_M64_N32_K64_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "bmm"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        206.732
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "B: 128, M: 64, N: 32, K: 64, device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "bmm"
      }
    },
    "model": {
      "name": "bmm_B128_M64_N32_K64_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "bmm"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "B: 128, M: 64, N: 32, K: 64, device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "bmm"
      }
    },
    "model": {
      "name": "bmm_B128_M64_N32_K64_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "bmm"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.144293246195806
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "B: 2, M: 1, N: 8, K: 2, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "baddbmm"
      }
    },
    "model": {
      "name": "baddbmm_B2_M1_N8_K2_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "baddbmm"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.489
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "B: 2, M: 1, N: 8, K: 2, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "baddbmm"
      }
    },
    "model": {
      "name": "baddbmm_B2_M1_N8_K2_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "baddbmm"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "B: 2, M: 1, N: 8, K: 2, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "baddbmm"
      }
    },
    "model": {
      "name": "baddbmm_B2_M1_N8_K2_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "baddbmm"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.08997840416853314
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "B: 2, M: 1, N: 8, K: 2, device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "baddbmm"
      }
    },
    "model": {
      "name": "baddbmm_B2_M1_N8_K2_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "baddbmm"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.458
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "B: 2, M: 1, N: 8, K: 2, device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "baddbmm"
      }
    },
    "model": {
      "name": "baddbmm_B2_M1_N8_K2_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "baddbmm"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "B: 2, M: 1, N: 8, K: 2, device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "baddbmm"
      }
    },
    "model": {
      "name": "baddbmm_B2_M1_N8_K2_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "baddbmm"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0455732534974899
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "B: 128, M: 64, N: 32, K: 64, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "baddbmm"
      }
    },
    "model": {
      "name": "baddbmm_B128_M64_N32_K64_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "baddbmm"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        257.687
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "B: 128, M: 64, N: 32, K: 64, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "baddbmm"
      }
    },
    "model": {
      "name": "baddbmm_B128_M64_N32_K64_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "baddbmm"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "B: 128, M: 64, N: 32, K: 64, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "baddbmm"
      }
    },
    "model": {
      "name": "baddbmm_B128_M64_N32_K64_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "baddbmm"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        24.415148045400304
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "B: 128, M: 64, N: 32, K: 64, device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "baddbmm"
      }
    },
    "model": {
      "name": "baddbmm_B128_M64_N32_K64_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "baddbmm"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        281.689
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "B: 128, M: 64, N: 32, K: 64, device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "baddbmm"
      }
    },
    "model": {
      "name": "baddbmm_B128_M64_N32_K64_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "baddbmm"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "B: 128, M: 64, N: 32, K: 64, device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "baddbmm"
      }
    },
    "model": {
      "name": "baddbmm_B128_M64_N32_K64_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "baddbmm"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        11.167395200708496
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "all"
      }
    },
    "model": {
      "name": "all_M1_N1_K1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "all"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.751
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "all"
      }
    },
    "model": {
      "name": "all_M1_N1_K1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "all"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "all"
      }
    },
    "model": {
      "name": "all_M1_N1_K1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "all"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0004209584698595188
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "all"
      }
    },
    "model": {
      "name": "all_M64_N64_K64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "all"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        68.111
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "all"
      }
    },
    "model": {
      "name": "all_M64_N64_K64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "all"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "all"
      }
    },
    "model": {
      "name": "all_M64_N64_K64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "all"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        7.69752808512297
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "all"
      }
    },
    "model": {
      "name": "all_M64_N64_K128_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "all"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        72.023
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "all"
      }
    },
    "model": {
      "name": "all_M64_N64_K128_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "all"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "all"
      }
    },
    "model": {
      "name": "all_M64_N64_K128_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "all"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        14.558996801289199
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (1, 1, 1), N: 2, dim: 0, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "cat"
      }
    },
    "model": {
      "name": "cat_sizes(1,1,1)_N2_dim0_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "cat"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.993
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (1, 1, 1), N: 2, dim: 0, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "cat"
      }
    },
    "model": {
      "name": "cat_sizes(1,1,1)_N2_dim0_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "cat"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (1, 1, 1), N: 2, dim: 0, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "cat"
      }
    },
    "model": {
      "name": "cat_sizes(1,1,1)_N2_dim0_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "cat"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.008029726376446937
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (512, 512, 2), N: 2, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "cat"
      }
    },
    "model": {
      "name": "cat_sizes(512,512,2)_N2_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "cat"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.276
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (512, 512, 2), N: 2, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "cat"
      }
    },
    "model": {
      "name": "cat_sizes(512,512,2)_N2_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "cat"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (512, 512, 2), N: 2, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "cat"
      }
    },
    "model": {
      "name": "cat_sizes(512,512,2)_N2_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "cat"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        80.44640731996297
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (128, 1024, 2), N: 2, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "cat"
      }
    },
    "model": {
      "name": "cat_sizes(128,1024,2)_N2_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "cat"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.327
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (128, 1024, 2), N: 2, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "cat"
      }
    },
    "model": {
      "name": "cat_sizes(128,1024,2)_N2_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "cat"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (128, 1024, 2), N: 2, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "cat"
      }
    },
    "model": {
      "name": "cat_sizes(128,1024,2)_N2_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "cat"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        41.393597427698985
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 2, channels_per_group: 16, height: 16, width: 16, groups: 2, channel_last: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size2_channels_per_group16_height16_width16_groups2_channel_lastTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        45.284
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 2, channels_per_group: 16, height: 16, width: 16, groups: 2, channel_last: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size2_channels_per_group16_height16_width16_groups2_channel_lastTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 2, channels_per_group: 16, height: 16, width: 16, groups: 2, channel_last: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size2_channels_per_group16_height16_width16_groups2_channel_lastTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.8944309380554487
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 2, channels_per_group: 16, height: 16, width: 16, groups: 2, channel_last: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size2_channels_per_group16_height16_width16_groups2_channel_lastFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        51.985
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 2, channels_per_group: 16, height: 16, width: 16, groups: 2, channel_last: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size2_channels_per_group16_height16_width16_groups2_channel_lastFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 2, channels_per_group: 16, height: 16, width: 16, groups: 2, channel_last: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size2_channels_per_group16_height16_width16_groups2_channel_lastFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.5213509629991595
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 2, channels_per_group: 32, height: 32, width: 32, groups: 2, channel_last: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size2_channels_per_group32_height32_width32_groups2_channel_lastTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        51.701
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 2, channels_per_group: 32, height: 32, width: 32, groups: 2, channel_last: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size2_channels_per_group32_height32_width32_groups2_channel_lastTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 2, channels_per_group: 32, height: 32, width: 32, groups: 2, channel_last: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size2_channels_per_group32_height32_width32_groups2_channel_lastTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        20.281588036510552
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 2, channels_per_group: 32, height: 32, width: 32, groups: 2, channel_last: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size2_channels_per_group32_height32_width32_groups2_channel_lastFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        48.565
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 2, channels_per_group: 32, height: 32, width: 32, groups: 2, channel_last: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size2_channels_per_group32_height32_width32_groups2_channel_lastFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 2, channels_per_group: 32, height: 32, width: 32, groups: 2, channel_last: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size2_channels_per_group32_height32_width32_groups2_channel_lastFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        21.591264871345246
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 4, channels_per_group: 32, height: 32, width: 32, groups: 4, channel_last: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size4_channels_per_group32_height32_width32_groups4_channel_lastTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        55.839
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 4, channels_per_group: 32, height: 32, width: 32, groups: 4, channel_last: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size4_channels_per_group32_height32_width32_groups4_channel_lastTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 4, channels_per_group: 32, height: 32, width: 32, groups: 4, channel_last: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size4_channels_per_group32_height32_width32_groups4_channel_lastTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        75.11395161821567
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 4, channels_per_group: 32, height: 32, width: 32, groups: 4, channel_last: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size4_channels_per_group32_height32_width32_groups4_channel_lastFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        54.745
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 4, channels_per_group: 32, height: 32, width: 32, groups: 4, channel_last: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size4_channels_per_group32_height32_width32_groups4_channel_lastFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 4, channels_per_group: 32, height: 32, width: 32, groups: 4, channel_last: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size4_channels_per_group32_height32_width32_groups4_channel_lastFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        76.61485260291248
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 4, channels_per_group: 64, height: 64, width: 64, groups: 4, channel_last: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size4_channels_per_group64_height64_width64_groups4_channel_lastTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        147.981
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 4, channels_per_group: 64, height: 64, width: 64, groups: 4, channel_last: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size4_channels_per_group64_height64_width64_groups4_channel_lastTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 4, channels_per_group: 64, height: 64, width: 64, groups: 4, channel_last: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size4_channels_per_group64_height64_width64_groups4_channel_lastTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        226.74818628913198
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 4, channels_per_group: 64, height: 64, width: 64, groups: 4, channel_last: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size4_channels_per_group64_height64_width64_groups4_channel_lastFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        149.998
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 4, channels_per_group: 64, height: 64, width: 64, groups: 4, channel_last: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size4_channels_per_group64_height64_width64_groups4_channel_lastFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 4, channels_per_group: 64, height: 64, width: 64, groups: 4, channel_last: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size4_channels_per_group64_height64_width64_groups4_channel_lastFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        223.69963733550495
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 8, channels_per_group: 64, height: 64, width: 64, groups: 8, channel_last: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size8_channels_per_group64_height64_width64_groups8_channel_lastTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        692.342
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 8, channels_per_group: 64, height: 64, width: 64, groups: 8, channel_last: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size8_channels_per_group64_height64_width64_groups8_channel_lastTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 8, channels_per_group: 64, height: 64, width: 64, groups: 8, channel_last: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size8_channels_per_group64_height64_width64_groups8_channel_lastTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        193.86058049678127
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 8, channels_per_group: 64, height: 64, width: 64, groups: 8, channel_last: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size8_channels_per_group64_height64_width64_groups8_channel_lastFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        595.055
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 8, channels_per_group: 64, height: 64, width: 64, groups: 8, channel_last: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size8_channels_per_group64_height64_width64_groups8_channel_lastFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 8, channels_per_group: 64, height: 64, width: 64, groups: 8, channel_last: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size8_channels_per_group64_height64_width64_groups8_channel_lastFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        225.55517517996057
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 16, channels_per_group: 64, height: 64, width: 64, groups: 16, channel_last: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size16_channels_per_group64_height64_width64_groups16_channel_lastTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3544.356
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 16, channels_per_group: 64, height: 64, width: 64, groups: 16, channel_last: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size16_channels_per_group64_height64_width64_groups16_channel_lastTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 16, channels_per_group: 64, height: 64, width: 64, groups: 16, channel_last: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size16_channels_per_group64_height64_width64_groups16_channel_lastTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        151.47205992460997
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 16, channels_per_group: 64, height: 64, width: 64, groups: 16, channel_last: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size16_channels_per_group64_height64_width64_groups16_channel_lastFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2332.607
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 16, channels_per_group: 64, height: 64, width: 64, groups: 16, channel_last: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size16_channels_per_group64_height64_width64_groups16_channel_lastFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "batch_size: 16, channels_per_group: 64, height: 64, width: 64, groups: 16, channel_last: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "channel"
      }
    },
    "model": {
      "name": "channel_shuffle_batch_size16_channels_per_group64_height64_width64_groups16_channel_lastFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "channel"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        230.15914980927482
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 8, N: 8, chunks: 2, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "chunk"
      }
    },
    "model": {
      "name": "chunk_M8_N8_chunks2_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "chunk"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.76
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 8, N: 8, chunks: 2, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "chunk"
      }
    },
    "model": {
      "name": "chunk_M8_N8_chunks2_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "chunk"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 8, N: 8, chunks: 2, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "chunk"
      }
    },
    "model": {
      "name": "chunk_M8_N8_chunks2_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "chunk"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.18552499250821666
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 256, N: 512, chunks: 2, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "chunk"
      }
    },
    "model": {
      "name": "chunk_M256_N512_chunks2_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "chunk"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.744
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 256, N: 512, chunks: 2, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "chunk"
      }
    },
    "model": {
      "name": "chunk_M256_N512_chunks2_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "chunk"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 256, N: 512, chunks: 2, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "chunk"
      }
    },
    "model": {
      "name": "chunk_M256_N512_chunks2_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "chunk"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        382.12862742210706
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, chunks: 2, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "chunk"
      }
    },
    "model": {
      "name": "chunk_M512_N512_chunks2_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "chunk"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.739
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, chunks: 2, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "chunk"
      }
    },
    "model": {
      "name": "chunk_M512_N512_chunks2_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "chunk"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, chunks: 2, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "chunk"
      }
    },
    "model": {
      "name": "chunk_M512_N512_chunks2_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "chunk"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        765.7969969636432
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 128, OC: 256, kernel: 3, stride: 1, N: 1, L: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Conv1d"
      }
    },
    "model": {
      "name": "Conv1d_IC128_OC256_kernel3_stride1_N1_L64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Conv1d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        161.538
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 128, OC: 256, kernel: 3, stride: 1, N: 1, L: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Conv1d"
      }
    },
    "model": {
      "name": "Conv1d_IC128_OC256_kernel3_stride1_N1_L64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Conv1d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 128, OC: 256, kernel: 3, stride: 1, N: 1, L: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Conv1d"
      }
    },
    "model": {
      "name": "Conv1d_IC128_OC256_kernel3_stride1_N1_L64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Conv1d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.030064228029941
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 256, OC: 256, kernel: 3, stride: 2, N: 4, L: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Conv1d"
      }
    },
    "model": {
      "name": "Conv1d_IC256_OC256_kernel3_stride2_N4_L64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Conv1d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        394.738
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 256, OC: 256, kernel: 3, stride: 2, N: 4, L: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Conv1d"
      }
    },
    "model": {
      "name": "Conv1d_IC256_OC256_kernel3_stride2_N4_L64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Conv1d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 256, OC: 256, kernel: 3, stride: 2, N: 4, L: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Conv1d"
      }
    },
    "model": {
      "name": "Conv1d_IC256_OC256_kernel3_stride2_N4_L64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Conv1d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.9780579978751787
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 2016, OC: 1026, kernel: 1024, stride: 256, N: 1, L: 224, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "ConvTranspose1d"
      }
    },
    "model": {
      "name": "ConvTranspose1d_IC2016_OC1026_kernel1024_stride256_N1_L224_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ConvTranspose1d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2400947.63
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 2016, OC: 1026, kernel: 1024, stride: 256, N: 1, L: 224, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "ConvTranspose1d"
      }
    },
    "model": {
      "name": "ConvTranspose1d_IC2016_OC1026_kernel1024_stride256_N1_L224_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ConvTranspose1d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 2016, OC: 1026, kernel: 1024, stride: 256, N: 1, L: 224, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "ConvTranspose1d"
      }
    },
    "model": {
      "name": "ConvTranspose1d_IC2016_OC1026_kernel1024_stride256_N1_L224_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ConvTranspose1d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.628787988742033
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 128, OC: 256, kernel: 3, stride: 1, N: 1, L: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "ConvTranspose1d"
      }
    },
    "model": {
      "name": "ConvTranspose1d_IC128_OC256_kernel3_stride1_N1_L64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ConvTranspose1d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        196.336
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 128, OC: 256, kernel: 3, stride: 1, N: 1, L: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "ConvTranspose1d"
      }
    },
    "model": {
      "name": "ConvTranspose1d_IC128_OC256_kernel3_stride1_N1_L64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ConvTranspose1d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 128, OC: 256, kernel: 3, stride: 1, N: 1, L: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "ConvTranspose1d"
      }
    },
    "model": {
      "name": "ConvTranspose1d_IC128_OC256_kernel3_stride1_N1_L64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ConvTranspose1d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.5138896505903032
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 256, OC: 256, kernel: 3, stride: 2, N: 4, L: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "ConvTranspose1d"
      }
    },
    "model": {
      "name": "ConvTranspose1d_IC256_OC256_kernel3_stride2_N4_L64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ConvTranspose1d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        799.859
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 256, OC: 256, kernel: 3, stride: 2, N: 4, L: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "ConvTranspose1d"
      }
    },
    "model": {
      "name": "ConvTranspose1d_IC256_OC256_kernel3_stride2_N4_L64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ConvTranspose1d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 256, OC: 256, kernel: 3, stride: 2, N: 4, L: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "ConvTranspose1d"
      }
    },
    "model": {
      "name": "ConvTranspose1d_IC256_OC256_kernel3_stride2_N4_L64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ConvTranspose1d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.9715486005975216
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 256, OC: 256, kernel: 3, stride: 1, N: 1, H: 16, W: 16, G: 1, pad: 0, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Conv2d"
      }
    },
    "model": {
      "name": "Conv2d_IC256_OC256_kernel3_stride1_N1_H16_W16_G1_pad0_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Conv2d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        841.087
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 256, OC: 256, kernel: 3, stride: 1, N: 1, H: 16, W: 16, G: 1, pad: 0, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Conv2d"
      }
    },
    "model": {
      "name": "Conv2d_IC256_OC256_kernel3_stride1_N1_H16_W16_G1_pad0_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Conv2d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 256, OC: 256, kernel: 3, stride: 1, N: 1, H: 16, W: 16, G: 1, pad: 0, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Conv2d"
      }
    },
    "model": {
      "name": "Conv2d_IC256_OC256_kernel3_stride1_N1_H16_W16_G1_pad0_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Conv2d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.355354477922
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 256, OC: 256, kernel: 3, stride: 1, N: 1, H: 16, W: 16, G: 1, pad: 0, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "ConvTranspose2d"
      }
    },
    "model": {
      "name": "ConvTranspose2d_IC256_OC256_kernel3_stride1_N1_H16_W16_G1_pad0_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ConvTranspose2d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1129.846
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 256, OC: 256, kernel: 3, stride: 1, N: 1, H: 16, W: 16, G: 1, pad: 0, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "ConvTranspose2d"
      }
    },
    "model": {
      "name": "ConvTranspose2d_IC256_OC256_kernel3_stride1_N1_H16_W16_G1_pad0_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ConvTranspose2d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 256, OC: 256, kernel: 3, stride: 1, N: 1, H: 16, W: 16, G: 1, pad: 0, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "ConvTranspose2d"
      }
    },
    "model": {
      "name": "ConvTranspose2d_IC256_OC256_kernel3_stride1_N1_H16_W16_G1_pad0_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ConvTranspose2d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.6138222040655386
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 256, OC: 256, stride: 1, N: 1, H: 16, W: 16, G: 1, pad: 0, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Conv2dPointwise"
      }
    },
    "model": {
      "name": "Conv2dPointwise_IC256_OC256_stride1_N1_H16_W16_G1_pad0_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Conv2dPointwise"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        365.839
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 256, OC: 256, stride: 1, N: 1, H: 16, W: 16, G: 1, pad: 0, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Conv2dPointwise"
      }
    },
    "model": {
      "name": "Conv2dPointwise_IC256_OC256_stride1_N1_H16_W16_G1_pad0_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Conv2dPointwise"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 256, OC: 256, stride: 1, N: 1, H: 16, W: 16, G: 1, pad: 0, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Conv2dPointwise"
      }
    },
    "model": {
      "name": "Conv2dPointwise_IC256_OC256_stride1_N1_H16_W16_G1_pad0_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Conv2dPointwise"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.1496677691538166
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 64, OC: 64, kernel: 3, stride: 1, N: 8, D: 4, H: 16, W: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Conv3d"
      }
    },
    "model": {
      "name": "Conv3d_IC64_OC64_kernel3_stride1_N8_D4_H16_W16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Conv3d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1984.695
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 64, OC: 64, kernel: 3, stride: 1, N: 8, D: 4, H: 16, W: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Conv3d"
      }
    },
    "model": {
      "name": "Conv3d_IC64_OC64_kernel3_stride1_N8_D4_H16_W16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Conv3d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 64, OC: 64, kernel: 3, stride: 1, N: 8, D: 4, H: 16, W: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Conv3d"
      }
    },
    "model": {
      "name": "Conv3d_IC64_OC64_kernel3_stride1_N8_D4_H16_W16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Conv3d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.6840555975321743
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 64, OC: 64, kernel: 3, stride: 1, N: 8, D: 4, H: 16, W: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "ConvTranspose3d"
      }
    },
    "model": {
      "name": "ConvTranspose3d_IC64_OC64_kernel3_stride1_N8_D4_H16_W16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ConvTranspose3d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4625.592
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 64, OC: 64, kernel: 3, stride: 1, N: 8, D: 4, H: 16, W: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "ConvTranspose3d"
      }
    },
    "model": {
      "name": "ConvTranspose3d_IC64_OC64_kernel3_stride1_N8_D4_H16_W16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ConvTranspose3d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 64, OC: 64, kernel: 3, stride: 1, N: 8, D: 4, H: 16, W: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "ConvTranspose3d"
      }
    },
    "model": {
      "name": "ConvTranspose3d_IC64_OC64_kernel3_stride1_N8_D4_H16_W16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ConvTranspose3d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.4097292220024022
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dim: 1, M: 64, N: 64, diagonal: 0, out: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "diag"
      }
    },
    "model": {
      "name": "diag_dim1_M64_N64_diagonal0_outTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "diag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.699
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dim: 1, M: 64, N: 64, diagonal: 0, out: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "diag"
      }
    },
    "model": {
      "name": "diag_dim1_M64_N64_diagonal0_outTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "diag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dim: 1, M: 64, N: 64, diagonal: 0, out: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "diag"
      }
    },
    "model": {
      "name": "diag_dim1_M64_N64_diagonal0_outTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "diag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.79622041695085
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dim: 2, M: 128, N: 128, diagonal: -10, out: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "diag"
      }
    },
    "model": {
      "name": "diag_dim2_M128_N128_diagonal-10_outFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "diag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        6.024
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dim: 2, M: 128, N: 128, diagonal: -10, out: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "diag"
      }
    },
    "model": {
      "name": "diag_dim2_M128_N128_diagonal-10_outFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "diag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dim: 2, M: 128, N: 128, diagonal: -10, out: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "diag"
      }
    },
    "model": {
      "name": "diag_dim2_M128_N128_diagonal-10_outFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "diag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        21.758117385826505
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dim: 1, M: 256, N: 256, diagonal: 20, out: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "diag"
      }
    },
    "model": {
      "name": "diag_dim1_M256_N256_diagonal20_outTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "diag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.934
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dim: 1, M: 256, N: 256, diagonal: 20, out: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "diag"
      }
    },
    "model": {
      "name": "diag_dim1_M256_N256_diagonal20_outTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "diag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dim: 1, M: 256, N: 256, diagonal: 20, out: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "diag"
      }
    },
    "model": {
      "name": "diag_dim1_M256_N256_diagonal20_outTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "diag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.9303272381551775
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        20.556
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.007005147312465101
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        71.826
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002004835918315394
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        20.476
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.007032623076390026
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        70.53
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002041678889545149
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        20.825
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.013061021404765236
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        69.192
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0039310770102976905
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.201
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012829725317943179
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        69.184
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.003931549980335451
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        23.192
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.044842115803392535
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        75.608
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.013755067676077442
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        22.45
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.04632618235761796
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        76.522
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.013590950896631926
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        20.632
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006979567344052249
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        72.705
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0019805944382876874
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        20.767
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006934104816879244
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        73.701
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0019538287134772915
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.036
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012930130016782228
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        70.609
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0038522088735643873
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        20.855
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.013042222334903724
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        69.918
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0038902932042326186
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        22.927
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.045362056820923875
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.001
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.013506281045673947
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        22.539
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.04614210478855386
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.028
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.013501614561905753
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        20.786
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006927667423218124
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        74.124
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0019426790476837113
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        20.825
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006914624532114233
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        74.086
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0019436844817738975
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.007
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012947878385829444
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        68.414
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.003975778737365717
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.001
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012951810889614557
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        68.655
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.003961818682515994
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        22.959
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.04529856573017449
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.093
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.013490173900016451
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        22.921
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.04537342533350657
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.407
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.013435494876999675
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        20.662
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006969247665395087
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        74.705
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0019275923928845488
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        20.49
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.007027724851243855
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        74.98
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0019205063254885254
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        20.983
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012963054639290705
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        70.724
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0038459484492891316
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        20.845
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.013048442831255409
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        69.976
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.003887067835614735
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        23.312
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.04461210049247004
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.903
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.013349864380540892
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        22.777
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.04566056841541821
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.198
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.013471776399725053
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        70.609
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00203939291893512
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        70.538
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0020414592733653397
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        62.531
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002302869360229976
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        62.982
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0022863848565360845
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        71.687
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.003794267360693448
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        71.665
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0037954486221981297
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        63.397
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.004290410608681925
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        63.514
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.004282488804382888
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.27
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.01345924954001961
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.255
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.013461930119717047
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        67.025
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.015516667157178973
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        66.889
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.015548049302905041
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        70.325
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0020476268450351147
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        70.712
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0020364339691873777
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        65.182
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002209183816116863
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        65.383
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002202419456470563
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        71.595
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.003799149950237595
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        71.601
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.003798851146054128
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        65.927
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.004125792740112617
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        66.14
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0041124998428701135
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.174
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.013476008897078116
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.518
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.013416279481101256
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        69.76
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.014908286624580417
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        69.783
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.014903321096957401
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        70.568
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0020405750242774904
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        70.911
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002030704821008523
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        175.708
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0008195415113252452
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        177.611
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0008107622887594336
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        71.988
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0037784297537082298
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        71.687
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0037942711318502717
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        176.793
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.001538521698151791
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        178.177
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0015265759616701396
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.228
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.013466634018527412
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.352
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.013444986383791525
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        180.169
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0057723717912467245
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        179.794
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.005784382417754359
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        70.517
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0020420681007457682
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        70.518
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0020420193337758303
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        176.878
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0008141182097291958
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        177.17
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.000812777869976961
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        71.589
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0037994764823625904
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        71.992
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0037781806525260136
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        177.842
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.001529447986972611
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        177.249
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0015345672052896775
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.611
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.013400143139980437
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.36
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.013443568603042478
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        182.658
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.005693691580993502
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        182.37
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embeddingbag"
      }
    },
    "model": {
      "name": "embeddingbag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.005702704367700059
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings10_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.356
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings10_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings10_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.011271895462594092
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings10_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.39
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings10_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings10_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.022476024978893606
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings10_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.787
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings10_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings10_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.08687568787137502
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings120_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.228
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings120_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings120_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.011400294388390133
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings120_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.363
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings120_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings120_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.022528276844374553
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings120_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.863
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings120_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings120_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0863213713462104
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings1000_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.378
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings1000_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings1000_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.011249650508450587
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings1000_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.394
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings1000_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings1000_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.02246831977540788
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings1000_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.942
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings1000_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings1000_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.08574464778512751
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings2300_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.426
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings2300_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings2300_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.011202932368960583
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings2300_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.379
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings2300_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings2300_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.022496929911875806
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings2300_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.948
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings2300_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings2300_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.08570258201486279
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings10_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        51.057
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings10_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings10_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002507011729573113
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings10_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        51.677
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings10_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings10_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.004953849063470178
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings10_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        56.521
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings10_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings10_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.018117169609625994
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings120_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        52.742
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings120_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings120_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002426897072735971
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings120_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        54.165
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings120_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings120_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.004726260877872355
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings120_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        58.486
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings120_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings120_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.017508314211805397
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings1000_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        157.892
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings1000_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings1000_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0008106829150324286
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings1000_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        158.475
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings1000_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings1000_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.001615397871554085
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings1000_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        165.072
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings1000_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings1000_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006203369847402274
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings2300_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        190.613
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings2300_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings2300_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0006715168082969595
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings2300_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        195.074
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings2300_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings2300_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0013123240841757967
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings2300_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        198.732
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings2300_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "embedding"
      }
    },
    "model": {
      "name": "embedding_num_embeddings2300_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "embedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.005152663247581568
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "N: 1, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fill"
      }
    },
    "model": {
      "name": "fill__N1_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fill"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.351
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "N: 1, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fill"
      }
    },
    "model": {
      "name": "fill__N1_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fill"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "N: 1, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fill"
      }
    },
    "model": {
      "name": "fill__N1_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fill"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.005922009384796796
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "N: 1024, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fill"
      }
    },
    "model": {
      "name": "fill__N1024_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fill"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.674
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "N: 1024, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fill"
      }
    },
    "model": {
      "name": "fill__N1024_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fill"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "N: 1024, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fill"
      }
    },
    "model": {
      "name": "fill__N1024_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fill"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.893765790910585
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "N: 2048, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fill"
      }
    },
    "model": {
      "name": "fill__N2048_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fill"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.754
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "N: 2048, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fill"
      }
    },
    "model": {
      "name": "fill__N2048_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fill"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "N: 2048, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fill"
      }
    },
    "model": {
      "name": "fill__N2048_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fill"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        9.340188870585722
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 256, N: 512, dim: 0, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "gather"
      }
    },
    "model": {
      "name": "gather_M256_N512_dim0_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gather"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.14
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 256, N: 512, dim: 0, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "gather"
      }
    },
    "model": {
      "name": "gather_M256_N512_dim0_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gather"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 256, N: 512, dim: 0, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "gather"
      }
    },
    "model": {
      "name": "gather_M256_N512_dim0_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gather"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        18.70126166779793
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "gather"
      }
    },
    "model": {
      "name": "gather_M512_N512_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gather"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        72.008
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "gather"
      }
    },
    "model": {
      "name": "gather_M512_N512_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gather"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "gather"
      }
    },
    "model": {
      "name": "gather_M512_N512_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gather"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        58.247489315581824
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (32, 8, 16), num_groups: 2",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "GroupNormBenchmark"
      }
    },
    "model": {
      "name": "GroupNormBenchmark_dims(32,8,16)_num_groups2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "GroupNormBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        56.691
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (32, 8, 16), num_groups: 2",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "GroupNormBenchmark"
      }
    },
    "model": {
      "name": "GroupNormBenchmark_dims(32,8,16)_num_groups2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "GroupNormBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (32, 8, 16), num_groups: 2",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "GroupNormBenchmark"
      }
    },
    "model": {
      "name": "GroupNormBenchmark_dims(32,8,16)_num_groups2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "GroupNormBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.5791437344408268
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (32, 8, 16), num_groups: 4",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "GroupNormBenchmark"
      }
    },
    "model": {
      "name": "GroupNormBenchmark_dims(32,8,16)_num_groups4",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "GroupNormBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        56.737
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (32, 8, 16), num_groups: 4",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "GroupNormBenchmark"
      }
    },
    "model": {
      "name": "GroupNormBenchmark_dims(32,8,16)_num_groups4",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "GroupNormBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (32, 8, 16), num_groups: 4",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "GroupNormBenchmark"
      }
    },
    "model": {
      "name": "GroupNormBenchmark_dims(32,8,16)_num_groups4",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "GroupNormBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.5786668674776194
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (32, 8, 56, 56), num_groups: 2",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "GroupNormBenchmark"
      }
    },
    "model": {
      "name": "GroupNormBenchmark_dims(32,8,56,56)_num_groups2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "GroupNormBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        94.516
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (32, 8, 56, 56), num_groups: 2",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "GroupNormBenchmark"
      }
    },
    "model": {
      "name": "GroupNormBenchmark_dims(32,8,56,56)_num_groups2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "GroupNormBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (32, 8, 56, 56), num_groups: 2",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "GroupNormBenchmark"
      }
    },
    "model": {
      "name": "GroupNormBenchmark_dims(32,8,56,56)_num_groups2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "GroupNormBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        67.9527159391959
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (32, 8, 56, 56), num_groups: 4",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "GroupNormBenchmark"
      }
    },
    "model": {
      "name": "GroupNormBenchmark_dims(32,8,56,56)_num_groups4",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "GroupNormBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        94.074
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (32, 8, 56, 56), num_groups: 4",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "GroupNormBenchmark"
      }
    },
    "model": {
      "name": "GroupNormBenchmark_dims(32,8,56,56)_num_groups4",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "GroupNormBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (32, 8, 56, 56), num_groups: 4",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "GroupNormBenchmark"
      }
    },
    "model": {
      "name": "GroupNormBenchmark_dims(32,8,56,56)_num_groups4",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "GroupNormBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        68.27156881207544
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Hardsigmoid"
      }
    },
    "model": {
      "name": "Hardsigmoid_N1_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Hardsigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        63.881
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Hardsigmoid"
      }
    },
    "model": {
      "name": "Hardsigmoid_N1_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Hardsigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Hardsigmoid"
      }
    },
    "model": {
      "name": "Hardsigmoid_N1_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Hardsigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        24.621782087852463
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 4, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Hardsigmoid"
      }
    },
    "model": {
      "name": "Hardsigmoid_N4_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Hardsigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        72.607
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 4, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Hardsigmoid"
      }
    },
    "model": {
      "name": "Hardsigmoid_N4_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Hardsigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 4, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Hardsigmoid"
      }
    },
    "model": {
      "name": "Hardsigmoid_N4_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Hardsigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        86.65038692395328
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Hardswish"
      }
    },
    "model": {
      "name": "Hardswish_N1_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Hardswish"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        65.322
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Hardswish"
      }
    },
    "model": {
      "name": "Hardswish_N1_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Hardswish"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Hardswish"
      }
    },
    "model": {
      "name": "Hardswish_N1_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Hardswish"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        24.078697994414078
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 4, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Hardswish"
      }
    },
    "model": {
      "name": "Hardswish_N4_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Hardswish"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        76.674
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 4, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Hardswish"
      }
    },
    "model": {
      "name": "Hardswish_N4_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Hardswish"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 4, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Hardswish"
      }
    },
    "model": {
      "name": "Hardswish_N4_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Hardswish"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        82.05426436154357
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 8, N: 32, K: 1, dim: 0, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_add__M8_N32_K1_dim0_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        320.874
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 8, N: 32, K: 1, dim: 0, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_add__M8_N32_K1_dim0_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 8, N: 32, K: 1, dim: 0, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_add__M8_N32_K1_dim0_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0076540963303008995
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, dim: 1, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_add__M256_N512_K1_dim1_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        211.908
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, dim: 1, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_add__M256_N512_K1_dim1_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, dim: 1, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_add__M256_N512_K1_dim1_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        6.940095685445591
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 1, dim: 2, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_add__M512_N512_K1_dim2_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        126.62
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 1, dim: 2, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_add__M512_N512_K1_dim2_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 1, dim: 2, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_add__M512_N512_K1_dim2_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        24.843936912239123
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 8, N: 8, K: 1, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_select_M8_N8_K1_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.897
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 8, N: 8, K: 1, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_select_M8_N8_K1_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 8, N: 8, K: 1, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_select_M8_N8_K1_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.2825614395421375
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_select_M256_N512_K1_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        58.458
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_select_M256_N512_K1_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_select_M256_N512_K1_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        17.994541887894428
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 1, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_select_M512_N512_K1_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.501
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 1, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_select_M512_N512_K1_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 1, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_select_M512_N512_K1_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        18.18596711475961
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 8, N: 8, K: 2, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_select_M8_N8_K2_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.907
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 8, N: 8, K: 2, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_select_M8_N8_K2_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 8, N: 8, K: 2, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_select_M8_N8_K2_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.5495919194865554
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 2, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_select_M256_N512_K2_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        204.998
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 2, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_select_M256_N512_K2_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 2, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_select_M256_N512_K2_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.246436449430355
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_select_M512_N512_K2_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        405.383
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_select_M512_N512_K2_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, dim: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "index"
      }
    },
    "model": {
      "name": "index_select_M512_N512_K2_dim1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "index"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.354778051544695
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (32, 8, 16)",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "InstanceNormBenchmark"
      }
    },
    "model": {
      "name": "InstanceNormBenchmark_dims(32,8,16)",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "InstanceNormBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        166.247
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (32, 8, 16)",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "InstanceNormBenchmark"
      }
    },
    "model": {
      "name": "InstanceNormBenchmark_dims(32,8,16)",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "InstanceNormBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (32, 8, 16)",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "InstanceNormBenchmark"
      }
    },
    "model": {
      "name": "InstanceNormBenchmark_dims(32,8,16)",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "InstanceNormBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.19748916514893342
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (32, 8, 56, 56)",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "InstanceNormBenchmark"
      }
    },
    "model": {
      "name": "InstanceNormBenchmark_dims(32,8,56,56)",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "InstanceNormBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        342.679
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (32, 8, 56, 56)",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "InstanceNormBenchmark"
      }
    },
    "model": {
      "name": "InstanceNormBenchmark_dims(32,8,56,56)",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "InstanceNormBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (32, 8, 56, 56)",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "InstanceNormBenchmark"
      }
    },
    "model": {
      "name": "InstanceNormBenchmark_dims(32,8,56,56)",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "InstanceNormBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        18.742317055011593
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: True, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastTrue_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        7.454
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: True, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastTrue_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: True, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastTrue_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        7.72698538342108
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: True, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastTrue_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.788
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: True, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastTrue_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: True, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastTrue_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.88448752929783
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: True, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastTrue_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        41.327
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: True, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastTrue_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: True, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastTrue_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.3937604298885904
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: False, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastFalse_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        17.421
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: False, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastFalse_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: False, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastFalse_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.306436935193591
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: False, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastFalse_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        20.299
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: False, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastFalse_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: False, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastFalse_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.8375758905679245
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: False, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastFalse_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        30.883
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: False, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastFalse_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: False, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastFalse_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.8651068892336693
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: True, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastTrue_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.101
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: True, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastTrue_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: True, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastTrue_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        46.41362420568358
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: True, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastTrue_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        187.516
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: True, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastTrue_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: True, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastTrue_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        30.71741379849384
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: True, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastTrue_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        467.317
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: True, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastTrue_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: True, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastTrue_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        12.325670264011269
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: False, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastFalse_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.07
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: False, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastFalse_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: False, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastFalse_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        74.73700396178914
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: False, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastFalse_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.196
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: False, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastFalse_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: False, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastFalse_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        54.23926281528091
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: False, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastFalse_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        284.89
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: False, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastFalse_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: False, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastFalse_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        20.21833733342232
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 320, 320), output_size: (256, 256), channels_last: True, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,320,320)_output_size(256,256)_channels_lastTrue_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        132.145
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 320, 320), output_size: (256, 256), channels_last: True, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,320,320)_output_size(256,256)_channels_lastTrue_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 320, 320), output_size: (256, 256), channels_last: True, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,320,320)_output_size(256,256)_channels_lastTrue_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        18.597719835316106
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 320, 320), output_size: (256, 256), channels_last: True, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,320,320)_output_size(256,256)_channels_lastTrue_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        201.55
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 320, 320), output_size: (256, 256), channels_last: True, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,320,320)_output_size(256,256)_channels_lastTrue_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 320, 320), output_size: (256, 256), channels_last: True, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,320,320)_output_size(256,256)_channels_lastTrue_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        12.193513596754903
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 320, 320), output_size: (256, 256), channels_last: True, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,320,320)_output_size(256,256)_channels_lastTrue_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        516.242
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 320, 320), output_size: (256, 256), channels_last: True, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,320,320)_output_size(256,256)_channels_lastTrue_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 320, 320), output_size: (256, 256), channels_last: True, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,320,320)_output_size(256,256)_channels_lastTrue_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.760558759046556
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 320, 320), output_size: (256, 256), channels_last: False, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,320,320)_output_size(256,256)_channels_lastFalse_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.097
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 320, 320), output_size: (256, 256), channels_last: False, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,320,320)_output_size(256,256)_channels_lastFalse_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 320, 320), output_size: (256, 256), channels_last: False, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,320,320)_output_size(256,256)_channels_lastFalse_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        31.87655138780786
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 320, 320), output_size: (256, 256), channels_last: False, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,320,320)_output_size(256,256)_channels_lastFalse_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.972
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 320, 320), output_size: (256, 256), channels_last: False, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,320,320)_output_size(256,256)_channels_lastFalse_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 320, 320), output_size: (256, 256), channels_last: False, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,320,320)_output_size(256,256)_channels_lastFalse_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        21.94827505688319
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 320, 320), output_size: (256, 256), channels_last: False, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,320,320)_output_size(256,256)_channels_lastFalse_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        318.85
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 320, 320), output_size: (256, 256), channels_last: False, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,320,320)_output_size(256,256)_channels_lastFalse_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 3, 320, 320), output_size: (256, 256), channels_last: False, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,320,320)_output_size(256,256)_channels_lastFalse_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        7.707693305484976
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 60, 40), output_size: (24, 24), channels_last: True, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,60,40)_output_size(24,24)_channels_lastTrue_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        6.945
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 60, 40), output_size: (24, 24), channels_last: True, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,60,40)_output_size(24,24)_channels_lastTrue_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 60, 40), output_size: (24, 24), channels_last: True, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,60,40)_output_size(24,24)_channels_lastTrue_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.7644194759310037
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 60, 40), output_size: (24, 24), channels_last: True, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,60,40)_output_size(24,24)_channels_lastTrue_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        7.894
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 60, 40), output_size: (24, 24), channels_last: True, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,60,40)_output_size(24,24)_channels_lastTrue_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 60, 40), output_size: (24, 24), channels_last: True, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,60,40)_output_size(24,24)_channels_lastTrue_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.432257306297948
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 60, 40), output_size: (24, 24), channels_last: True, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,60,40)_output_size(24,24)_channels_lastTrue_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.886
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 60, 40), output_size: (24, 24), channels_last: True, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,60,40)_output_size(24,24)_channels_lastTrue_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 60, 40), output_size: (24, 24), channels_last: True, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,60,40)_output_size(24,24)_channels_lastTrue_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.8772694748422941
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 60, 40), output_size: (24, 24), channels_last: False, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,60,40)_output_size(24,24)_channels_lastFalse_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        6.899
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 60, 40), output_size: (24, 24), channels_last: False, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,60,40)_output_size(24,24)_channels_lastFalse_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 60, 40), output_size: (24, 24), channels_last: False, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,60,40)_output_size(24,24)_channels_lastFalse_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.7829723537720814
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 60, 40), output_size: (24, 24), channels_last: False, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,60,40)_output_size(24,24)_channels_lastFalse_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.031
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 60, 40), output_size: (24, 24), channels_last: False, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,60,40)_output_size(24,24)_channels_lastFalse_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 60, 40), output_size: (24, 24), channels_last: False, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,60,40)_output_size(24,24)_channels_lastFalse_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.390853121870625
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 60, 40), output_size: (24, 24), channels_last: False, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,60,40)_output_size(24,24)_channels_lastFalse_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.653
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 60, 40), output_size: (24, 24), channels_last: False, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,60,40)_output_size(24,24)_channels_lastFalse_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 60, 40), output_size: (24, 24), channels_last: False, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,60,40)_output_size(24,24)_channels_lastFalse_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.8867309229812467
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 600, 400), output_size: (240, 240), channels_last: True, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,600,400)_output_size(240,240)_channels_lastTrue_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        75.648
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 600, 400), output_size: (240, 240), channels_last: True, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,600,400)_output_size(240,240)_channels_lastTrue_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 600, 400), output_size: (240, 240), channels_last: True, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,600,400)_output_size(240,240)_channels_lastTrue_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        25.380587360330658
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 600, 400), output_size: (240, 240), channels_last: True, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,600,400)_output_size(240,240)_channels_lastTrue_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.308
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 600, 400), output_size: (240, 240), channels_last: True, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,600,400)_output_size(240,240)_channels_lastTrue_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 600, 400), output_size: (240, 240), channels_last: True, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,600,400)_output_size(240,240)_channels_lastTrue_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        18.0607874560186
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 600, 400), output_size: (240, 240), channels_last: True, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,600,400)_output_size(240,240)_channels_lastTrue_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        282.394
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 600, 400), output_size: (240, 240), channels_last: True, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,600,400)_output_size(240,240)_channels_lastTrue_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 600, 400), output_size: (240, 240), channels_last: True, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,600,400)_output_size(240,240)_channels_lastTrue_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        6.799002883749656
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 600, 400), output_size: (240, 240), channels_last: False, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,600,400)_output_size(240,240)_channels_lastFalse_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        75.982
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 600, 400), output_size: (240, 240), channels_last: False, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,600,400)_output_size(240,240)_channels_lastFalse_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 600, 400), output_size: (240, 240), channels_last: False, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,600,400)_output_size(240,240)_channels_lastFalse_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        25.2692370581427
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 600, 400), output_size: (240, 240), channels_last: False, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,600,400)_output_size(240,240)_channels_lastFalse_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        105.094
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 600, 400), output_size: (240, 240), channels_last: False, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,600,400)_output_size(240,240)_channels_lastFalse_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 600, 400), output_size: (240, 240), channels_last: False, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,600,400)_output_size(240,240)_channels_lastFalse_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        18.26929024813219
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 600, 400), output_size: (240, 240), channels_last: False, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,600,400)_output_size(240,240)_channels_lastFalse_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        285.341
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 600, 400), output_size: (240, 240), channels_last: False, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,600,400)_output_size(240,240)_channels_lastFalse_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 600, 400), output_size: (240, 240), channels_last: False, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,600,400)_output_size(240,240)_channels_lastFalse_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        6.728801305778347
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 320, 320), output_size: (256, 256), channels_last: True, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,320,320)_output_size(256,256)_channels_lastTrue_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        76.062
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 320, 320), output_size: (256, 256), channels_last: True, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,320,320)_output_size(256,256)_channels_lastTrue_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 320, 320), output_size: (256, 256), channels_last: True, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,320,320)_output_size(256,256)_channels_lastTrue_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.77017137266379
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 320, 320), output_size: (256, 256), channels_last: True, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,320,320)_output_size(256,256)_channels_lastTrue_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.538
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 320, 320), output_size: (256, 256), channels_last: True, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,320,320)_output_size(256,256)_channels_lastTrue_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 320, 320), output_size: (256, 256), channels_last: True, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,320,320)_output_size(256,256)_channels_lastTrue_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        7.344571404956257
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 320, 320), output_size: (256, 256), channels_last: True, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,320,320)_output_size(256,256)_channels_lastTrue_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        314.157
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 320, 320), output_size: (256, 256), channels_last: True, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,320,320)_output_size(256,256)_channels_lastTrue_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 320, 320), output_size: (256, 256), channels_last: True, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,320,320)_output_size(256,256)_channels_lastTrue_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.6076137435207296
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 320, 320), output_size: (256, 256), channels_last: False, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,320,320)_output_size(256,256)_channels_lastFalse_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        76.78
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 320, 320), output_size: (256, 256), channels_last: False, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,320,320)_output_size(256,256)_channels_lastFalse_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 320, 320), output_size: (256, 256), channels_last: False, mode: nearest",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,320,320)_output_size(256,256)_channels_lastFalse_modenearest",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.669438654239096
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 320, 320), output_size: (256, 256), channels_last: False, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,320,320)_output_size(256,256)_channels_lastFalse_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.447
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 320, 320), output_size: (256, 256), channels_last: False, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,320,320)_output_size(256,256)_channels_lastFalse_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 320, 320), output_size: (256, 256), channels_last: False, mode: linear",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,320,320)_output_size(256,256)_channels_lastFalse_modelinear",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        7.417155924068082
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 320, 320), output_size: (256, 256), channels_last: False, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,320,320)_output_size(256,256)_channels_lastFalse_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        313.821
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 320, 320), output_size: (256, 256), channels_last: False, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,320,320)_output_size(256,256)_channels_lastFalse_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "input_size: (1, 1, 320, 320), output_size: (256, 256), channels_last: False, mode: bicubic",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,320,320)_output_size(256,256)_channels_lastFalse_modebicubic",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.6104078525515724
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: True, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastTrue_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        7.699
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: True, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastTrue_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: True, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastTrue_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.8704298651570717
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: False, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastFalse_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        19.471
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: False, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastFalse_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 3, 60, 40), output_size: (24, 24), channels_last: False, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,60,40)_output_size(24,24)_channels_lastFalse_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.7395523515151221
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: True, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastTrue_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        138.083
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: True, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastTrue_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: True, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastTrue_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.428480545169583
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: False, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastFalse_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        96.983
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: False, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastFalse_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 3, 600, 400), output_size: (240, 240), channels_last: False, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,600,400)_output_size(240,240)_channels_lastFalse_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        14.848016438431946
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 3, 320, 320), output_size: (256, 256), channels_last: True, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,320,320)_output_size(256,256)_channels_lastTrue_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        148.011
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 3, 320, 320), output_size: (256, 256), channels_last: True, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,320,320)_output_size(256,256)_channels_lastTrue_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 3, 320, 320), output_size: (256, 256), channels_last: True, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,320,320)_output_size(256,256)_channels_lastTrue_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.15104190552071
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 3, 320, 320), output_size: (256, 256), channels_last: False, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,320,320)_output_size(256,256)_channels_lastFalse_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.965
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 3, 320, 320), output_size: (256, 256), channels_last: False, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,320,320)_output_size(256,256)_channels_lastFalse_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 3, 320, 320), output_size: (256, 256), channels_last: False, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,3,320,320)_output_size(256,256)_channels_lastFalse_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        6.085285502420396
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 1, 60, 40), output_size: (24, 24), channels_last: True, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,60,40)_output_size(24,24)_channels_lastTrue_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        7.185
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 1, 60, 40), output_size: (24, 24), channels_last: True, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,60,40)_output_size(24,24)_channels_lastTrue_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 1, 60, 40), output_size: (24, 24), channels_last: True, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,60,40)_output_size(24,24)_channels_lastTrue_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.6680978140576688
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 1, 60, 40), output_size: (24, 24), channels_last: False, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,60,40)_output_size(24,24)_channels_lastFalse_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        7.279
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 1, 60, 40), output_size: (24, 24), channels_last: False, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,60,40)_output_size(24,24)_channels_lastFalse_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 1, 60, 40), output_size: (24, 24), channels_last: False, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,60,40)_output_size(24,24)_channels_lastFalse_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.6593906032950368
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 1, 600, 400), output_size: (240, 240), channels_last: True, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,600,400)_output_size(240,240)_channels_lastTrue_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        96.163
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 1, 600, 400), output_size: (240, 240), channels_last: True, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,600,400)_output_size(240,240)_channels_lastTrue_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 1, 600, 400), output_size: (240, 240), channels_last: True, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,600,400)_output_size(240,240)_channels_lastTrue_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.9915335418192335
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 1, 600, 400), output_size: (240, 240), channels_last: False, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,600,400)_output_size(240,240)_channels_lastFalse_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        96.086
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 1, 600, 400), output_size: (240, 240), channels_last: False, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,600,400)_output_size(240,240)_channels_lastFalse_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 1, 600, 400), output_size: (240, 240), channels_last: False, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,600,400)_output_size(240,240)_channels_lastFalse_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.995508075575129
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 1, 320, 320), output_size: (256, 256), channels_last: True, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,320,320)_output_size(256,256)_channels_lastTrue_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.692
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 1, 320, 320), output_size: (256, 256), channels_last: True, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,320,320)_output_size(256,256)_channels_lastTrue_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 1, 320, 320), output_size: (256, 256), channels_last: True, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,320,320)_output_size(256,256)_channels_lastTrue_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.033922459905075
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 1, 320, 320), output_size: (256, 256), channels_last: False, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,320,320)_output_size(256,256)_channels_lastFalse_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.859
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 1, 320, 320), output_size: (256, 256), channels_last: False, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,320,320)_output_size(256,256)_channels_lastFalse_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "uint8",
      "extra_info": {
        "input_config": "input_size: (1, 1, 320, 320), output_size: (256, 256), channels_last: False, mode: nearest, dtype: torch.uint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "interpolate"
      }
    },
    "model": {
      "name": "interpolate_input_size(1,1,320,320)_output_size(256,256)_channels_lastFalse_modenearest_dtypetorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "interpolate"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.030556689958503
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (1, 8, 16)",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "LayerNormBenchmark"
      }
    },
    "model": {
      "name": "LayerNormBenchmark_dims(1,8,16)",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "LayerNormBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.254
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (1, 8, 16)",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "LayerNormBenchmark"
      }
    },
    "model": {
      "name": "LayerNormBenchmark_dims(1,8,16)",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "LayerNormBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (1, 8, 16)",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "LayerNormBenchmark"
      }
    },
    "model": {
      "name": "LayerNormBenchmark_dims(1,8,16)",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "LayerNormBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.4813762707736463
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (8, 8, 16)",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "LayerNormBenchmark"
      }
    },
    "model": {
      "name": "LayerNormBenchmark_dims(8,8,16)",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "LayerNormBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        55.181
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (8, 8, 16)",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "LayerNormBenchmark"
      }
    },
    "model": {
      "name": "LayerNormBenchmark_dims(8,8,16)",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "LayerNormBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (8, 8, 16)",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "LayerNormBenchmark"
      }
    },
    "model": {
      "name": "LayerNormBenchmark_dims(8,8,16)",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "LayerNormBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.16701495144339093
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (32, 8, 16)",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "LayerNormBenchmark"
      }
    },
    "model": {
      "name": "LayerNormBenchmark_dims(32,8,16)",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "LayerNormBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        55.595
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (32, 8, 16)",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "LayerNormBenchmark"
      }
    },
    "model": {
      "name": "LayerNormBenchmark_dims(32,8,16)",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "LayerNormBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (32, 8, 16)",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "LayerNormBenchmark"
      }
    },
    "model": {
      "name": "LayerNormBenchmark_dims(32,8,16)",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "LayerNormBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.6078197058754271
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (64, 128, 56, 56)",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "LayerNormBenchmark"
      }
    },
    "model": {
      "name": "LayerNormBenchmark_dims(64,128,56,56)",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "LayerNormBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2450.554
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (64, 128, 56, 56)",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "LayerNormBenchmark"
      }
    },
    "model": {
      "name": "LayerNormBenchmark_dims(64,128,56,56)",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "LayerNormBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "dims: (64, 128, 56, 56)",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "LayerNormBenchmark"
      }
    },
    "model": {
      "name": "LayerNormBenchmark_dims(64,128,56,56)",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "LayerNormBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        85.17752845374766
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, IN: 1, OUT: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "linear"
      }
    },
    "model": {
      "name": "linear_N1_IN1_OUT1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "linear"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.52
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, IN: 1, OUT: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "linear"
      }
    },
    "model": {
      "name": "linear_N1_IN1_OUT1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "linear"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, IN: 1, OUT: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "linear"
      }
    },
    "model": {
      "name": "linear_N1_IN1_OUT1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "linear"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0005917238679906632
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 4, IN: 256, OUT: 128, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "linear"
      }
    },
    "model": {
      "name": "linear_N4_IN256_OUT128_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "linear"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        67.959
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 4, IN: 256, OUT: 128, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "linear"
      }
    },
    "model": {
      "name": "linear_N4_IN256_OUT128_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "linear"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 4, IN: 256, OUT: 128, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "linear"
      }
    },
    "model": {
      "name": "linear_N4_IN256_OUT128_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "linear"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.12054243285581011
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 16, IN: 512, OUT: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "linear"
      }
    },
    "model": {
      "name": "linear_N16_IN512_OUT256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "linear"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        157.096
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 16, IN: 512, OUT: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "linear"
      }
    },
    "model": {
      "name": "linear_N16_IN512_OUT256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "linear"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 16, IN: 512, OUT: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "linear"
      }
    },
    "model": {
      "name": "linear_N16_IN512_OUT256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "linear"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.4171708757215356
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, trans_a: True, trans_b: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "matmul"
      }
    },
    "model": {
      "name": "matmul_M1_N1_K1_trans_aTrue_trans_bFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "matmul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.111
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, trans_a: True, trans_b: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "matmul"
      }
    },
    "model": {
      "name": "matmul_M1_N1_K1_trans_aTrue_trans_bFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "matmul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, trans_a: True, trans_b: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "matmul"
      }
    },
    "model": {
      "name": "matmul_M1_N1_K1_trans_aTrue_trans_bFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "matmul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0029191903921457697
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 128, N: 128, K: 128, trans_a: True, trans_b: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "matmul"
      }
    },
    "model": {
      "name": "matmul_M128_N128_K128_trans_aTrue_trans_bFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "matmul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        129.435
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 128, N: 128, K: 128, trans_a: True, trans_b: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "matmul"
      }
    },
    "model": {
      "name": "matmul_M128_N128_K128_trans_aTrue_trans_bFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "matmul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 128, N: 128, K: 128, trans_a: True, trans_b: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "matmul"
      }
    },
    "model": {
      "name": "matmul_M128_N128_K128_trans_aTrue_trans_bFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "matmul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.5189735589281117
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 256, N: 256, K: 256, trans_a: False, trans_b: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "matmul"
      }
    },
    "model": {
      "name": "matmul_M256_N256_K256_trans_aFalse_trans_bTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "matmul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3089.168
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 256, N: 256, K: 256, trans_a: False, trans_b: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "matmul"
      }
    },
    "model": {
      "name": "matmul_M256_N256_K256_trans_aFalse_trans_bTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "matmul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 256, N: 256, K: 256, trans_a: False, trans_b: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "matmul"
      }
    },
    "model": {
      "name": "matmul_M256_N256_K256_trans_aFalse_trans_bTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "matmul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.25457727311415645
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mm"
      }
    },
    "model": {
      "name": "mm_M1_N1_K1_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mm"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.963
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mm"
      }
    },
    "model": {
      "name": "mm_M1_N1_K1_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mm"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mm"
      }
    },
    "model": {
      "name": "mm_M1_N1_K1_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mm"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00302784863667795
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mm"
      }
    },
    "model": {
      "name": "mm_M64_N64_K64_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mm"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        58.264
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mm"
      }
    },
    "model": {
      "name": "mm_M64_N64_K64_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mm"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mm"
      }
    },
    "model": {
      "name": "mm_M64_N64_K64_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mm"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.843603009696815
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mm"
      }
    },
    "model": {
      "name": "mm_M64_N64_K128_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mm"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        61.439
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mm"
      }
    },
    "model": {
      "name": "mm_M64_N64_K128_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mm"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "mm"
      }
    },
    "model": {
      "name": "mm_M64_N64_K128_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mm"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.3333616254241534
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float32, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M16_N64_dtypetorch.float32_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.749
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float32, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M16_N64_dtypetorch.float32_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float32, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M16_N64_dtypetorch.float32_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.979480270762425
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float32, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M16_N64_dtypetorch.float32_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.177
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float32, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M16_N64_dtypetorch.float32_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float32, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M16_N64_dtypetorch.float32_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.578758453091101
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float64, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M16_N64_dtypetorch.float64_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.085
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float64, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M16_N64_dtypetorch.float64_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float64, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M16_N64_dtypetorch.float64_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.311453268455049
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float64, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M16_N64_dtypetorch.float64_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.53
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float64, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M16_N64_dtypetorch.float64_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float64, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M16_N64_dtypetorch.float64_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.641509712812137
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float32, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M16_N64_dtypetorch.float32_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.723
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float32, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M16_N64_dtypetorch.float32_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float32, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M16_N64_dtypetorch.float32_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.00846732241243
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float32, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M16_N64_dtypetorch.float32_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.153
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float32, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M16_N64_dtypetorch.float32_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float32, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M16_N64_dtypetorch.float32_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.5980624312746645
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float64, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M16_N64_dtypetorch.float64_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.083
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float64, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M16_N64_dtypetorch.float64_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float64, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M16_N64_dtypetorch.float64_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.3140505475608295
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float64, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M16_N64_dtypetorch.float64_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.529
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float64, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M16_N64_dtypetorch.float64_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float64, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M16_N64_dtypetorch.float64_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.643204199506216
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float32, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M64_N64_dtypetorch.float32_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.344
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float32, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M64_N64_dtypetorch.float32_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float32, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M64_N64_dtypetorch.float32_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        9.800061230925257
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float32, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M64_N64_dtypetorch.float32_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.778
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float32, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M64_N64_dtypetorch.float32_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float32, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M64_N64_dtypetorch.float32_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        8.674062371608883
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float64, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M64_N64_dtypetorch.float64_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.251
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float64, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M64_N64_dtypetorch.float64_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float64, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M64_N64_dtypetorch.float64_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        15.415900703729935
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float64, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M64_N64_dtypetorch.float64_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.687
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float64, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M64_N64_dtypetorch.float64_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float64, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M64_N64_dtypetorch.float64_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        13.983818487344804
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float32, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M64_N64_dtypetorch.float32_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.337
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float32, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M64_N64_dtypetorch.float32_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float32, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M64_N64_dtypetorch.float32_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        9.819842846627003
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float32, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M64_N64_dtypetorch.float32_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.778
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float32, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M64_N64_dtypetorch.float32_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float32, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M64_N64_dtypetorch.float32_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        8.673278795153145
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float64, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M64_N64_dtypetorch.float64_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.256
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float64, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M64_N64_dtypetorch.float64_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float64, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M64_N64_dtypetorch.float64_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        15.397497944530752
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float64, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M64_N64_dtypetorch.float64_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.692
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float64, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M64_N64_dtypetorch.float64_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float64, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num_M64_N64_dtypetorch.float64_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        13.969033488705541
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float32, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M16_N64_dtypetorch.float32_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.97
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float32, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M16_N64_dtypetorch.float32_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float32, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M16_N64_dtypetorch.float32_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.158707769747042
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float32, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M16_N64_dtypetorch.float32_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.376
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float32, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M16_N64_dtypetorch.float32_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float32, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M16_N64_dtypetorch.float32_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.4470908953422645
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float64, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M16_N64_dtypetorch.float64_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.283
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float64, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M16_N64_dtypetorch.float64_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float64, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M16_N64_dtypetorch.float64_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        7.1766206000854815
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float64, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M16_N64_dtypetorch.float64_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.678
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float64, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M16_N64_dtypetorch.float64_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float64, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M16_N64_dtypetorch.float64_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        6.117922118077335
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float32, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M16_N64_dtypetorch.float32_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.97
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float32, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M16_N64_dtypetorch.float32_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float32, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M16_N64_dtypetorch.float32_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.159012167152757
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float32, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M16_N64_dtypetorch.float32_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.384
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float32, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M16_N64_dtypetorch.float32_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float32, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M16_N64_dtypetorch.float32_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.4367849682036478
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float64, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M16_N64_dtypetorch.float64_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.273
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float64, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M16_N64_dtypetorch.float64_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float64, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M16_N64_dtypetorch.float64_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        7.206950101264317
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float64, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M16_N64_dtypetorch.float64_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.697
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float64, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M16_N64_dtypetorch.float64_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 16, N: 64, dtype: torch.float64, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M16_N64_dtypetorch.float64_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        6.075163128989983
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float32, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M64_N64_dtypetorch.float32_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.595
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float32, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M64_N64_dtypetorch.float32_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float32, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M64_N64_dtypetorch.float32_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        12.62510332789463
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float32, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M64_N64_dtypetorch.float32_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.993
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float32, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M64_N64_dtypetorch.float32_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float32, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M64_N64_dtypetorch.float32_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.948457554675505
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float64, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M64_N64_dtypetorch.float64_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.508
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float64, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M64_N64_dtypetorch.float64_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float64, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M64_N64_dtypetorch.float64_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        18.684508901249036
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float64, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M64_N64_dtypetorch.float64_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.923
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float64, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M64_N64_dtypetorch.float64_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float64, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M64_N64_dtypetorch.float64_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        16.706287535055367
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float32, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M64_N64_dtypetorch.float32_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.585
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float32, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M64_N64_dtypetorch.float32_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float32, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M64_N64_dtypetorch.float32_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        12.67795609810409
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float32, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M64_N64_dtypetorch.float32_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.997
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float32, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M64_N64_dtypetorch.float32_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float32, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M64_N64_dtypetorch.float32_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.93462085547946
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float64, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M64_N64_dtypetorch.float64_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.506
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float64, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M64_N64_dtypetorch.float64_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float64, replace_inf: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M64_N64_dtypetorch.float64_replace_infTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        18.69175863053867
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float64, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M64_N64_dtypetorch.float64_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.927
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float64, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M64_N64_dtypetorch.float64_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, dtype: torch.float64, replace_inf: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "nan"
      }
    },
    "model": {
      "name": "nan_to_num__M64_N64_dtypetorch.float64_replace_infFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "nan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        16.690229195537217
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: 3, stride: 1, N: 8, C: 256, L: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MaxPool1d"
      }
    },
    "model": {
      "name": "MaxPool1d_kernel3_stride1_N8_C256_L256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MaxPool1d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        91.394
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: 3, stride: 1, N: 8, C: 256, L: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MaxPool1d"
      }
    },
    "model": {
      "name": "MaxPool1d_kernel3_stride1_N8_C256_L256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MaxPool1d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: 3, stride: 1, N: 8, C: 256, L: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MaxPool1d"
      }
    },
    "model": {
      "name": "MaxPool1d_kernel3_stride1_N8_C256_L256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MaxPool1d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        45.89263558244807
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: 3, stride: 1, N: 8, C: 256, L: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "AvgPool1d"
      }
    },
    "model": {
      "name": "AvgPool1d_kernel3_stride1_N8_C256_L256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "AvgPool1d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        301.639
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: 3, stride: 1, N: 8, C: 256, L: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "AvgPool1d"
      }
    },
    "model": {
      "name": "AvgPool1d_kernel3_stride1_N8_C256_L256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "AvgPool1d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: 3, stride: 1, N: 8, C: 256, L: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "AvgPool1d"
      }
    },
    "model": {
      "name": "AvgPool1d_kernel3_stride1_N8_C256_L256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "AvgPool1d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        13.905033219121918
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: [3, 1], stride: [2, 1], N: 1, C: 16, H: 32, W: 32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MaxPool2d"
      }
    },
    "model": {
      "name": "MaxPool2d_kernel[3,1]_stride[2,1]_N1_C16_H32_W32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MaxPool2d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        55.7
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: [3, 1], stride: [2, 1], N: 1, C: 16, H: 32, W: 32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MaxPool2d"
      }
    },
    "model": {
      "name": "MaxPool2d_kernel[3,1]_stride[2,1]_N1_C16_H32_W32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MaxPool2d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: [3, 1], stride: [2, 1], N: 1, C: 16, H: 32, W: 32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MaxPool2d"
      }
    },
    "model": {
      "name": "MaxPool2d_kernel[3,1]_stride[2,1]_N1_C16_H32_W32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MaxPool2d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.3531797710373223
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: [3, 1], stride: [2, 1], N: 1, C: 16, H: 32, W: 32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "AvgPool2d"
      }
    },
    "model": {
      "name": "AvgPool2d_kernel[3,1]_stride[2,1]_N1_C16_H32_W32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "AvgPool2d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        54.987
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: [3, 1], stride: [2, 1], N: 1, C: 16, H: 32, W: 32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "AvgPool2d"
      }
    },
    "model": {
      "name": "AvgPool2d_kernel[3,1]_stride[2,1]_N1_C16_H32_W32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "AvgPool2d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: [3, 1], stride: [2, 1], N: 1, C: 16, H: 32, W: 32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "AvgPool2d"
      }
    },
    "model": {
      "name": "AvgPool2d_kernel[3,1]_stride[2,1]_N1_C16_H32_W32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "AvgPool2d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.3837112007117196
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: [3, 1], stride: [2, 1], N: 1, C: 16, H: 32, W: 32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "AdaptiveMaxPool2d"
      }
    },
    "model": {
      "name": "AdaptiveMaxPool2d_kernel[3,1]_stride[2,1]_N1_C16_H32_W32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "AdaptiveMaxPool2d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        61.333
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: [3, 1], stride: [2, 1], N: 1, C: 16, H: 32, W: 32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "AdaptiveMaxPool2d"
      }
    },
    "model": {
      "name": "AdaptiveMaxPool2d_kernel[3,1]_stride[2,1]_N1_C16_H32_W32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "AdaptiveMaxPool2d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: [3, 1], stride: [2, 1], N: 1, C: 16, H: 32, W: 32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "AdaptiveMaxPool2d"
      }
    },
    "model": {
      "name": "AdaptiveMaxPool2d_kernel[3,1]_stride[2,1]_N1_C16_H32_W32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "AdaptiveMaxPool2d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.1370637083211155
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: [3, 1], stride: [2, 1], N: 1, C: 16, H: 32, W: 32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "FractionalMaxPool2d"
      }
    },
    "model": {
      "name": "FractionalMaxPool2d_kernel[3,1]_stride[2,1]_N1_C16_H32_W32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "FractionalMaxPool2d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        66.417
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: [3, 1], stride: [2, 1], N: 1, C: 16, H: 32, W: 32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "FractionalMaxPool2d"
      }
    },
    "model": {
      "name": "FractionalMaxPool2d_kernel[3,1]_stride[2,1]_N1_C16_H32_W32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "FractionalMaxPool2d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: [3, 1], stride: [2, 1], N: 1, C: 16, H: 32, W: 32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "FractionalMaxPool2d"
      }
    },
    "model": {
      "name": "FractionalMaxPool2d_kernel[3,1]_stride[2,1]_N1_C16_H32_W32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "FractionalMaxPool2d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.9734612879196523
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: [3, 1, 3], stride: [2, 1, 2], N: 1, C: 16, D: 16, H: 32, W: 32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MaxPool3d"
      }
    },
    "model": {
      "name": "MaxPool3d_kernel[3,1,3]_stride[2,1,2]_N1_C16_D16_H32_W32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MaxPool3d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        231.556
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: [3, 1, 3], stride: [2, 1, 2], N: 1, C: 16, D: 16, H: 32, W: 32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MaxPool3d"
      }
    },
    "model": {
      "name": "MaxPool3d_kernel[3,1,3]_stride[2,1,2]_N1_C16_D16_H32_W32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MaxPool3d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: [3, 1, 3], stride: [2, 1, 2], N: 1, C: 16, D: 16, H: 32, W: 32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MaxPool3d"
      }
    },
    "model": {
      "name": "MaxPool3d_kernel[3,1,3]_stride[2,1,2]_N1_C16_D16_H32_W32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MaxPool3d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        9.056783427818596
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: [3, 1, 3], stride: [2, 1, 2], N: 1, C: 16, D: 16, H: 32, W: 32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "AvgPool3d"
      }
    },
    "model": {
      "name": "AvgPool3d_kernel[3,1,3]_stride[2,1,2]_N1_C16_D16_H32_W32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "AvgPool3d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        91.517
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: [3, 1, 3], stride: [2, 1, 2], N: 1, C: 16, D: 16, H: 32, W: 32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "AvgPool3d"
      }
    },
    "model": {
      "name": "AvgPool3d_kernel[3,1,3]_stride[2,1,2]_N1_C16_D16_H32_W32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "AvgPool3d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: [3, 1, 3], stride: [2, 1, 2], N: 1, C: 16, D: 16, H: 32, W: 32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "AvgPool3d"
      }
    },
    "model": {
      "name": "AvgPool3d_kernel[3,1,3]_stride[2,1,2]_N1_C16_D16_H32_W32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "AvgPool3d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        22.915350002166196
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: [3, 1, 3], stride: [2, 1, 2], N: 1, C: 16, D: 16, H: 32, W: 32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "AdaptiveMaxPool3d"
      }
    },
    "model": {
      "name": "AdaptiveMaxPool3d_kernel[3,1,3]_stride[2,1,2]_N1_C16_D16_H32_W32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "AdaptiveMaxPool3d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        182.809
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: [3, 1, 3], stride: [2, 1, 2], N: 1, C: 16, D: 16, H: 32, W: 32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "AdaptiveMaxPool3d"
      }
    },
    "model": {
      "name": "AdaptiveMaxPool3d_kernel[3,1,3]_stride[2,1,2]_N1_C16_D16_H32_W32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "AdaptiveMaxPool3d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: [3, 1, 3], stride: [2, 1, 2], N: 1, C: 16, D: 16, H: 32, W: 32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "AdaptiveMaxPool3d"
      }
    },
    "model": {
      "name": "AdaptiveMaxPool3d_kernel[3,1,3]_stride[2,1,2]_N1_C16_D16_H32_W32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "AdaptiveMaxPool3d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        11.471820942693478
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: [3, 1, 3], stride: [2, 1, 2], N: 1, C: 16, D: 16, H: 32, W: 32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "FractionalMaxPool3d"
      }
    },
    "model": {
      "name": "FractionalMaxPool3d_kernel[3,1,3]_stride[2,1,2]_N1_C16_D16_H32_W32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "FractionalMaxPool3d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        66.494
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: [3, 1, 3], stride: [2, 1, 2], N: 1, C: 16, D: 16, H: 32, W: 32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "FractionalMaxPool3d"
      }
    },
    "model": {
      "name": "FractionalMaxPool3d_kernel[3,1,3]_stride[2,1,2]_N1_C16_D16_H32_W32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "FractionalMaxPool3d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "kernel: [3, 1, 3], stride: [2, 1, 2], N: 1, C: 16, D: 16, H: 32, W: 32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "FractionalMaxPool3d"
      }
    },
    "model": {
      "name": "FractionalMaxPool3d_kernel[3,1,3]_stride[2,1,2]_N1_C16_D16_H32_W32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "FractionalMaxPool3d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        31.538999123662546
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M1_N1_K1_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.827
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M1_N1_K1_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M1_N1_K1_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006567232644042962
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M1_N1_K1_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.84
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M1_N1_K1_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M1_N1_K1_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006521673378387014
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M1_N1_K1_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.841
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M1_N1_K1_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M1_N1_K1_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.01303923723494617
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M64_N64_K64_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.368
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M64_N64_K64_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M64_N64_K64_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        24.129561174309583
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M64_N64_K64_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        149.349
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M64_N64_K64_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M64_N64_K64_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        21.06287877765339
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M64_N64_K64_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        240.094
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M64_N64_K64_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M64_N64_K64_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        26.204121620953853
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M64_N64_K128_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        205.452
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M64_N64_K128_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M64_N64_K128_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        30.622462672113063
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M64_N64_K128_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        240.759
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M64_N64_K128_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M64_N64_K128_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        26.13171408475492
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M64_N64_K128_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        422.523
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M64_N64_K128_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "fmod"
      }
    },
    "model": {
      "name": "fmod_M64_N64_K128_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "fmod"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        29.780429714558288
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M1_N1_K1_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.849
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M1_N1_K1_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M1_N1_K1_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00648851270894438
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M1_N1_K1_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.866
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M1_N1_K1_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M1_N1_K1_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006430015314274856
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M1_N1_K1_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.868
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M1_N1_K1_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 1, N: 1, K: 1, device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M1_N1_K1_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012847105987022692
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M64_N64_K64_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        145.075
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M64_N64_K64_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M64_N64_K64_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        21.683482360202625
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M64_N64_K64_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        168.588
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M64_N64_K64_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M64_N64_K64_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        18.65931637000805
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M64_N64_K64_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        284.854
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M64_N64_K64_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 64, device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M64_N64_K64_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        22.086629048716794
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M64_N64_K128_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        232.831
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M64_N64_K128_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "int32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M64_N64_K128_cpu_dtypetorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        27.021572655798774
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M64_N64_K128_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        278.261
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M64_N64_K128_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M64_N64_K128_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        22.609905605506007
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M64_N64_K128_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        511.309
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M64_N64_K128_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float64",
      "extra_info": {
        "input_config": "M: 64, N: 64, K: 128, device: cpu, dtype: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "remainder"
      }
    },
    "model": {
      "name": "remainder_M64_N64_K128_cpu_dtypetorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "remainder"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        24.609214313426914
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Softmax"
      }
    },
    "model": {
      "name": "Softmax_N1_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Softmax"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.121
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Softmax"
      }
    },
    "model": {
      "name": "Softmax_N1_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Softmax"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Softmax"
      }
    },
    "model": {
      "name": "Softmax_N1_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Softmax"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        14.283082181608135
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 4, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Softmax"
      }
    },
    "model": {
      "name": "Softmax_N4_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Softmax"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        314.903
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 4, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Softmax"
      }
    },
    "model": {
      "name": "Softmax_N4_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Softmax"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 4, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Softmax"
      }
    },
    "model": {
      "name": "Softmax_N4_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Softmax"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        19.979012323871288
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Softmax2d"
      }
    },
    "model": {
      "name": "Softmax2d_N1_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Softmax2d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.562
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Softmax2d"
      }
    },
    "model": {
      "name": "Softmax2d_N1_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Softmax2d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Softmax2d"
      }
    },
    "model": {
      "name": "Softmax2d_N1_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Softmax2d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        14.35594480731757
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 4, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Softmax2d"
      }
    },
    "model": {
      "name": "Softmax2d_N4_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Softmax2d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        314.582
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 4, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Softmax2d"
      }
    },
    "model": {
      "name": "Softmax2d_N4_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Softmax2d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 4, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "Softmax2d"
      }
    },
    "model": {
      "name": "Softmax2d_N4_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "Softmax2d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        19.999412037345405
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "LogSoftmax"
      }
    },
    "model": {
      "name": "LogSoftmax_N1_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "LogSoftmax"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        158.618
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "LogSoftmax"
      }
    },
    "model": {
      "name": "LogSoftmax_N1_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "LogSoftmax"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "LogSoftmax"
      }
    },
    "model": {
      "name": "LogSoftmax_N1_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "LogSoftmax"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        9.916063243518646
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 4, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "LogSoftmax"
      }
    },
    "model": {
      "name": "LogSoftmax_N4_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "LogSoftmax"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        263.778
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 4, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "LogSoftmax"
      }
    },
    "model": {
      "name": "LogSoftmax_N4_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "LogSoftmax"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 4, C: 3, H: 256, W: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "LogSoftmax"
      }
    },
    "model": {
      "name": "LogSoftmax_N4_C3_H256_W256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "LogSoftmax"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        23.851296424230096
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 8, N: 8, parts: 2, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "split"
      }
    },
    "model": {
      "name": "split_M8_N8_parts2_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "split"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        6.009
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 8, N: 8, parts: 2, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "split"
      }
    },
    "model": {
      "name": "split_M8_N8_parts2_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "split"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 8, N: 8, parts: 2, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "split"
      }
    },
    "model": {
      "name": "split_M8_N8_parts2_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "split"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.08521181136016474
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 256, N: 512, parts: 2, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "split"
      }
    },
    "model": {
      "name": "split_M256_N512_parts2_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "split"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        5.914
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 256, N: 512, parts: 2, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "split"
      }
    },
    "model": {
      "name": "split_M256_N512_parts2_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "split"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 256, N: 512, parts: 2, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "split"
      }
    },
    "model": {
      "name": "split_M256_N512_parts2_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "split"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        177.2897379697679
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, parts: 2, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "split"
      }
    },
    "model": {
      "name": "split_M512_N512_parts2_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "split"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        6.079
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, parts: 2, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "split"
      }
    },
    "model": {
      "name": "split_M512_N512_parts2_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "split"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, parts: 2, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "split"
      }
    },
    "model": {
      "name": "split_M512_N512_parts2_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "split"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        344.95555704062116
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (1, 1, 1), N: 2, device: cpu, dim: 0",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(1,1,1)_N2_cpu_dim0",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.717
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (1, 1, 1), N: 2, device: cpu, dim: 0",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(1,1,1)_N2_cpu_dim0",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (1, 1, 1), N: 2, device: cpu, dim: 0",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(1,1,1)_N2_cpu_dim0",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0033922799956081777
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (1, 1, 1), N: 2, device: cpu, dim: 1",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(1,1,1)_N2_cpu_dim1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        5.458
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (1, 1, 1), N: 2, device: cpu, dim: 1",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(1,1,1)_N2_cpu_dim1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (1, 1, 1), N: 2, device: cpu, dim: 1",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(1,1,1)_N2_cpu_dim1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002931314551730942
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (1, 1, 1), N: 2, device: cpu, dim: 2",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(1,1,1)_N2_cpu_dim2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        5.493
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (1, 1, 1), N: 2, device: cpu, dim: 2",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(1,1,1)_N2_cpu_dim2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (1, 1, 1), N: 2, device: cpu, dim: 2",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(1,1,1)_N2_cpu_dim2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0029125526682827352
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (1, 1, 1), N: 2, device: cpu, dim: 3",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(1,1,1)_N2_cpu_dim3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        5.964
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (1, 1, 1), N: 2, device: cpu, dim: 3",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(1,1,1)_N2_cpu_dim3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (1, 1, 1), N: 2, device: cpu, dim: 3",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(1,1,1)_N2_cpu_dim3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0026827781818506914
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (512, 512, 2), N: 2, device: cpu, dim: 0",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(512,512,2)_N2_cpu_dim0",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.75
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (512, 512, 2), N: 2, device: cpu, dim: 0",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(512,512,2)_N2_cpu_dim0",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (512, 512, 2), N: 2, device: cpu, dim: 0",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(512,512,2)_N2_cpu_dim0",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        81.64090404934302
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (512, 512, 2), N: 2, device: cpu, dim: 1",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(512,512,2)_N2_cpu_dim1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        105.658
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (512, 512, 2), N: 2, device: cpu, dim: 1",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(512,512,2)_N2_cpu_dim1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (512, 512, 2), N: 2, device: cpu, dim: 1",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(512,512,2)_N2_cpu_dim1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        79.39404565542355
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (512, 512, 2), N: 2, device: cpu, dim: 2",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(512,512,2)_N2_cpu_dim2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        199.893
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (512, 512, 2), N: 2, device: cpu, dim: 2",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(512,512,2)_N2_cpu_dim2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (512, 512, 2), N: 2, device: cpu, dim: 2",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(512,512,2)_N2_cpu_dim2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        41.96550833318024
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (512, 512, 2), N: 2, device: cpu, dim: 3",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(512,512,2)_N2_cpu_dim3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        163.381
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (512, 512, 2), N: 2, device: cpu, dim: 3",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(512,512,2)_N2_cpu_dim3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (512, 512, 2), N: 2, device: cpu, dim: 3",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(512,512,2)_N2_cpu_dim3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        51.34373342704487
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (128, 1024, 2), N: 2, device: cpu, dim: 0",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(128,1024,2)_N2_cpu_dim0",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.961
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (128, 1024, 2), N: 2, device: cpu, dim: 0",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(128,1024,2)_N2_cpu_dim0",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (128, 1024, 2), N: 2, device: cpu, dim: 0",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(128,1024,2)_N2_cpu_dim0",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        41.54379208447893
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (128, 1024, 2), N: 2, device: cpu, dim: 1",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(128,1024,2)_N2_cpu_dim1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.835
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (128, 1024, 2), N: 2, device: cpu, dim: 1",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(128,1024,2)_N2_cpu_dim1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (128, 1024, 2), N: 2, device: cpu, dim: 1",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(128,1024,2)_N2_cpu_dim1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        40.78682316652942
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (128, 1024, 2), N: 2, device: cpu, dim: 2",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(128,1024,2)_N2_cpu_dim2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        154.573
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (128, 1024, 2), N: 2, device: cpu, dim: 2",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(128,1024,2)_N2_cpu_dim2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (128, 1024, 2), N: 2, device: cpu, dim: 2",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(128,1024,2)_N2_cpu_dim2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        27.134744306790086
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (128, 1024, 2), N: 2, device: cpu, dim: 3",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(128,1024,2)_N2_cpu_dim3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        128.246
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (128, 1024, 2), N: 2, device: cpu, dim: 3",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(128,1024,2)_N2_cpu_dim3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "sizes: (128, 1024, 2), N: 2, device: cpu, dim: 3",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "stack"
      }
    },
    "model": {
      "name": "stack_sizes(128,1024,2)_N2_cpu_dim3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "stack"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        32.70517986506003
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 64, V: 32, dim: 0, contiguous: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R64_V32_dim0_contiguousTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.092
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 64, V: 32, dim: 0, contiguous: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R64_V32_dim0_contiguousTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 64, V: 32, dim: 0, contiguous: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R64_V32_dim0_contiguousTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.299558354290063
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 64, V: 32, dim: 0, contiguous: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R64_V32_dim0_contiguousFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.547
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 64, V: 32, dim: 0, contiguous: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R64_V32_dim0_contiguousFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 64, V: 32, dim: 0, contiguous: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R64_V32_dim0_contiguousFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.619048971499442
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 64, V: 32, dim: 1, contiguous: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R64_V32_dim1_contiguousTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.206
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 64, V: 32, dim: 1, contiguous: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R64_V32_dim1_contiguousTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 64, V: 32, dim: 1, contiguous: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R64_V32_dim1_contiguousTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.1098837774081325
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 64, V: 32, dim: 1, contiguous: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R64_V32_dim1_contiguousFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.707
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 64, V: 32, dim: 1, contiguous: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R64_V32_dim1_contiguousFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 64, V: 32, dim: 1, contiguous: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R64_V32_dim1_contiguousFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.419677872371348
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 64, V: 512, dim: 0, contiguous: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R64_V512_dim0_contiguousTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        55.229
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 64, V: 512, dim: 0, contiguous: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R64_V512_dim0_contiguousTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 64, V: 512, dim: 0, contiguous: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R64_V512_dim0_contiguousTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.74649101949899
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 64, V: 512, dim: 0, contiguous: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R64_V512_dim0_contiguousFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        50.352
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 64, V: 512, dim: 0, contiguous: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R64_V512_dim0_contiguousFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 64, V: 512, dim: 0, contiguous: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R64_V512_dim0_contiguousFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.206221756137052
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 64, V: 512, dim: 1, contiguous: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R64_V512_dim1_contiguousTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        47.495
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 64, V: 512, dim: 1, contiguous: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R64_V512_dim1_contiguousTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 64, V: 512, dim: 1, contiguous: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R64_V512_dim1_contiguousTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.519441445122059
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 64, V: 512, dim: 1, contiguous: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R64_V512_dim1_contiguousFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        52.914
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 64, V: 512, dim: 1, contiguous: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R64_V512_dim1_contiguousFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 64, V: 512, dim: 1, contiguous: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R64_V512_dim1_contiguousFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.954192280158746
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 256, V: 32, dim: 0, contiguous: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R256_V32_dim0_contiguousTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.499
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 256, V: 32, dim: 0, contiguous: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R256_V32_dim0_contiguousTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 256, V: 32, dim: 0, contiguous: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R256_V32_dim0_contiguousTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        18.727957092137277
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 256, V: 32, dim: 0, contiguous: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R256_V32_dim0_contiguousFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        5.724
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 256, V: 32, dim: 0, contiguous: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R256_V32_dim0_contiguousFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 256, V: 32, dim: 0, contiguous: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R256_V32_dim0_contiguousFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        11.449498651346085
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 256, V: 32, dim: 1, contiguous: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R256_V32_dim1_contiguousTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.519
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 256, V: 32, dim: 1, contiguous: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R256_V32_dim1_contiguousTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 256, V: 32, dim: 1, contiguous: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R256_V32_dim1_contiguousTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        18.62268083897933
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 256, V: 32, dim: 1, contiguous: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R256_V32_dim1_contiguousFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.992
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 256, V: 32, dim: 1, contiguous: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R256_V32_dim1_contiguousFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 256, V: 32, dim: 1, contiguous: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R256_V32_dim1_contiguousFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        13.127570515246951
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 256, V: 512, dim: 0, contiguous: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R256_V512_dim0_contiguousTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        54.51
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 256, V: 512, dim: 0, contiguous: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R256_V512_dim0_contiguousTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 256, V: 512, dim: 0, contiguous: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R256_V512_dim0_contiguousTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        19.236284947344192
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 256, V: 512, dim: 0, contiguous: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R256_V512_dim0_contiguousFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        54.749
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 256, V: 512, dim: 0, contiguous: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R256_V512_dim0_contiguousFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 256, V: 512, dim: 0, contiguous: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R256_V512_dim0_contiguousFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        19.152515141123086
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 256, V: 512, dim: 1, contiguous: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R256_V512_dim1_contiguousTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        55.205
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 256, V: 512, dim: 1, contiguous: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R256_V512_dim1_contiguousTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 256, V: 512, dim: 1, contiguous: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R256_V512_dim1_contiguousTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        18.994220247509716
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 256, V: 512, dim: 1, contiguous: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R256_V512_dim1_contiguousFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        54.423
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 256, V: 512, dim: 1, contiguous: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R256_V512_dim1_contiguousFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "R: 256, V: 512, dim: 1, contiguous: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sum"
      }
    },
    "model": {
      "name": "sum_R256_V512_dim1_contiguousFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sum"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        19.26731624465304
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.032
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        7.937138999610875
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.363
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.4662284254903653
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.352
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.4824312479908857
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.43
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.3710891723951253
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.658
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.0823183881486567
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.071
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.667401671020048
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.721
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.7351975191282756
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        5.972
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.3716864602527468
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.4
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.862006432255744
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.583
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bool, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bool_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.78740127529191
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.365
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.463565786902177
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.029
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        7.957654532399352
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.327
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.520017064041889
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.418
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.387861997003937
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.645
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.0973584122043367
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.097
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.6449579076995464
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.194
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.9534748183817845
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.378
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.4249492696505524
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.01
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.7217919237777903
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.553
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.uint8, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.uint8_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.3054950961246083
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.348
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.488205530341891
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.318
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.533810072353725
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.03
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        7.955778089704519
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.402
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.410288392312933
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.615
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.1324335759707447
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.085
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.655099223314433
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.994
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.050957224083086
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.379
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.424144570088443
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.02
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.712506295739252
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.515
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int8, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int8_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.3306770801641337
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.477
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        6.615467842333945
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.38
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        6.882917121995213
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.408
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        6.804267183093412
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.03
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        15.912018001848233
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.609
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        6.279632388273226
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.802
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.847853435686017
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.045
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.050281772080697
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.386
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.838050625730026
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.013
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.437491913629479
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.595
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int16, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int16_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.557856699477533
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.701
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        12.13175145294431
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.505
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        13.080787437571338
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.518
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        13.013588176687309
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.59
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        12.649476327296993
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.027
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        31.897439110500045
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.835
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        11.556637305351572
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.17
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        7.857697373058137
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.424
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        9.56869921619094
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.114
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.521896532954194
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.25
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int32, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int32_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.081165163614319
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.838
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        23.094188884788906
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.836
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        23.10677043561531
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.826
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        23.18852886958919
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.693
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        24.339636017862315
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.811
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        23.31341448401012
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.028
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        63.72339790401816
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        5.427
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        12.075019709408787
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        5.828
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        11.244941681347143
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.25
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        15.420217613304809
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.348
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.int64, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.int64_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        19.57352010635135
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.736
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.987834755230355
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.12
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.9767071731811034
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.316
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.796398929483569
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.263
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.843626335880618
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.368
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.7509945139155083
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.304
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.806429586425833
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.03
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        15.903987831415971
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.574
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.5843205990676
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        5.434
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.0152083785780714
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.377
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float16, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float16_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.852218600574247
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.776
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.901396176750577
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.205
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.8965451571687577
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.725
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        6.013254128198139
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.695
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        6.078615335550909
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.759
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.93908797293236
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.583
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.5751400756449847
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.003
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.09270809529129
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.034
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        15.848618200137254
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.187
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.141577554190324
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.033
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.bfloat16, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.bfloat16_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.401984654030455
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.71
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        12.09057600181073
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.188
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        7.825109937987304
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.624
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        12.485755188563633
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.698
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        12.145394097066704
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.819
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        11.623619348542059
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.177
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        7.845395043872552
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.718
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.5764847849347676
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.635
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        9.013821049930712
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.03
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        31.811888714080517
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.101
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float32, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float32_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.567985049813439
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.834
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.bool",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.bool",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        23.124636397886672
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.841
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.uint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.uint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        23.07123544683879
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.816
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.int8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.int8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        23.274317564131692
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.796
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.int16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.int16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        23.435164519557592
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.94
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.int32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.int32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        22.287464390573355
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.06
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.int64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.int64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        21.414492666777388
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4.009
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.float16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        16.34749495820274
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.674
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        17.836741261149818
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.139
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        20.878288004910914
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1.028
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 32, N: 128, device: cpu, dtype_one: torch.float64, dtype_two: torch.float64",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "model": {
      "name": "TensorConversionBenchmark_M32_N128_cpu_dtype_onetorch.float64_dtype_twotorch.float64",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "TensorConversionBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        63.723988463947265
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1, N: 2, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "addcmul"
      }
    },
    "model": {
      "name": "addcmul_M1_N2_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "addcmul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.029
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1, N: 2, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "addcmul"
      }
    },
    "model": {
      "name": "addcmul_M1_N2_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "addcmul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1, N: 2, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "addcmul"
      }
    },
    "model": {
      "name": "addcmul_M1_N2_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "addcmul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.01576881986134461
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1, N: 2, device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "addcmul"
      }
    },
    "model": {
      "name": "addcmul_M1_N2_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "addcmul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.027
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1, N: 2, device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "addcmul"
      }
    },
    "model": {
      "name": "addcmul_M1_N2_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "addcmul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1, N: 2, device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "addcmul"
      }
    },
    "model": {
      "name": "addcmul_M1_N2_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "addcmul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.007895124983965732
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 32, N: 64, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "addcmul"
      }
    },
    "model": {
      "name": "addcmul_M32_N64_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "addcmul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.531
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 32, N: 64, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "addcmul"
      }
    },
    "model": {
      "name": "addcmul_M32_N64_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "addcmul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 32, N: 64, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "addcmul"
      }
    },
    "model": {
      "name": "addcmul_M32_N64_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "addcmul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        12.949078796027852
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 32, N: 64, device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "addcmul"
      }
    },
    "model": {
      "name": "addcmul_M32_N64_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "addcmul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.245
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 32, N: 64, device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "addcmul"
      }
    },
    "model": {
      "name": "addcmul_M32_N64_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "addcmul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 32, N: 64, device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "addcmul"
      }
    },
    "model": {
      "name": "addcmul_M32_N64_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "addcmul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.049118712464399
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1, N: 2, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "addcdiv"
      }
    },
    "model": {
      "name": "addcdiv_M1_N2_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "addcdiv"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.011
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1, N: 2, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "addcdiv"
      }
    },
    "model": {
      "name": "addcdiv_M1_N2_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "addcdiv"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1, N: 2, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "addcdiv"
      }
    },
    "model": {
      "name": "addcdiv_M1_N2_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "addcdiv"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.01591251434802747
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1, N: 2, device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "addcdiv"
      }
    },
    "model": {
      "name": "addcdiv_M1_N2_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "addcdiv"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.02
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1, N: 2, device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "addcdiv"
      }
    },
    "model": {
      "name": "addcdiv_M1_N2_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "addcdiv"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1, N: 2, device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "addcdiv"
      }
    },
    "model": {
      "name": "addcdiv_M1_N2_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "addcdiv"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.007919789202487851
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 32, N: 64, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "addcdiv"
      }
    },
    "model": {
      "name": "addcdiv_M32_N64_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "addcdiv"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.852
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 32, N: 64, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "addcdiv"
      }
    },
    "model": {
      "name": "addcdiv_M32_N64_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "addcdiv"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 32, N: 64, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "addcdiv"
      }
    },
    "model": {
      "name": "addcdiv_M32_N64_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "addcdiv"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        11.490159196071799
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 32, N: 64, device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "addcdiv"
      }
    },
    "model": {
      "name": "addcdiv_M32_N64_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "addcdiv"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.365
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 32, N: 64, device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "addcdiv"
      }
    },
    "model": {
      "name": "addcdiv_M32_N64_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "addcdiv"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 32, N: 64, device: cpu, dtype: torch.bfloat16",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "addcdiv"
      }
    },
    "model": {
      "name": "addcdiv_M32_N64_cpu_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "addcdiv"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.869035634199156
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "shape: (16, 4), k: 4, dim: 1, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "topk"
      }
    },
    "model": {
      "name": "topk_shape(16,4)_k4_dim1_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "topk"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.376
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "shape: (16, 4), k: 4, dim: 1, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "topk"
      }
    },
    "model": {
      "name": "topk_shape(16,4)_k4_dim1_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "topk"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "shape: (16, 4), k: 4, dim: 1, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "topk"
      }
    },
    "model": {
      "name": "topk_shape(16,4)_k4_dim1_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "topk"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.15164092717400285
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "shape: (1048576,), k: 16, dim: 0, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "topk"
      }
    },
    "model": {
      "name": "topk_shape(1048576,)_k16_dim0_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "topk"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1984.207
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "shape: (1048576,), k: 16, dim: 0, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "topk"
      }
    },
    "model": {
      "name": "topk_shape(1048576,)_k16_dim0_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "topk"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "shape: (1048576,), k: 16, dim: 0, device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "topk"
      }
    },
    "model": {
      "name": "topk_shape(1048576,)_k16_dim0_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "topk"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.227687005633928
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "cond_shape: (8, 16, 1), input_shape: (1,), other_shape: (1,), device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "where"
      }
    },
    "model": {
      "name": "where_cond_shape(8,16,1)_input_shape(1,)_other_shape(1,)_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "where"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.674
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "cond_shape: (8, 16, 1), input_shape: (1,), other_shape: (1,), device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "where"
      }
    },
    "model": {
      "name": "where_cond_shape(8,16,1)_input_shape(1,)_other_shape(1,)_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "where"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "cond_shape: (8, 16, 1), input_shape: (1,), other_shape: (1,), device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "where"
      }
    },
    "model": {
      "name": "where_cond_shape(8,16,1)_input_shape(1,)_other_shape(1,)_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "where"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.09874013986887355
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "cond_shape: (8, 16, 1), input_shape: (16, 1), other_shape: (8, 16, 1), device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "where"
      }
    },
    "model": {
      "name": "where_cond_shape(8,16,1)_input_shape(16,1)_other_shape(8,16,1)_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "where"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.719
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "cond_shape: (8, 16, 1), input_shape: (16, 1), other_shape: (8, 16, 1), device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "where"
      }
    },
    "model": {
      "name": "where_cond_shape(8,16,1)_input_shape(16,1)_other_shape(8,16,1)_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "where"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "cond_shape: (8, 16, 1), input_shape: (16, 1), other_shape: (8, 16, 1), device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "where"
      }
    },
    "model": {
      "name": "where_cond_shape(8,16,1)_input_shape(16,1)_other_shape(8,16,1)_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "where"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.30599768213827166
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "cond_shape: (8, 16, 1), input_shape: (8, 1, 1), other_shape: (1,), device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "where"
      }
    },
    "model": {
      "name": "where_cond_shape(8,16,1)_input_shape(8,1,1)_other_shape(1,)_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "where"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.725
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "cond_shape: (8, 16, 1), input_shape: (8, 1, 1), other_shape: (1,), device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "where"
      }
    },
    "model": {
      "name": "where_cond_shape(8,16,1)_input_shape(8,1,1)_other_shape(1,)_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "where"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "cond_shape: (8, 16, 1), input_shape: (8, 1, 1), other_shape: (1,), device: cpu, dtype: torch.float32",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "where"
      }
    },
    "model": {
      "name": "where_cond_shape(8,16,1)_input_shape(8,1,1)_other_shape(1,)_cpu_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "where"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.10717232183288909
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        7.801
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.015382734912934858
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        7.802
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.01538163459631341
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        7.842
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.06120677708550503
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.129
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.02952411051419994
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.267
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.029031847014606576
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.087
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.11870448429748766
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.623
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        6.754291313224332
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        89.216
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.876633514978726
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        79.924
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        26.239444281152654
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        80.451
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        6.516832438707645
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        94.186
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.566512985780611
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.348
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        20.898745734447235
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.359
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.014355994364386412
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.258
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.014531881402081689
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.4
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.05714566606045688
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.802
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.02726741163741624
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.922
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.026899566533834737
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.842
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.10857186153102787
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        86.524
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        6.059474538987214
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        86.344
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        6.072095306655427
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        85.351
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        24.570827048950648
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        87.448
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.995432460005625
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        87.908
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.964021293431466
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.402
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "relu6"
      }
    },
    "model": {
      "name": "relu6_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu6"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        19.709663171013574
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        5.841
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.020543173888631677
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        5.954
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.020155533269436077
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        5.655
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.08487733222121797
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        6.28
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0382156885993976
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        6.541
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.036690192978768126
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        6.304
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.15228577857829897
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        83.289
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        6.294767079948397
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        82.346
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        6.366929525923203
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        81.974
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        25.583116245088878
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        83.224
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        6.299753405000918
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        83.139
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        6.306175297005176
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.423
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardtanh"
      }
    },
    "model": {
      "name": "functional.hardtanh_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardtanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        20.277511001710856
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.789
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.04303201806041938
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.812
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.042676264077589725
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2.807
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.17098093615772042
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.287
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.07302174189024485
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.32
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.07227857330331584
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.317
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.28939916838991964
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        350.846
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.4943525253175007
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        356.6
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.4702397892525756
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        361.935
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.794275586720237
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        352.786
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.4861365898316574
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        357.7
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.4657182072130701
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        363.718
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardsigmoid"
      }
    },
    "model": {
      "name": "functional.hardsigmoid_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardsigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.76587229318529
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.964
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012043078515812041
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.927
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012088801003028329
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.614
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.04992737259557043
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.936
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.021945928357956338
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.018
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0217819167832417
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.899
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.08808398075386709
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        447.394
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.171872082166361
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        449.424
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.166578238158314
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        538.985
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.8909301192101893
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        447.631
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.1712505192374714
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        449.443
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.1665289361612972
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        559.757
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.leaky"
      }
    },
    "model": {
      "name": "functional.leaky_relu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.leaky"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.7465407129693067
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.04
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.03946923337380177
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.042
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.039453140432022894
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.07
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.15633893310317623
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.834
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.06259383599475096
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.862
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.06214259819728892
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.898
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.24628738997362482
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        600.039
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.8737560911593591
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        659.456
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.7950315742993536
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        682.336
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.073487223400617
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        598.944
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.8753539179331221
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        666.221
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.7869582527547085
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        690.043
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.sigmoid"
      }
    },
    "model": {
      "name": "functional.sigmoid_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.sigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.0391633095677335
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.009
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.03987999237846176
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.117
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.03849593451536518
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.09
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.15535451172156875
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.604
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.06658526011719398
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.951
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.06073804795024377
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3.937
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.24382496605647003
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        406.368
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.2901807776192322
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        578.407
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.9064337476563308
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        577.074
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.634111995573601
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        407.924
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.2852602417166117
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        576.398
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.9095940301452418
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        576.702
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.tanh"
      }
    },
    "model": {
      "name": "functional.tanh_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.tanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.636457295899704
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.213
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.013025498615865922
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.233
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012997543352336171
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.291
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.051662684382195415
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.227
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.023466328303362188
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.297
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.023306661773500614
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.245
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.09370338690454837
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        338.963
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.5467410669182018
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        351.964
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.489605246317926
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        354.827
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.910357184584959
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        341.292
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.5361839646774496
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        350.895
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.4941443547169866
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        356.79
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.hardswish"
      }
    },
    "model": {
      "name": "functional.hardswish_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.hardswish"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.877831846097373
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.902
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.01211913163217717
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.878
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012148129354248235
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.046
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0477789269031645
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.891
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.02203659849144575
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.025
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.02176825282082799
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.041
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.08694799565285367
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        159.026
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.2968656289263154
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        458.159
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.1443364922182857
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        464.096
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.518784644325115
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        160.866
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.2591699150134525
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        459.055
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.142103226531821
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        468.897
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.elu"
      }
    },
    "model": {
      "name": "functional.elu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.elu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.472518837280884
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.408
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012754724991087683
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.493
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012641434393101914
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.656
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.04970848620426866
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.531
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.022789493331419768
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.566
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.022713922911825984
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.748
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (2, 3, 4, 5), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(2,3,4,5)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.08931731738773986
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        164.324
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.190579159739254
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        453.714
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.1555470478117755
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        456.615
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (512, 512), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(512,512)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.592819183115855
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        160.677
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.26298423794572
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        455.694
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.1505256418401089
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.704
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "dims: (256, 1024), contig: False, inplace: False, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "functional.celu"
      }
    },
    "model": {
      "name": "functional.celu_dims(256,1024)_contigFalse_inplaceFalse_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "functional.celu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.5421998962443
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N2_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        56.605
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N2_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N2_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00021199450792230975
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N2_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        53.578
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N2_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N2_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00022397075595151513
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N2_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        53.921
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N2_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N2_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00022254618565408646
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N2_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        52.987
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N2_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N2_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00022646907570048213
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N2_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.615
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N2_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N2_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.004992377848655311
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N2_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.301
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N2_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N2_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.005160671835333024
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N8_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        59.567
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N8_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N8_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00322323861028539
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N8_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        55.684
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N8_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N8_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.003448002190829263
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N8_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        63.69
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N8_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N8_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0030146138854408697
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N8_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        56.25
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N8_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N8_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.003413353054990629
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N8_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.217
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N8_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N8_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.07516764071632523
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N8_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.621
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N8_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N8_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.07230847757564403
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N64_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        65.439
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N64_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N64_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.18777762929042663
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N64_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        54.224
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N64_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N64_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.22661472870768568
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N64_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        65.71
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N64_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N64_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.18700350667600257
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N64_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        55.718
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N64_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N64_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.2205378212896089
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N64_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        26.837
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N64_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N64_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.831521460797667
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N64_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        89.892
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N64_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N64_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.5467915901930985
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N512_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        211.16
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N512_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N512_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.7243437376568354
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N512_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        64.667
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N512_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N512_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        12.161320488771997
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N512_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        210.235
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N512_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N512_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.740733036867828
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N512_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        60.078
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N512_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N512_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        13.090179272822319
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N512_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        187.324
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N512_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N512_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        16.79295121920787
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N512_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        713.143
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N512_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_N512_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.4110775857941515
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N2_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.56
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N2_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N2_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0012551942138965034
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N2_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.287
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N2_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N2_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00129210084744663
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N2_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.41
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N2_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N2_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0012752494355497592
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N2_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.228
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N2_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N2_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0013003275051722296
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N2_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.463
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N2_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N2_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.005072230514556148
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N2_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.214
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N2_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N2_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.005209307742225871
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N8_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.114
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N8_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N8_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.01898387805877148
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N8_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.579
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N8_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N8_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.018149310335356612
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N8_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.321
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N8_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N8_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.01860316906114288
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N8_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.58
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N8_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N8_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.018147651972547377
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N8_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.293
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N8_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N8_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.07461456843663404
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N8_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.726
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N8_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N8_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.07160127529294467
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N64_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        27.411
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N64_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N64_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.4482906528848711
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N64_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        83.014
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N64_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N64_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.14802273882105513
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N64_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        50.108
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N64_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N64_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.24523137311655813
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N64_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        86.696
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N64_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N64_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.14173655817369712
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N64_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        40.203
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N64_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N64_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.2225820432378571
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N64_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        90.799
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N64_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N64_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.5413269253893566
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N512_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        196.797
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N512_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N512_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.9961610163221013
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N512_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        644.259
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N512_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N512_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.2206774122323856
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N512_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        477.311
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N512_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N512_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.647628709510551
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N512_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        757.133
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N512_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N512_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.0386975569063996
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N512_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        403.693
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N512_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N512_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        7.792367765925418
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N512_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        704.962
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N512_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_relu_N512_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.462263044565543
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N2_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.742
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N2_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N2_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0012317511773758739
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N2_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.388
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N2_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N2_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0012781646886460916
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N2_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.78
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N2_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N2_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0005509649415891111
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N2_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.414
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N2_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N2_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0010512970542123166
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N2_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.721
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N2_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N2_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.004937572875931857
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N2_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.5
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N2_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N2_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00505243850025895
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N8_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.275
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N8_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N8_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.01868678610837999
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N8_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.631
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N8_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N8_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.019936099016748095
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N8_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        398.098
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N8_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N8_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0004822937832033128
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N8_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        378.662
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N8_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N8_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0005070491312952366
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N8_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.103
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N8_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N8_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0760184960090585
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N8_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.402
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N8_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N8_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.08168048448427312
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N64_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        22.912
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N64_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N64_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.5363020581347955
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N64_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        16.513
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N64_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N64_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.7441256531264469
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N64_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        407.667
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N64_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N64_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.03014226157687908
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N64_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        380.121
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N64_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N64_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.032326533636204434
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N64_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        20.722
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N64_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N64_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.37202428639774
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N64_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.901
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N64_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N64_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.129967259327557
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N512_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        335.726
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N512_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N512_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.3424847758839253
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N512_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        272.826
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N512_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N512_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.8825410485489305
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N512_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        679.448
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N512_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N512_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.1574574940330222
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N512_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        406.674
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N512_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N512_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.9338160914764866
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N512_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        142.095
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N512_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N512_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        22.138272194599697
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N512_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        79.008
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N512_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_N512_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        39.81513724328702
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N2_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.524
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N2_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N2_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0009384760577528013
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N2_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.316
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N2_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N2_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0009620014319680219
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N2_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.653
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N2_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N2_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0009245320366321998
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N2_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.368
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N2_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N2_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0009559670201054482
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N2_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.544
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N2_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N2_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0037454595732687064
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N2_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.377
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N2_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N2_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0038201729324295677
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N8_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.007
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N8_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N8_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.014210823232720712
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N8_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.646
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N8_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N8_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.014804389356198197
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N8_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.597
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N8_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N8_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.014889454039577683
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N8_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.21
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N8_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N8_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.015591469914938769
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N8_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.726
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N8_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N8_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.05867623421557977
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N8_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.302
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N8_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N8_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.06166983621645117
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N64_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        18.484
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N64_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N64_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.44320177073424
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N64_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        15.85
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N64_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N64_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.5168506432394766
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N64_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.961
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N64_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N64_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.6320721852277917
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N64_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.602
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N64_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N64_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.9523121716663263
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N64_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.137
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N64_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N64_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.6997401067346662
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N64_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.585
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N64_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N64_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.4188531052875706
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N512_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.577
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N512_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N512_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.27720871549542
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N512_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.424
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N512_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N512_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.020754193509327
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N512_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        80.467
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N512_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N512_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        6.515583871435241
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N512_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        55.916
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N512_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N512_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        9.376398868993906
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N512_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        85.716
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N512_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N512_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        24.466243333331825
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N512_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        59.023
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N512_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "add"
      }
    },
    "model": {
      "name": "add_scalar_N512_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "add"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        35.53103671920594
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N2_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.674
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N2_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N2_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0009223403561289985
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N2_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.445
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N2_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N2_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0009473620399538414
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N2_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.565
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N2_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N2_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0009340228945187996
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N2_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.398
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N2_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N2_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0009525564382421273
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N2_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.493
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N2_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N2_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.003767659616756943
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N2_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.433
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N2_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 2, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N2_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0037945420386333506
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N8_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.703
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N8_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N8_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.014708076139525041
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N8_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.334
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N8_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N8_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.015358955357153538
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N8_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.727
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N8_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N8_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.014667319212033667
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N8_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.395
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N8_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N8_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.015247446552368125
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N8_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.688
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N8_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N8_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.05893162262924898
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N8_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.12
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N8_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N8_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.06305245403992556
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N64_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.914
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N64_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N64_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.6343455896124244
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N64_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.853
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N64_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N64_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.9253873084752863
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N64_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.022
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N64_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N64_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.6290982918510266
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N64_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        8.786
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N64_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N64_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.9323409583882829
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N64_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.434
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N64_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N64_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.6352713534550727
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N64_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.764
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N64_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N64_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.3558401031926848
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N512_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        80.297
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N512_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N512_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        6.529359319920425
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N512_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        58.285
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N512_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N512_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        8.995213923661128
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N512_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        81.267
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N512_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N512_dtypetorch.qint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        6.4513928759605
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N512_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        56.379
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N512_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N512_dtypetorch.qint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        9.299276473835043
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N512_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        85.189
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N512_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N512_dtypetorch.qint32_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        24.61777144772665
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N512_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        60.07
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N512_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 512, dtype: torch.qint32, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "mul"
      }
    },
    "model": {
      "name": "mul_scalar_N512_dtypetorch.qint32_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "mul"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        34.911762939872794
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        247.079
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.000582809902775532
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        298.359
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.000482639258993488
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        244.691
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0011116057029869914
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        304.232
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.000894054214087936
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        246.634
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.004216776630818434
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        316.359
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.003287408371736467
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        265.492
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0005423882451928344
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        321.57
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0004478025519752917
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        266.599
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0010202569772279407
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        323.501
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0008408023522208252
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        268.527
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0038729751479576486
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        339.542
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0030629521580750585
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        469.408
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00030676956630412396
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        516.425
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00027883995582995665
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        468.177
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0005809766542211246
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        520.249
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0005228262574210985
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        472.74
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002199939396561227
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        536.136
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0019398056122630902
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        487.46
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0002954087297317938
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        533.594
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00026986785382925385
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        488.136
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0005572217494873023
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        539.554
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0005041200086616394
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        486.076
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0021395840513276643
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        547.705
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.001898832669338049
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        71.663
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0020094083591089724
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        71.888
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002003108817928053
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        72.67
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0037429714995648703
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        72.272
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0037635590386471663
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        75.483
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.013777925374352776
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        75.377
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.013797336430682348
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        81.184
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0017737553495667281
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        81.967
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.001756812816110903
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        82.014
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.003316490522497166
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        82.788
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.003285484266237834
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        85.718
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012132807511972462
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        86.099
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012079178112345894
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        314.745
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00045751326110464013
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        313.978
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0004586312894838385
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        314.394
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0008651571558564404
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        315.921
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0008609750537450645
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        315.737
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.003293879968860147
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        316.908
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0032817094130474195
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        310.088
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0004643839181816411
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        309.008
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0004660069133345226
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        312.454
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.000870527591484656
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        313.197
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0008684616010889622
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        319.056
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.003259620802638348
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        317.532
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbeddingBag"
      }
    },
    "model": {
      "name": "qatEmbeddingBag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0032752643142154553
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings10_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        233.268
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings10_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings10_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.000548725277422764
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings10_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        234.057
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings10_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings10_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0010937486523374831
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings10_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        235.355
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings10_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings10_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.004350868850236495
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings120_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        252.253
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings120_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings120_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0005074271527612579
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings120_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        255.307
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings120_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings120_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0010027132279168073
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings120_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        254.425
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings120_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings120_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.004024762197115668
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings1000_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        456.976
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings1000_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings1000_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00028010216261353067
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings1000_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        454.346
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings1000_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings1000_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0005634475074709834
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings1000_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.996
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings1000_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings1000_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0022212786608405695
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings2300_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        469.704
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings2300_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings2300_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0002725118180704768
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings2300_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        470.821
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings2300_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings2300_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0005437312084190445
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings2300_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        477.187
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings2300_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings2300_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002145907248918078
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings10_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        60.288
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings10_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings10_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0021231544883943344
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings10_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        60.975
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings10_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings10_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0041984239960800975
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings10_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        66.6
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings10_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 10, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings10_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.015375302943008448
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings120_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        68.836
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings120_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings120_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0018594996509435143
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings120_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        70.226
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings120_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings120_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0036453509280257395
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings120_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        74.897
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings120_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 120, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings120_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.01367218043402571
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings1000_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        290.19
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings1000_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings1000_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0004410904654853121
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings1000_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        293.524
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings1000_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings1000_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0008721592765206346
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings1000_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        297.746
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings1000_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 1000, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings1000_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0034391752676371334
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings2300_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        322.267
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings2300_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings2300_embedding_dim64_input_size8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00039718607281857116
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings2300_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        327.031
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings2300_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 16, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings2300_embedding_dim64_input_size16_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0007827995650308272
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings2300_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        330.122
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings2300_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 2300, embedding_dim: 64, input_size: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qatEmbedding"
      }
    },
    "model": {
      "name": "qatEmbedding_num_embeddings2300_embedding_dim64_input_size64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qatEmbedding"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0031018802045755375
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "M: 1, N: 256, K: 3136, device: cpu, dtype: torch.qint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QBatchNorm1d"
      }
    },
    "model": {
      "name": "QBatchNorm1d_M1_N256_K3136_cpu_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QBatchNorm1d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1289.786
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "M: 1, N: 256, K: 3136, device: cpu, dtype: torch.qint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QBatchNorm1d"
      }
    },
    "model": {
      "name": "QBatchNorm1d_M1_N256_K3136_cpu_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QBatchNorm1d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "M: 1, N: 256, K: 3136, device: cpu, dtype: torch.qint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QBatchNorm1d"
      }
    },
    "model": {
      "name": "QBatchNorm1d_M1_N256_K3136_cpu_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QBatchNorm1d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.2480586513336254
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "M: 1, N: 256, K: 3136, device: cpu, dtype: torch.qint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QBatchNorm2d"
      }
    },
    "model": {
      "name": "QBatchNorm2d_M1_N256_K3136_cpu_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QBatchNorm2d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1161.98
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "M: 1, N: 256, K: 3136, device: cpu, dtype: torch.qint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QBatchNorm2d"
      }
    },
    "model": {
      "name": "QBatchNorm2d_M1_N256_K3136_cpu_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QBatchNorm2d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "M: 1, N: 256, K: 3136, device: cpu, dtype: torch.qint8",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QBatchNorm2d"
      }
    },
    "model": {
      "name": "QBatchNorm2d_M1_N256_K3136_cpu_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QBatchNorm2d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.3853321122634605
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: all, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contigall_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        316.225
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: all, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contigall_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: all, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contigall_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        null
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: all, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contigall_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        317.371
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: all, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contigall_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: all, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contigall_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        null
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: all, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contigall_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        300.022
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: all, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contigall_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: all, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contigall_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        null
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: one, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contigone_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        385.738
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: one, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contigone_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: one, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contigone_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        null
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: one, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contigone_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        386.288
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: one, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contigone_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: one, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contigone_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        null
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: one, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contigone_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        375.065
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: one, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contigone_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: one, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contigone_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        null
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: none, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contignone_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        448.385
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: none, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contignone_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: none, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contignone_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        null
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: none, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contignone_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        448.079
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: none, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contignone_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: none, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contignone_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        null
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: none, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contignone_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        450.536
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: none, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contignone_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 1, L: 2, dim: 0, contig: none, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M256_N512_K1_L2_dim0_contignone_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        null
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: all, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contigall_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        473.476
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: all, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contigall_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: all, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contigall_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        null
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: all, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contigall_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        478.216
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: all, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contigall_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: all, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contigall_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        null
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: all, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contigall_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        439.766
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: all, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contigall_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: all, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contigall_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        null
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: one, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contigone_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        568.68
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: one, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contigone_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: one, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contigone_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        null
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: one, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contigone_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        575.783
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: one, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contigone_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: one, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contigone_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        null
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: one, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contigone_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        561.133
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: one, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contigone_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: one, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contigone_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        null
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: none, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contignone_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        653.342
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: none, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contignone_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: none, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contignone_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        null
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: none, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contignone_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        663.39
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: none, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contignone_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: none, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contignone_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        null
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: none, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contignone_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        659.331
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: none, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contignone_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "M: 512, N: 512, K: 2, L: 1, dim: 1, contig: none, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qcat"
      }
    },
    "model": {
      "name": "qcat_M512_N512_K2_L1_dim1_contignone_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qcat"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        null
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.156
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0017429788451669651
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        125.325
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0015320106729330713
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        66.36
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0028933261175998906
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        78.48
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0024464802968857777
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.621
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0018709606593802276
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.494
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0016341234423230702
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        62.128
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0030903742760889537
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        72.175
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0026601829844359374
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.415
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.001738887556920714
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.607
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00154084861722216
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        66.519
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0028863902153826258
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        78.094
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002458570471565102
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.161
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0018611686452265875
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.57
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.001619301986921774
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        62.021
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.003095743579328437
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        72.435
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002650654138556972
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.391
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006957119518146641
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        125.994
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006095542388683862
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        67.63
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.011355965911484692
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.329
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.009931580720308008
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.274
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0075092186756471275
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.923
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006457978011165598
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        61.33
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012522450834349651
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        72.553
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.01058536572843316
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.784
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.10522016300738365
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        129.067
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.09520619470146094
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        73.671
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.16679521081083776
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        85.722
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.14334720327549852
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.787
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.11295465212744064
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.845
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.09922077190432228
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        65.128
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.188675993316236
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.827
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.1578876643298238
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.774
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.10433569186252688
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.277
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0943220630592611
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        73.516
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.1671464890629763
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        86.52
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.14202466222114404
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.238
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.11458629816789688
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.994
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.10155880009589918
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        66.337
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.1852363846546838
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.683
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.15818061526560273
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.872
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.42056241945335276
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        129.494
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.3795704146514035
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        73.068
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.6726841420245144
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        85.945
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.5718989476914731
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.366
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.4494250018557749
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.358
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.40838274080007336
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        65.222
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.7536130566600053
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        78.057
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "eq"
      }
    },
    "model": {
      "name": "eq_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "eq"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.6296970836685791
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.478
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.001753770969742218
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.683
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0015650069240521322
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        67.442
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002846894460707069
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.248
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002485493128488567
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.489
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0018918376531667305
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.393
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0016355249651852852
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        60.995
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0031478241345796586
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        71.885
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002670928466868379
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.069
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0017766447760408526
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.615
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0015532055215596607
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        66.744
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0028766720477736572
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.136
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0024891246643054584
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.25
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0018962886174989002
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.451
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0016347235851252378
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        60.823
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00315672602136115
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        71.61
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002681175164138142
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.473
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.007015409456942649
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.612
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0062129945452742905
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        65.789
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.011673649934766989
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.523
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.009906680608534469
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.844
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.007615743615001841
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.953
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006511047957563028
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        61.994
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012388270163184044
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        72.086
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.010653980060741832
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.443
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.10737245648960905
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.01
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.09451613393401057
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        73.426
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.16735103945110177
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        86.081
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.14274938037814636
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.132
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.11469958743093932
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.361
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.10125183295588976
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        63.1
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.19473790848895717
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        76.601
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.1604149182514485
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.495
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.10458280262040642
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        131.008
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.09379551413873517
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        74.103
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.16582368237944914
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        86.621
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.14185912164593764
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        105.418
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.11656425800167226
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.79
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.10089465852654352
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        63.748
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.1927588500857095
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.331
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.1589019821951743
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.409
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.4334060352870008
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        129.52
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.3794945391020771
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        72.892
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.6743120479484396
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        86.153
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.5705173891741095
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.975
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.46822775568012204
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.957
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.4097453913246033
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        65.425
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.7512773583665228
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        78.535
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ne"
      }
    },
    "model": {
      "name": "ne_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ne"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.6258584997836684
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.189
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0017424576050045892
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.772
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0015512343012264948
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        67.424
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002847649589411511
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        76.745
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0025017814045671296
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.775
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0019052320699226451
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.362
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0016643249855917124
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        61.671
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.003113273539090336
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        68.897
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0027867689769811273
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.432
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0017386266203770697
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.065
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0015601453555744095
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        67.217
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002856400078889585
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.089
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0024906151889738477
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.589
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0018899618434566133
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.198
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0016523452052983915
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        61.555
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.003119143633633814
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        70.001
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0027428112818885615
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.21
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.007097325295786302
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.66
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006210565387057679
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        67.472
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.01138248232635429
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.083
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.009963333000757217
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.764
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.007473449798692235
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.72
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006579877173753563
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        62.193
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012348624584511782
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        69.471
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.011055004703091759
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.328
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.10563247834743637
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.292
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.09431158251938694
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        74.139
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.16574202788648182
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        86.086
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.14274039883189737
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.522
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.11428390684308136
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.83
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.10254569212585946
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        65.648
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.18717929504980166
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        76.36
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.1609211224972854
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.398
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.1046700070639954
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        129.265
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.09506058833694231
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        73.922
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.16622964095667012
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        86.411
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.14220370772163454
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.856
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.11288339635600707
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.684
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.10098246716458069
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        65.815
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.18670404351373873
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        76.509
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.16060878677592283
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.56
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.4181019151760999
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        129.898
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.37838819270341506
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        73.335
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.6702426714957245
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        85.178
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.5770488750849567
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.523
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.4529191032204377
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.552
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.40772552384576083
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        64.79
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.758632415818469
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        75.825
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "lt"
      }
    },
    "model": {
      "name": "lt_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.6482327244238123
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.286
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0017252898720632828
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.207
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0015583588645082483
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        66.88
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0028708340012039927
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        76.622
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0025057922689238257
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.965
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.001882996422289658
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.596
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0016467132584751442
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        60.305
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.003183828402780895
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        72.233
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002658063493449791
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.639
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0017512072713211872
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.911
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0015621015154579244
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        66.478
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002888172811529318
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        76.485
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002510308895605921
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.554
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0019094299804023767
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.919
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0016421573655377823
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        61.127
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0031410129545798213
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        72.413
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002651450013453144
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.242
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.007030273613690602
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.364
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006276356151726368
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        66.12
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.011615325816364843
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.724
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.009881055508650228
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.996
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.007456628762774461
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.104
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006614759875765887
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        61.269
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012534956696949111
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        72.474
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.010596934788348004
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.89
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.10512453677924197
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.256
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.09433719817326901
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        74.005
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.1660428279324449
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        85.969
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.14293577848368072
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.208
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.11569701755259224
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.472
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.1003335321396243
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        65.693
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.18705118105455484
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.695
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.15815613220228364
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.276
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.10568003046047207
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        129.849
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.09463302514505519
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        74.276
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.1654367293089076
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        86.713
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.14170822353866508
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.464
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.11541934409402482
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.112
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.10316333993961997
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        64.436
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.19070083889556275
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.039
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.15950458876497992
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.829
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.4280467668156705
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.593
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.37637413893906435
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        73.188
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.6715878744307471
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        84.834
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.579389355950973
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.833
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.46008358695028917
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.505
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.4045249492899534
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        65.774
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.7472897583228285
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.583
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "gt"
      }
    },
    "model": {
      "name": "gt_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.6335421289557306
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.203
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0017422420688422587
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.644
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0015403884087036178
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        66.595
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0028831172663703578
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        76.618
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0025059297623473338
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.101
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0018804898706106996
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.042
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.001640430601004691
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        59.763
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0032126772240127135
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        71.611
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0026811472239707352
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.573
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0017522601596375276
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.358
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.001543928802973206
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        68.007
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0028232429356055255
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.56
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002475514087398411
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.543
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.001872384969368905
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.781
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0016440985095637214
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        60.078
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0031958207153949306
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        71.879
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002671138737227464
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.254
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006965764716206771
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.079
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0062910168890311525
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        66.054
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.011626924687500848
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        76.922
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.009984129495716301
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.623
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.007557357258003305
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.249
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0065501347690440775
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        60.971
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012596176132203795
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        72.827
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.010545532822444536
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.291
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.10658233957804118
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        131.23
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.09363681488008319
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        73.105
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.16808714940144678
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        85.613
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.14353012805704937
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        105.481
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.11649455225324423
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.707
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.1018002032760855
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        64.687
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.1899614795820318
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.816
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.15791171364743659
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.926
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.10509192005609004
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.272
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.09432548430672476
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        74.018
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.1660138728076958
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        86.156
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.1426243606423516
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.1
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.11473403935189704
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.981
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.10156978694461824
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        64.591
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.1902436645516804
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.687
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.158173232392881
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.957
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.43132212346717663
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        128.872
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.3814019598655858
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        72.979
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.6735079697085552
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        85.837
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.5726204270232812
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.815
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.46016137319442313
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.986
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.40626288052925064
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        64.345
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.763880298079439
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        78.45
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "le"
      }
    },
    "model": {
      "name": "le_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "le"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.6265429075591556
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.313
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00175642402224697
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.593
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0015661573868051204
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        65.596
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0029270125691195415
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.236
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0024859026882157464
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.62
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0019081608577155393
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.275
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0016371736930712259
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        61.102
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.003142301196342181
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        72.348
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0026538503634113628
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.98
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0017617976789359863
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        125.414
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.001530930091534215
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        67.205
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0028569513574431406
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.227
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.002486172302871495
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.305
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.001914171085855581
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.243
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0016376246829915135
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        61.416
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.003126227892928077
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        72.165
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0026605580646133433
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.159
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.007035604269649772
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.087
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006239504095925483
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        65.936
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.011647629381218001
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.82
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.009868987583472013
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.88
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0075383095565802576
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.749
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.006578213059470266
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        60.374
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.01272078490628553
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        72.683
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 8, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N8_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.010566426318878447
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.477
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.10641048225337765
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        129.878
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.quint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.09461195120714457
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        74.097
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.16583562234722107
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        85.679
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.quint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.14341921973650307
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.761
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.11402987081930709
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.378
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.quint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.10123743594974222
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        64.255
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.19123865817227845
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        78.104
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.quint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.quint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.1573284128222363
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.62
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.10447163109156109
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.851
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint8_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.09390821545057988
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        73.266
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.16771847917370755
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        85.862
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint8_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.14311362839477929
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.668
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.11968685931484352
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.351
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint8_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.10125965679385464
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        65.364
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.18799203909926618
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.698
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint8, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint8_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.15815165815982632
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.16
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.4343586368455839
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.84
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint32_contigFalse_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.37566492978859595
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        72.462
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.6783107282820612
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        85.608
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: False, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint32_contigFalse_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.5741490058504044
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        105.791
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.4646151315643262
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.947
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: False, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint32_contigTrue_other_scalarFalse_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.4097793069906493
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        62.386
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.7878672972473982
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        78.579
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 64, dtype: torch.qint32, contig: True, other_scalar: True, out_variant: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "ge"
      }
    },
    "model": {
      "name": "ge_N64_dtypetorch.qint32_contigTrue_other_scalarTrue_out_variantTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ge"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.6255116976077579
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 128, OC: 256, kernel: 3, stride: 1, N: 1, L: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QConv1d"
      }
    },
    "model": {
      "name": "QConv1d_IC128_OC256_kernel3_stride1_N1_L64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QConv1d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        128.439
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 128, OC: 256, kernel: 3, stride: 1, N: 1, L: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QConv1d"
      }
    },
    "model": {
      "name": "QConv1d_IC128_OC256_kernel3_stride1_N1_L64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QConv1d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 128, OC: 256, kernel: 3, stride: 1, N: 1, L: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QConv1d"
      }
    },
    "model": {
      "name": "QConv1d_IC128_OC256_kernel3_stride1_N1_L64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QConv1d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.1275629554839703
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 256, OC: 256, kernel: 3, stride: 2, N: 4, L: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QConv1d"
      }
    },
    "model": {
      "name": "QConv1d_IC256_OC256_kernel3_stride2_N4_L64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QConv1d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        203.938
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 256, OC: 256, kernel: 3, stride: 2, N: 4, L: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QConv1d"
      }
    },
    "model": {
      "name": "QConv1d_IC256_OC256_kernel3_stride2_N4_L64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QConv1d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 256, OC: 256, kernel: 3, stride: 2, N: 4, L: 64, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QConv1d"
      }
    },
    "model": {
      "name": "QConv1d_IC256_OC256_kernel3_stride2_N4_L64_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QConv1d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.6427062014688358
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 256, OC: 256, kernel: 3, stride: 1, N: 1, H: 16, W: 16, G: 1, pad: 0, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QConv2d"
      }
    },
    "model": {
      "name": "QConv2d_IC256_OC256_kernel3_stride1_N1_H16_W16_G1_pad0_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QConv2d"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        293.929
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 256, OC: 256, kernel: 3, stride: 1, N: 1, H: 16, W: 16, G: 1, pad: 0, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QConv2d"
      }
    },
    "model": {
      "name": "QConv2d_IC256_OC256_kernel3_stride1_N1_H16_W16_G1_pad0_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QConv2d"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "IC: 256, OC: 256, kernel: 3, stride: 1, N: 1, H: 16, W: 16, G: 1, pad: 0, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QConv2d"
      }
    },
    "model": {
      "name": "QConv2d_IC256_OC256_kernel3_stride1_N1_H16_W16_G1_pad0_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QConv2d"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.4459306654698656
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_prepack_num_embeddings80_embedding_dim128",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        52.159
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_prepack_num_embeddings80_embedding_dim128",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_prepack_num_embeddings80_embedding_dim128",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.5705903388227234
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_prepack_num_embeddings80_embedding_dim256",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        53.624
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_prepack_num_embeddings80_embedding_dim256",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_prepack_num_embeddings80_embedding_dim256",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.0553647592446205
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_prepack_num_embeddings80_embedding_dim512",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        55.706
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_prepack_num_embeddings80_embedding_dim512",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_prepack_num_embeddings80_embedding_dim512",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.882263448909108
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_prepack_num_embeddings80_embedding_dim128",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        53.687
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_prepack_num_embeddings80_embedding_dim128",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_prepack_num_embeddings80_embedding_dim128",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.5258891722992094
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_prepack_num_embeddings80_embedding_dim256",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        55.851
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_prepack_num_embeddings80_embedding_dim256",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_prepack_num_embeddings80_embedding_dim256",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.933536908930339
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_prepack_num_embeddings80_embedding_dim512",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        59.43
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_prepack_num_embeddings80_embedding_dim512",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_prepack_num_embeddings80_embedding_dim512",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.5136937816697795
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_prepack_num_embeddings80_embedding_dim128",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        53.772
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_prepack_num_embeddings80_embedding_dim128",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_prepack_num_embeddings80_embedding_dim128",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.5234598928105738
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_prepack_num_embeddings80_embedding_dim256",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        55.598
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_prepack_num_embeddings80_embedding_dim256",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_prepack_num_embeddings80_embedding_dim256",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.9468900691774027
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_prepack_num_embeddings80_embedding_dim512",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        59.517
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_prepack_num_embeddings80_embedding_dim512",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_prepack_num_embeddings80_embedding_dim512",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.505657333828846
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_unpack_num_embeddings80_embedding_dim128",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        54.333
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_unpack_num_embeddings80_embedding_dim128",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_unpack_num_embeddings80_embedding_dim128",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.4004919554075293
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_unpack_num_embeddings80_embedding_dim256",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        55.185
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_unpack_num_embeddings80_embedding_dim256",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_unpack_num_embeddings80_embedding_dim256",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.7654250059049582
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_unpack_num_embeddings80_embedding_dim512",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        55.848
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_unpack_num_embeddings80_embedding_dim512",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_unpack_num_embeddings80_embedding_dim512",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.4897690513143866
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_unpack_num_embeddings80_embedding_dim128",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        56.576
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_unpack_num_embeddings80_embedding_dim128",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_unpack_num_embeddings80_embedding_dim128",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.3846146777093701
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_unpack_num_embeddings80_embedding_dim256",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        59.257
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_unpack_num_embeddings80_embedding_dim256",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_unpack_num_embeddings80_embedding_dim256",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.712829266661432
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_unpack_num_embeddings80_embedding_dim512",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        66.982
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_unpack_num_embeddings80_embedding_dim512",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_unpack_num_embeddings80_embedding_dim512",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.2421158125823772
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_unpack_num_embeddings80_embedding_dim128",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        60.035
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_unpack_num_embeddings80_embedding_dim128",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_unpack_num_embeddings80_embedding_dim128",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.36245276809184857
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_unpack_num_embeddings80_embedding_dim256",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        67.258
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_unpack_num_embeddings80_embedding_dim256",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_unpack_num_embeddings80_embedding_dim256",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.6280279087254423
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_unpack_num_embeddings80_embedding_dim512",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        94.788
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_unpack_num_embeddings80_embedding_dim512",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_unpack_num_embeddings80_embedding_dim512",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.8777494224520919
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_prepack_num_embeddings80_embedding_dim128_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        71.941
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_prepack_num_embeddings80_embedding_dim128_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_prepack_num_embeddings80_embedding_dim128_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        11.387157108221794
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_prepack_num_embeddings80_embedding_dim256_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.531
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_prepack_num_embeddings80_embedding_dim256_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_prepack_num_embeddings80_embedding_dim256_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        16.136942601795827
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_prepack_num_embeddings80_embedding_dim512_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        153.175
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_prepack_num_embeddings80_embedding_dim512_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_prepack_num_embeddings80_embedding_dim512_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        21.392497497593272
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_prepack_num_embeddings80_embedding_dim128_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        45.013
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_prepack_num_embeddings80_embedding_dim128_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_prepack_num_embeddings80_embedding_dim128_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        18.1990011579665
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_prepack_num_embeddings80_embedding_dim256_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        45.068
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_prepack_num_embeddings80_embedding_dim256_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_prepack_num_embeddings80_embedding_dim256_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        36.35413088947765
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_prepack_num_embeddings80_embedding_dim512_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        45.237
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_prepack_num_embeddings80_embedding_dim512_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_prepack_num_embeddings80_embedding_dim512_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        72.4356696853461
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_prepack_num_embeddings80_embedding_dim128_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        45.771
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_prepack_num_embeddings80_embedding_dim128_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_prepack_num_embeddings80_embedding_dim128_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        17.897866666112385
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_prepack_num_embeddings80_embedding_dim256_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        45.023
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_prepack_num_embeddings80_embedding_dim256_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_prepack_num_embeddings80_embedding_dim256_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        36.390111591246736
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_prepack_num_embeddings80_embedding_dim512_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        46.267
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_prepack_num_embeddings80_embedding_dim512_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_prepack_num_embeddings80_embedding_dim512_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        70.82318539118981
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_unpack_num_embeddings80_embedding_dim128_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        56.371
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_unpack_num_embeddings80_embedding_dim128_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_unpack_num_embeddings80_embedding_dim128_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.860152397467323
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_unpack_num_embeddings80_embedding_dim256_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        56.724
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_unpack_num_embeddings80_embedding_dim256_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_unpack_num_embeddings80_embedding_dim256_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        7.446595435828388
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_unpack_num_embeddings80_embedding_dim512_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        58.692
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_unpack_num_embeddings80_embedding_dim512_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_byte_unpack_num_embeddings80_embedding_dim512_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        14.175706189046055
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_unpack_num_embeddings80_embedding_dim128_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        54.403
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_unpack_num_embeddings80_embedding_dim128_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_unpack_num_embeddings80_embedding_dim128_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.999810670706859
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_unpack_num_embeddings80_embedding_dim256_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        54.639
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_unpack_num_embeddings80_embedding_dim256_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_unpack_num_embeddings80_embedding_dim256_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        7.730749559280426
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_unpack_num_embeddings80_embedding_dim512_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        53.949
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_unpack_num_embeddings80_embedding_dim512_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_4bit_unpack_num_embeddings80_embedding_dim512_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        15.421864334268747
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_unpack_num_embeddings80_embedding_dim128_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        55.255
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_unpack_num_embeddings80_embedding_dim128_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 128, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_unpack_num_embeddings80_embedding_dim128_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        3.938102208916928
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_unpack_num_embeddings80_embedding_dim256_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        54.726
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_unpack_num_embeddings80_embedding_dim256_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 256, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_unpack_num_embeddings80_embedding_dim256_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        7.718506928379327
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_unpack_num_embeddings80_embedding_dim512_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        55.741
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_unpack_num_embeddings80_embedding_dim512_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "num_embeddings: 80, embedding_dim: 512, batch_size: 10",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qembeddingbag"
      }
    },
    "model": {
      "name": "qembeddingbag_2bit_unpack_num_embeddings80_embedding_dim512_batch_size10",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qembeddingbag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        14.926161695239413
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        34.771
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.004141365362824466
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        83.345
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0017277532633194358
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        34.918
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.004123946090219999
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        83.876
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0017168192489702967
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        35.013
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.007768566322940358
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        68.735
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.003957207097068587
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        34.908
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.007791960624648155
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        69.739
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0039002639419092374
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        36.281
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.028665380769064035
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        85.159
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012212413795631651
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        36.318
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.028636173461804713
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        85.458
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 10, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags10_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012169684440741884
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        34.759
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.004142778366068671
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        86.25
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0016695598820995242
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        34.672
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.004153231567917767
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        84.53
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0017035380323360894
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        34.996
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.007772393840155847
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        68.975
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0039434533593430375
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        34.691
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.007840643391250813
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        69.994
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.003886058861163625
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        36.276
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.028669410583254517
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        85.312
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012190600530114672
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        36.267
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.028676227684086356
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        84.768
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 120, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags120_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012268808798903656
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        34.726
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.004146727171462763
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        85.638
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0016814877039254923
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        34.83
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.004134349401635569
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        80.543
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.001787873205249782
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        34.841
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.007806907970823467
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        70.174
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0038760632343551238
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        35.031
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.007764636715470064
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        68.899
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0039478312335807985
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        36.372
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.028593091994876287
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        85.318
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012189703439198292
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        36.38
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0285870297986988
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        85.467
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 1000, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags1000_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012168468779248685
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        34.961
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.004118848887443671
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        82.569
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.001744003785335633
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        34.756
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.004143206917002112
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        84.253
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 8, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size8_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0017091440108006944
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        34.931
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00778687954811733
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        73.06
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0037229592389769303
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        35.125
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.007743757160527638
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        70.468
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 16, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size16_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0038599040892734054
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        36.222
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.02871152890198554
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        85.872
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: True, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseTrue_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.012111019826478569
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        36.186
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: True, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetTrue_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.02874027025695075
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        85.277
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "embeddingbags: 2300, dim: 64, mode: sum, input_size: 64, offset: 0, sparse: False, include_last_offset: False, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "qEmbeddingBag"
      }
    },
    "model": {
      "name": "qEmbeddingBag_embeddingbags2300_dim64_modesum_input_size64_offset0_sparseFalse_include_last_offsetFalse_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qEmbeddingBag"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.01219559769375709
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (32, 8, 16), num_groups: 2, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QGroupNormBenchmark"
      }
    },
    "model": {
      "name": "QGroupNormBenchmark_dims(32,8,16)_num_groups2_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QGroupNormBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        63.114
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (32, 8, 16), num_groups: 2, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QGroupNormBenchmark"
      }
    },
    "model": {
      "name": "QGroupNormBenchmark_dims(32,8,16)_num_groups2_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QGroupNormBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (32, 8, 16), num_groups: 2, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QGroupNormBenchmark"
      }
    },
    "model": {
      "name": "QGroupNormBenchmark_dims(32,8,16)_num_groups2_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QGroupNormBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.13081176384756635
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (32, 8, 16), num_groups: 4, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QGroupNormBenchmark"
      }
    },
    "model": {
      "name": "QGroupNormBenchmark_dims(32,8,16)_num_groups4_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QGroupNormBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        62.541
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (32, 8, 16), num_groups: 4, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QGroupNormBenchmark"
      }
    },
    "model": {
      "name": "QGroupNormBenchmark_dims(32,8,16)_num_groups4_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QGroupNormBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (32, 8, 16), num_groups: 4, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QGroupNormBenchmark"
      }
    },
    "model": {
      "name": "QGroupNormBenchmark_dims(32,8,16)_num_groups4_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QGroupNormBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.13200912463008502
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (32, 8, 56, 56), num_groups: 2, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QGroupNormBenchmark"
      }
    },
    "model": {
      "name": "QGroupNormBenchmark_dims(32,8,56,56)_num_groups2_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QGroupNormBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1122.355
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (32, 8, 56, 56), num_groups: 2, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QGroupNormBenchmark"
      }
    },
    "model": {
      "name": "QGroupNormBenchmark_dims(32,8,56,56)_num_groups2_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QGroupNormBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (32, 8, 56, 56), num_groups: 2, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QGroupNormBenchmark"
      }
    },
    "model": {
      "name": "QGroupNormBenchmark_dims(32,8,56,56)_num_groups2_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QGroupNormBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.4306492411484253
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (32, 8, 56, 56), num_groups: 4, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QGroupNormBenchmark"
      }
    },
    "model": {
      "name": "QGroupNormBenchmark_dims(32,8,56,56)_num_groups4_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QGroupNormBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1122.275
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (32, 8, 56, 56), num_groups: 4, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QGroupNormBenchmark"
      }
    },
    "model": {
      "name": "QGroupNormBenchmark_dims(32,8,56,56)_num_groups4_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QGroupNormBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (32, 8, 56, 56), num_groups: 4, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QGroupNormBenchmark"
      }
    },
    "model": {
      "name": "QGroupNormBenchmark_dims(32,8,56,56)_num_groups4_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QGroupNormBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.4307507802336217
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (32, 8, 16), dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QInstanceNormBenchmark"
      }
    },
    "model": {
      "name": "QInstanceNormBenchmark_dims(32,8,16)_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QInstanceNormBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        62.056
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (32, 8, 16), dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QInstanceNormBenchmark"
      }
    },
    "model": {
      "name": "QInstanceNormBenchmark_dims(32,8,16)_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QInstanceNormBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (32, 8, 16), dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QInstanceNormBenchmark"
      }
    },
    "model": {
      "name": "QInstanceNormBenchmark_dims(32,8,16)_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QInstanceNormBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.13304070893640993
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (32, 8, 56, 56), dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QInstanceNormBenchmark"
      }
    },
    "model": {
      "name": "QInstanceNormBenchmark_dims(32,8,56,56)_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QInstanceNormBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1120.843
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (32, 8, 56, 56), dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QInstanceNormBenchmark"
      }
    },
    "model": {
      "name": "QInstanceNormBenchmark_dims(32,8,56,56)_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QInstanceNormBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (32, 8, 56, 56), dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QInstanceNormBenchmark"
      }
    },
    "model": {
      "name": "QInstanceNormBenchmark_dims(32,8,56,56)_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QInstanceNormBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.432578346608527
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 32, N: 32, K: 32, dtype: torch.quint8, mode: nearest, scale: 0.5, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_interpolate_M32_N32_K32_dtypetorch.quint8_modenearest_scale0.5_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        5.51
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 32, N: 32, K: 32, dtype: torch.quint8, mode: nearest, scale: 0.5, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_interpolate_M32_N32_K32_dtypetorch.quint8_modenearest_scale0.5_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 32, N: 32, K: 32, dtype: torch.quint8, mode: nearest, scale: 0.5, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_interpolate_M32_N32_K32_dtypetorch.quint8_modenearest_scale0.5_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        11.894593935852313
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 32, N: 32, K: 32, dtype: torch.quint8, mode: bilinear, scale: 0.5, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_interpolate_M32_N32_K32_dtypetorch.quint8_modebilinear_scale0.5_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        7.911
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 32, N: 32, K: 32, dtype: torch.quint8, mode: bilinear, scale: 0.5, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_interpolate_M32_N32_K32_dtypetorch.quint8_modebilinear_scale0.5_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 32, N: 32, K: 32, dtype: torch.quint8, mode: bilinear, scale: 0.5, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_interpolate_M32_N32_K32_dtypetorch.quint8_modebilinear_scale0.5_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        8.284211253699848
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 32, N: 32, K: 32, dtype: torch.quint8, mode: nearest, scale: 2.0, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_interpolate_M32_N32_K32_dtypetorch.quint8_modenearest_scale2.0_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        5.46
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 32, N: 32, K: 32, dtype: torch.quint8, mode: nearest, scale: 2.0, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_interpolate_M32_N32_K32_dtypetorch.quint8_modenearest_scale2.0_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 32, N: 32, K: 32, dtype: torch.quint8, mode: nearest, scale: 2.0, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_interpolate_M32_N32_K32_dtypetorch.quint8_modenearest_scale2.0_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        12.002947561369734
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 32, N: 32, K: 32, dtype: torch.quint8, mode: bilinear, scale: 2.0, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_interpolate_M32_N32_K32_dtypetorch.quint8_modebilinear_scale2.0_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        7.916
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 32, N: 32, K: 32, dtype: torch.quint8, mode: bilinear, scale: 2.0, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_interpolate_M32_N32_K32_dtypetorch.quint8_modebilinear_scale2.0_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 32, N: 32, K: 32, dtype: torch.quint8, mode: bilinear, scale: 2.0, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_interpolate_M32_N32_K32_dtypetorch.quint8_modebilinear_scale2.0_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        8.278850966921272
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 3, N: 720, K: 1280, dtype: torch.quint8, mode: bilinear, scale: 0.83333, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_interpolate_M3_N720_K1280_dtypetorch.quint8_modebilinear_scale0.83333_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        65.259
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 3, N: 720, K: 1280, dtype: torch.quint8, mode: bilinear, scale: 0.83333, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_interpolate_M3_N720_K1280_dtypetorch.quint8_modebilinear_scale0.83333_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 3, N: 720, K: 1280, dtype: torch.quint8, mode: bilinear, scale: 0.83333, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_interpolate_M3_N720_K1280_dtypetorch.quint8_modebilinear_scale0.83333_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        84.73362148349922
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (1, 8, 16), dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QLayerNormBenchmark"
      }
    },
    "model": {
      "name": "QLayerNormBenchmark_dims(1,8,16)_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLayerNormBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        15.182
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (1, 8, 16), dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QLayerNormBenchmark"
      }
    },
    "model": {
      "name": "QLayerNormBenchmark_dims(1,8,16)_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLayerNormBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (1, 8, 16), dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QLayerNormBenchmark"
      }
    },
    "model": {
      "name": "QLayerNormBenchmark_dims(1,8,16)_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLayerNormBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.08431303587157349
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (8, 8, 16), dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QLayerNormBenchmark"
      }
    },
    "model": {
      "name": "QLayerNormBenchmark_dims(8,8,16)_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLayerNormBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        63.456
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (8, 8, 16), dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QLayerNormBenchmark"
      }
    },
    "model": {
      "name": "QLayerNormBenchmark_dims(8,8,16)_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLayerNormBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (8, 8, 16), dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QLayerNormBenchmark"
      }
    },
    "model": {
      "name": "QLayerNormBenchmark_dims(8,8,16)_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLayerNormBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.048411631121900035
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (32, 8, 16), dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QLayerNormBenchmark"
      }
    },
    "model": {
      "name": "QLayerNormBenchmark_dims(32,8,16)_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLayerNormBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        67.23
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (32, 8, 16), dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QLayerNormBenchmark"
      }
    },
    "model": {
      "name": "QLayerNormBenchmark_dims(32,8,16)_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLayerNormBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (32, 8, 16), dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QLayerNormBenchmark"
      }
    },
    "model": {
      "name": "QLayerNormBenchmark_dims(32,8,16)_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLayerNormBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.13708069719201965
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (64, 128, 56, 56), dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QLayerNormBenchmark"
      }
    },
    "model": {
      "name": "QLayerNormBenchmark_dims(64,128,56,56)_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLayerNormBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        82898.576
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (64, 128, 56, 56), dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QLayerNormBenchmark"
      }
    },
    "model": {
      "name": "QLayerNormBenchmark_dims(64,128,56,56)_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLayerNormBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "dims: (64, 128, 56, 56), dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QLayerNormBenchmark"
      }
    },
    "model": {
      "name": "QLayerNormBenchmark_dims(64,128,56,56)_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLayerNormBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.6585334826558406
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, IN: 1, OUT: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QLinear"
      }
    },
    "model": {
      "name": "QLinear_N1_IN1_OUT1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLinear"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        39.037
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, IN: 1, OUT: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QLinear"
      }
    },
    "model": {
      "name": "QLinear_N1_IN1_OUT1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLinear"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, IN: 1, OUT: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QLinear"
      }
    },
    "model": {
      "name": "QLinear_N1_IN1_OUT1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLinear"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.1233084686592485e-05
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 4, IN: 256, OUT: 128, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QLinear"
      }
    },
    "model": {
      "name": "QLinear_N4_IN256_OUT128_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLinear"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        93.637
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 4, IN: 256, OUT: 128, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QLinear"
      }
    },
    "model": {
      "name": "QLinear_N4_IN256_OUT128_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLinear"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 4, IN: 256, OUT: 128, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QLinear"
      }
    },
    "model": {
      "name": "QLinear_N4_IN256_OUT128_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLinear"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.02187173864552805
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 16, IN: 512, OUT: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QLinear"
      }
    },
    "model": {
      "name": "QLinear_N16_IN512_OUT256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLinear"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        91.19
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 16, IN: 512, OUT: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QLinear"
      }
    },
    "model": {
      "name": "QLinear_N16_IN512_OUT256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLinear"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 16, IN: 512, OUT: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QLinear"
      }
    },
    "model": {
      "name": "QLinear_N16_IN512_OUT256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLinear"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.17966891199671292
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, IN: 1, OUT: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QDynamicLinear"
      }
    },
    "model": {
      "name": "QDynamicLinear_N1_IN1_OUT1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QDynamicLinear"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        38.236
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, IN: 1, OUT: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QDynamicLinear"
      }
    },
    "model": {
      "name": "QDynamicLinear_N1_IN1_OUT1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QDynamicLinear"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, IN: 1, OUT: 1, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QDynamicLinear"
      }
    },
    "model": {
      "name": "QDynamicLinear_N1_IN1_OUT1_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QDynamicLinear"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00020922786418288617
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 4, IN: 256, OUT: 128, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QDynamicLinear"
      }
    },
    "model": {
      "name": "QDynamicLinear_N4_IN256_OUT128_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QDynamicLinear"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        183.267
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 4, IN: 256, OUT: 128, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QDynamicLinear"
      }
    },
    "model": {
      "name": "QDynamicLinear_N4_IN256_OUT128_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QDynamicLinear"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 4, IN: 256, OUT: 128, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QDynamicLinear"
      }
    },
    "model": {
      "name": "QDynamicLinear_N4_IN256_OUT128_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QDynamicLinear"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.04469981810415864
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 16, IN: 512, OUT: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QDynamicLinear"
      }
    },
    "model": {
      "name": "QDynamicLinear_N16_IN512_OUT256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QDynamicLinear"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        187.296
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 16, IN: 512, OUT: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QDynamicLinear"
      }
    },
    "model": {
      "name": "QDynamicLinear_N16_IN512_OUT256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QDynamicLinear"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 16, IN: 512, OUT: 256, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "QDynamicLinear"
      }
    },
    "model": {
      "name": "QDynamicLinear_N16_IN512_OUT256_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QDynamicLinear"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.3499057275137864
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_tensor_affine",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MinMaxObserver"
      }
    },
    "model": {
      "name": "MinMaxObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_tensor_affine",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MinMaxObserver"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        152.534
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_tensor_affine",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MinMaxObserver"
      }
    },
    "model": {
      "name": "MinMaxObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_tensor_affine",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MinMaxObserver"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_tensor_affine",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MinMaxObserver"
      }
    },
    "model": {
      "name": "MinMaxObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_tensor_affine",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MinMaxObserver"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        41.24623387991263
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_tensor_symmetric",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MinMaxObserver"
      }
    },
    "model": {
      "name": "MinMaxObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_tensor_symmetric",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MinMaxObserver"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        142.183
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_tensor_symmetric",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MinMaxObserver"
      }
    },
    "model": {
      "name": "MinMaxObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_tensor_symmetric",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MinMaxObserver"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_tensor_symmetric",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MinMaxObserver"
      }
    },
    "model": {
      "name": "MinMaxObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_tensor_symmetric",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MinMaxObserver"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        44.24895506292818
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_tensor_affine",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MovingAverageMinMaxObserver"
      }
    },
    "model": {
      "name": "MovingAverageMinMaxObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_tensor_affine",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MovingAverageMinMaxObserver"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        164.383
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_tensor_affine",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MovingAverageMinMaxObserver"
      }
    },
    "model": {
      "name": "MovingAverageMinMaxObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_tensor_affine",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MovingAverageMinMaxObserver"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_tensor_affine",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MovingAverageMinMaxObserver"
      }
    },
    "model": {
      "name": "MovingAverageMinMaxObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_tensor_affine",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MovingAverageMinMaxObserver"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        38.273186344078944
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_tensor_symmetric",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MovingAverageMinMaxObserver"
      }
    },
    "model": {
      "name": "MovingAverageMinMaxObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_tensor_symmetric",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MovingAverageMinMaxObserver"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        156.978
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_tensor_symmetric",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MovingAverageMinMaxObserver"
      }
    },
    "model": {
      "name": "MovingAverageMinMaxObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_tensor_symmetric",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MovingAverageMinMaxObserver"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_tensor_symmetric",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MovingAverageMinMaxObserver"
      }
    },
    "model": {
      "name": "MovingAverageMinMaxObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_tensor_symmetric",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MovingAverageMinMaxObserver"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        40.07860085600146
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_channel_affine",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "PerChannelMinMaxObserver"
      }
    },
    "model": {
      "name": "PerChannelMinMaxObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_channel_affine",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "PerChannelMinMaxObserver"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        366.225
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_channel_affine",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "PerChannelMinMaxObserver"
      }
    },
    "model": {
      "name": "PerChannelMinMaxObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_channel_affine",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "PerChannelMinMaxObserver"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_channel_affine",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "PerChannelMinMaxObserver"
      }
    },
    "model": {
      "name": "PerChannelMinMaxObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_channel_affine",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "PerChannelMinMaxObserver"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        17.179230669972153
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_channel_symmetric",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "PerChannelMinMaxObserver"
      }
    },
    "model": {
      "name": "PerChannelMinMaxObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_channel_symmetric",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "PerChannelMinMaxObserver"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        358.325
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_channel_symmetric",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "PerChannelMinMaxObserver"
      }
    },
    "model": {
      "name": "PerChannelMinMaxObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_channel_symmetric",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "PerChannelMinMaxObserver"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_channel_symmetric",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "PerChannelMinMaxObserver"
      }
    },
    "model": {
      "name": "PerChannelMinMaxObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_channel_symmetric",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "PerChannelMinMaxObserver"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        17.55793603439939
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_channel_affine",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MovingAveragePerChannelMinMaxObserver"
      }
    },
    "model": {
      "name": "MovingAveragePerChannelMinMaxObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_channel_affine",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MovingAveragePerChannelMinMaxObserver"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        362.67
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_channel_affine",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MovingAveragePerChannelMinMaxObserver"
      }
    },
    "model": {
      "name": "MovingAveragePerChannelMinMaxObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_channel_affine",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MovingAveragePerChannelMinMaxObserver"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_channel_affine",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MovingAveragePerChannelMinMaxObserver"
      }
    },
    "model": {
      "name": "MovingAveragePerChannelMinMaxObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_channel_affine",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MovingAveragePerChannelMinMaxObserver"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        17.347618579661336
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_channel_symmetric",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MovingAveragePerChannelMinMaxObserver"
      }
    },
    "model": {
      "name": "MovingAveragePerChannelMinMaxObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_channel_symmetric",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MovingAveragePerChannelMinMaxObserver"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        387.146
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_channel_symmetric",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MovingAveragePerChannelMinMaxObserver"
      }
    },
    "model": {
      "name": "MovingAveragePerChannelMinMaxObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_channel_symmetric",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MovingAveragePerChannelMinMaxObserver"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_channel_symmetric",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "MovingAveragePerChannelMinMaxObserver"
      }
    },
    "model": {
      "name": "MovingAveragePerChannelMinMaxObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_channel_symmetric",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "MovingAveragePerChannelMinMaxObserver"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        16.25087748812168
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_tensor_affine",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "HistogramObserver"
      }
    },
    "model": {
      "name": "HistogramObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_tensor_affine",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "HistogramObserver"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1305.592
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_tensor_affine",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "HistogramObserver"
      }
    },
    "model": {
      "name": "HistogramObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_tensor_affine",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "HistogramObserver"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_tensor_affine",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "HistogramObserver"
      }
    },
    "model": {
      "name": "HistogramObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_tensor_affine",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "HistogramObserver"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        null
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_tensor_symmetric",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "HistogramObserver"
      }
    },
    "model": {
      "name": "HistogramObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_tensor_symmetric",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "HistogramObserver"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1268.877
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_tensor_symmetric",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "HistogramObserver"
      }
    },
    "model": {
      "name": "HistogramObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_tensor_symmetric",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "HistogramObserver"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_tensor_symmetric",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "HistogramObserver"
      }
    },
    "model": {
      "name": "HistogramObserver_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_tensor_symmetric",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "HistogramObserver"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        null
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_tensor_affine",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "HistogramObserverCalculateQparams"
      }
    },
    "model": {
      "name": "HistogramObserverCalculateQparams_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_tensor_affine",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "HistogramObserverCalculateQparams"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1221.227
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_tensor_affine",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "HistogramObserverCalculateQparams"
      }
    },
    "model": {
      "name": "HistogramObserverCalculateQparams_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_tensor_affine",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "HistogramObserverCalculateQparams"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_tensor_affine",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "HistogramObserverCalculateQparams"
      }
    },
    "model": {
      "name": "HistogramObserverCalculateQparams_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_tensor_affine",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "HistogramObserverCalculateQparams"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        null
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_tensor_symmetric",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "HistogramObserverCalculateQparams"
      }
    },
    "model": {
      "name": "HistogramObserverCalculateQparams_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_tensor_symmetric",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "HistogramObserverCalculateQparams"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1267.623
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_tensor_symmetric",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "HistogramObserverCalculateQparams"
      }
    },
    "model": {
      "name": "HistogramObserverCalculateQparams_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_tensor_symmetric",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "HistogramObserverCalculateQparams"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, device: cpu, qscheme: torch.per_tensor_symmetric",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "HistogramObserverCalculateQparams"
      }
    },
    "model": {
      "name": "HistogramObserverCalculateQparams_C3_M512_N512_dtypetorch.quint8_cpu_qschemetorch.per_tensor_symmetric",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "HistogramObserverCalculateQparams"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        null
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 4, C: 3, input_size: (224, 224), output_size: (112, 112), contig: True, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QAdaptiveAvgPool2dBenchmark"
      }
    },
    "model": {
      "name": "QAdaptiveAvgPool2dBenchmark_N4_C3_input_size(224,224)_output_size(112,112)_contigTrue_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QAdaptiveAvgPool2dBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.572
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 4, C: 3, input_size: (224, 224), output_size: (112, 112), contig: True, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QAdaptiveAvgPool2dBenchmark"
      }
    },
    "model": {
      "name": "QAdaptiveAvgPool2dBenchmark_N4_C3_input_size(224,224)_output_size(112,112)_contigTrue_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QAdaptiveAvgPool2dBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "N: 4, C: 3, input_size: (224, 224), output_size: (112, 112), contig: True, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QAdaptiveAvgPool2dBenchmark"
      }
    },
    "model": {
      "name": "QAdaptiveAvgPool2dBenchmark_N4_C3_input_size(224,224)_output_size(112,112)_contigTrue_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QAdaptiveAvgPool2dBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        38.66761114170313
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 4, C: 3, input_size: (224, 224), output_size: (112, 112), contig: True, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QAdaptiveAvgPool2dBenchmark"
      }
    },
    "model": {
      "name": "QAdaptiveAvgPool2dBenchmark_N4_C3_input_size(224,224)_output_size(112,112)_contigTrue_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QAdaptiveAvgPool2dBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.055
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 4, C: 3, input_size: (224, 224), output_size: (112, 112), contig: True, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QAdaptiveAvgPool2dBenchmark"
      }
    },
    "model": {
      "name": "QAdaptiveAvgPool2dBenchmark_N4_C3_input_size(224,224)_output_size(112,112)_contigTrue_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QAdaptiveAvgPool2dBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "N: 4, C: 3, input_size: (224, 224), output_size: (112, 112), contig: True, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QAdaptiveAvgPool2dBenchmark"
      }
    },
    "model": {
      "name": "QAdaptiveAvgPool2dBenchmark_N4_C3_input_size(224,224)_output_size(112,112)_contigTrue_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QAdaptiveAvgPool2dBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.03056211880513
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 4, C: 3, input_size: (224, 224), output_size: (112, 112), contig: True, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QAdaptiveAvgPool2dBenchmark"
      }
    },
    "model": {
      "name": "QAdaptiveAvgPool2dBenchmark_N4_C3_input_size(224,224)_output_size(112,112)_contigTrue_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QAdaptiveAvgPool2dBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.908
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 4, C: 3, input_size: (224, 224), output_size: (112, 112), contig: True, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QAdaptiveAvgPool2dBenchmark"
      }
    },
    "model": {
      "name": "QAdaptiveAvgPool2dBenchmark_N4_C3_input_size(224,224)_output_size(112,112)_contigTrue_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QAdaptiveAvgPool2dBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "N: 4, C: 3, input_size: (224, 224), output_size: (112, 112), contig: True, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QAdaptiveAvgPool2dBenchmark"
      }
    },
    "model": {
      "name": "QAdaptiveAvgPool2dBenchmark_N4_C3_input_size(224,224)_output_size(112,112)_contigTrue_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QAdaptiveAvgPool2dBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        9.959865947287227
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "C: 1, H: 3, W: 3, k: (3, 3), s: (1, 1), p: (0, 0), N: 2, contig: True, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QAvgPool2dBenchmark"
      }
    },
    "model": {
      "name": "QAvgPool2dBenchmark_C1_H3_W3_k(3,3)_s(1,1)_p(0,0)_N2_contigTrue_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QAvgPool2dBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        58.882
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "C: 1, H: 3, W: 3, k: (3, 3), s: (1, 1), p: (0, 0), N: 2, contig: True, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QAvgPool2dBenchmark"
      }
    },
    "model": {
      "name": "QAvgPool2dBenchmark_C1_H3_W3_k(3,3)_s(1,1)_p(0,0)_N2_contigTrue_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QAvgPool2dBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "C: 1, H: 3, W: 3, k: (3, 3), s: (1, 1), p: (0, 0), N: 2, contig: True, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QAvgPool2dBenchmark"
      }
    },
    "model": {
      "name": "QAvgPool2dBenchmark_C1_H3_W3_k(3,3)_s(1,1)_p(0,0)_N2_contigTrue_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QAvgPool2dBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0024455669659915447
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "C: 1, H: 3, W: 3, k: (3, 3), s: (1, 1), p: (0, 0), N: 2, contig: True, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QAvgPool2dBenchmark"
      }
    },
    "model": {
      "name": "QAvgPool2dBenchmark_C1_H3_W3_k(3,3)_s(1,1)_p(0,0)_N2_contigTrue_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QAvgPool2dBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        58.684
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "C: 1, H: 3, W: 3, k: (3, 3), s: (1, 1), p: (0, 0), N: 2, contig: True, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QAvgPool2dBenchmark"
      }
    },
    "model": {
      "name": "QAvgPool2dBenchmark_C1_H3_W3_k(3,3)_s(1,1)_p(0,0)_N2_contigTrue_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QAvgPool2dBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "C: 1, H: 3, W: 3, k: (3, 3), s: (1, 1), p: (0, 0), N: 2, contig: True, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QAvgPool2dBenchmark"
      }
    },
    "model": {
      "name": "QAvgPool2dBenchmark_C1_H3_W3_k(3,3)_s(1,1)_p(0,0)_N2_contigTrue_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QAvgPool2dBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.000613452031757622
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 1, H: 3, W: 3, k: (3, 3), s: (1, 1), p: (0, 0), N: 2, contig: True, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QAvgPool2dBenchmark"
      }
    },
    "model": {
      "name": "QAvgPool2dBenchmark_C1_H3_W3_k(3,3)_s(1,1)_p(0,0)_N2_contigTrue_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QAvgPool2dBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        59.464
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 1, H: 3, W: 3, k: (3, 3), s: (1, 1), p: (0, 0), N: 2, contig: True, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QAvgPool2dBenchmark"
      }
    },
    "model": {
      "name": "QAvgPool2dBenchmark_C1_H3_W3_k(3,3)_s(1,1)_p(0,0)_N2_contigTrue_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QAvgPool2dBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 1, H: 3, W: 3, k: (3, 3), s: (1, 1), p: (0, 0), N: 2, contig: True, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QAvgPool2dBenchmark"
      }
    },
    "model": {
      "name": "QAvgPool2dBenchmark_C1_H3_W3_k(3,3)_s(1,1)_p(0,0)_N2_contigTrue_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QAvgPool2dBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0006054066701915022
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "C: 1, H: 3, W: 3, k: (3, 3), s: (1, 1), p: (0, 0), N: 2, contig: True, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QMaxPool2dBenchmark"
      }
    },
    "model": {
      "name": "QMaxPool2dBenchmark_C1_H3_W3_k(3,3)_s(1,1)_p(0,0)_N2_contigTrue_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QMaxPool2dBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        62.614
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "C: 1, H: 3, W: 3, k: (3, 3), s: (1, 1), p: (0, 0), N: 2, contig: True, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QMaxPool2dBenchmark"
      }
    },
    "model": {
      "name": "QMaxPool2dBenchmark_C1_H3_W3_k(3,3)_s(1,1)_p(0,0)_N2_contigTrue_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QMaxPool2dBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint32",
      "extra_info": {
        "input_config": "C: 1, H: 3, W: 3, k: (3, 3), s: (1, 1), p: (0, 0), N: 2, contig: True, dtype: torch.qint32",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QMaxPool2dBenchmark"
      }
    },
    "model": {
      "name": "QMaxPool2dBenchmark_C1_H3_W3_k(3,3)_s(1,1)_p(0,0)_N2_contigTrue_dtypetorch.qint32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QMaxPool2dBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0022997911979900157
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "C: 1, H: 3, W: 3, k: (3, 3), s: (1, 1), p: (0, 0), N: 2, contig: True, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QMaxPool2dBenchmark"
      }
    },
    "model": {
      "name": "QMaxPool2dBenchmark_C1_H3_W3_k(3,3)_s(1,1)_p(0,0)_N2_contigTrue_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QMaxPool2dBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        62.772
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "C: 1, H: 3, W: 3, k: (3, 3), s: (1, 1), p: (0, 0), N: 2, contig: True, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QMaxPool2dBenchmark"
      }
    },
    "model": {
      "name": "QMaxPool2dBenchmark_C1_H3_W3_k(3,3)_s(1,1)_p(0,0)_N2_contigTrue_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QMaxPool2dBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "C: 1, H: 3, W: 3, k: (3, 3), s: (1, 1), p: (0, 0), N: 2, contig: True, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QMaxPool2dBenchmark"
      }
    },
    "model": {
      "name": "QMaxPool2dBenchmark_C1_H3_W3_k(3,3)_s(1,1)_p(0,0)_N2_contigTrue_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QMaxPool2dBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0005735040369509889
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 1, H: 3, W: 3, k: (3, 3), s: (1, 1), p: (0, 0), N: 2, contig: True, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QMaxPool2dBenchmark"
      }
    },
    "model": {
      "name": "QMaxPool2dBenchmark_C1_H3_W3_k(3,3)_s(1,1)_p(0,0)_N2_contigTrue_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QMaxPool2dBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        62.439
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 1, H: 3, W: 3, k: (3, 3), s: (1, 1), p: (0, 0), N: 2, contig: True, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QMaxPool2dBenchmark"
      }
    },
    "model": {
      "name": "QMaxPool2dBenchmark_C1_H3_W3_k(3,3)_s(1,1)_p(0,0)_N2_contigTrue_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QMaxPool2dBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 1, H: 3, W: 3, k: (3, 3), s: (1, 1), p: (0, 0), N: 2, contig: True, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QMaxPool2dBenchmark"
      }
    },
    "model": {
      "name": "QMaxPool2dBenchmark_C1_H3_W3_k(3,3)_s(1,1)_p(0,0)_N2_contigTrue_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QMaxPool2dBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0005765661858323996
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "I: 1, H: 3, NL: 1, B: True, D: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QLSTM"
      }
    },
    "model": {
      "name": "QLSTM_I1_H3_NL1_BTrue_DFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLSTM"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21669.148
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "I: 1, H: 3, NL: 1, B: True, D: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QLSTM"
      }
    },
    "model": {
      "name": "QLSTM_I1_H3_NL1_BTrue_DFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLSTM"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "I: 1, H: 3, NL: 1, B: True, D: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QLSTM"
      }
    },
    "model": {
      "name": "QLSTM_I1_H3_NL1_BTrue_DFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLSTM"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0007738190610965175
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "I: 1, H: 3, NL: 1, B: True, D: True, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QLSTM"
      }
    },
    "model": {
      "name": "QLSTM_I1_H3_NL1_BTrue_DTrue_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLSTM"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        42931.896
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "I: 1, H: 3, NL: 1, B: True, D: True, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QLSTM"
      }
    },
    "model": {
      "name": "QLSTM_I1_H3_NL1_BTrue_DTrue_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLSTM"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "I: 1, H: 3, NL: 1, B: True, D: True, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QLSTM"
      }
    },
    "model": {
      "name": "QLSTM_I1_H3_NL1_BTrue_DTrue_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLSTM"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.00039951647977645233
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "I: 5, H: 7, NL: 4, B: True, D: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QLSTM"
      }
    },
    "model": {
      "name": "QLSTM_I5_H7_NL4_BTrue_DFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLSTM"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        86468.744
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "I: 5, H: 7, NL: 4, B: True, D: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QLSTM"
      }
    },
    "model": {
      "name": "QLSTM_I5_H7_NL4_BTrue_DFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLSTM"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "I: 5, H: 7, NL: 4, B: True, D: False, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QLSTM"
      }
    },
    "model": {
      "name": "QLSTM_I5_H7_NL4_BTrue_DFalse_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLSTM"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0009888428619567147
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "I: 5, H: 7, NL: 4, B: True, D: True, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QLSTM"
      }
    },
    "model": {
      "name": "QLSTM_I5_H7_NL4_BTrue_DTrue_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLSTM"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        172979.251
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "I: 5, H: 7, NL: 4, B: True, D: True, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QLSTM"
      }
    },
    "model": {
      "name": "QLSTM_I5_H7_NL4_BTrue_DTrue_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLSTM"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "qint8",
      "extra_info": {
        "input_config": "I: 5, H: 7, NL: 4, B: True, D: True, dtype: torch.qint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QLSTM"
      }
    },
    "model": {
      "name": "QLSTM_I5_H7_NL4_BTrue_DTrue_dtypetorch.qint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QLSTM"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.0005150213078585019
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 32, N: 32, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QMethodTensorInputCopyBenchmark"
      }
    },
    "model": {
      "name": "QMethodTensorInputCopyBenchmark_M32_N32_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QMethodTensorInputCopyBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        0.926
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 32, N: 32, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QMethodTensorInputCopyBenchmark"
      }
    },
    "model": {
      "name": "QMethodTensorInputCopyBenchmark_M32_N32_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QMethodTensorInputCopyBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 32, N: 32, dtype: torch.quint8, contig: False",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QMethodTensorInputCopyBenchmark"
      }
    },
    "model": {
      "name": "QMethodTensorInputCopyBenchmark_M32_N32_dtypetorch.quint8_contigFalse",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QMethodTensorInputCopyBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.2127591099048862
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 32, N: 32, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QMethodTensorInputCopyBenchmark"
      }
    },
    "model": {
      "name": "QMethodTensorInputCopyBenchmark_M32_N32_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QMethodTensorInputCopyBenchmark"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        0.918
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 32, N: 32, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QMethodTensorInputCopyBenchmark"
      }
    },
    "model": {
      "name": "QMethodTensorInputCopyBenchmark_M32_N32_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QMethodTensorInputCopyBenchmark"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 32, N: 32, dtype: torch.quint8, contig: True",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QMethodTensorInputCopyBenchmark"
      }
    },
    "model": {
      "name": "QMethodTensorInputCopyBenchmark_M32_N32_dtypetorch.quint8_contigTrue",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QMethodTensorInputCopyBenchmark"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.2314807118162423
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, mode: Q",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QuantizePerTensor"
      }
    },
    "model": {
      "name": "QuantizePerTensor_C3_M512_N512_dtypetorch.quint8_modeQ",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QuantizePerTensor"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        194.782
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, mode: Q",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QuantizePerTensor"
      }
    },
    "model": {
      "name": "QuantizePerTensor_C3_M512_N512_dtypetorch.quint8_modeQ",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QuantizePerTensor"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, mode: Q",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QuantizePerTensor"
      }
    },
    "model": {
      "name": "QuantizePerTensor_C3_M512_N512_dtypetorch.quint8_modeQ",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QuantizePerTensor"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        32.29991866289547
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, mode: D",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "DequantizePerTensor"
      }
    },
    "model": {
      "name": "DequantizePerTensor_C3_M512_N512_dtypetorch.quint8_modeD",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "DequantizePerTensor"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        64.219
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, mode: D",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "DequantizePerTensor"
      }
    },
    "model": {
      "name": "DequantizePerTensor_C3_M512_N512_dtypetorch.quint8_modeD",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "DequantizePerTensor"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, mode: D",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "DequantizePerTensor"
      }
    },
    "model": {
      "name": "DequantizePerTensor_C3_M512_N512_dtypetorch.quint8_modeD",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "DequantizePerTensor"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        24.49209067172244
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, mode: Q, axis: 0",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QuantizePerChannel"
      }
    },
    "model": {
      "name": "QuantizePerChannel_C3_M512_N512_dtypetorch.quint8_modeQ_axis0",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QuantizePerChannel"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.782
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, mode: Q, axis: 0",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QuantizePerChannel"
      }
    },
    "model": {
      "name": "QuantizePerChannel_C3_M512_N512_dtypetorch.quint8_modeQ_axis0",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QuantizePerChannel"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, mode: Q, axis: 0",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "QuantizePerChannel"
      }
    },
    "model": {
      "name": "QuantizePerChannel_C3_M512_N512_dtypetorch.quint8_modeQ_axis0",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "QuantizePerChannel"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        48.10666348157906
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, mode: D, axis: 0",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "DequantizePerChannel"
      }
    },
    "model": {
      "name": "DequantizePerChannel_C3_M512_N512_dtypetorch.quint8_modeD_axis0",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "DequantizePerChannel"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        292.796
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, mode: D, axis: 0",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "DequantizePerChannel"
      }
    },
    "model": {
      "name": "DequantizePerChannel_C3_M512_N512_dtypetorch.quint8_modeD_axis0",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "DequantizePerChannel"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "C: 3, M: 512, N: 512, dtype: torch.quint8, mode: D, axis: 0",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "DequantizePerChannel"
      }
    },
    "model": {
      "name": "DequantizePerChannel_C3_M512_N512_dtypetorch.quint8_modeD_axis0",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "DequantizePerChannel"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.372007587082224
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "FakeQuantize"
      }
    },
    "model": {
      "name": "FakeQuantize_N1_C3_H512_W512_zero_point_dtypetorch.int32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "FakeQuantize"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        427.906
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "FakeQuantize"
      }
    },
    "model": {
      "name": "FakeQuantize_N1_C3_H512_W512_zero_point_dtypetorch.int32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "FakeQuantize"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "FakeQuantize"
      }
    },
    "model": {
      "name": "FakeQuantize_N1_C3_H512_W512_zero_point_dtypetorch.int32_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "FakeQuantize"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        14.702888492996626
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        207.434
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        30.32995779106123
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        208.248
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        30.211340587148303
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        204.207
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        30.80922786581165
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        203.242
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        30.955569683359627
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        613.243
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.259328026396112
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        609.695
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.319040544261666
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        608.47
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.339808491758165
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        607.797
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.351263388401247
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        607.876
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.349912607244672
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        609.415
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.323778859635592
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        607.706
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.352801407458545
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        607.471
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.35680790159215
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        371.648
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        16.928552836055804
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        370.568
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        16.977889931223885
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        370.859
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        16.964571083523154
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        370.62
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        16.975523643578263
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        370.978
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        16.9591282805341
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        369.121
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        17.044442425024823
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        370.75
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        16.969571589063456
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        371.727
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_tensor_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        16.92494853822621
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        441.353
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        14.254981925578427
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        440.988
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        14.266789512904252
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        439.188
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        14.325263911121452
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        435.093
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        14.460081737545925
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        667.519
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        9.425167361066519
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        666.281
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        9.442688863089787
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        664.826
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        9.463347148130577
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        665.853
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        9.448754596694128
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        662.215
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        9.500657648743957
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        664.283
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        9.471081792998467
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        664.794
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        9.463797561189207
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        665.187
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "learnable"
      }
    },
    "model": {
      "name": "learnable_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd3",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "learnable"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        9.458213711255294
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        372.333
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        16.89747453854879
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        371.318
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 4, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits4_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        16.94364701569169
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        371.057
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        16.955559198897998
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        370.788
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "training",
      "dtype": "float",
      "extra_info": {
        "input_config": "N: 1, C: 3, H: 512, W: 512, zero_point_dtype: torch.int32, nbits: 8, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "original"
      }
    },
    "model": {
      "name": "original_kernel_channel_N1_C3_H512_W512_zero_point_dtypetorch.int32_nbits8_cpu_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "original"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        16.967884138066
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_argsort_M512_N512_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        486.297
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_argsort_M512_N512_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_argsort_M512_N512_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.0781226821968257
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_clone_M512_N512_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        50.294
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_clone_M512_N512_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_clone_M512_N512_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.424488877579225
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_mean_M512_N512_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        95.913
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_mean_M512_N512_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_mean_M512_N512_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.466309650237217
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_relu_M512_N512_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        52.148
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_relu_M512_N512_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_relu_M512_N512_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.053832284077943
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_relu__M512_N512_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        50.787
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_relu__M512_N512_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_relu__M512_N512_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.323184807631245
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_sort_M512_N512_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        485.974
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_sort_M512_N512_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "q"
      }
    },
    "model": {
      "name": "q_sort_M512_N512_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "q"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.078840091199366
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, k: 5, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qtopk"
      }
    },
    "model": {
      "name": "qtopk_M512_N512_k5_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qtopk"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.298
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, k: 5, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qtopk"
      }
    },
    "model": {
      "name": "qtopk_M512_N512_k5_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qtopk"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "quint8",
      "extra_info": {
        "input_config": "M: 512, N: 512, k: 5, dtype: torch.quint8",
        "device": "unknown",
        "arch": "unknown",
        "use_compile": false,
        "operator_name": "qtopk"
      }
    },
    "model": {
      "name": "qtopk_M512_N512_k5_dtypetorch.quint8",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "qtopk"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        5.125110971856992
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "abs"
      }
    },
    "model": {
      "name": "abs_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "abs"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        53.163
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "abs"
      }
    },
    "model": {
      "name": "abs_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "abs"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "abs"
      }
    },
    "model": {
      "name": "abs_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "abs"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        39.4476286245762
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "abs"
      }
    },
    "model": {
      "name": "abs__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "abs"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        52.49
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "abs"
      }
    },
    "model": {
      "name": "abs__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "abs"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "abs"
      }
    },
    "model": {
      "name": "abs__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "abs"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        39.95302198784044
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "acos"
      }
    },
    "model": {
      "name": "acos_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "acos"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        155.238
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "acos"
      }
    },
    "model": {
      "name": "acos_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "acos"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "acos"
      }
    },
    "model": {
      "name": "acos_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "acos"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        13.50926441608584
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "acos"
      }
    },
    "model": {
      "name": "acos__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "acos"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        148.637
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "acos"
      }
    },
    "model": {
      "name": "acos__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "acos"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "acos"
      }
    },
    "model": {
      "name": "acos__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "acos"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        14.109198599220823
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "argsort"
      }
    },
    "model": {
      "name": "argsort_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "argsort"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1383.326
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "argsort"
      }
    },
    "model": {
      "name": "argsort_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "argsort"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "argsort"
      }
    },
    "model": {
      "name": "argsort_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "argsort"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.516021717707593
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asin"
      }
    },
    "model": {
      "name": "asin_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asin"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        134.628
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asin"
      }
    },
    "model": {
      "name": "asin_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asin"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asin"
      }
    },
    "model": {
      "name": "asin_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asin"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        15.577418073261939
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asin"
      }
    },
    "model": {
      "name": "asin__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asin"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        129.851
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asin"
      }
    },
    "model": {
      "name": "asin__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asin"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "asin"
      }
    },
    "model": {
      "name": "asin__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "asin"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        16.15043014109024
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "atan"
      }
    },
    "model": {
      "name": "atan_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "atan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        177.451
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "atan"
      }
    },
    "model": {
      "name": "atan_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "atan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "atan"
      }
    },
    "model": {
      "name": "atan_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "atan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        11.81822664495731
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "atan"
      }
    },
    "model": {
      "name": "atan__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "atan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        174.23
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "atan"
      }
    },
    "model": {
      "name": "atan__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "atan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "atan"
      }
    },
    "model": {
      "name": "atan__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "atan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        12.036702422766789
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "ceil"
      }
    },
    "model": {
      "name": "ceil_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ceil"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        52.282
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "ceil"
      }
    },
    "model": {
      "name": "ceil_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ceil"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "ceil"
      }
    },
    "model": {
      "name": "ceil_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ceil"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        40.112394552074846
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "ceil"
      }
    },
    "model": {
      "name": "ceil__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ceil"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        50.37
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "ceil"
      }
    },
    "model": {
      "name": "ceil__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ceil"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "ceil"
      }
    },
    "model": {
      "name": "ceil__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "ceil"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        41.634821575769365
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "clamp"
      }
    },
    "model": {
      "name": "clamp_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "clamp"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        56.734
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "clamp"
      }
    },
    "model": {
      "name": "clamp_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "clamp"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "clamp"
      }
    },
    "model": {
      "name": "clamp_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "clamp"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        36.96441580741095
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "clone"
      }
    },
    "model": {
      "name": "clone_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "clone"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        51.464
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "clone"
      }
    },
    "model": {
      "name": "clone_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "clone"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "clone"
      }
    },
    "model": {
      "name": "clone_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "clone"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        40.74970129795435
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "cos"
      }
    },
    "model": {
      "name": "cos_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "cos"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        143.654
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "cos"
      }
    },
    "model": {
      "name": "cos_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "cos"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "cos"
      }
    },
    "model": {
      "name": "cos_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "cos"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        14.598680787779758
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "cos"
      }
    },
    "model": {
      "name": "cos__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "cos"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        143.124
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "cos"
      }
    },
    "model": {
      "name": "cos__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "cos"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "cos"
      }
    },
    "model": {
      "name": "cos__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "cos"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        14.652732225389212
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "cosh"
      }
    },
    "model": {
      "name": "cosh_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "cosh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        229.143
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "cosh"
      }
    },
    "model": {
      "name": "cosh_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "cosh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "cosh"
      }
    },
    "model": {
      "name": "cosh_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "cosh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        9.152161858365744
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "digamma"
      }
    },
    "model": {
      "name": "digamma_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "digamma"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        493.186
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "digamma"
      }
    },
    "model": {
      "name": "digamma_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "digamma"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "digamma"
      }
    },
    "model": {
      "name": "digamma_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "digamma"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.252255777499257
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "erf"
      }
    },
    "model": {
      "name": "erf_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "erf"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        93.381
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "erf"
      }
    },
    "model": {
      "name": "erf_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "erf"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "erf"
      }
    },
    "model": {
      "name": "erf_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "erf"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        22.458122730826876
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "erf"
      }
    },
    "model": {
      "name": "erf__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "erf"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        88.116
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "erf"
      }
    },
    "model": {
      "name": "erf__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "erf"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "erf"
      }
    },
    "model": {
      "name": "erf__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "erf"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        23.80000940549323
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "erfc"
      }
    },
    "model": {
      "name": "erfc_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "erfc"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        480.706
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "erfc"
      }
    },
    "model": {
      "name": "erfc_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "erfc"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "erfc"
      }
    },
    "model": {
      "name": "erfc_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "erfc"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.36265117225452
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "erfc"
      }
    },
    "model": {
      "name": "erfc__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "erfc"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        479.568
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "erfc"
      }
    },
    "model": {
      "name": "erfc__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "erfc"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "erfc"
      }
    },
    "model": {
      "name": "erfc__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "erfc"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        4.373000532249168
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "erfinv"
      }
    },
    "model": {
      "name": "erfinv_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "erfinv"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1262.693
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "erfinv"
      }
    },
    "model": {
      "name": "erfinv_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "erfinv"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "erfinv"
      }
    },
    "model": {
      "name": "erfinv_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "erfinv"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.6608567029905026
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "exp"
      }
    },
    "model": {
      "name": "exp_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "exp"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        94.915
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "exp"
      }
    },
    "model": {
      "name": "exp_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "exp"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "exp"
      }
    },
    "model": {
      "name": "exp_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "exp"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        22.095008693710398
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "exp"
      }
    },
    "model": {
      "name": "exp__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "exp"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        90.849
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "exp"
      }
    },
    "model": {
      "name": "exp__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "exp"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "exp"
      }
    },
    "model": {
      "name": "exp__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "exp"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        23.083808594407166
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "expm1"
      }
    },
    "model": {
      "name": "expm1_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "expm1"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        212.644
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "expm1"
      }
    },
    "model": {
      "name": "expm1_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "expm1"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "expm1"
      }
    },
    "model": {
      "name": "expm1_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "expm1"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        9.862283684368846
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "expm1"
      }
    },
    "model": {
      "name": "expm1__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "expm1"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        211.244
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "expm1"
      }
    },
    "model": {
      "name": "expm1__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "expm1"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "expm1"
      }
    },
    "model": {
      "name": "expm1__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "expm1"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        9.927620254437576
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "floor"
      }
    },
    "model": {
      "name": "floor_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "floor"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        52.013
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "floor"
      }
    },
    "model": {
      "name": "floor_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "floor"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "floor"
      }
    },
    "model": {
      "name": "floor_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "floor"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        40.31977154178481
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "floor"
      }
    },
    "model": {
      "name": "floor__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "floor"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        50.342
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "floor"
      }
    },
    "model": {
      "name": "floor__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "floor"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "floor"
      }
    },
    "model": {
      "name": "floor__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "floor"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        41.65812550039811
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "frac"
      }
    },
    "model": {
      "name": "frac_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "frac"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        53.537
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "frac"
      }
    },
    "model": {
      "name": "frac_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "frac"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "frac"
      }
    },
    "model": {
      "name": "frac_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "frac"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        39.17229998105321
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "frac"
      }
    },
    "model": {
      "name": "frac__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "frac"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        52.738
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "frac"
      }
    },
    "model": {
      "name": "frac__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "frac"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "frac"
      }
    },
    "model": {
      "name": "frac__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "frac"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        39.76568955142267
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "gelu"
      }
    },
    "model": {
      "name": "gelu_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gelu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        146.445
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "gelu"
      }
    },
    "model": {
      "name": "gelu_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gelu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "gelu"
      }
    },
    "model": {
      "name": "gelu_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "gelu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        14.320375083472305
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "hardshrink"
      }
    },
    "model": {
      "name": "hardshrink_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "hardshrink"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        56.189
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "hardshrink"
      }
    },
    "model": {
      "name": "hardshrink_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "hardshrink"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "hardshrink"
      }
    },
    "model": {
      "name": "hardshrink_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "hardshrink"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        37.32345611834427
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lgamma"
      }
    },
    "model": {
      "name": "lgamma_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lgamma"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        926.646
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lgamma"
      }
    },
    "model": {
      "name": "lgamma_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lgamma"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "lgamma"
      }
    },
    "model": {
      "name": "lgamma_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "lgamma"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.263162964092375
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "log"
      }
    },
    "model": {
      "name": "log_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "log"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        144.808
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "log"
      }
    },
    "model": {
      "name": "log_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "log"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "log"
      }
    },
    "model": {
      "name": "log_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "log"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        14.482307668435508
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "log10"
      }
    },
    "model": {
      "name": "log10_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "log10"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        150.126
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "log10"
      }
    },
    "model": {
      "name": "log10_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "log10"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "log10"
      }
    },
    "model": {
      "name": "log10_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "log10"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        13.969310921453394
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "log10"
      }
    },
    "model": {
      "name": "log10__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "log10"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        147.909
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "log10"
      }
    },
    "model": {
      "name": "log10__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "log10"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "log10"
      }
    },
    "model": {
      "name": "log10__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "log10"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        14.17868092348836
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "log1p"
      }
    },
    "model": {
      "name": "log1p_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "log1p"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        152.913
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "log1p"
      }
    },
    "model": {
      "name": "log1p_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "log1p"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "log1p"
      }
    },
    "model": {
      "name": "log1p_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "log1p"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        13.714712237173849
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "log1p"
      }
    },
    "model": {
      "name": "log1p__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "log1p"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        150.128
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "log1p"
      }
    },
    "model": {
      "name": "log1p__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "log1p"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "log1p"
      }
    },
    "model": {
      "name": "log1p__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "log1p"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        13.969093389563428
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "log2"
      }
    },
    "model": {
      "name": "log2_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "log2"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        150.107
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "log2"
      }
    },
    "model": {
      "name": "log2_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "log2"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "log2"
      }
    },
    "model": {
      "name": "log2_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "log2"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        13.971007756002765
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "log2"
      }
    },
    "model": {
      "name": "log2__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "log2"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        149.077
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "log2"
      }
    },
    "model": {
      "name": "log2__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "log2"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "log2"
      }
    },
    "model": {
      "name": "log2__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "log2"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        14.067616887325931
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "log"
      }
    },
    "model": {
      "name": "log__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "log"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        142.626
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "log"
      }
    },
    "model": {
      "name": "log__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "log"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "log"
      }
    },
    "model": {
      "name": "log__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "log"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        14.703868432581809
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "logit"
      }
    },
    "model": {
      "name": "logit_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "logit"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        172.898
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "logit"
      }
    },
    "model": {
      "name": "logit_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "logit"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "logit"
      }
    },
    "model": {
      "name": "logit_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "logit"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        12.129444178147098
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "logit"
      }
    },
    "model": {
      "name": "logit__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "logit"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        169.021
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "logit"
      }
    },
    "model": {
      "name": "logit__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "logit"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "logit"
      }
    },
    "model": {
      "name": "logit__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "logit"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        12.40761082239176
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "neg"
      }
    },
    "model": {
      "name": "neg_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "neg"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        53.694
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "neg"
      }
    },
    "model": {
      "name": "neg_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "neg"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "neg"
      }
    },
    "model": {
      "name": "neg_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "neg"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        39.057592036564316
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "neg"
      }
    },
    "model": {
      "name": "neg__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "neg"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        52.068
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "neg"
      }
    },
    "model": {
      "name": "neg__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "neg"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "neg"
      }
    },
    "model": {
      "name": "neg__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "neg"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        40.27730073588841
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "reciprocal"
      }
    },
    "model": {
      "name": "reciprocal_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "reciprocal"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        58.995
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "reciprocal"
      }
    },
    "model": {
      "name": "reciprocal_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "reciprocal"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "reciprocal"
      }
    },
    "model": {
      "name": "reciprocal_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "reciprocal"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        35.5477262244876
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "reciprocal"
      }
    },
    "model": {
      "name": "reciprocal__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "reciprocal"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        57.139
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "reciprocal"
      }
    },
    "model": {
      "name": "reciprocal__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "reciprocal"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "reciprocal"
      }
    },
    "model": {
      "name": "reciprocal__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "reciprocal"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        36.702797762684675
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        53.223
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        39.40337246427088
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        52.098
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "relu"
      }
    },
    "model": {
      "name": "relu__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "relu"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        40.25398529282265
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "round"
      }
    },
    "model": {
      "name": "round_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "round"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        51.022
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "round"
      }
    },
    "model": {
      "name": "round_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "round"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "round"
      }
    },
    "model": {
      "name": "round_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "round"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        41.10317748991485
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "round"
      }
    },
    "model": {
      "name": "round__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "round"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        50.404
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "round"
      }
    },
    "model": {
      "name": "round__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "round"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "round"
      }
    },
    "model": {
      "name": "round__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "round"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        41.6065966103246
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "rsqrt"
      }
    },
    "model": {
      "name": "rsqrt_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "rsqrt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        69.708
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "rsqrt"
      }
    },
    "model": {
      "name": "rsqrt_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "rsqrt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "rsqrt"
      }
    },
    "model": {
      "name": "rsqrt_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "rsqrt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        30.084888609565276
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "rsqrt"
      }
    },
    "model": {
      "name": "rsqrt__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "rsqrt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        65.638
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "rsqrt"
      }
    },
    "model": {
      "name": "rsqrt__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "rsqrt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "rsqrt"
      }
    },
    "model": {
      "name": "rsqrt__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "rsqrt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        31.950119377738424
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sigmoid"
      }
    },
    "model": {
      "name": "sigmoid_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.972
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sigmoid"
      }
    },
    "model": {
      "name": "sigmoid_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sigmoid"
      }
    },
    "model": {
      "name": "sigmoid_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        19.244931308379208
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sigmoid"
      }
    },
    "model": {
      "name": "sigmoid__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sigmoid"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.915
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sigmoid"
      }
    },
    "model": {
      "name": "sigmoid__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sigmoid"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sigmoid"
      }
    },
    "model": {
      "name": "sigmoid__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sigmoid"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        19.61505640505049
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sign"
      }
    },
    "model": {
      "name": "sign_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sign"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        55.495
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sign"
      }
    },
    "model": {
      "name": "sign_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sign"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sign"
      }
    },
    "model": {
      "name": "sign_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sign"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        37.79012535139149
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sgn"
      }
    },
    "model": {
      "name": "sgn_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sgn"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        55.504
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sgn"
      }
    },
    "model": {
      "name": "sgn_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sgn"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sgn"
      }
    },
    "model": {
      "name": "sgn_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sgn"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        37.78368725675268
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sin"
      }
    },
    "model": {
      "name": "sin_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sin"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.42
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sin"
      }
    },
    "model": {
      "name": "sin_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sin"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sin"
      }
    },
    "model": {
      "name": "sin_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sin"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        16.99200793646481
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sin"
      }
    },
    "model": {
      "name": "sin__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sin"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.628
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sin"
      }
    },
    "model": {
      "name": "sin__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sin"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sin"
      }
    },
    "model": {
      "name": "sin__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sin"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        17.530612363950343
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sinh"
      }
    },
    "model": {
      "name": "sinh_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sinh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        233.793
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sinh"
      }
    },
    "model": {
      "name": "sinh_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sinh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sinh"
      }
    },
    "model": {
      "name": "sinh_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sinh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        8.970140840318974
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sqrt"
      }
    },
    "model": {
      "name": "sqrt_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sqrt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        54.579
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sqrt"
      }
    },
    "model": {
      "name": "sqrt_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sqrt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sqrt"
      }
    },
    "model": {
      "name": "sqrt_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sqrt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        38.424324773700775
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sqrt"
      }
    },
    "model": {
      "name": "sqrt__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sqrt"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        53.416
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sqrt"
      }
    },
    "model": {
      "name": "sqrt__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sqrt"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sqrt"
      }
    },
    "model": {
      "name": "sqrt__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sqrt"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        39.26073418734446
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "square"
      }
    },
    "model": {
      "name": "square_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "square"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        54.148
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "square"
      }
    },
    "model": {
      "name": "square_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "square"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "square"
      }
    },
    "model": {
      "name": "square_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "square"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        38.73011012492103
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "square"
      }
    },
    "model": {
      "name": "square__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "square"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        53.682
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "square"
      }
    },
    "model": {
      "name": "square__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "square"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "square"
      }
    },
    "model": {
      "name": "square__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "square"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        39.066241983119234
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "tan"
      }
    },
    "model": {
      "name": "tan_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "tan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        203.023
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "tan"
      }
    },
    "model": {
      "name": "tan_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "tan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "tan"
      }
    },
    "model": {
      "name": "tan_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "tan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.329609870230774
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "tan"
      }
    },
    "model": {
      "name": "tan__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "tan"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        200.744
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "tan"
      }
    },
    "model": {
      "name": "tan__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "tan"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "tan"
      }
    },
    "model": {
      "name": "tan__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "tan"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.446914161722058
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "tanh"
      }
    },
    "model": {
      "name": "tanh_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "tanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        245.353
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "tanh"
      }
    },
    "model": {
      "name": "tanh_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "tanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "tanh"
      }
    },
    "model": {
      "name": "tanh_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "tanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        8.547503178002598
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "tanh"
      }
    },
    "model": {
      "name": "tanh__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "tanh"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        244.166
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "tanh"
      }
    },
    "model": {
      "name": "tanh__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "tanh"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "tanh"
      }
    },
    "model": {
      "name": "tanh__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "tanh"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        8.589046487344737
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "trunc"
      }
    },
    "model": {
      "name": "trunc_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "trunc"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        52.542
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "trunc"
      }
    },
    "model": {
      "name": "trunc_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "trunc"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "trunc"
      }
    },
    "model": {
      "name": "trunc_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "trunc"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        39.91419154065383
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "trunc"
      }
    },
    "model": {
      "name": "trunc__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "trunc"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        50.854
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "trunc"
      }
    },
    "model": {
      "name": "trunc__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "trunc"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "trunc"
      }
    },
    "model": {
      "name": "trunc__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "trunc"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        41.23839291131651
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "unique"
      }
    },
    "model": {
      "name": "unique_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "unique"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        20871.022
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "unique"
      }
    },
    "model": {
      "name": "unique_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "unique"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "unique"
      }
    },
    "model": {
      "name": "unique_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "unique"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.10048152041193019
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "zero"
      }
    },
    "model": {
      "name": "zero__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "zero"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        51.249
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "zero"
      }
    },
    "model": {
      "name": "zero__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "zero"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "zero"
      }
    },
    "model": {
      "name": "zero__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "zero"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        40.920450723837725
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "bernoulli"
      }
    },
    "model": {
      "name": "bernoulli__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "bernoulli"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2754.978
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "bernoulli"
      }
    },
    "model": {
      "name": "bernoulli__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "bernoulli"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "bernoulli"
      }
    },
    "model": {
      "name": "bernoulli__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "bernoulli"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.7612228999838027
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "cauchy"
      }
    },
    "model": {
      "name": "cauchy__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "cauchy"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        6124.048
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "cauchy"
      }
    },
    "model": {
      "name": "cauchy__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "cauchy"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "cauchy"
      }
    },
    "model": {
      "name": "cauchy__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "cauchy"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.34244536823361393
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "digamma"
      }
    },
    "model": {
      "name": "digamma__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "digamma"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        962.443
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "digamma"
      }
    },
    "model": {
      "name": "digamma__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "digamma"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "digamma"
      }
    },
    "model": {
      "name": "digamma__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "digamma"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.1789874725861296
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "exponential"
      }
    },
    "model": {
      "name": "exponential__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "exponential"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        4538.804
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "exponential"
      }
    },
    "model": {
      "name": "exponential__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "exponential"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "exponential"
      }
    },
    "model": {
      "name": "exponential__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "exponential"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        0.46204946720910717
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "normal"
      }
    },
    "model": {
      "name": "normal__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "normal"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        1957.055
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "normal"
      }
    },
    "model": {
      "name": "normal__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "normal"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "normal"
      }
    },
    "model": {
      "name": "normal__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "normal"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        1.0715856373322057
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "random"
      }
    },
    "model": {
      "name": "random__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "random"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        752.92
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "random"
      }
    },
    "model": {
      "name": "random__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "random"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "random"
      }
    },
    "model": {
      "name": "random__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "random"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.7853598919562734
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sign"
      }
    },
    "model": {
      "name": "sign__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sign"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        53.883
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sign"
      }
    },
    "model": {
      "name": "sign__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sign"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "sign"
      }
    },
    "model": {
      "name": "sign__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "sign"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        38.920676514873
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "uniform"
      }
    },
    "model": {
      "name": "uniform__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "uniform"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        720.309
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "uniform"
      }
    },
    "model": {
      "name": "uniform__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "uniform"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "uniform"
      }
    },
    "model": {
      "name": "uniform__M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "uniform"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        2.9114604568878546
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "half"
      }
    },
    "model": {
      "name": "half_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "half"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        194.402
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "half"
      }
    },
    "model": {
      "name": "half_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "half"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "half"
      }
    },
    "model": {
      "name": "half_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "half"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        10.787692650507472
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "long"
      }
    },
    "model": {
      "name": "long_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "long"
      }
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        63.326
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "long"
      }
    },
    "model": {
      "name": "long_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "long"
      }
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        0.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator benchmark",
      "mode": "inference",
      "dtype": "float",
      "extra_info": {
        "input_config": "M: 512, N: 512, device: cpu",
        "device": "cpu",
        "arch": "aarch64",
        "use_compile": false,
        "operator_name": "long"
      }
    },
    "model": {
      "name": "long_M512_N512_cpu",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ],
      "extra_info": {
        "operator_name": "long"
      }
    },
    "metric": {
      "name": "memory bandwidth",
      "unit": "GB/s",
      "benchmark_values": [
        33.11692578380784
      ],
      "target_value": null
    }
  }
]