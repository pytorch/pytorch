# Inline Fusion vs Async Compilation æ·±åº¦åˆ†æ

**Date**: 2025-11-07
**Purpose**: ç†è§£ inline fusion ä¸ async compilation çš„å†²çªï¼Œä»¥åŠå¦‚ä½•è§£å†³

---

## TL;DR - æ ¸å¿ƒé—®é¢˜å›ç­”

### Q1: Custom Op è¦èµ° defer è·¯çº¿ï¼ˆMultiTemplateBufferï¼‰è¿˜éœ€è¦åšä»€ä¹ˆï¼Ÿ

**A**: éœ€è¦ 5 ä¸ªå…³é”®æ”¹åŠ¨ï¼š

1. âœ… **Config æ ‡å¿—**: æ·»åŠ  `config.benchmark_collective_epilogue_fusion = True`
2. âœ… **Custom Op è°ƒç”¨**: ä¼ é€’ `return_multi_template=True` åˆ° `autotune_select_algorithm()`
3. âš ï¸ **Scheduler é›†æˆ**: æ‰©å±• `finalize_multi_template_buffers()` å¤„ç† collective ops
4. âš ï¸ **Precompile æ–¹æ³•**: SubgraphChoiceCaller éœ€è¦å®ç° `precompile()` æ–¹æ³•ï¼ˆ**å…³é”®**ï¼‰
5. âš ï¸ **Async å…¼å®¹æ€§**: ç¡®ä¿ subgraph å¯ä»¥å¹¶è¡Œ benchmarkï¼ˆé¿å… serialization bottleneckï¼‰

### Q2: Inline Fusion ä¸ºä»€ä¹ˆæ²¡ç”¨åœ¨ internalï¼Ÿ

**A**: å› ä¸º **breaks async compilation**ï¼Œå…·ä½“åŸå› ï¼š

1. **SubgraphChoiceCaller ç¼ºå°‘ `precompile()` æ–¹æ³•**ï¼Œæ— æ³•å‚ä¸å¹¶è¡Œé¢„ç¼–è¯‘
2. **Async compilation pipeline æ— æ³•å¤„ç† fused subgraphs**ï¼Œå¯¼è‡´ serialization bottleneck
3. **ThreadPoolExecutor çš„å¹¶è¡Œæ€§è¢«ç ´å**ï¼Œfusion å¿…é¡»åŒæ­¥ç¼–è¯‘
4. **Default config æ˜¯ `benchmark_epilogue_fusion=False`**ï¼Œæ‰€ä»¥ inline fusion ä¸å¯ç”¨

### Q3: tuned_mm çš„ decompose_k èƒ½åš epilogue fusion å—ï¼Ÿ

**A**: **YESï¼**âœ…

- `decompose_k_subgraph_template` é€šè¿‡ **SubgraphBuffer** æ”¯æŒ epilogue fusion
- Test è¯æ®: `(a @ b).relu()` ç”Ÿæˆ `triton_.*_fused_mm_0.run`ï¼ˆèåˆ kernelï¼‰
- æœºåˆ¶: SubgraphBuffer â†’ inline_subgraph_to_ir_nodes() â†’ ç”Ÿæˆå¯èåˆçš„ IR nodes

### Q4: å¦‚ä½•æŠŠ decompose_k inline fusion é›†æˆåˆ° internal mmï¼Ÿ

**A**: æœ‰ **3 ç§æ–¹æ¡ˆ**ï¼Œæ¨èç¨‹åº¦ä»é«˜åˆ°ä½ï¼š

1. ğŸ¥‡ **ä¿®å¤ async compilation** (æ¨èï¼Œä½†å¤æ‚)
   - ç»™ SubgraphChoiceCaller æ·»åŠ  `precompile()` æ–¹æ³•
   - æ”¯æŒå¹¶è¡Œé¢„ç¼–è¯‘ subgraphs

2. ğŸ¥ˆ **ä½¿ç”¨ MultiTemplateBuffer** (ä¸­ç­‰å¤æ‚)
   - å»¶è¿Ÿ benchmarking åˆ° scheduler é˜¶æ®µ
   - é¿å… async precompilation é—®é¢˜

3. ğŸ¥‰ **ç¦ç”¨å¹¶è¡Œé¢„ç¼–è¯‘** (ç®€å•ä½†æ…¢)
   - è®¾ç½® `config.max_autotune_gemm_threads = 1`
   - æ‰€æœ‰ choices ä¸²è¡Œç¼–è¯‘

---

## ç›®å½•

1. [Current Custom Op Inline Fusion å®ç°](#1-current-custom-op-inline-fusion-å®ç°)
2. [Decompose K Subgraph æœºåˆ¶](#2-decompose-k-subgraph-æœºåˆ¶)
3. [Async Compilation æ¶æ„](#3-async-compilation-æ¶æ„)
4. [ä¸ºä»€ä¹ˆ Inline Fusion ç ´å Async Compilation](#4-ä¸ºä»€ä¹ˆ-inline-fusion-ç ´å-async-compilation)
5. [è§£å†³æ–¹æ¡ˆå¯¹æ¯”](#5-è§£å†³æ–¹æ¡ˆå¯¹æ¯”)
6. [å®ç°è·¯çº¿å›¾](#6-å®ç°è·¯çº¿å›¾)

---

## 1. Current Custom Op Inline Fusion å®ç°

### ä½ç½®ä¸ä»£ç 

**æ–‡ä»¶**: `/torch/_inductor/kernel/custom_op.py` (Lines 373-389)

```python
# Apply inlining for fusion if winning_choice has graph;
# otherwise return result as-is (default fallback impl)
if winning_choice.gm is not None:
    log.debug(
        "Inlining winning choice: %s (name=%s)",
        getattr(winning_choice, "name", type(winning_choice).__name__),
        name,
    )
    from torch._inductor.codegen.subgraph import inline_subgraph_to_ir_nodes

    return inline_subgraph_to_ir_nodes(winning_choice.gm, inputs, name)

log.debug(
    "Winning choice does not support inlining: %s (name=%s)",
    getattr(winning_choice, "name", type(winning_choice).__name__),
    name,
)
return selected_result
```

### Inline Fusion æœºåˆ¶

```
Winning Choice (has .gm attribute)
        â†“
inline_subgraph_to_ir_nodes(gm, inputs, name)
        â†“ (subgraph.py:27-40)
process_subgraph_nodes(gm, inputs)
        â†“ (lowering.py:7310-7336)
For each FX node:
â”œâ”€ placeholder â†’ map to input args
â”œâ”€ compute nodes â†’ V.graph.run_node()
â””â”€ output â†’ extract result
        â†“
Returns: TensorBox with individual IR nodes (fusable!)
```

**å…³é”®ç‰¹æ€§**:
1. âœ… **FX graph åˆ†è§£**: æ¯ä¸ªæ“ä½œå˜æˆç‹¬ç«‹çš„ ComputedBuffer
2. âœ… **Fusable IR**: å¯ä»¥ä¸åç»­ epilogue æ“ä½œèåˆ
3. âœ… **å·²å®ç°**: ä»£ç å·²åœ¨ custom_op.py ä¸­

**ä¸ºä»€ä¹ˆæ²¡ç”¨åœ¨ internalï¼Ÿ**
- âŒ **Breaks async compilation** (ä¸‹é¢ä¼šè¯¦ç»†è§£é‡Š)
- âŒ **Default config ä¸å¯ç”¨**: `benchmark_epilogue_fusion=False`
- âŒ **SubgraphChoiceCaller ç¼ºå°‘ precompile()**

---

## 2. Decompose K Subgraph æœºåˆ¶

### Definition ä¸ Algorithm

**æ–‡ä»¶**: `/torch/_inductor/kernel/mm.py` (Lines 998-1047)

```python
def decomposeK(a, b, k_splits):
    """
    Decompose large K dimension into batched matmuls.

    Strategy:
    1. Reshape K into B (batch) dimension
    2. Use torch.bmm (batched matmul)
    3. Reduce results across batch dimension

    Example: (m, k) @ (k, n) with k_splits=32
    â†’ Reshape: (m, 32, k//32) @ (32, k//32, n)
    â†’ BMM: (32, m, k//32) @ (32, k//32, n) â†’ (32, m, n)
    â†’ Sum: (32, m, n) â†’ (m, n)
    """
    m = a.shape[0]
    n = b.shape[1]
    k = a.shape[1]

    k_parts = k // k_splits
    B = k_splits
    a_reshaped = torch.permute(a.reshape(m, B, k_parts), (1, 0, 2))  # [B, m, k_parts]
    b_reshaped = b.reshape(B, k_parts, n)                            # [B, k_parts, n]
    result = torch.bmm(a_reshaped, b_reshaped, out_dtype=torch.float32)  # [B, m, n]
    reduced_buf = torch.sum(result, 0)  # Sum across B dimension
    return reduced_buf.to(a.dtype)
```

### Epilogue Fusion æ”¯æŒ

**âœ… YES - é€šè¿‡ SubgraphBuffer**

**Test è¯æ®** (`test_max_autotune.py`, Lines 1527-1541):
```python
# Test adding epilogue also equivalent to eager
compiled_func = torch.compile(lambda a, b: (a @ b).relu(), dynamic=dynamic)
out, code = run_and_get_code(compiled_func, a, b)

FileCheck().check("extern_kernels.bmm_dtype").check_regex(
    "triton_.*_fused_mm_0.run"  # <-- "fused_mm_0" = decompose_k + relu fusion!
).check("decompose_k").run(code[0])
```

### Fusion å®ç°è·¯å¾„

```
tuned_mm() é€‰æ‹© decompose_k_subgraph_template
        â†“
generate() åˆ›å»º SubgraphChoiceCaller
        â†“
Autotuning é€‰æ‹©æœ€ä½³ choice
        â†“
custom_op.py: if winning_choice.gm is not None
        â†“
inline_subgraph_to_ir_nodes(winning_choice.gm, inputs, name)
        â†“
FX graph nodes â†’ Individual IR nodes (ComputedBuffer)
        â†“
Epilogue (e.g., relu) å¯ä»¥èåˆåˆ°æœ€åä¸€ä¸ª IR node
```

**å…³é”®ç‚¹**:
1. âœ… **SubgraphBuffer** ç”Ÿæˆå¯èåˆçš„ IR nodes
2. âœ… **Test éªŒè¯**: decompose_k + relu èåˆæˆåŠŸ
3. âœ… **Production ready**: æœºåˆ¶å·²å­˜åœ¨

---

## 3. Async Compilation æ¶æ„

### ThreadPoolExecutor Pipeline

**æ–‡ä»¶**: `/torch/_inductor/select_algorithm.py` (Lines 3009-3181)

```python
def make_precompile_fn(self, choices, name, inputs_key, precompilation_timeout_seconds):
    """
    Parallel precompilation of all choices using ThreadPoolExecutor.
    """
    num_workers = inductor_config.compile.max_workers()
    executor = ThreadPoolExecutor(max_workers=num_workers)  # Line 3095
    async_compile = torch._inductor.async_compile.AsyncCompile()  # Line 3096

    futures = {}

    for c in choices:
        if hasattr(c, "precompile"):  # Line 3112 - KEY CHECK
            triton_cuda_choice = isinstance(c, TritonTemplateCaller) and isinstance(
                c.bmreq, TritonGPUBenchmarkRequest)

            if triton_cuda_choice and async_compile.use_process_pool():
                # TRITON PATH: Async process pool compilation
                future = async_compile.triton(
                    kernel_name=c.bmreq.kernel_name,
                    source_code=source_code
                ).future  # Lines 3119-3121
            else:
                # FALLBACK PATH: Thread pool compilation
                future = executor.submit(precompile_with_captured_stdout, c)
                # Line 3124-3125

            futures[c] = future
        # else: NO precompile() â†’ skipped!

    return precompile_fn
```

### Async Compilation Decision Tree

```
Choice éœ€è¦ precompile?
    â”‚
    â”œâ”€ NO â†’ è·³è¿‡é¢„ç¼–è¯‘ï¼Œåç»­åŒæ­¥ç¼–è¯‘ï¼ˆSLOWï¼‰
    â”‚
    â””â”€ YES â†’ å¹¶è¡Œé¢„ç¼–è¯‘
           â”‚
           â”œâ”€ TritonTemplateCaller + CUDA?
           â”‚  â””â”€ YES â†’ AsyncCompile.triton() (Process Pool)
           â”‚          â”œâ”€ å¼‚æ­¥è¿›ç¨‹æ± ç¼–è¯‘
           â”‚          â””â”€ è¿”å› Future
           â”‚
           â””â”€ Other choices?
              â””â”€ YES â†’ ThreadPoolExecutor.submit()
                       â”œâ”€ çº¿ç¨‹æ± å¹¶è¡Œç¼–è¯‘
                       â””â”€ è¿”å› Future
```

### Key Methods

| Class | Method | Purpose |
|-------|--------|---------|
| `ThreadPoolExecutor` | `submit(fn, *args)` | æäº¤ä»»åŠ¡åˆ°çº¿ç¨‹æ±  |
| `AsyncCompile` | `triton()` | Triton kernel å¼‚æ­¥ç¼–è¯‘ |
| `TritonTemplateCaller` | `precompile()` | é¢„ç¼–è¯‘ Triton kernel |
| `SubgraphChoiceCaller` | âŒ **MISSING** `precompile()` | **é—®é¢˜æ‰€åœ¨** |

---

## 4. ä¸ºä»€ä¹ˆ Inline Fusion ç ´å Async Compilation

### Root Cause: SubgraphChoiceCaller ç¼ºå°‘ precompile()

**æ–‡ä»¶**: `/torch/_inductor/codegen/subgraph.py` (Lines 43-167)

```python
class SubgraphChoiceCaller(ir.ChoiceCaller):
    def __init__(self, gm, input_nodes, ...):
        self.gm = gm  # FX GraphModule
        self.original_inputs = input_nodes
        # ...

    def benchmark(self, *args, out):
        """Benchmark by compiling subgraph on-the-fly."""
        # Create GraphLowering
        bm_graph_lowering = GraphLowering(...)

        # Compile to module (SYNCHRONOUS!)
        mod = bm_graph_lowering.compile_to_module()

        # Benchmark
        return benchmarker.benchmark(...)

    # âŒ MISSING: def precompile(self): ...
    #            Cannot participate in async compilation!
```

**å¯¹æ¯” TritonTemplateCaller**:

```python
class TritonTemplateCaller(ir.TritonTemplateCallerBase):
    def __init__(self, ..., bmreq):
        self.bmreq = bmreq  # TritonBenchmarkRequest

    # âœ… HAS precompile() method
    def precompile(self):
        assert self.bmreq is not None
        self.bmreq.precompile()  # Can be called from thread/process pool
```

### Failure Chain

```
1. tuned_mm() æ”¶é›† choices
   â”œâ”€ TritonTemplateCaller (æœ‰ precompile())
   â”œâ”€ ExternKernelCaller (æœ‰ precompile())
   â””â”€ decompose_k_subgraph_template â†’ SubgraphChoiceCaller (âŒ æ—  precompile())

2. make_precompile_fn() å¼€å§‹å¹¶è¡Œé¢„ç¼–è¯‘
   â”œâ”€ for choice in choices:
   â”‚  â””â”€ if hasattr(choice, "precompile"):  # Line 3112
   â”‚     â”œâ”€ TritonTemplateCaller â†’ submit to pool âœ…
   â”‚     â”œâ”€ ExternKernelCaller â†’ submit to pool âœ…
   â”‚     â””â”€ SubgraphChoiceCaller â†’ SKIP (no precompile) âŒ
   â”‚
   â””â”€ SubgraphChoiceCaller ä¸ä¼šè¢«é¢„ç¼–è¯‘

3. åç»­ benchmark é˜¶æ®µ
   â”œâ”€ TritonTemplateCaller â†’ å·²é¢„ç¼–è¯‘ï¼Œå¿«é€Ÿ benchmark âœ…
   â”œâ”€ ExternKernelCaller â†’ å·²é¢„ç¼–è¯‘ï¼Œå¿«é€Ÿ benchmark âœ…
   â””â”€ SubgraphChoiceCaller â†’ å¿…é¡»åŒæ­¥ç¼–è¯‘ (SLOW) âŒ
                            â””â”€ Serialization bottleneck!

4. ç»“æœ
   â”œâ”€ Async å¹¶è¡Œæ€§è¢«ç ´å
   â”œâ”€ SubgraphChoiceCaller æˆä¸ºç“¶é¢ˆ
   â””â”€ æ€»ç¼–è¯‘æ—¶é—´æ˜¾è‘—å¢åŠ 
```

### Benchmark Serialization Problem

```
Without precompile():
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Thread 1: [Triton 1 precompile] [Triton 1 benchmark]
Thread 2: [Triton 2 precompile] [Triton 2 benchmark]
Thread 3: [Extern 1 precompile] [Extern 1 benchmark]
Main:     [Wait.....................] [Subgraph compile + benchmark]
                                      â†‘ BOTTLENECK (synchronous)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

With precompile():
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Thread 1: [Triton 1 precompile] [Triton 1 benchmark]
Thread 2: [Triton 2 precompile] [Triton 2 benchmark]
Thread 3: [Extern 1 precompile] [Extern 1 benchmark]
Thread 4: [Subgraph precompile] [Subgraph benchmark]
                                â†‘ PARALLEL (no bottleneck)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

---

## 5. è§£å†³æ–¹æ¡ˆå¯¹æ¯”

### æ–¹æ¡ˆ 1: ä¿®å¤ Async Compilation (æ¨è ğŸ¥‡)

**ç›®æ ‡**: ç»™ SubgraphChoiceCaller æ·»åŠ  `precompile()` æ–¹æ³•

#### å®ç°æ­¥éª¤

**Step 1: æ·»åŠ  precompile() æ–¹æ³•**

```python
# subgraph.py
class SubgraphChoiceCaller(ir.ChoiceCaller):
    def __init__(self, gm, input_nodes, ...):
        self.gm = gm
        self.original_inputs = input_nodes
        self._compiled_module = None  # Cache compiled module
        self._precompile_done = False

    def precompile(self):
        """Precompile subgraph for async compilation."""
        if self._precompile_done:
            return

        try:
            # Create GraphLowering with example inputs
            fake_mode = torch._subclasses.FakeTensorMode()
            with V.set_fake_mode(fake_mode):
                # Generate fake inputs
                fake_inputs = [
                    torch.empty_strided(
                        inp.get_size(), inp.get_stride(),
                        dtype=inp.get_dtype(), device=inp.get_device()
                    ) for inp in self.original_inputs
                ]

                # Compile subgraph
                bm_graph_lowering = GraphLowering(
                    self.gm,
                    example_inputs=fake_inputs,
                    ...
                )

                # Cache compiled module
                self._compiled_module = bm_graph_lowering.compile_to_module()
                self._precompile_done = True
        except Exception as e:
            log.warning(f"Precompile failed for {self.name}: {e}")
            self._precompile_done = False

    def benchmark(self, *args, out):
        """Use cached compiled module if available."""
        if self._compiled_module is not None:
            # Use pre-compiled module
            mod = self._compiled_module
        else:
            # Fallback: compile on-demand
            bm_graph_lowering = GraphLowering(...)
            mod = bm_graph_lowering.compile_to_module()

        return benchmarker.benchmark(...)
```

**Step 2: æµ‹è¯•å¹¶è¡Œé¢„ç¼–è¯‘**

```python
# test_subgraph_parallel_precompile.py
import torch
from torch._inductor.kernel.mm import decompose_k_subgraph_template
from torch._inductor.select_algorithm import autotune_select_algorithm

@torch.compile
def test_decompose_k_parallel(a, b):
    return (a @ b).relu()

# Enable parallel precompilation
torch._inductor.config.max_autotune_gemm_threads = 8

a = torch.randn(1024, 8192, device='cuda', dtype=torch.float16)
b = torch.randn(8192, 2048, device='cuda', dtype=torch.float16)

# Should use parallel precompilation
result = test_decompose_k_parallel(a, b)
```

#### ä¼˜ç‚¹ & ç¼ºç‚¹

| ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|------|
| âœ… å®Œå…¨å¹¶è¡ŒåŒ– | âš ï¸ å®ç°å¤æ‚ |
| âœ… æ— æ€§èƒ½æŸå¤± | âš ï¸ éœ€è¦å¤„ç† fake tensor mode |
| âœ… ä¿æŒ async æ¶æ„ | âš ï¸ å¯èƒ½æœ‰ cache coherency é—®é¢˜ |
| âœ… é•¿æœŸæœ€ä¼˜è§£ | âš ï¸ éœ€è¦å¤§é‡æµ‹è¯• |

---

### æ–¹æ¡ˆ 2: ä½¿ç”¨ MultiTemplateBuffer (ä¸­ç­‰å¤æ‚ ğŸ¥ˆ)

**ç›®æ ‡**: å»¶è¿Ÿ benchmarking åˆ° scheduler é˜¶æ®µï¼Œé¿å… async precompilation

#### æ¶æ„

```
custom_op.py
    â†“
autotune_select_algorithm(
    choices=[...],
    return_multi_template=True  # å¯ç”¨å»¶è¿Ÿ
)
    â†“
AlgorithmSelectorCache.__call__()
    â”œâ”€ ä¸ç«‹å³ benchmark
    â”œâ”€ åˆ›å»º MultiTemplateBuffer
    â””â”€ è¿”å›åŒ…å«æ‰€æœ‰ choices çš„ buffer
    â†“
Scheduler: finalize_multi_template_buffers()
    â”œâ”€ æ£€æµ‹ epilogue fusion æœºä¼š
    â”œâ”€ å¯¹æ¯ä¸ª choice (åŒ…æ‹¬ subgraph):
    â”‚  â””â”€ Benchmark with epilogue fused
    â””â”€ é€‰æ‹©æœ€ä½³ choice
```

#### å®ç°æ­¥éª¤

**Step 1: å¯ç”¨ MultiTemplateBuffer**

```python
# custom_op.py
def call_function(self, target, args, kwargs):
    # ... (existing detection code)

    if is_collective:
        return autotune_select_algorithm(
            f"custom_op_{op_overload}",
            choices=choices,
            is_collective=True,
            process_group=process_group,
            return_multi_template=True,  # NEW!
        )
```

**Step 2: Scheduler é›†æˆ**

```python
# scheduler.py
def finalize_multi_template_buffers(self, nodes):
    for node in nodes:
        multi_node = node.node

        # Check if has subgraph choices
        has_subgraph = any(
            isinstance(c, SubgraphChoiceCaller)
            for c in multi_node.unfiltered_choices
        )

        if has_subgraph:
            # Sequential benchmarking for subgraphs (no async)
            self._finalize_with_subgraph_choices(node, multi_node)
        else:
            # Standard parallel benchmarking
            self._finalize_compute_multi_template(node, multi_node)

def _finalize_with_subgraph_choices(self, node, multi_node):
    """
    Benchmark subgraph choices sequentially to avoid async issues.
    """
    timings = {}

    for choice in multi_node.unfiltered_choices:
        if isinstance(choice, SubgraphChoiceCaller):
            # Sequential benchmark (no precompile)
            with multi_node.swap_as_triton_caller(choice):
                ms = self._benchmark_single_choice(choice)
                timings[choice] = ms
        else:
            # Use cached timings from async precompilation
            cached_timings = multi_node.choice_timings()
            timings[choice] = cached_timings[choice]

    # Select best
    best_choice = min(timings, key=timings.__getitem__)
    multi_node.finalize_as_triton_caller(best_choice)
```

#### ä¼˜ç‚¹ & ç¼ºç‚¹

| ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|------|
| âœ… é¿å… async precompile é—®é¢˜ | âš ï¸ Subgraph ä»ç„¶ä¸²è¡Œ benchmark |
| âœ… æ”¯æŒ epilogue fusion | âš ï¸ å¢åŠ  scheduler å¤æ‚åº¦ |
| âœ… æ¸è¿›å¼å®ç° | âš ï¸ ç¼–è¯‘æ—¶é—´å¯èƒ½æ›´é•¿ |
| âœ… å¯ä»¥ä¸æ–¹æ¡ˆ 1 ç»“åˆ | âš ï¸ éœ€è¦ scheduler æ”¹åŠ¨ |

---

### æ–¹æ¡ˆ 3: ç¦ç”¨å¹¶è¡Œé¢„ç¼–è¯‘ (ç®€å•ä½†æ…¢ ğŸ¥‰)

**ç›®æ ‡**: å¼ºåˆ¶æ‰€æœ‰ choices ä¸²è¡Œç¼–è¯‘

#### å®ç°

```python
# config.py æˆ– runtime
torch._inductor.config.max_autotune_gemm_threads = 1  # Disable parallelism

# æˆ–è€…åœ¨ tuned_mm() ä¸­
if any(isinstance(c, SubgraphChoiceCaller) for c in choices):
    # Disable async precompilation for this tuned_mm call
    with torch._inductor.config.patch(max_autotune_gemm_threads=1):
        return autotune_select_algorithm(...)
```

#### ä¼˜ç‚¹ & ç¼ºç‚¹

| ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|------|
| âœ… æœ€ç®€å•å®ç° | âŒ ç¼–è¯‘æ—¶é—´æ˜¾è‘—å¢åŠ  |
| âœ… æ— éœ€ä»£ç æ”¹åŠ¨ | âŒ æµªè´¹ CPU æ ¸å¿ƒ |
| âœ… æµ‹è¯•/è°ƒè¯•å‹å¥½ | âŒ ä¸å¯æ‰©å±• |
| âœ… å¿«é€Ÿ workaround | âŒ é•¿æœŸä¸å¯è¡Œ |

---

## 6. å®ç°è·¯çº¿å›¾

### Phase 1: Quick Fix (æ–¹æ¡ˆ 3) - Week 1
```
Goal: å…ˆè®© inline fusion è·‘èµ·æ¥
â”œâ”€ 1.1: è®¾ç½® config.max_autotune_gemm_threads = 1
â”œâ”€ 1.2: æµ‹è¯• decompose_k + relu fusion
â”œâ”€ 1.3: éªŒè¯ functional correctness
â””â”€ 1.4: Benchmark performance (baseline)
```

### Phase 2: MultiTemplateBuffer (æ–¹æ¡ˆ 2) - Week 2-3
```
Goal: æ”¯æŒ epilogue fusionï¼Œä½†ä¿æŒä¸²è¡Œ subgraph benchmark
â”œâ”€ 2.1: å¯ç”¨ return_multi_template=True
â”œâ”€ 2.2: Scheduler é›†æˆ
â”‚  â”œâ”€ æ‰©å±• finalize_multi_template_buffers()
â”‚  â””â”€ å®ç° _finalize_with_subgraph_choices()
â”œâ”€ 2.3: æµ‹è¯• fusion benchmarking
â””â”€ 2.4: Performance å¯¹æ¯” (vs Phase 1)
```

### Phase 3: Async Fix (æ–¹æ¡ˆ 1) - Week 4-6
```
Goal: å®Œå…¨å¹¶è¡ŒåŒ–ï¼Œæ—  bottleneck
â”œâ”€ 3.1: SubgraphChoiceCaller.precompile() å®ç°
â”‚  â”œâ”€ Fake tensor mode æ”¯æŒ
â”‚  â”œâ”€ Compiled module caching
â”‚  â””â”€ Error handling
â”œâ”€ 3.2: Async compilation é›†æˆæµ‹è¯•
â”‚  â”œâ”€ Thread pool utilization
â”‚  â”œâ”€ Cache coherency
â”‚  â””â”€ Race condition æ£€æŸ¥
â”œâ”€ 3.3: Performance benchmarking
â”‚  â”œâ”€ Compilation time å¯¹æ¯”
â”‚  â”œâ”€ Parallel scalability (1/2/4/8 threads)
â”‚  â””â”€ Memory usage
â””â”€ 3.4: Production rollout
   â”œâ”€ Default config è°ƒæ•´
   â””â”€ Documentation
```

---

## å…³é”®æ–‡ä»¶æ”¹åŠ¨æ€»ç»“

### æ–¹æ¡ˆ 1 (Async Fix)

| æ–‡ä»¶ | æ”¹åŠ¨ | è¡Œæ•°ä¼°è®¡ |
|-----|------|---------|
| `subgraph.py` | æ·»åŠ  `SubgraphChoiceCaller.precompile()` | +50 |
| `select_algorithm.py` | æ— éœ€æ”¹åŠ¨ï¼ˆè‡ªåŠ¨æ”¯æŒï¼‰ | 0 |
| `test_subgraph_choice.py` | æµ‹è¯•å¹¶è¡Œé¢„ç¼–è¯‘ | +100 |

### æ–¹æ¡ˆ 2 (MultiTemplateBuffer)

| æ–‡ä»¶ | æ”¹åŠ¨ | è¡Œæ•°ä¼°è®¡ |
|-----|------|---------|
| `custom_op.py` | ä¼ é€’ `return_multi_template=True` | +5 |
| `scheduler.py` | æ‰©å±• `finalize_multi_template_buffers()` | +80 |
| `config.py` | æ·»åŠ  `benchmark_collective_epilogue_fusion` | +5 |
| `test_collective_autotuning.py` | æµ‹è¯• fusion benchmarking | +150 |

### æ–¹æ¡ˆ 3 (Quick Fix)

| æ–‡ä»¶ | æ”¹åŠ¨ | è¡Œæ•°ä¼°è®¡ |
|-----|------|---------|
| `mm.py` æˆ– runtime | è®¾ç½® `max_autotune_gemm_threads=1` | +3 |

---

## æ¨èç­–ç•¥

### çŸ­æœŸ (1-2 å‘¨)
ä½¿ç”¨ **æ–¹æ¡ˆ 3** å¿«é€ŸéªŒè¯ inline fusion çš„ correctness å’Œ performance gainsã€‚

```python
# Quick test in mm.py
if any(isinstance(c, SubgraphChoiceCaller) for c in choices):
    with torch._inductor.config.patch(max_autotune_gemm_threads=1):
        return autotune_select_algorithm(...)
```

### ä¸­æœŸ (3-4 å‘¨)
å®ç° **æ–¹æ¡ˆ 2** (MultiTemplateBuffer) ä»¥æ”¯æŒ epilogue fusion benchmarkingã€‚

ä¼˜å…ˆçº§:
1. Custom op autotuning èµ° defer è·¯çº¿
2. Scheduler é›†æˆ
3. Fusion benchmarking æµ‹è¯•

### é•¿æœŸ (5-8 å‘¨)
å®ç° **æ–¹æ¡ˆ 1** (Async Fix) ä½œä¸ºæœ€ç»ˆä¼˜åŒ–ã€‚

é‡ç‚¹:
1. SubgraphChoiceCaller.precompile() å®ç°
2. å……åˆ†æµ‹è¯•å¹¶è¡Œæ€§å’Œ cache coherency
3. Performance profiling å’Œä¼˜åŒ–

---

## æ€»ç»“

| é—®é¢˜ | å›ç­” | å…³é”®æ–‡ä»¶ |
|-----|------|---------|
| Custom op è¦èµ° defer è·¯çº¿è¿˜éœ€è¦åšä»€ä¹ˆï¼Ÿ | 5 ä¸ªæ”¹åŠ¨ï¼ˆè§ TL;DRï¼‰ | custom_op.py, scheduler.py, subgraph.py |
| Inline fusion ä¸ºä»€ä¹ˆæ²¡ç”¨åœ¨ internalï¼Ÿ | Breaks async compilation | select_algorithm.py:3112 |
| decompose_k èƒ½åš epilogue fusion å—ï¼Ÿ | YES âœ… (via SubgraphBuffer) | mm.py, test_max_autotune.py |
| å¦‚ä½•é›†æˆ decompose_k inline fusionï¼Ÿ | 3 ç§æ–¹æ¡ˆï¼ˆæ¨èæ–¹æ¡ˆ 1 é•¿æœŸï¼‰ | è§å®ç°è·¯çº¿å›¾ |

**Next Step**: é€‰æ‹©ä¸€ä¸ªæ–¹æ¡ˆå¼€å§‹å®ç°ï¼æ¨èä»æ–¹æ¡ˆ 3 å¼€å§‹å¿«é€ŸéªŒè¯ã€‚

---

**Document Version**: 1.0
**Last Updated**: 2025-11-07
**Author**: Collective Op Autotuning Team
