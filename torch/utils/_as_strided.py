"""Utility for reconstructing a sequence of view operations that is equivalent
to an as_strided call (change a source tensor's size/stride/offset to a
target size/stride/offset).

Given an arbitrary source tensor, imagine that a user has applied a
sequence of view operations (slice, permute and view) producing a target
tensor.  With only the source and the target tensor, construct a sequence
of views that takes the source tensor to the target tensor.

This problem is trivial with as_strided, but often, it can be helpful to be
able to construct a sequence of "normal" view operations instead of brute
forcing.  The reason is that as_strided is extremely flexible, making it
difficult for backends to implement: for example, using it you can generate
views with strange overlap patterns (e.g., rolling windows) or generate an
output view which is out of bounds for the original view.  If you are
implementing a tensor subclass, it may be possible to implement simple views
but not as_strided (e.g., DTensor sharding propagation).  These utilities help
you reconstruct view operations in some situations where it is possible.

We apply some simplifying assumptions for this algorithm:

1. The stride of a size-1 dimension doesn't matter.  Actually, sometimes it
   does (e.g., in the case of inferring memory layout), but our longer term
   plan for addressing this is to add a special unsqueeze operation which will
   let us specify exactly what stride an unsqueezed dimension should get.

2. We assume the input tensor is non-overlapping (except for stride-0 dimensions)
   i.e., that for every physical location there is a unique coordinate that
   maps to it.  (This implies the destination tensor is non-overlapping except
   for stride-0 dimensions, as we do not include unfold in the list of valid
   view operations.)

3. We only account for these view operations:

    - view; or equivalently, these four operations:
      - squeeze
      - unsqueeze
      - unflatten
      - flatten (output view only)
    - permute (this subsumes transpose, movedim, etc.)
    - narrow (slice with step=1 only; no support for nontrivial step)
    - expand

# Definition of view operations

To start, it's helpful to review how these view operations affect the size/stride
of a tensor.  In general, these operations (aside from permute and flatten) only affect a
single source dimension, so we will only discuss the action on a single dimension.
We will use (size):(stride) (CuTe notation) to compactly denote sizes and strides.
It can be helpful to study the rules when a = 1, as this variable is unconstrained
in all the formulas.

The important operations are these three:

- unflatten_2d(dim, x, y)  # 2D case is sufficient to implement ND case

  (x * y,):(a,)  -->  (x, y):(y * a, a)

- narrow(dim, start, length)

  (x,):(a,)  -->  (length,):(a,)

    where storage_offset += start * a

  NB: slice(dim, start, stop, step) with nontrivial step is not currently
  supported, though it could be added in the future.

- squeeze(dim)

  (1,):(a,)  -->  ():()

These two are simply inverses:

- unsqueeze(dim):

  (x,):(a,)  -->  (1, x):(x * a, a)

- flatten_2d(dim)  # flatten dim and dim+1; sufficient for ND case

  (x, y):(y * a, a)  -->  (x * y,):(a,)

And permute reorders the sizes-strides without otherwise making modifications.

# The algorithm

First, take the source tensor and put it into canonical form by:

1. Removing all size-1 and stride-0 dimensions: For each stride-0 dimension,
   narrow it to size 1, then squeeze all size-1 dimensions at once.
2. Permuting the tensor so the strides are in strictly descending order.
   This is always possible as all size-1 dimensions are removed and we
   required the input to be non-overlapping.
3. Flattening all contiguous dims, so that every pair of adjacent
   dims is non-contiguous with each other (cannot be flattened).

For any non size-1/stride-0 dimension in the target tensor, we can uniquely
assign it to the only canonical source dim that could have created it.
Specifically, for any dimension (x,):(a,), any target stride s such that
a <= s <= (x-1) * a could only have been generated from this source dim.
(x*a is excluded as it can only be generated by a size-1 dim!  And it is
important to be precise on the bound here because it is not
guaranteed that on a canonical source tensor (x,y):(a,b) that y*b <= a).
So our plan is to process each canonical source dim one-by-one and translate
them into the target dimensions.

For each canonical dimension, we may have multiple target dimensions that map
to it. We process these target dimensions left to right (largest stride first).

For each target dimension (except the last one from this canonical dim):
  1. We unflatten to create the target dimension and a "remainder" dimension.
     The key insight: unflatten(x*y, (x, y)) gives strides (y*a, a) where a
     is the canonical stride. To get the target stride s for the first dim,
     we need y*a = s, so we choose y = s/a.
  2. This creates dimension with the correct stride. We then move to the next
     target dimension, which will be carved out of the "remainder" dimension.
  3. If the needed size (target_size * y) exceeds available size, we return
     NotImplemented.

For the last target dimension from this canonical dim:
  1. Its stride must match the canonical stride, otherwise we return NotImplemented.
  2. Narrow to the final target size.

Limitations:
  - Slice operations with nontrivial step (e.g., [::2]) are not currently
    supported. This means some valid view sequences cannot be reconstructed.
"""

import functools
import types

import torch


def _canonicalize_tensor(tensor: torch.Tensor) -> torch.Tensor:
    """
    Canonicalize a tensor by:
    1. Narrowing stride-0 dimensions to size 1
    2. Squeezing all size-1 dimensions
    3. Permuting so strides are in descending order
    4. Flattening contiguous dimensions

    Returns a tensor with strictly descending strides where no two adjacent
    dims are contiguous with each other, and every dim has size > 1.
    """
    result = tensor

    # Narrow stride-0 dimensions to size 1
    for dim in reversed(range(result.ndim)):
        if result.stride(dim) == 0:
            result = result.narrow(dim, 0, 1)

    # Squeeze all size-1 dimensions
    # TODO: don't squeeze if unnecessary
    result = result.squeeze()

    # Permute so strides are in descending order
    stride_order = sorted(
        range(result.ndim), key=lambda i: result.stride(i), reverse=True
    )
    if stride_order != list(range(result.ndim)):
        result = result.permute(stride_order)

    # Flatten contiguous dimensions
    # TODO: do it in one go rather than lots of flatten calls
    i = 0
    while i < result.ndim - 1:
        if result.stride(i) == result.size(i + 1) * result.stride(i + 1):
            result = result.flatten(i, i + 1)
        else:
            i += 1

    return result


def _equal_significant_size_strides(lsize, lstride, rsize, rstride):
    if lsize != rsize:
        return False
    if any(s == 0 for s in lsize):
        return True
    for s, l, r in zip(lsize, lstride, rstride):
        if s == 1:
            continue
        if l != r:
            return False
    return True


def _unexpand_target_then(result: torch.Tensor, size, stride, storage_offset, cb):
    """
    Remove stride-0 dimensions from target, call cb, then expand them back.

    This handles expand operations which create stride-0 dimensions.
    For example: (5,):(1,) -> expand -> (3, 5):(0, 1)
    """
    # Identify stride-0 dimensions (from expand)
    stride0_dims = tuple(i for i, s in enumerate(stride) if s == 0)
    stride0_sizes = tuple(size[i] for i in stride0_dims)

    # Remove stride-0 dimensions
    new_size = tuple(s for i, s in enumerate(size) if i not in stride0_dims)
    new_stride = tuple(s for i, s in enumerate(stride) if i not in stride0_dims)

    result = cb(result, new_size, new_stride, storage_offset)
    if result is NotImplemented:
        return NotImplemented
    assert (
        _equal_significant_size_strides(
            result.size(), result.stride(), new_size, new_stride
        )
        and result.storage_offset() == storage_offset
    )

    # Expand the stride-0 dimensions back
    for i, orig_size in zip(stride0_dims, stride0_sizes):
        # Because we expand left-to-right, result's dims get shifted so we
        # need to unsqueeze at position i then expand
        result = torch.unsqueeze(result, i)
        # Expand the newly unsqueezed dimension to the original size
        expand_size = list(result.size())
        expand_size[i] = orig_size
        result = result.expand(expand_size)

    assert (
        _equal_significant_size_strides(result.size(), result.stride(), size, stride)
        and result.storage_offset() == storage_offset
    )
    return result


def _squeeze_target_then(result: torch.Tensor, size, stride, storage_offset, cb):
    dims = tuple(i for i, s in enumerate(size) if s == 1)
    new_size = tuple(s for i, s in enumerate(size) if i not in dims)
    new_stride = tuple(s for i, s in enumerate(stride) if i not in dims)
    result = cb(result, new_size, new_stride, storage_offset)
    if result is NotImplemented:
        return NotImplemented
    assert (
        _equal_significant_size_strides(
            result.size(), result.stride(), new_size, new_stride
        )
        and result.storage_offset() == storage_offset
    )
    for i in dims:
        # Because we unsqueeze left-to-right result's dims get shifted so we
        # put dims in the right spot as we go
        result = torch.unsqueeze(result, i)
    assert (
        _equal_significant_size_strides(result.size(), result.stride(), size, stride)
        and result.storage_offset() == storage_offset
    )
    return result


def _permute_target_then(result: torch.Tensor, size, stride, storage_offset, cb):
    perm, sorted_stride = zip(
        *sorted(enumerate(stride), key=lambda x: x[1], reverse=True)
    )
    sorted_size = tuple(size[i] for i in perm)

    result = cb(result, sorted_size, sorted_stride, storage_offset)
    if result is NotImplemented:
        return NotImplemented
    assert (
        _equal_significant_size_strides(
            result.size(), result.stride(), sorted_size, sorted_stride
        )
        and result.storage_offset() == storage_offset
    )

    inv = [0] * len(perm)
    for i, p in enumerate(perm):
        inv[p] = i
    result = result.permute(inv)
    assert (
        _equal_significant_size_strides(result.size(), result.stride(), size, stride)
        and result.storage_offset() == storage_offset
    )
    return result


def _process_canonical_dims(
    result: torch.Tensor,
    size,
    stride,
    storage_offset,
) -> torch.Tensor | types.NotImplementedType:
    """
    Process canonical source dimensions and map them to target dimensions.

    For each canonical dimension (x,):(a,), any target stride s such that
    a <= s <= (x-1) * a could only have been generated from this source dim.

    Since the target stride is sorted in descending order (after _permute_target_then),
    we can process each canonical dim and consume target dims as we go.
    """
    # Read canonical sizes/strides from result (already canonicalized)
    canonical_sizes = result.size()
    canonical_strides = result.stride()

    # Target dims are already sorted by stride descending (via _permute_target_then)
    # and size-1/stride-0 dims have been removed (via _squeeze_target_then)
    target_dims = [(i, size[i], stride[i]) for i in range(len(size))]

    # Pointer to current position in target_dims
    target_idx = 0
    # Current dimension in result that we're working on
    current_dim = 0

    for canonical_dim in range(len(canonical_sizes)):
        canonical_size = canonical_sizes[canonical_dim]
        canonical_stride = canonical_strides[canonical_dim]

        # Collect all target dims that map to this canonical dim
        # For dimension (x,):(a,), target stride s must satisfy: a <= s <= (x-1) * a
        min_stride = canonical_stride
        max_stride = (canonical_size - 1) * canonical_stride

        target_dims_for_this_canonical = []
        while target_idx < len(target_dims):
            original_pos, target_size, target_stride = target_dims[target_idx]
            if min_stride <= target_stride <= max_stride:
                target_dims_for_this_canonical.append(
                    (original_pos, target_size, target_stride)
                )
                target_idx += 1
            else:
                # Since target strides are in descending order, once we find one that
                # doesn't match, we won't find any more for this canonical dim
                break

        if not target_dims_for_this_canonical:
            # No target dims map to this canonical dim, skip it
            # (This dimension gets "lost" in the transformation)
            continue

        # Process target_dims left to right (largest stride first, already sorted)
        for i, (original_pos, target_size, target_stride) in enumerate(
            target_dims_for_this_canonical
        ):
            is_last = i == len(target_dims_for_this_canonical) - 1

            if not is_last:
                # unflatten(a*b, (a, b)) gives strides (b*canonical_stride, canonical_stride)
                # To get first dim stride = target_stride: b * canonical_stride = target_stride
                # So b = target_stride / canonical_stride
                next_dim_size = target_stride // canonical_stride

                needed_size = target_size * next_dim_size

                # Check if we have enough size
                if result.size(current_dim) < needed_size:
                    return NotImplemented

                # Narrow and unflatten
                if result.size(current_dim) != needed_size:
                    result = result.narrow(current_dim, 0, needed_size)

                result = result.unflatten(current_dim, (target_size, next_dim_size))

            else:
                # Last target dim
                # Its stride must match the canonical stride
                if target_stride != canonical_stride:
                    return NotImplemented

                # Narrow to final size
                if result.size(current_dim) < target_size:
                    return NotImplemented
                if result.size(current_dim) != target_size:
                    result = result.narrow(current_dim, 0, target_size)

            current_dim += 1

    return result


def as_strided_via_views(
    tensor: torch.Tensor,
    size: tuple[int, ...],
    stride: tuple[int, ...],
    storage_offset: int = 0,
) -> torch.Tensor | types.NotImplementedType:
    """
    Attempt to reconstruct a sequence of view operations that would produce
    the target size/stride/offset from the source tensor.

    Args:
        tensor: Source tensor
        size: Target size
        stride: Target stride
        storage_offset: Target storage offset (default: 0)

    Returns:
        A view of the tensor with the target size/stride/offset, or NotImplemented
        if it cannot be achieved via simple view operations.
    """
    import math

    # NB: When strides are insignificant, we don't reproduce them exactly, as
    # this would make the algorithm a lot more complicated for no reason

    target_numel = math.prod(size)

    # Easy case 1: source tensor has numel==0
    if tensor.numel() == 0:
        if target_numel != 0:
            return NotImplemented
        return tensor.view(size)

    # Easy case 2: source tensor has numel==1
    if tensor.numel() == 1:
        if storage_offset != tensor.storage_offset():
            return NotImplemented
        if target_numel == 0:
            # If tensor is 0D scalar, we need to unsqueeze first to get a dimension to narrow
            if tensor.ndim == 0:
                tensor = tensor.unsqueeze(0)
            tensor = tensor.narrow(0, 0, 0)
            return tensor.view(size)
        if target_numel == 1:
            # Simple case: numel 1 -> numel 1 (no expand needed)
            return tensor.view(size)
        # target_numel > 1: For numel==1 source, target is valid only if
        # all dimensions with size > 1 have stride 0 (can be expanded)
        requires_expand = any(sz > 1 and st != 0 for sz, st in zip(size, stride))
        if requires_expand:
            return NotImplemented
        # Build target by unsqueezing and expanding
        result = tensor.view(1)  # Flatten to (1,)
        # Unsqueeze to match target ndim
        for _ in range(len(size) - 1):
            result = result.unsqueeze(0)
        # Now expand to target size (this creates stride-0 for expanded dims)
        result = result.expand(size)
        return result

    # Step 1: Canonicalize source tensor
    result = _canonicalize_tensor(tensor)

    # Step 2: Handle storage offset by narrowing canonical dimensions
    # After canonicalization, we have a tensor with strictly descending strides
    # We can narrow each dimension to consume the required offset
    offset_delta = storage_offset - result.storage_offset()
    if offset_delta < 0:
        return NotImplemented

    if offset_delta > 0:
        # Greedily consume offset from each canonical dimension (largest stride first)
        for dim in range(result.ndim):
            if offset_delta == 0:
                break

            canonical_size = result.size(dim)
            canonical_stride = result.stride(dim)

            # Maximum offset we can consume from this dimension
            max_offset_for_dim = (canonical_size - 1) * canonical_stride
            offset_to_consume = min(offset_delta, max_offset_for_dim)

            # Calculate start position for narrow
            start = offset_to_consume // canonical_stride

            if start > 0:
                new_length = canonical_size - start
                result = result.narrow(dim, start, new_length)
                offset_delta -= start * canonical_stride

        # Check if we consumed all the required offset
        if offset_delta != 0:
            return NotImplemented

    # We're not going to take this straight to the target size/stride.
    # Instead we're going to first go to a "canonicalized" target which is in
    # sorted order, has no size-1 dims, no stride-0 dims (unlike source, we
    # don't have to flatten contiguous dimensions; the algorithm below can
    # handle it.)  We need to compute this canonicalized target, and we should
    # also record enough information so we can invert this transformation (so
    # that we can apply the inverse on result to get to our final, desired
    # result.  So _unexpand_target_then/_squeeze_target_then/_permute_target_then
    # take care of modifying the target and inverting it, and _process_canonical_dims
    # is the main payload.

    return _unexpand_target_then(
        result,
        size,
        stride,
        storage_offset,
        cb=functools.partial(
            _squeeze_target_then,
            cb=functools.partial(_permute_target_then, cb=_process_canonical_dims),
        ),
    )
