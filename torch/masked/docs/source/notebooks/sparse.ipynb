{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/maskedtensor/blob/main/docs/source/notebooks/sparse.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Sparsity in PyTorch](https://pytorch.org/docs/stable/sparse.html) is a quickly growing area that has found a lot of support and demand due to its efficiency in both memory and compute. This tutorial is meant to be used in conjunction with the the PyTorch link above, as the sparse tensors are ultimately the building blocks for MaskedTensors (just as regular `torch.Tensor`s are as well).\n",
    "\n",
    "Sparse storage formats have been proven to be powerful in a variety of ways. As a primer, the first use case most practitioners think about is when the majority of elements are equal to zero (a high degree of sparsity), but even in cases of lower sparsity, certain formats (e.g. BSR) can take advantage of substructures within a matrix. There are a number of different [sparse storage formats](https://en.wikipedia.org/wiki/Sparse_matrix) that can be leveraged with various tradeoffs and degrees of adoption.\n",
    "\n",
    "\"Specified\" and \"unspecified\" elements (e.g. elements that are stored vs. not) have a long history in PyTorch without formal semantics and certainly without consistency; indeed, MaskedTensor was partially born out of a build up of issues (e.g. the [nan_grad tutorial](https://pytorch.org/maskedtensor/main/notebooks/nan_grad.html)) that vanilla tensors could not address. A major goal of the MaskedTensor project is to become the primary source of truth for specified/unspecified semantics where they are a first class citizen instead of an afterthought.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note: Currently, only the COO and CSR sparse storage formats are supported in MaskedTensor (BSR and CSC will be developed in the future). If you have another format that you would like supported, please file an issue!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `input` and `mask` must have the same storage format, whether that's `torch.strided`, `torch.sparse_coo`, or `torch.sparse_csr`.\n",
    "\n",
    "2. `input` and `mask` must have the same size, indicated by `t.size()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse COO Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from maskedtensor import masked_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In accordance with Principle #1, a sparse MaskedTensor is created by passing in two sparse tensors, which can be initialized with any of the constructors, e.g. `torch.sparse_coo_tensor`.\n",
    "\n",
    "As a recap of [sparse COO tensors](https://pytorch.org/docs/stable/sparse.html#sparse-coo-tensors), the COO format stands for \"Coordinate format\", where the specified elements are stored as tuples of their indices and the corresponding values. That is, the following are provided:\n",
    "\n",
    "- `indices`: array of size `(ndim, nse)` and dtype `torch.int64`\n",
    "- `values`: array of size `(nse,)` with any integer or floating point number dtype\n",
    "\n",
    "where `ndim` is the dimensionality of the tensor and `nse` is the number of specified elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both sparse COO and CSR tensors, you can construct them by doing either:\n",
    "1) `masked_tensor(sparse_tensor_data, sparse_tensor_mask)`\n",
    "2) `dense_masked_tensor.to_sparse_coo()`\n",
    "\n",
    "The is second is easier to illustrate so we have shown that below, but for more on the first and the nuances behind the approach, please read the Appendix at the bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masked tensor:\n",
      " masked_tensor(\n",
      "  [\n",
      "    [      --,       --, 3],\n",
      "    [      --,       --, 5]\n",
      "  ]\n",
      ")\n",
      "sparse coo masked tensor:\n",
      " masked_tensor(\n",
      "  [\n",
      "    [      --,       --, 3],\n",
      "    [      --,       --, 5]\n",
      "  ]\n",
      ")\n",
      "sparse data:\n",
      " tensor(indices=tensor([[0, 1],\n",
      "                       [2, 2]]),\n",
      "       values=tensor([3, 5]),\n",
      "       size=(2, 3), nnz=2, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "# To start, create a MaskedTensor\n",
    "values = torch.tensor(\n",
    "     [[0, 0, 3],\n",
    "      [4, 0, 5]]\n",
    ")\n",
    "mask = torch.tensor(\n",
    "     [[False, False, True],\n",
    "      [False, False, True]]\n",
    ")\n",
    "mt = masked_tensor(values, mask)\n",
    "\n",
    "sparse_coo_mt = mt.to_sparse_coo()\n",
    "\n",
    "print(\"masked tensor:\\n\", mt)\n",
    "print(\"sparse coo masked tensor:\\n\", sparse_coo_mt)\n",
    "print(\"sparse data:\\n\", sparse_coo_mt.data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse CSR Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, MaskedTensor also supports the [CSR (Compressed Sparse Row)](https://pytorch.org/docs/stable/sparse.html#sparse-csr-tensor) sparse tensor format. Instead of storing the tuples of the indices like sparse COO tensors, sparse CSR tensors aim to decrease the memory requirements by storing compressed row indices. In particular, a CSR sparse tensor consists of three 1-D tensors:\n",
    "\n",
    "- `crow_indices`: array of compressed row indices with size `(size[0] + 1,)`. This array indicates which row a given entry in `values` lives in. The last element is the number of specified elements, while `crow_indices[i+1] - crow_indices[i]` indicates the number of specified elements in row `i`.\n",
    "- `col_indices`: array of size `(nnz,)`. Indicates the column indices for each value.\n",
    "- `values`: array of size `(nnz,)`. Contains the values of the CSR tensor.\n",
    "\n",
    "Of note, both sparse COO and CSR tensors are in a [beta](https://pytorch.org/docs/stable/index.html) state.\n",
    "\n",
    "By way of example (and again, you can find more examples in the Appendix):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values:\n",
      " tensor(crow_indices=tensor([0, 1, 2]),\n",
      "       col_indices=tensor([2, 2]),\n",
      "       values=tensor([3, 5]), size=(2, 3), nnz=2, layout=torch.sparse_csr)\n",
      "mask:\n",
      " tensor(crow_indices=tensor([0, 1, 2]),\n",
      "       col_indices=tensor([2, 2]),\n",
      "       values=tensor([True, True]), size=(2, 3), nnz=2,\n",
      "       layout=torch.sparse_csr)\n",
      "mt:\n",
      " masked_tensor(\n",
      "  [\n",
      "    [      --,       --, 3],\n",
      "    [      --,       --, 5]\n",
      "  ]\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/georgeqi/work/repos/maskedtensor/maskedtensor/core.py:179: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /scratch/georgeqi/work/repos/pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:68.)\n",
      "  sparse_mask = mask.to_sparse_csr()\n"
     ]
    }
   ],
   "source": [
    "mt_sparse_csr = mt.to_sparse_csr()\n",
    "\n",
    "print(\"values:\\n\", mt_sparse_csr.data())\n",
    "print(\"mask:\\n\", mt_sparse_csr.mask())\n",
    "print(\"mt:\\n\", mt_sparse_csr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supported Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[All unary operations are supported](https://pytorch.org/maskedtensor/main/unary.html), e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_tensor(\n",
       "  [\n",
       "    [      --,       --,   0.1411],\n",
       "    [      --,       --,  -0.9589]\n",
       "  ]\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.sin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Binary operations are also supported](https://pytorch.org/maskedtensor/main/binary.html), but the input masks from the two masked tensors must match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = [[0, 1, 1],\n",
    "     [2, 0, 2]]\n",
    "v1 = [3, 4, 5]\n",
    "v2 = [20, 30, 40]\n",
    "m = torch.tensor([True, False, True])\n",
    "\n",
    "s1 = torch.sparse_coo_tensor(i, v1, (2, 3))\n",
    "s2 = torch.sparse_coo_tensor(i, v2, (2, 3))\n",
    "mask = torch.sparse_coo_tensor(i, m, (2, 3))\n",
    "\n",
    "mt1 = masked_tensor(s1, mask)\n",
    "mt2 = masked_tensor(s2, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mt1:\n",
      " masked_tensor(\n",
      "  [\n",
      "    [      --,       --, 3],\n",
      "    [      --,       --, 5]\n",
      "  ]\n",
      ")\n",
      "mt2:\n",
      " masked_tensor(\n",
      "  [\n",
      "    [      --,       --, 20],\n",
      "    [      --,       --, 40]\n",
      "  ]\n",
      ")\n",
      "torch.div(mt2, mt1):\n",
      " masked_tensor(\n",
      "  [\n",
      "    [      --,       --,   6.6667],\n",
      "    [      --,       --,   8.0000]\n",
      "  ]\n",
      ")\n",
      "torch.mul(mt1, mt2):\n",
      " masked_tensor(\n",
      "  [\n",
      "    [      --,       --, 60],\n",
      "    [      --,       --, 200]\n",
      "  ]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"mt1:\\n\", mt1)\n",
    "print(\"mt2:\\n\", mt2)\n",
    "print(\"torch.div(mt2, mt1):\\n\", torch.div(mt2, mt1))\n",
    "print(\"torch.mul(mt1, mt2):\\n\", torch.mul(mt1, mt2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reductions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, when the underlying data is sparse, only [reductions](https://pytorch.org/maskedtensor/main/reductions.html) across all dimensions are supported and not a particular dimension (e.g. `mt.sum()` is supported but not `mt.sum(dim=1)`). This is next in line to work on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mt:\n",
      " masked_tensor(\n",
      "  [\n",
      "    [      --,       --, 3],\n",
      "    [      --,       --, 5]\n",
      "  ]\n",
      ")\n",
      "mt.sum():\n",
      " masked_tensor(8, True)\n",
      "mt.amin():\n",
      " masked_tensor(3, True)\n"
     ]
    }
   ],
   "source": [
    "print(\"mt:\\n\", mt)\n",
    "print(\"mt.sum():\\n\", mt.sum())\n",
    "print(\"mt.amin():\\n\", mt.amin())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaskedTensor methods and sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`to_dense()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_tensor(\n",
       "  [\n",
       "    [      --,       --, 3],\n",
       "    [      --,       --, 5]\n",
       "  ]\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.to_dense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`to_sparse_coo()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = [[3, 0, 0],\n",
    "     [0, 4, 5]]\n",
    "m = [[True, False, False],\n",
    "     [False, True, True]]\n",
    "mt = masked_tensor(torch.tensor(v), torch.tensor(m))\n",
    "\n",
    "mt_sparse = mt.to_sparse_coo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`to_sparse_csr()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = [[3, 0, 0],\n",
    "     [0, 4, 5]]\n",
    "m = [[True, False, False],\n",
    "     [False, True, True]]\n",
    "mt = masked_tensor(torch.tensor(v), torch.tensor(m))\n",
    "\n",
    "mt_sparse_csr = mt.to_sparse_csr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`is_sparse` / `is_sparse_coo` / `is_sparse_csr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mt.is_sparse:  False\n",
      "mt_sparse.is_sparse:  True\n",
      "mt.is_sparse_coo:  False\n",
      "mt_sparse.is_sparse_coo:  True\n",
      "mt.is_sparse_csr:  False\n",
      "mt_sparse_csr.is_sparse_csr:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"mt.is_sparse: \", mt.is_sparse())\n",
    "print(\"mt_sparse.is_sparse: \", mt_sparse.is_sparse())\n",
    "\n",
    "print(\"mt.is_sparse_coo: \", mt.is_sparse_coo())\n",
    "print(\"mt_sparse.is_sparse_coo: \", mt_sparse.is_sparse_coo())\n",
    "\n",
    "print(\"mt.is_sparse_csr: \", mt.is_sparse_csr())\n",
    "print(\"mt_sparse_csr.is_sparse_csr: \", mt_sparse_csr.is_sparse_csr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse COO construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall in our original example, we created a MaskedTensor and then converted it to a sparse COO MaskedTensor with `mt.to_sparse_coo()`\n",
    "\n",
    "Alternatively, we can also construct a sparse COO MaskedTensor by passing in two sparse COO tensors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values:\n",
      " tensor(indices=tensor([[0, 1, 1],\n",
      "                       [2, 0, 2]]),\n",
      "       values=tensor([3, 4, 5]),\n",
      "       size=(2, 3), nnz=3, layout=torch.sparse_coo)\n",
      "mask:\n",
      " tensor(indices=tensor([[0, 1],\n",
      "                       [2, 2]]),\n",
      "       values=tensor([True, True]),\n",
      "       size=(2, 3), nnz=2, layout=torch.sparse_coo)\n",
      "mt:\n",
      " masked_tensor(\n",
      "  [\n",
      "    [      --,       --, 3],\n",
      "    [      --,       --, 5]\n",
      "  ]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "values = torch.tensor([[0, 0, 3], [4, 0, 5]]).to_sparse()\n",
    "mask = torch.tensor([[False, False, True], [False, False, True]]).to_sparse()\n",
    "\n",
    "mt = masked_tensor(values, mask)  \n",
    "\n",
    "print(\"values:\\n\", values)\n",
    "print(\"mask:\\n\", mask)\n",
    "print(\"mt:\\n\", mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of doing `dense_tensor.to_sparse()`, we can also create the sparse COO tensors directly, which brings us to a word of warning: when using a function like `.to_sparse_coo()`, if the user does not specify the indices like in the above example, then 0 values will be default \"unspecified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values:\n",
      " tensor(indices=tensor([[0, 1, 1],\n",
      "                       [2, 0, 2]]),\n",
      "       values=tensor([3, 4, 5]),\n",
      "       size=(2, 3), nnz=3, layout=torch.sparse_coo)\n",
      "mask:\n",
      " tensor(indices=tensor([[0, 1, 1],\n",
      "                       [2, 0, 2]]),\n",
      "       values=tensor([ True, False,  True]),\n",
      "       size=(2, 3), nnz=3, layout=torch.sparse_coo)\n",
      "mt2:\n",
      " masked_tensor(\n",
      "  [\n",
      "    [      --,       --, 3],\n",
      "    [      --,       --, 5]\n",
      "  ]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "i = [[0, 1, 1],\n",
    "     [2, 0, 2]]\n",
    "v =  [3, 4, 5]\n",
    "m = torch.tensor([True, False, True])\n",
    "\n",
    "values = torch.sparse_coo_tensor(i, v, (2, 3))\n",
    "mask = torch.sparse_coo_tensor(i, m, (2, 3))\n",
    "mt2 = masked_tensor(values, mask)\n",
    "\n",
    "print(\"values:\\n\", values)\n",
    "print(\"mask:\\n\", mask)\n",
    "print(\"mt2:\\n\", mt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `mt` and `mt2` will have the same value in the vast majority of operations, but this brings us to a note on the implementation under the hood:\n",
    "\n",
    "`input` and `mask` - only for sparse formats - can have a different number of elements (`tensor.nnz()`) **at creation**, but the indices of `mask` must then be a subset of the indices from `input`. In this case, `input` will assume the shape of mask using the function `input.sparse_mask(mask)`; in other words, any of the elements in `input` that are not `True` in `mask` will be thrown away\n",
    "\n",
    "Therefore, under the hood, the data looks slightly different; `mt2` has the 4 value masked out and `mt` is completely without it. In other words, their underlying data still has different shapes, so `mt + mt2` is invalid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mt.masked_data:\n",
      " tensor(indices=tensor([[0, 1],\n",
      "                       [2, 2]]),\n",
      "       values=tensor([3, 5]),\n",
      "       size=(2, 3), nnz=2, layout=torch.sparse_coo)\n",
      "mt2.masked_data:\n",
      " tensor(indices=tensor([[0, 1, 1],\n",
      "                       [2, 0, 2]]),\n",
      "       values=tensor([3, 4, 5]),\n",
      "       size=(2, 3), nnz=3, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "print(\"mt.masked_data:\\n\", mt.data())\n",
    "print(\"mt2.masked_data:\\n\", mt2.data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse CSR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also construct a sparse CSR MaskedTensor using sparse CSR tensors, and like the example above, they have a similar treatment under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csr tensor:\n",
      " tensor([[1., 2.],\n",
      "        [3., 4.]], dtype=torch.float64)\n",
      "mask csr tensor:\n",
      " tensor([[ True, False],\n",
      "        [False,  True]])\n",
      "masked tensor:\n",
      " masked_tensor(\n",
      "  [\n",
      "    [  1.0000,       --],\n",
      "    [      --,   4.0000]\n",
      "  ]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "crow_indices = torch.tensor([0, 2, 4])\n",
    "col_indices = torch.tensor([0, 1, 0, 1])\n",
    "values = torch.tensor([1, 2, 3, 4])\n",
    "mask_values = torch.tensor([True, False, False, True])\n",
    "\n",
    "csr = torch.sparse_csr_tensor(crow_indices, col_indices, values, dtype=torch.double)\n",
    "mask = torch.sparse_csr_tensor(crow_indices, col_indices, mask_values, dtype=torch.bool)\n",
    "\n",
    "mt = masked_tensor(csr, mask)\n",
    "\n",
    "print(\"csr tensor:\\n\", csr.to_dense())\n",
    "print(\"mask csr tensor:\\n\", mask.to_dense())\n",
    "print(\"masked tensor:\\n\", mt)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f53e922b446dc65d06f6118b3e8c84e0dbdd5cafb12d35760abf4d14ea01879d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
