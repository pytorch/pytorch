{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24f693fb-5cb1-4509-b1e2-fb7223634540",
   "metadata": {},
   "source": [
    "# Implemented missing torch.nan\\* operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be109fd7-a834-4729-bb3a-77c5a9699264",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/maskedtensor/blob/main/docs/source/notebooks/nan_operators.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c02f641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from maskedtensor import masked_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6540597c-0b2d-4c89-905a-b85d19b8808f",
   "metadata": {},
   "source": [
    "### [Issue 21987](https://github.com/pytorch/pytorch/issues/21987)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f101442-e4dd-48be-85d7-d164be0d9fcf",
   "metadata": {},
   "source": [
    "This issue was closed by inclusion into [Issue 61474 - Implement missing torch.nan\\* operators](https://github.com/pytorch/pytorch/issues/61474). This proposes an alternative, which is to use masked tensors instead of introducing additional operators. Since nanmean [has already landed](https://github.com/pytorch/pytorch/issues/21987), we can use it as a comparison point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53cf970f-9ba7-408b-8b85-b84d86c69597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([nan,  1.,  4.,  9., nan,  5., 12., 21., nan,  9., 20., 33., nan, 13.,\n",
      "        28., 45., nan, 17., 36., 57., nan, 21., 44., 69., nan, 25., 52., 81.,\n",
      "        nan, 29., 60., 93.])\n",
      "tensor(32.6667)\n",
      "masked_tensor( 32.6667, True)\n"
     ]
    }
   ],
   "source": [
    "y = torch.arange(32).float()\n",
    "x = y * y.fmod(4)\n",
    "x = x.masked_fill(x == 0, float('nan'))\n",
    "print(x)\n",
    "print(torch.nanmean(x))\n",
    "print(torch.mean(masked_tensor(x, ~torch.isnan(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f6058f-05b3-4e2c-aaa5-cb148110b467",
   "metadata": {},
   "source": [
    "MaskedTensor can further support reduction when fully masked out, as would be the case when a given Tensor is completetely nan. nanmean on the other hand returns nan when the input is entirely nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e451020-7235-4c6c-9343-4742b318294c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "tensor(nan)\n",
      "masked_tensor(--, False)\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(32)\n",
    "x.fill_(float('nan'))\n",
    "print(x)\n",
    "print(torch.nanmean(x))\n",
    "print(torch.mean(masked_tensor(x, ~torch.isnan(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9507b3c5-927a-48ce-858c-fcf142807392",
   "metadata": {},
   "source": [
    "Further [some users](https://github.com/pytorch/pytorch/issues/63870) already want to use nan reductions to encode masked semantics."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d0a07e0fa82e52b776976e55e335decf2d0ac48acfa03bb0e56e7f3ca52a96d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
