# PyTorch ONNX Exporter (POE) Rules are based on sarif ReportingDescriptor format.

# TODO: Define additional format requirements on top of sarif for our usage.
#       For example: pre defined keys for message_strings for logging on different levels.
# TODO: Based on above, create helper script to generate new rules.
# TODO: Separate rules into individual files.
# TODO: These rules are for demonstration purposes only. They are not complete.

- id: POE0001
  name: node-missing-onnx-shape-inference
  short_description:
    text: Node is missing ONNX shape inference.
  full_description:
    text: "Node is missing ONNX shape inference.
      This usually happens when the node is not valid under standard ONNX operator spec."
    markdown: |
      Node is missing ONNX shape inference.
      This usually happens when the node is not valid under standard ONNX operator spec.
  message_strings:
    default:
      text: "The shape inference of {op_name} type is missing, so it may result in wrong shape inference for the exported graph.
      Please consider adding it in symbolic function."
  help_uri:
  properties:
    deprecated: false
    tags: []

- id: POE0002
  name: missing-custom-symbolic-function
  short_description:
    text: Missing symbolic function for custom PyTorch operator, cannot translate node to ONNX.
  full_description:
    text: Missing symbolic function for custom PyTorch operator, cannot translate node to ONNX.
    markdown: |
      Missing symbolic function for custom PyTorch operator, cannot translate node to ONNX.
  message_strings:
    default:
      text: "ONNX export failed on an operator with unrecognized namespace {op_name}.
      If you are trying to export a custom operator, make sure you registered
      it with the right domain and version."
  help_uri:
  properties:
    deprecated: false
    tags: []

- id: POE0003
  name: missing-standard-symbolic-function
  short_description:
    text: Missing symbolic function for standard PyTorch operator, cannot translate node to ONNX.
  full_description:
    text: Missing symbolic function for standard PyTorch operator, cannot translate node to ONNX.
    markdown: |
      Missing symbolic function for standard PyTorch operator, cannot translate node to ONNX.
  message_strings:
    default:
      text: "Exporting the operator '{op_name}' to ONNX opset version {opset_version} is not supported.
      Please feel free to request support or submit a pull request on PyTorch GitHub: {issue_url}."
  help_uri:
  properties:
    deprecated: false
    tags: []


- id: POE0004
  name: operator-supported-in-newer-opset-version
  short_description:
    text: Operator is supported in newer opset version.
  full_description:
    text: Operator is supported in newer opset version.
    markdown: |
      Operator is supported in newer opset version.

      Example:
      ```python
      torch.onnx.export(model, args, ..., opset_version=9)
      ```
  message_strings:
    default:
      text: "Exporting the operator '{op_name}' to ONNX opset version {opset_version} is not supported.
      Support for this operator was added in version {supported_opset_version}, try exporting with this version."
  help_uri:
  properties:
    deprecated: false
    tags: []



- id: FXE0001
  name: fx-tracer-success
  short_description:
    text: FX Tracer succeeded.
  full_description:
    text: "FX Tracer succeeded.
      The callable is successfully traced as a 'torch.fx.GraphModule' by one of the fx tracers."
    markdown: |
      FX Tracer succeeded.
      The callable is successfully traced as a 'torch.fx.GraphModule' by one of the fx tracers.
  message_strings:
    default:
      text: "The callable '{fn_name}' is successfully traced as a 'torch.fx.GraphModule' by '{tracer_name}'."
  help_uri:
  properties:
    deprecated: false
    tags: []

- id: FXE0002
  name: fx-tracer-failure
  short_description:
    text: FX Tracer failed.
  full_description:
    text: "FX Tracer failed.
      The callable is not successfully traced as a 'torch.fx.GraphModule'."
    markdown: |
      FX Tracer failed.
      The callable is not successfully traced as a 'torch.fx.GraphModule'.
  message_strings:
    default:
      text: "The callable '{fn_name}' is not successfully traced as a 'torch.fx.GraphModule' by '{tracer_name}'.

      {explanation}"
  help_uri:
  properties:
    deprecated: false
    tags: []


- id: FXE0003
  name: fx-frontend-aotautograd
  short_description:
    text: FX Tracer succeeded.
  full_description:
    text: "FX Tracer succeeded.
      The callable is successfully traced as a 'torch.fx.GraphModule' by one of the fx tracers."
    markdown: |
      FX Tracer succeeded.
      The callable is successfully traced as a 'torch.fx.GraphModule' by one of the fx tracers.
  message_strings:
    default:
      text: "The callable '{fn_name}' is successfully traced as a 'torch.fx.GraphModule' by '{tracer_name}'."
  help_uri:
  properties:
    deprecated: false
    tags: []


- id: FXE0004
  name: fx-pass-convert-neg-to-sigmoid
  short_description:
    text: FX pass converting torch.neg to torch.sigmoid.
  full_description:
    text: "A 'fx.Interpreter' based pass to convert all 'torch.neg' calls to 'torch.sigmoid' for
      a given 'torch.fx.GraphModule' object."
    markdown: |
      A 'fx.Interpreter' based pass to convert all 'torch.neg' calls to 'torch.sigmoid' for
      a given 'torch.fx.GraphModule' object.
  message_strings:
    default:
      text: "Running 'convert-neg-to-sigmoid' pass on 'torch.fx.GraphModule'."
  help_uri:
  properties:
    deprecated: false
    tags: []


- id: FXE0005
  name: fx-ir-add-node
  short_description:
    text: ToDo, experimenting diagnostics, placeholder text.
  full_description:
    text: "ToDo, experimenting diagnostics, placeholder text."
    markdown: |
      ToDo, experimenting diagnostics, placeholder text.
  message_strings:
    default:
      text: "ToDo, experimenting diagnostics, placeholder text."
  help_uri:
  properties:
    deprecated: false
    tags: []


- id: FXE0006
  name: atenlib-symbolic-function
  short_description:
    text: Op level tracking. ToDo, experimenting diagnostics, placeholder text.
  full_description:
    text: "ToDo, experimenting diagnostics, placeholder text."
    markdown: |
      ToDo, experimenting diagnostics, placeholder text.
  message_strings:
    default:
      text: "ToDo, experimenting diagnostics, placeholder text."
  help_uri:
  properties:
    deprecated: false
    tags: []


- id: FXE0007
  name: atenlib-fx-to-onnx
  short_description:
    text: Graph level tracking. Each op is a step. ToDo, experimenting diagnostics, placeholder text.
  full_description:
    text: "ToDo, experimenting diagnostics, placeholder text."
    markdown: |
      ToDo, experimenting diagnostics, placeholder text.
  message_strings:
    default:
      text: "ToDo, experimenting diagnostics, placeholder text."
  help_uri:
  properties:
    deprecated: false
    tags: []

- id: FXE0008
  name: fx-node-to-onnx
  short_description:
    text: Node level tracking. ToDo, experimenting diagnostics, placeholder text.
  full_description:
    text: "ToDo, experimenting diagnostics, placeholder text."
    markdown: |
      ToDo, experimenting diagnostics, placeholder text.
  message_strings:
    default:
      text: "ToDo, experimenting diagnostics, placeholder text."
  help_uri:
  properties:
    deprecated: false
    tags: []

- id: FXE0009
  name: fx-frontend-dynamo-make-fx
  short_description:
    text: The make_fx + decomposition pass on fx graph produced from Dynamo, before ONNX export.
  full_description:
    text: "ToDo, experimenting diagnostics, placeholder text."
    markdown: |
      ToDo, experimenting diagnostics, placeholder text.
  message_strings:
    default:
      text: "ToDo, experimenting diagnostics, placeholder text."
  help_uri:
  properties:
    deprecated: false
    tags: []

- id: FXE0010
  name: fx-pass
  short_description:
    text: FX graph transformation before ONNX export.
  full_description:
    text: "ToDo, experimenting diagnostics, placeholder text."
    markdown: |
      ToDo, experimenting diagnostics, placeholder text.
  message_strings:
    default:
      text: "ToDo, experimenting diagnostics, placeholder text."
  help_uri:
  properties:
    deprecated: false
    tags: []

- id: FXE0011
  name: no-symbolic-function-for-call-function
  short_description:
    text: Cannot find symbolic function to convert the "call_function" FX node to ONNX.
  full_description:
    text: "Cannot find symbolic function to convert the \"call_function\" FX node to ONNX.
      "
    markdown: |
      This error occurs when the ONNX converter is unable to find a corresponding symbolic function
      to convert a "call_function" node in the input graph to its equivalence in ONNX. The "call_function"
      node represents a normalized function call in PyTorch, such as "torch.aten.ops.add".

      To resolve this error, you can try one of the following:

      - If exists, apply the auto-fix suggested by the diagnostic. TODO: this part is not available yet.
      - Rewrite the model using only supported PyTorch operators or functions.
      - Follow this [guide](https://pytorch.org/docs/stable/onnx.html#onnx-script-functions) to write and
        register a custom symbolic function for the unsupported call_function FX node.

      TODO: Replace above link once docs for `dynamo_export` custom op registration are available.
  message_strings:
    default:
      text: "No symbolic function to convert the \"call_function\" node {target} to ONNX. "
  help_uri:
  properties:
    deprecated: false
    tags: []

- id: FXE0012
  name: unsupported-fx-node-analysis
  short_description:
    text: Result from FX graph analysis to reveal unsupported FX nodes.
  full_description:
    text: "Result from FX graph analysis to reveal unsupported FX nodes."
    markdown: |
      This error indicates that an FX graph contains one or more unsupported nodes. The error message
      is typically accompanied by a list of the unsupported nodes found during analysis.

      To resolve this error, you can try resolving each individual unsupported node error by following
      the suggestions by its diagnostic. Typically, options include:

      - If exists, apply the auto-fix suggested by the diagnostic. TODO: this part is not available yet.
      - Rewrite the model using only supported PyTorch operators or functions.
      - Follow this [guide](https://pytorch.org/docs/stable/onnx.html#onnx-script-functions) to write and
        register a custom symbolic function for the unsupported call_function FX node.
  message_strings:
    default:
      text: "Unsupported FX nodes: {node_op_to_target_mapping}. "
  help_uri:
  properties:
    deprecated: false
    tags: []

- id: FXE0013
  name: op-level-debugging
  short_description:
    text: Report any op level validation failure in warnings.
  full_description:
    text: "Report any op level validation failure in warnings."
    markdown: |
      This warning message indicates that during op level debugging, certain symbolic functions
      have failed to match the results of torch ops when using real tensors generated from fake
      tensors. It is important to note that the symbolic functions may not necessarily be
      incorrect, as the validation process is non-deterministic and should only be used as a
      reference.

      There are two categories of warnings that can be triggered:

      1. Non-validated operators:
        If the warnings are caused by the following errors, they can be disregarded by users,
        as these errors occur due to the non-deterministic nature of the validation. However,
        it is important to be aware that the operators have not been validated.

        - IndexError: Unsupported input arguments of randomized dimensions/indices(INT64).
        - RuntimeError: Unsupported input arguments for torch ops are generated.
        - ValueError: Arguments/keyword arguments do not match the signature of the symbolic function.

      2. Potentially wrong torchlib operators:
        If the warnings are triggered by the following error, users should be aware that the symbolic functions
        may be incorrect in dispatching or implementation. In such cases, it is recommended to report
        the issue to the PyTorch-ONNX team, or create/register a custom symbolic function to replace the default one.

        - AssertionError: The symbolic function is potentially wrong as the results do not match the results of torch ops.
        - TypeError: The symbolic function is potentially wrong as the opschema doesn't match inputs.

  message_strings:
    default:
      text: "FX node: {node} and its onnx function: {symbolic_fn} fails on op level validation."
  help_uri:
  properties:
    deprecated: false
    tags: []

- id: FXE0014
  name: find-opschema-matched-symbolic-function
  short_description:
    text: Find the OnnxFunction that matches the input/attribute dtypes by comparing them with their opschemas.
  full_description:
    text: "Find the OnnxFunction that matches the input dtypes by comparing them with their opschemas.
      A warning will be issued if the matched OnnxFunction is not an exact match."
    markdown: |
      When an ATen/Custom operator is registered and needs to be dispatched to an OnnxFunction, the input/attribute
      dtypes of the ATen/Custom operator are compared with the input/attribute dtypes of the OnnxFunction opschemas
      to find a match. However, if a perfect/exact match is not found, the dispatcher will attempt to find
      the nearest match with the highest number of input/attribute dtypes matching the OnnxFunction opschemas, while
      issuing a warning.

      There are two types of level that can be triggered in this rule:

      1. NOTE: A perfect match is found, and no warning is issued.
      2. WARNING: The matched OnnxFunction is not a perfect/exact match.

      Here are some suggestions based on the WARNING situation:

      1. If there are NO errors or mismatches in the results, it is safe to disregard this warning,
        as the definition of OnnxFunction schema is usually more stringent.
      2. If there are errors or mismatches in the results, it is recommended to:
        (a) Enable op_level_debugging to determine if the OnnxFunction might be incorrect.
        (b) Report the issue to the PyTorch-ONNX team.
        (c) Create/register a custom symbolic function to replace the default one.

  message_strings:
    default:
      text: "The OnnxFunction: {symbolic_fn} is the nearest match of the node {node}."
  help_uri:
  properties:
    deprecated: false
    tags: []

- id: FXE0015
  name: fx-node-insert-type-promotion
  short_description:
    text: Determine if type promotion is required for the FX node. Insert cast nodes if needed.
  full_description:
    text: "Determine if type promotion is required for the FX node. Insert cast nodes if needed."
    markdown: |
      This diagnostic monitors the node-level type promotion insertion process. In PyTorch, there is an automatic process called implicit type promotion,
      where the input types of an operator are promoted to a common type. The determination of the common type is based on the type promotion rule specific to each operator.
      To learn more about PyTorch's type promotion rules, refer to the [elementwise_dtypes doc](https://github.com/pytorch/pytorch/blob/f044613f78df713fb57f70c608483c9f10ad332e/torch/_prims_common/__init__.py#L1252-L1335)
      and [torch._refs ops](https://github.com/pytorch/pytorch/blob/a475ea4542dfe961c9d097e33ab5041f61c8c17f/torch/_refs/__init__.py#L484).

      However, implicit type promotion is not supported in ONNX. Therefore, to replicate the PyTorch behavior, we need to explicitly insert cast nodes.
      This diagnostic tracks the process of node-level type promotion insertion.

      The type promotion rules used by this process can be found in `torch/onnx/_internal/fx/passes/type_promotion.py.`
      To update or add new type promotion rules, please refer to the [Note: Update type promotion rule] section.
  message_strings:
    default:
      text: "Performing explicit type promotion for node {target}. "
  help_uri:
  properties:
    deprecated: false
    tags: []

- id: FXE0016
  name: find-operator-overloads-in-onnx-registry
  short_description:
    text: Find the list of OnnxFunction of the PyTorch operator in onnx registry.
  full_description:
    text: "This rule involves finding the list of OnnxFunction for the PyTorch operator overload in the ONNX registry.
      If the operator overload is not supported but its default overload is, a warning will be issued.
      If both the operator overload and its default overload are not supported, an error will be issued."
    markdown: |
      The operator overload name serves the purpose of verifying whether a PyTorch operator is registered in the ONNX registry.
      If it's not found, the dispatcher takes a fallback approach and tries to locate the default overload of the PyTorch
      operator in the registry. If even the default overload is absent, it signifies that the operator is officially unsupported.

      There are three types of level that can be triggered in this rule:

      1. NOTE: The op overload is supported.
      2. WARNING: The op overload is not supported, but it's default overload is supported.
      3. ERROR: The op overload is not supported, and it's default overload is also not supported.

      Here are some suggestions based on the WARNING situation:

      1. If there are NO errors or mismatches in the results, it is safe to disregard this warning.
      2. If there are errors or mismatches in the results, it is recommended to:
        (a) Enable op_level_debugging to determine if the OnnxFunction might be incorrect.
        (b) Report the unsupported overload to the PyTorch-ONNX team.
        (c) Create/register a custom symbolic function to replace the default one.

      Here are some suggestions based on the ERROR situation:

      1. Report the unsupported operator to the PyTorch-ONNX team.
      2. Create/register a custom symbolic function to replace the default one.

  message_strings:
    default:
      text: "Checking if the FX node: {node} is supported in onnx registry."
  help_uri:
  properties:
    deprecated: false
    tags: []

- id: DIAGSYS0001
  name: arg-format-too-verbose
  short_description:
    text: The formatted str for argument to display is too verbose.
  full_description:
    text: "ToDo, experimenting diagnostics, placeholder text."
    markdown: |
      ToDo, experimenting diagnostics, placeholder text.
  message_strings:
    default:
      text: "Too verbose ({length} > {length_limit}). Argument type {argument_type} for formatter {formatter_type}."
  help_uri:
  properties:
    deprecated: false
    tags: []
