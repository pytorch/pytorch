#if defined(TH_REAL_IS_DOUBLE) || defined(TH_REAL_IS_FLOAT)
#define BUILD_REAL_FMT "d"
#else
#define BUILD_REAL_FMT "L"
#endif

#if !IS_CUDA && !IS_DISTRIBUTED
[[
  name: THPTensor_(apply)
  python_name: apply_
  defined_if: "!IS_CUDA && !IS_DISTRIBUTED"
  cpu_half: True
  only_register: True
  override_method_flags: METH_O
]]
static PyObject * THPTensor_(apply)(THPTensor *self, PyObject *arg)
{
  HANDLE_TH_ERRORS
  if (!PyCallable_Check(arg)) {
    THPUtils_setError("apply requires a callable as it's first argument");
    return NULL;
  }

  THTensor *tensor = self->cdata;
  TH_TENSOR_APPLY(real, tensor,
                  PyObject *ret =
                      PyObject_CallFunction(arg, (char*)BUILD_REAL_FMT, *tensor_data);
                  if (!ret)
                    return NULL;
                  if (!THPUtils_(checkReal)(ret)) {
                    Py_DECREF(ret);
                    THError("given function should return a number");
                  }
                  *tensor_data = THPUtils_(unpackReal)(ret);
                  Py_DECREF(ret);
                  );

  Py_INCREF(self);
  return (PyObject*)self;
  END_HANDLE_TH_ERRORS
}

[[
  name: THPTensor_(map)
  python_name: map_
  defined_if: "!IS_CUDA && !IS_DISTRIBUTED"
  cpu_half: True
  only_register: True
]]
static PyObject * THPTensor_(map)(THPTensor *self, PyObject *args)
{
  HANDLE_TH_ERRORS
    PyObject *fn;
    THPTensor *src_object;
    if (!PyArg_ParseTuple(args, "O!O&", THPTensorClass, &src_object, THPUtils_getCallable, &fn))
      return NULL;

  THTensor *tensor = self->cdata;
  THTensor *src = src_object->cdata;
  TH_TENSOR_APPLY2(real, tensor, real, src,
                  PyObject *ret =
                      PyObject_CallFunction(fn, (char*)(BUILD_REAL_FMT BUILD_REAL_FMT),
                                            *tensor_data, *src_data);
                  if (!ret)
                    return NULL;
                  if (!THPUtils_(checkReal)(ret)) {
                    Py_DECREF(ret);
                    THError("given function should return a number");
                  }
                  *tensor_data = THPUtils_(unpackReal)(ret);
                  Py_DECREF(ret);
                  );

  Py_INCREF(self);
  return (PyObject*)self;
  END_HANDLE_TH_ERRORS
}

[[
  name: THPTensor_(map2)
  python_name: map2_
  defined_if: "!IS_CUDA && !IS_DISTRIBUTED"
  cpu_half: True
  only_register: True
]]
static PyObject * THPTensor_(map2)(THPTensor *self, PyObject *args)
{
  HANDLE_TH_ERRORS
    PyObject *fn;
    THPTensor *src1_object;
    THPTensor *src2_object;
    if (!PyArg_ParseTuple(args, "O!O!O&", THPTensorClass, &src1_object, THPTensorClass, &src2_object, THPUtils_getCallable, &fn))
      return NULL;

  THTensor *tensor = self->cdata;
  THTensor *src1 = src1_object->cdata;
  THTensor *src2 = src2_object->cdata;
  TH_TENSOR_APPLY3(real, tensor, real, src1, real, src2,
                  PyObject *ret =
                      PyObject_CallFunction(fn, (char*)(BUILD_REAL_FMT BUILD_REAL_FMT BUILD_REAL_FMT),
                                            *tensor_data, *src1_data, *src2_data);
                  if (!ret)
                    return NULL;
                  if (!THPUtils_(checkReal)(ret)) {
                    Py_DECREF(ret);
                    THError("given function should return a number");
                  }
                  *tensor_data = THPUtils_(unpackReal)(ret);
                  Py_DECREF(ret);
                  );

  Py_INCREF(self);
  return (PyObject*)self;
  END_HANDLE_TH_ERRORS
}
#endif /* !IS_CUDA */

#undef BUILD_REAL_FMT
