#pragma once

#include <torch/optim/adagrad.h>
#include <torch/optim/adam.h>
#include <torch/optim/adamw.h>
#include <torch/optim/lbfgs.h>
#include <torch/optim/optimizer.h>
#include <torch/optim/rmsprop.h>
#include <torch/optim/sgd.h>
#include <torch/optim/adadelta.h>

#include <torch/optim/schedulers/lr_scheduler.h>
#include <torch/optim/schedulers/step_lr.h>
