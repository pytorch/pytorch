#pragma once

#include <ATen/core/interned_strings.h>
#include <c10/util/ArrayRef.h>
#include <torch/csrc/lazy/core/shape.h>
#include <torch/csrc/lazy/core/ir.h>

namespace torch {
namespace lazy {

hash_t OperandHashes(const OpList& operands, const hash_t& seed, bool bakeInSizes);

class TORCH_API BackendNode : public lazy::Node {
 public:
  BackendNode(OpKind op, OpList operands, std::vector<Shape>&& shapes,
         size_t num_outputs = 1, hash_t hash_seed = kHashSeed);

  // Same as the constructor above, but the shape is generated by a function,
  // only if needed (shape cache miss).
  BackendNode(OpKind op, OpList operands,
         const std::function<Shape()>& shape_fn,
         size_t num_outputs = 1, hash_t hash_seed = kHashSeed);

  // The shape is set later.
  BackendNode(OpKind op, OpList operands, size_t num_outputs = 1,
         hash_t hash_seed = kHashSeed);

  void SetShapeDeferred(const std::function<Shape()>& shape_fn);

  // Contructor used to create leaf nodes.
  BackendNode(OpKind op, Shape shape, size_t num_outputs = 1,
         hash_t hash_seed = kHashSeed);

  ~BackendNode() override = default;

  Shape GetOpShape(
      const std::function<Shape()>& shape_fn) const;

  // Retrieves the full shape of the IR Node.
  c10::ArrayRef<Shape> shapes() const override { return shapes_; }

  // Retrieves the shape of the output at a given index.
  virtual const Shape& shape(size_t output_index = 0) const override;

  virtual std::string ToString() const override;

  static hash_t GetOpHash(OpKind op, const Shape& shape, hash_t hash_seed, bool bakeInSizes);

  const std::vector<Output>& operands() const override {
    return operands_as_outputs_;
  }
  const Output& operand(size_t i) const override {
    return operands_as_outputs_.at(i);
  }

  const std::string& getPythonStacktrace() const {
         return python_stacktrace_;
  }

 protected:
  // Adds node's index output number as operand.
  void AddOperand(NodePtr node, size_t index = 0);

  std::vector<Shape> shapes_;
  // A node holds a real reference to its operands.
  std::vector<NodePtr> operands_;
  // Outputs do not hold references on the nodes, and neither do the uses, since
  // otherwise we get into circular reference counting.
  std::vector<Output> operands_as_outputs_;
  std::string python_stacktrace_;
};


// Note: this OpKind is separate from ltc_ops.h since it would be a circular import otherwise, I like leaving TensorList
// in this file, and I think most of ltc_ops special cases will be deleted anyway
const OpKind tensor_list_opkind = OpKind::Get("lazy_tensors::tensor_list");

// TensorList represents an at::TensorList which is a vector[Tensor] but is also a first-class IValue
// and can be fed as a single input to a program. It is much easier to handle TensorLists in Lazy Tensor code
// if they are represented as a single Node so there can be more than one TensorList and more than one Tensor
// side-by-side as operands to an op.
//
// Note: shape is undefined for TensorList.  We assert in some places that #shapes matches #outputs and this stems from
//       the fact that currently all IR nodes represent tensors (there is no type system for this IR).  Becuase of this,
//       TensorList is a bit of a hack.
struct TORCH_API TensorList : public BackendNode {
  TensorList() = delete;
  TensorList(OpList values);

  const Shape& shape(size_t output_index = 0) const override;
};

}  // namespace lazy
}  // namespace torch
