"""
Pythonify module for torch.compile.

This module provides infrastructure for generating explicit Python code
from torch.compile's runtime machinery. It consists of:

- IR nodes (ir.py): Structured representation of runtime operations
- Code generation backends:
  - gen_binary.py: Produces compiled artifacts (current behavior)
  - gen_python.py: Emits explicit Python source code
- Pipeline (pipeline.py): Orchestrates IR construction and code generation
- Adapters (adapters/): Translate compilation artifacts to IR nodes

Usage:
    torch.compile(model, pythonify="/path/to/output.py")
"""

from .gen_binary import (
    ArgumentExtractor,
    BinaryCodeGenVisitor,
    CompiledWrapper,
    CUDAGraphConfig,
    generate_binary_wrapper,
    GuardChecker,
)
from .gen_python import (
    CodeEmitter,
    generate_python_code,
    PythonCodeGenVisitor,
    write_python_file,
)
from .ir import (
    ArgumentExtractionNode,
    ArgumentSource,
    EffectTokensWrapperNode,
    AOTDispatchSubclassWrapperNode,
    FunctionalizedRngRuntimeWrapperNode,
    FakifiedOutWrapperNode,
    RuntimeWrapperNode,
    AOTDedupeWrapperNode,
    AOTSyntheticBaseWrapperNode,
    DebugAssertWrapperNode,
    AOTAutogradWrapperNode,
    CallableInvocationNode,
    CodeGenVisitor,
    CompiledRegionNode,
    CUDAGraphSetupNode,
    GuardCheckNode,
    GuardType,
    IRNode,
    KernelLoadNode,
    KernelType,
    ModelSource,
    MultiRegionDispatchNode,
    RegionExecutionMode,
    ReturnResultNode,
    RuntimeWrapperIR,
    WrapperStackSegment,
)
from .kernel_serializer import (
    decode_inline_kernel,
    inline_kernel_as_base64,
    KernelReference,
    KernelSerializer,
    KernelType as SerializerKernelType,
    SerializedKernelBundle,
    serialize_inductor_output,
)
from .context import (
    add_compilation_artifacts,
    add_inductor_output,
    generate_pythonify_output,
    get_backward_inductor_output,
    get_forward_inductor_output,
    get_latest_inductor_output,
    get_model_reference,
    get_model_source,
    get_pythonify_context,
    get_pythonify_path,
    is_pythonify_active,
    pythonify_context,
    PythonifyContext,
    set_model_reference,
)
from .errors import (
    create_pythonify_error,
    ErrorContext,
    format_code_generation_error,
    format_file_writing_error,
    format_guard_failure_message,
    format_ir_construction_error,
    PythonifyError,
    PythonifyStage,
)
from .pipeline import (
    CompilationArtifacts,
    RuntimeWrapperPipeline,
)
from .adapters import (
    AOTAutogradAdapter,
    AOTAutogradGraphSerializer,
    AOTAutogradInfo,
    AOTCompilationMode,
    create_dynamic_shape_guard,
    CUDACaptureMode,
    CUDAGraphAdapter,
    CUDAGraphInfo,
    CUDAGraphTreeMode,
    DynamoGuardType,
    extract_graph_metadata,
    extract_input_info_from_source,
    get_graph_readable,
    GraphSerializer,
    GuardAdapter,
    GuardInfo,
    InputAdapter,
    InputInfo,
    InputMutationInfo,
    InputSourceType,
    OutputAliasInfo,
    serialize_aot_autograd_graphs,
    serialize_graph_to_code,
    SerializedAOTAutogradInfo,
    SerializedGraph,
    StaticInputInfo,
    TensorGuardInfo,
    translate_aot_autograd,
    translate_cuda_graphs,
    translate_guards,
    translate_inputs,
)
from .warnings import (
    check_backend_compatibility,
    check_mode_compatibility,
    check_options_compatibility,
    check_pythonify_compatibility,
    emit_pythonify_warnings,
    get_limited_support_modes,
    get_limited_support_options,
    get_unsupported_backends,
    PythonifyWarning,
    PythonifyWarningCategory,
)


__all__ = [
    "add_compilation_artifacts",
    "add_inductor_output",
    "AOTAutogradAdapter",
    "AOTAutogradGraphSerializer",
    "AOTAutogradInfo",
    "AOTCompilationMode",
    "ArgumentExtractionNode",
    "ArgumentExtractor",
    "ArgumentSource",
    "EffectTokensWrapperNode",
    "AOTDispatchSubclassWrapperNode",
    "FunctionalizedRngRuntimeWrapperNode",
    "FakifiedOutWrapperNode",
    "RuntimeWrapperNode",
    "AOTDedupeWrapperNode",
    "AOTSyntheticBaseWrapperNode",
    "DebugAssertWrapperNode",
    "AOTAutogradWrapperNode",
    "BinaryCodeGenVisitor",
    "CallableInvocationNode",
    "check_backend_compatibility",
    "check_mode_compatibility",
    "check_options_compatibility",
    "check_pythonify_compatibility",
    "CodeEmitter",
    "CodeGenVisitor",
    "CompilationArtifacts",
    "CompiledRegionNode",
    "CompiledWrapper",
    "create_dynamic_shape_guard",
    "create_pythonify_error",
    "CUDACaptureMode",
    "CUDAGraphAdapter",
    "CUDAGraphConfig",
    "CUDAGraphInfo",
    "CUDAGraphSetupNode",
    "CUDAGraphTreeMode",
    "decode_inline_kernel",
    "DynamoGuardType",
    "emit_pythonify_warnings",
    "ErrorContext",
    "extract_graph_metadata",
    "extract_input_info_from_source",
    "format_code_generation_error",
    "format_file_writing_error",
    "format_guard_failure_message",
    "format_ir_construction_error",
    "generate_binary_wrapper",
    "generate_python_code",
    "generate_pythonify_output",
    "get_backward_inductor_output",
    "get_forward_inductor_output",
    "get_graph_readable",
    "get_latest_inductor_output",
    "get_limited_support_modes",
    "get_limited_support_options",
    "get_model_reference",
    "get_model_source",
    "get_pythonify_context",
    "get_pythonify_path",
    "get_unsupported_backends",
    "GraphSerializer",
    "GuardAdapter",
    "GuardCheckNode",
    "GuardChecker",
    "GuardInfo",
    "GuardType",
    "inline_kernel_as_base64",
    "InputAdapter",
    "InputInfo",
    "InputMutationInfo",
    "InputSourceType",
    "IRNode",
    "is_pythonify_active",
    "KernelLoadNode",
    "KernelReference",
    "KernelSerializer",
    "KernelType",
    "ModelSource",
    "MultiRegionDispatchNode",
    "OutputAliasInfo",
    "pythonify_context",
    "PythonCodeGenVisitor",
    "PythonifyContext",
    "PythonifyError",
    "PythonifyStage",
    "PythonifyWarning",
    "PythonifyWarningCategory",
    "RegionExecutionMode",
    "ReturnResultNode",
    "RuntimeWrapperIR",
    "RuntimeWrapperPipeline",
    "serialize_aot_autograd_graphs",
    "serialize_graph_to_code",
    "SerializedAOTAutogradInfo",
    "SerializedGraph",
    "SerializedKernelBundle",
    "SerializerKernelType",
    "serialize_inductor_output",
    "set_model_reference",
    "StaticInputInfo",
    "TensorGuardInfo",
    "translate_aot_autograd",
    "translate_cuda_graphs",
    "translate_guards",
    "translate_inputs",
    "write_python_file",
]
