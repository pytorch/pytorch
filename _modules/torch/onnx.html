


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch.onnx &mdash; PyTorch master documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/_modules/torch/onnx.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/jit.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/katex-math.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <div class="ecosystem-dropdown">
              <a id="dropdownMenuButton" data-toggle="ecosystem-dropdown">
                Ecosystem
              </a>
              <div class="ecosystem-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/hub"">
                  <span class=dropdown-title>Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class=dropdown-title>Tools & Libraries</span>
                  <p>Explore the ecosystem of tools and libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <div class="resources-dropdown">
              <a id="resourcesDropdownButton" data-toggle="resources-dropdown">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/resources"">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class=dropdown-title>About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  master (1.7.0a0+03e4e94 )
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
<div>
  <a style="color:#F05732" href="https://pytorch.org/docs/stable/_modules/torch/onnx.html">
    You are viewing unstable developer preview docs.
    Click here to view docs for latest stable release.
  </a>
</div>

            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../notes/amp_examples.html">Automatic Mixed Precision examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/cpu_threading_torchscript_inference.html">CPU threading and TorchScript inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/ddp.html">Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/large_scale_deployments.html">Features for large-scale deployments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/windows.html">Windows FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">Language Bindings</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../cpp_index.html">C++</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/javadoc/">Javadoc</a></li>
</ul>
<p class="caption"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor_view.html">Tensor Views</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../amp.html">torch.cuda.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../backends.html">torch.backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fft.html">torch.fft</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../futures.html">torch.futures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../linalg.html">torch.linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../complex_numbers.html">Complex Numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rpc.html">Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../random.html">torch.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mobile_optimizer.html">torch.utils.mobile_optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../named_tensor.html">Named Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../name_inference.html">Named Tensors operator coverage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../__config__.html">torch.__config__</a></li>
</ul>
<p class="caption"><span class="caption-text">Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/elastic/">TorchElastic</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="http://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>
<p class="caption"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../community/contribution_guide.html">PyTorch Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/governance.html">PyTorch Governance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/persons_of_interest.html">PyTorch Governance | Persons of Interest</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../index.html">Module code</a> &gt;</li>
        
          <li><a href="../torch.html">torch</a> &gt;</li>
        
      <li>torch.onnx</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torch.onnx</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">torch._C</span> <span class="k">as</span> <span class="nn">_C</span>

<span class="n">TensorProtoDataType</span> <span class="o">=</span> <span class="n">_C</span><span class="o">.</span><span class="n">_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span>
<span class="n">OperatorExportTypes</span> <span class="o">=</span> <span class="n">_C</span><span class="o">.</span><span class="n">_onnx</span><span class="o">.</span><span class="n">OperatorExportTypes</span>
<span class="n">TrainingMode</span> <span class="o">=</span> <span class="n">_C</span><span class="o">.</span><span class="n">_onnx</span><span class="o">.</span><span class="n">TrainingMode</span>
<span class="n">PYTORCH_ONNX_CAFFE2_BUNDLE</span> <span class="o">=</span> <span class="n">_C</span><span class="o">.</span><span class="n">_onnx</span><span class="o">.</span><span class="n">PYTORCH_ONNX_CAFFE2_BUNDLE</span>

<span class="n">ONNX_ARCHIVE_MODEL_PROTO_NAME</span> <span class="o">=</span> <span class="s2">&quot;__MODEL_PROTO&quot;</span>

<span class="c1"># TODO: Update these variables when there</span>
<span class="c1"># is a new ir_version and producer_version</span>
<span class="c1"># and use these values in the exporter</span>
<span class="n">ir_version</span> <span class="o">=</span> <span class="n">_C</span><span class="o">.</span><span class="n">_onnx</span><span class="o">.</span><span class="n">IR_VERSION</span>
<span class="n">producer_name</span> <span class="o">=</span> <span class="s2">&quot;pytorch&quot;</span>
<span class="n">producer_version</span> <span class="o">=</span> <span class="n">_C</span><span class="o">.</span><span class="n">_onnx</span><span class="o">.</span><span class="n">PRODUCER_VERSION</span>
<span class="n">constant_folding_opset_versions</span> <span class="o">=</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]</span>


<span class="k">class</span> <span class="nc">ExportTypes</span><span class="p">:</span>
    <span class="n">PROTOBUF_FILE</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">ZIP_ARCHIVE</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">COMPRESSED_ZIP_ARCHIVE</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">DIRECTORY</span> <span class="o">=</span> <span class="mi">4</span>


<span class="k">def</span> <span class="nf">_export</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">torch.onnx</span> <span class="kn">import</span> <span class="n">utils</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">_export</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>


<div class="viewcode-block" id="export"><a class="viewcode-back" href="../../onnx.html#torch.onnx.export">[docs]</a><span class="k">def</span> <span class="nf">export</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">export_params</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">TrainingMode</span><span class="o">.</span><span class="n">EVAL</span><span class="p">,</span>
           <span class="n">input_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">aten</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">export_raw_ir</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
           <span class="n">operator_export_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">opset_version</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_retain_param_name</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
           <span class="n">do_constant_folding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">example_outputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">strip_doc_string</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
           <span class="n">dynamic_axes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keep_initializers_as_inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">custom_opsets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
           <span class="n">enable_onnx_checker</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">use_external_data_format</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Export a model into ONNX format.  This exporter runs your model</span>
<span class="sd">    once in order to get a trace of its execution to be exported;</span>
<span class="sd">    at the moment, it supports a limited set of dynamic models (e.g., RNNs.)</span>

<span class="sd">    Arguments:</span>
<span class="sd">        model (torch.nn.Module): the model to be exported.</span>
<span class="sd">        args (tuple of arguments or torch.Tensor): the inputs to</span>
<span class="sd">            the model, e.g., such that ``model(*args)`` is a valid</span>
<span class="sd">            invocation of the model.  Any non-Tensor arguments will</span>
<span class="sd">            be hard-coded into the exported model; any Tensor arguments</span>
<span class="sd">            will become inputs of the exported model, in the order they</span>
<span class="sd">            occur in args.  If args is a Tensor, this is equivalent</span>
<span class="sd">            to having called it with a 1-ary tuple of that Tensor.</span>
<span class="sd">            (Note: passing keyword arguments to the model is not currently</span>
<span class="sd">            supported.  Give us a shout if you need it.)</span>
<span class="sd">        f: a file-like object (has to implement fileno that returns a file descriptor)</span>
<span class="sd">            or a string containing a file name.  A binary Protobuf will be written</span>
<span class="sd">            to this file.</span>
<span class="sd">        export_params (bool, default True): if specified, all parameters will</span>
<span class="sd">            be exported.  Set this to False if you want to export an untrained model.</span>
<span class="sd">            In this case, the exported model will first take all of its parameters</span>
<span class="sd">            as arguments, the ordering as specified by ``model.state_dict().values()``</span>
<span class="sd">        verbose (bool, default False): if specified, we will print out a debug</span>
<span class="sd">            description of the trace being exported.</span>
<span class="sd">        training (enum, default TrainingMode.EVAL):</span>
<span class="sd">            TrainingMode.EVAL: export the model in inference mode.</span>
<span class="sd">            TrainingMode.PRESERVE: export the model in inference mode if model.training is</span>
<span class="sd">            False and to a training friendly mode if model.training is True.</span>
<span class="sd">            TrainingMode.TRAINING: export the model in a training friendly mode.</span>
<span class="sd">        input_names(list of strings, default empty list): names to assign to the</span>
<span class="sd">            input nodes of the graph, in order</span>
<span class="sd">        output_names(list of strings, default empty list): names to assign to the</span>
<span class="sd">            output nodes of the graph, in order</span>
<span class="sd">        aten (bool, default False): [DEPRECATED. use operator_export_type] export the</span>
<span class="sd">            model in aten mode. If using aten mode, all the ops original exported</span>
<span class="sd">            by the functions in symbolic_opset&lt;version&gt;.py are exported as ATen ops.</span>
<span class="sd">        export_raw_ir (bool, default False): [DEPRECATED. use operator_export_type]</span>
<span class="sd">            export the internal IR directly instead of converting it to ONNX ops.</span>
<span class="sd">        operator_export_type (enum, default OperatorExportTypes.ONNX):</span>
<span class="sd">            OperatorExportTypes.ONNX: All ops are exported as regular ONNX ops</span>
<span class="sd">            (with ONNX namespace).</span>
<span class="sd">            OperatorExportTypes.ONNX_ATEN: All ops are exported as ATen ops</span>
<span class="sd">            (with aten namespace).</span>
<span class="sd">            OperatorExportTypes.ONNX_ATEN_FALLBACK: If an ATen op is not supported</span>
<span class="sd">            in ONNX or its symbolic is missing, fall back on ATen op. Registered ops</span>
<span class="sd">            are exported to ONNX regularly.</span>
<span class="sd">            Example graph::</span>

<span class="sd">                graph(%0 : Float)::</span>
<span class="sd">                  %3 : int = prim::Constant[value=0]()</span>
<span class="sd">                  %4 : Float = aten::triu(%0, %3) # missing op</span>
<span class="sd">                  %5 : Float = aten::mul(%4, %0) # registered op</span>
<span class="sd">                  return (%5)</span>

<span class="sd">            is exported as::</span>

<span class="sd">                graph(%0 : Float)::</span>
<span class="sd">                  %1 : Long() = onnx::Constant[value={0}]()</span>
<span class="sd">                  %2 : Float = aten::ATen[operator=&quot;triu&quot;](%0, %1)  # missing op</span>
<span class="sd">                  %3 : Float = onnx::Mul(%2, %0) # registered op</span>
<span class="sd">                  return (%3)</span>

<span class="sd">            In the above example, aten::triu is not supported in ONNX, hence</span>
<span class="sd">            exporter falls back on this op.</span>
<span class="sd">            OperatorExportTypes.RAW: Export raw ir.</span>
<span class="sd">            OperatorExportTypes.ONNX_FALLTHROUGH: If an op is not supported</span>
<span class="sd">            in ONNX, fall through and export the operator as is, as a custom </span>
<span class="sd">            ONNX op. Using this mode, the op can be exported and implemented by</span>
<span class="sd">            the user for their runtime backend.</span>
<span class="sd">            Example graph::</span>

<span class="sd">                graph(%x.1 : Long(1:1))::</span>
<span class="sd">                  %1 : None = prim::Constant()</span>
<span class="sd">                  %2 : Tensor = aten::sum(%x.1, %1)</span>
<span class="sd">                  %y.1 : Tensor[] = prim::ListConstruct(%2)</span>
<span class="sd">                  return (%y.1)</span>

<span class="sd">            is exported as::</span>

<span class="sd">                graph(%x.1 : Long(1:1))::</span>
<span class="sd">                  %1 : Tensor = onnx::ReduceSum[keepdims=0](%x.1)</span>
<span class="sd">                  %y.1 : Long() = prim::ListConstruct(%1)</span>
<span class="sd">                  return (%y.1)</span>

<span class="sd">            In the above example, prim::ListConstruct is not supported, hence</span>
<span class="sd">            exporter falls through.</span>

<span class="sd">        opset_version (int, default is 9): by default we export the model to the</span>
<span class="sd">            opset version of the onnx submodule. Since ONNX&#39;s latest opset may</span>
<span class="sd">            evolve before next stable release, by default we export to one stable</span>
<span class="sd">            opset version. Right now, supported stable opset version is 9.</span>
<span class="sd">            The opset_version must be _onnx_master_opset or in _onnx_stable_opsets</span>
<span class="sd">            which are defined in torch/onnx/symbolic_helper.py</span>
<span class="sd">        do_constant_folding (bool, default False): If True, the constant-folding</span>
<span class="sd">            optimization is applied to the model during export. Constant-folding</span>
<span class="sd">            optimization will replace some of the ops that have all constant</span>
<span class="sd">            inputs, with pre-computed constant nodes.</span>
<span class="sd">        example_outputs (tuple of Tensors, default None): Model&#39;s example outputs being exported.</span>
<span class="sd">            example_outputs must be provided when exporting a ScriptModule or TorchScript Function.</span>
<span class="sd">        strip_doc_string (bool, default True): if True, strips the field</span>
<span class="sd">            &quot;doc_string&quot; from the exported model, which information about the stack</span>
<span class="sd">            trace.</span>
<span class="sd">        dynamic_axes (dict&lt;string, dict&lt;int, string&gt;&gt; or dict&lt;string, list(int)&gt;, default empty dict):</span>
<span class="sd">            a dictionary to specify dynamic axes of input/output, such that:</span>
<span class="sd">            - KEY:  input and/or output names</span>
<span class="sd">            - VALUE: index of dynamic axes for given key and potentially the name to be used for</span>
<span class="sd">            exported dynamic axes. In general the value is defined according to one of the following</span>
<span class="sd">            ways or a combination of both:</span>
<span class="sd">            (1). A list of integers specifying the dynamic axes of provided input. In this scenario</span>
<span class="sd">            automated names will be generated and applied to dynamic axes of provided input/output</span>
<span class="sd">            during export.</span>
<span class="sd">            OR (2). An inner dictionary that specifies a mapping FROM the index of dynamic axis in</span>
<span class="sd">            corresponding input/output TO the name that is desired to be applied on such axis of</span>
<span class="sd">            such input/output during export.</span>

<span class="sd">            Example. if we have the following shape for inputs and outputs:</span>

<span class="sd">            .. code-block:: none</span>

<span class="sd">                shape(input_1) = (&#39;b&#39;, 3, &#39;w&#39;, &#39;h&#39;)</span>
<span class="sd">                and shape(input_2) = (&#39;b&#39;, 4)</span>
<span class="sd">                and shape(output)  = (&#39;b&#39;, &#39;d&#39;, 5)</span>

<span class="sd">            Then `dynamic axes` can be defined either as:</span>

<span class="sd">            1. ONLY INDICES::</span>

<span class="sd">                ``dynamic_axes = {&#39;input_1&#39;:[0, 2, 3],</span>
<span class="sd">                                  &#39;input_2&#39;:[0],</span>
<span class="sd">                                  &#39;output&#39;:[0, 1]}``</span>
<span class="sd">                where automatic names will be generated for exported dynamic axes</span>

<span class="sd">            2. INDICES WITH CORRESPONDING NAMES::</span>

<span class="sd">                ``dynamic_axes = {&#39;input_1&#39;:{0:&#39;batch&#39;,</span>
<span class="sd">                                             1:&#39;width&#39;,</span>
<span class="sd">                                             2:&#39;height&#39;},</span>
<span class="sd">                                  &#39;input_2&#39;:{0:&#39;batch&#39;},</span>
<span class="sd">                                  &#39;output&#39;:{0:&#39;batch&#39;,</span>
<span class="sd">                                            1:&#39;detections&#39;}``</span>
<span class="sd">                where provided names will be applied to exported dynamic axes</span>

<span class="sd">            3. MIXED MODE OF (1) and (2)::</span>

<span class="sd">                ``dynamic_axes = {&#39;input_1&#39;:[0, 2, 3],</span>
<span class="sd">                                  &#39;input_2&#39;:{0:&#39;batch&#39;},</span>
<span class="sd">                                  &#39;output&#39;:[0,1]}``</span>

<span class="sd">        keep_initializers_as_inputs (bool, default None): If True, all the</span>
<span class="sd">            initializers (typically corresponding to parameters) in the</span>
<span class="sd">            exported graph will also be added as inputs to the graph. If False,</span>
<span class="sd">            then initializers are not added as inputs to the graph, and only</span>
<span class="sd">            the non-parameter inputs are added as inputs.</span>

<span class="sd">            This may allow for better optimizations (such as constant folding</span>
<span class="sd">            etc.) by backends/runtimes that execute these graphs. If</span>
<span class="sd">            unspecified (default None), then the behavior is chosen</span>
<span class="sd">            automatically as follows. If operator_export_type is</span>
<span class="sd">            OperatorExportTypes.ONNX, the behavior is equivalent to setting</span>
<span class="sd">            this argument to False. For other values of operator_export_type,</span>
<span class="sd">            the behavior is equivalent to setting this argument to True. Note</span>
<span class="sd">            that for ONNX opset version &lt; 9, initializers MUST be part of graph</span>
<span class="sd">            inputs. Therefore, if opset_version argument is set to a 8 or</span>
<span class="sd">            lower, this argument will be ignored.</span>
<span class="sd">        custom_opsets (dict&lt;string, int&gt;, default empty dict): A dictionary to indicate</span>
<span class="sd">            custom opset domain and version at export. If model contains a custom opset,</span>
<span class="sd">            it is optional to specify the domain and opset version in the dictionary:</span>
<span class="sd">            - KEY: opset domain name</span>
<span class="sd">            - VALUE: opset version</span>
<span class="sd">            If the custom opset is not provided in this dictionary, opset version is set</span>
<span class="sd">            to 1 by default.</span>
<span class="sd">        enable_onnx_checker (bool, default True): If True the onnx model checker will be run</span>
<span class="sd">            as part of the export, to ensure the exported model is a valid ONNX model.</span>
<span class="sd">        external_data_format (bool, default False): If True, then the model is exported</span>
<span class="sd">            in ONNX external data format, in which case some of the model parameters are stored</span>
<span class="sd">            in external binary files and not in the ONNX model file itself. See link for format</span>
<span class="sd">            details: </span>
<span class="sd">            https://github.com/onnx/onnx/blob/8b3f7e2e7a0f2aba0e629e23d89f07c7fc0e6a5e/onnx/onnx.proto#L423</span>
<span class="sd">            Also, in this case,  argument &#39;f&#39; must be a string specifying the location of the model.</span>
<span class="sd">            The external binary files will be stored in the same location specified by the model </span>
<span class="sd">            location &#39;f&#39;. If False, then the model is stored in regular format, i.e. model and</span>
<span class="sd">            parameters are all in one file. This argument is ignored for all export types other</span>
<span class="sd">            than ONNX. </span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="kn">from</span> <span class="nn">torch.onnx</span> <span class="kn">import</span> <span class="n">utils</span>
    <span class="k">return</span> <span class="n">utils</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">export_params</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span>
                        <span class="n">input_names</span><span class="p">,</span> <span class="n">output_names</span><span class="p">,</span> <span class="n">aten</span><span class="p">,</span> <span class="n">export_raw_ir</span><span class="p">,</span>
                        <span class="n">operator_export_type</span><span class="p">,</span> <span class="n">opset_version</span><span class="p">,</span> <span class="n">_retain_param_name</span><span class="p">,</span>
                        <span class="n">do_constant_folding</span><span class="p">,</span> <span class="n">example_outputs</span><span class="p">,</span>
                        <span class="n">strip_doc_string</span><span class="p">,</span> <span class="n">dynamic_axes</span><span class="p">,</span> <span class="n">keep_initializers_as_inputs</span><span class="p">,</span>
                        <span class="n">custom_opsets</span><span class="p">,</span> <span class="n">enable_onnx_checker</span><span class="p">,</span> <span class="n">use_external_data_format</span><span class="p">)</span></div>


<div class="viewcode-block" id="export_to_pretty_string"><a class="viewcode-back" href="../../onnx.html#torch.onnx.export_to_pretty_string">[docs]</a><span class="k">def</span> <span class="nf">export_to_pretty_string</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">torch.onnx</span> <span class="kn">import</span> <span class="n">utils</span>
    <span class="k">return</span> <span class="n">utils</span><span class="o">.</span><span class="n">export_to_pretty_string</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_export_to_pretty_string</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">torch.onnx</span> <span class="kn">import</span> <span class="n">utils</span>
    <span class="k">return</span> <span class="n">utils</span><span class="o">.</span><span class="n">_export_to_pretty_string</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_optimize_trace</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">operator_export_type</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">torch.onnx</span> <span class="kn">import</span> <span class="n">utils</span>
    <span class="k">return</span> <span class="n">utils</span><span class="o">.</span><span class="n">_optimize_graph</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">operator_export_type</span><span class="p">)</span>


<div class="viewcode-block" id="select_model_mode_for_export"><a class="viewcode-back" href="../../onnx.html#torch.onnx.select_model_mode_for_export">[docs]</a><span class="k">def</span> <span class="nf">select_model_mode_for_export</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A context manager to temporarily set the training mode of &#39;model&#39;</span>
<span class="sd">    to &#39;mode&#39;, resetting it when we exit the with-block.  A no-op if</span>
<span class="sd">    mode is None.</span>

<span class="sd">    In version 1.6 changed to this from set_training</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="kn">from</span> <span class="nn">torch.onnx</span> <span class="kn">import</span> <span class="n">utils</span>
    <span class="k">return</span> <span class="n">utils</span><span class="o">.</span><span class="n">select_model_mode_for_export</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_run_symbolic_function</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">torch.onnx</span> <span class="kn">import</span> <span class="n">utils</span>
    <span class="k">return</span> <span class="n">utils</span><span class="o">.</span><span class="n">_run_symbolic_function</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_run_symbolic_method</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">torch.onnx</span> <span class="kn">import</span> <span class="n">utils</span>
    <span class="k">return</span> <span class="n">utils</span><span class="o">.</span><span class="n">_run_symbolic_method</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<div class="viewcode-block" id="is_in_onnx_export"><a class="viewcode-back" href="../../onnx.html#torch.onnx.is_in_onnx_export">[docs]</a><span class="k">def</span> <span class="nf">is_in_onnx_export</span><span class="p">():</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check whether it&#39;s in the middle of the ONNX export.</span>
<span class="sd">    This function returns True in the middle of torch.onnx.export().</span>
<span class="sd">    torch.onnx.export should be executed with single thread.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="kn">from</span> <span class="nn">torch.onnx</span> <span class="kn">import</span> <span class="n">utils</span>
    <span class="k">return</span> <span class="n">utils</span><span class="o">.</span><span class="n">is_in_onnx_export</span><span class="p">()</span></div>


<div class="viewcode-block" id="register_custom_op_symbolic"><a class="viewcode-back" href="../../onnx.html#torch.onnx.register_custom_op_symbolic">[docs]</a><span class="k">def</span> <span class="nf">register_custom_op_symbolic</span><span class="p">(</span><span class="n">symbolic_name</span><span class="p">,</span> <span class="n">symbolic_fn</span><span class="p">,</span> <span class="n">opset_version</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">torch.onnx</span> <span class="kn">import</span> <span class="n">utils</span>
    <span class="k">return</span> <span class="n">utils</span><span class="o">.</span><span class="n">register_custom_op_symbolic</span><span class="p">(</span><span class="n">symbolic_name</span><span class="p">,</span> <span class="n">symbolic_fn</span><span class="p">,</span> <span class="n">opset_version</span><span class="p">)</span></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Torch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
         <script src="../../_static/jquery.js"></script>
         <script src="../../_static/underscore.js"></script>
         <script src="../../_static/doctools.js"></script>
         <script src="../../_static/language_data.js"></script>
     

  

  <script type="text/javascript" src="../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90545585-1', 'auto');
  ga('send', 'pageview');

</script>

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>

<script>
  window.dataLayer = window.dataLayer || [];

  function gtag(){dataLayer.push(arguments);}

  gtag('js', new Date());
  gtag('config', 'UA-117752657-2');
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
            <a href="https://www.youtube.com/pytorch" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/features">Features</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>