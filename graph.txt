/data/users/shangdiy/pytorch/torch/_dynamo/variables/user_defined.py:1815: FutureWarning: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.
  return ctor(*args, **kwargs)
/data/users/shangdiy/pytorch/torch/_dynamo/variables/user_defined.py:1815: FutureWarning: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.
  return ctor(*args, **kwargs)
V1111 13:22:07.587000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr -1 to l_flat_args_0_
V1111 13:22:07.588000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr -1 to l_flat_args_1_
V1111 13:22:07.589000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr -1 to l_flat_args_2_
V1111 13:22:07.589000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr -1 to l_flat_args_3_
V1111 13:22:07.590000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr -1 to l_flat_args_4_
V1111 13:22:07.591000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr -1 to l_flat_args_5_
V1111 13:22:07.592000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr -1 to l_flat_args_6_
V1111 13:22:07.592000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr -1 to l_flat_args_7_
V1111 13:22:07.593000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr -1 to l_flat_args_8_
V1111 13:22:07.619000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr -1 to l__self____export_root_tok_embeddings_weight
V1111 13:22:07.621000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr -1 to embedding
V1111 13:22:07.626000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 0 to l__self____export_root_freqs_cis
V1111 13:22:07.630000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 0 to l__self____export_root_layers_0_attention_norm_weight
V1111 13:22:07.632000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 0 to rms_norm
V1111 13:22:07.640000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 1 to l__self____export_root_layers_0_attention_wq_weight
V1111 13:22:07.641000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 1 to linear
V1111 13:22:07.646000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 5 to view
V1111 13:22:07.650000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 6 to split
V1111 13:22:07.651000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 7 to getitem
V1111 13:22:07.652000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 7 to getitem_1
V1111 13:22:07.653000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 7 to float_1
V1111 13:22:07.654000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 7 to view_1
V1111 13:22:07.655000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 8 to view_as_complex
V1111 13:22:07.656000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 9 to view_2
V1111 13:22:07.658000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 9 to mul
V1111 13:22:07.660000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 10 to view_as_real
V1111 13:22:07.661000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 11 to flatten
V1111 13:22:07.662000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 12 to to
V1111 13:22:07.663000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 12 to cat
V1111 13:22:07.665000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 13 to l__self____export_root_layers_0_attention_wkv_a_weight
V1111 13:22:07.666000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 13 to linear_1
V1111 13:22:07.669000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 17 to split_1
V1111 13:22:07.670000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 18 to getitem_2
V1111 13:22:07.670000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 18 to getitem_3
V1111 13:22:07.670000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 18 to unsqueeze
V1111 13:22:07.671000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 19 to float_2
V1111 13:22:07.672000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 19 to view_3
V1111 13:22:07.673000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 20 to view_as_complex_1
V1111 13:22:07.674000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 21 to view_4
V1111 13:22:07.675000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 21 to mul_1
V1111 13:22:07.676000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 22 to view_as_real_1
V1111 13:22:07.677000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 23 to flatten_1
V1111 13:22:07.679000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 24 to to_1
V1111 13:22:07.680000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 24 to l__self____export_root_layers_0_attention_kv_norm_weight
V1111 13:22:07.682000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 24 to rms_norm_1
V1111 13:22:07.686000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 25 to l__self____export_root_layers_0_attention_wkv_b_weight
V1111 13:22:07.687000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 25 to linear_2
V1111 13:22:07.690000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 29 to view_5
V1111 13:22:07.692000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 30 to split_2
V1111 13:22:07.692000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 31 to getitem_4
V1111 13:22:07.693000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 31 to getitem_5
V1111 13:22:07.693000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 31 to expand
V1111 13:22:07.694000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 32 to cat_1
V1111 13:22:07.695000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 33 to transpose
V1111 13:22:07.696000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 34 to transpose_1
V1111 13:22:07.697000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 35 to transpose_2
V1111 13:22:07.720000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to q_3
V1111 13:22:07.721000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to new_empty
V1111 13:22:07.721000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to new_empty_1
V1111 13:22:07.722000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to new_empty_2
V1111 13:22:07.722000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to new_empty_3
V1111 13:22:07.723000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to new_empty_4
/data/users/shangdiy/pytorch/torch/_dynamo/variables/user_defined.py:1815: FutureWarning: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.
  return ctor(*args, **kwargs)
V1111 13:22:07.736000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to child
V1111 13:22:07.736000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to child_1
V1111 13:22:07.736000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to child_2
V1111 13:22:07.737000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to child_3
V1111 13:22:07.737000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to child_4
V1111 13:22:07.742000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to output
V1111 13:22:07.742000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to score_mod_0
V1111 13:22:07.743000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to q_3
V1111 13:22:07.743000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to new_empty
V1111 13:22:07.744000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to new_empty_1
V1111 13:22:07.744000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to new_empty_2
V1111 13:22:07.745000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to new_empty_3
V1111 13:22:07.754000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to child
V1111 13:22:07.755000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to child_1
V1111 13:22:07.755000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to child_2
V1111 13:22:07.755000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to child_3
V1111 13:22:07.759000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to new_ones
V1111 13:22:07.761000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to ge
V1111 13:22:07.763000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to and_
V1111 13:22:07.764000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to l__self___in_spec__children_0__children_1__context_2___closure___0_cell_contents_1___closure___0_cell_contents
V1111 13:22:07.766000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to l__self___in_spec__children_0__children_1__context_2___closure___0_cell_contents_1___closure___0_cell_contents
V1111 13:22:07.766000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 36 to getitem
V1111 13:22:07.768000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 37 to getitem_1
V1111 13:22:07.769000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 38 to eq
V1111 13:22:07.770000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 38 to and__1
V1111 13:22:07.770000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 38 to output
V1111 13:22:07.771000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 38 to mask_fn_0
V1111 13:22:07.771000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 38 to flex_attention
V1111 13:22:07.774000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 38 to arg0_1
V1111 13:22:07.774000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 38 to arg1_1
V1111 13:22:07.774000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 38 to arg2_1
V1111 13:22:07.775000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 38 to arg3_1
V1111 13:22:07.775000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 38 to arg4_1
V1111 13:22:07.775000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 38 to arg5_1
V1111 13:22:07.777000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 38 to output
V1111 13:22:07.782000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 39 to getitem_6
V1111 13:22:07.782000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 39 to getitem_7
V1111 13:22:07.782000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 39 to getitem_8
V1111 13:22:07.784000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 39 to transpose_3
V1111 13:22:07.785000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 40 to contiguous
V1111 13:22:07.785000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 40 to view_6
V1111 13:22:07.788000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 41 to l__self____export_root_layers_0_attention_wo_weight
V1111 13:22:07.789000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 41 to linear_3
V1111 13:22:07.792000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 45 to add
V1111 13:22:07.794000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 46 to l__self____export_root_layers_0_ffn_norm_weight
V1111 13:22:07.796000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 46 to rms_norm_2
V1111 13:22:07.798000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 47 to l__self____export_root_layers_0_feed_forward_w1_weight
V1111 13:22:07.799000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 47 to linear_4
V1111 13:22:07.802000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 51 to silu
V1111 13:22:07.806000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 52 to l__self____export_root_layers_0_feed_forward_w3_weight
V1111 13:22:07.807000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 52 to linear_5
V1111 13:22:07.808000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 56 to mul_2
V1111 13:22:07.810000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 57 to l__self____export_root_layers_0_feed_forward_w2_weight
V1111 13:22:07.811000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 57 to linear_6
V1111 13:22:07.813000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 61 to add_1
V1111 13:22:07.816000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 62 to l__self____export_root_layers_1_attention_norm_weight
V1111 13:22:07.817000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 62 to rms_norm_3
V1111 13:22:07.820000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 63 to l__self____export_root_layers_1_attention_wq_weight
V1111 13:22:07.821000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 63 to linear_7
V1111 13:22:07.822000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 67 to view_7
V1111 13:22:07.823000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 68 to split_3
V1111 13:22:07.824000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 69 to getitem_9
V1111 13:22:07.824000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 69 to getitem_10
V1111 13:22:07.825000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 69 to float_3
V1111 13:22:07.825000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 69 to view_8
V1111 13:22:07.826000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 70 to view_as_complex_2
V1111 13:22:07.827000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 71 to view_9
V1111 13:22:07.828000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 71 to mul_3
V1111 13:22:07.828000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 72 to view_as_real_2
V1111 13:22:07.829000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 73 to flatten_2
V1111 13:22:07.829000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 74 to to_2
V1111 13:22:07.830000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 74 to cat_2
V1111 13:22:07.831000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 75 to l__self____export_root_layers_1_attention_wkv_a_weight
V1111 13:22:07.833000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 75 to linear_8
V1111 13:22:07.834000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 79 to split_4
V1111 13:22:07.835000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 80 to getitem_11
V1111 13:22:07.835000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 80 to getitem_12
V1111 13:22:07.836000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 80 to unsqueeze_1
V1111 13:22:07.837000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 81 to float_4
V1111 13:22:07.837000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 81 to view_10
V1111 13:22:07.838000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 82 to view_as_complex_3
V1111 13:22:07.839000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 83 to view_11
V1111 13:22:07.839000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 83 to mul_4
V1111 13:22:07.840000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 84 to view_as_real_3
V1111 13:22:07.841000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 85 to flatten_3
V1111 13:22:07.841000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 86 to to_3
V1111 13:22:07.843000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 86 to l__self____export_root_layers_1_attention_kv_norm_weight
V1111 13:22:07.844000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 86 to rms_norm_4
V1111 13:22:07.846000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 87 to l__self____export_root_layers_1_attention_wkv_b_weight
V1111 13:22:07.847000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 87 to linear_9
V1111 13:22:07.848000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 91 to view_12
V1111 13:22:07.849000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 92 to split_5
V1111 13:22:07.850000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 93 to getitem_13
V1111 13:22:07.850000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 93 to getitem_14
V1111 13:22:07.851000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 93 to expand_1
V1111 13:22:07.851000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 94 to cat_3
V1111 13:22:07.852000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 95 to transpose_4
V1111 13:22:07.852000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 96 to transpose_5
V1111 13:22:07.853000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 97 to transpose_6
V1111 13:22:07.863000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to q_7
V1111 13:22:07.863000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to new_empty
V1111 13:22:07.864000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to new_empty_1
V1111 13:22:07.864000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to new_empty_2
V1111 13:22:07.865000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to new_empty_3
V1111 13:22:07.865000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to new_empty_4
/data/users/shangdiy/pytorch/torch/_dynamo/variables/user_defined.py:1815: FutureWarning: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.
  return ctor(*args, **kwargs)
V1111 13:22:07.876000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to child
V1111 13:22:07.876000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to child_1
V1111 13:22:07.876000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to child_2
V1111 13:22:07.877000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to child_3
V1111 13:22:07.877000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to child_4
V1111 13:22:07.881000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to output
V1111 13:22:07.882000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to score_mod_1
V1111 13:22:07.882000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to q_7
V1111 13:22:07.882000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to new_empty
V1111 13:22:07.883000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to new_empty_1
V1111 13:22:07.884000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to new_empty_2
V1111 13:22:07.884000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to new_empty_3
V1111 13:22:07.893000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to child
V1111 13:22:07.893000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to child_1
V1111 13:22:07.894000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to child_2
V1111 13:22:07.894000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to child_3
V1111 13:22:07.898000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to new_ones
V1111 13:22:07.899000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to ge
V1111 13:22:07.900000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to and_
V1111 13:22:07.900000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to l__self___in_spec__children_0__children_1__context_2___closure___0_cell_contents_1___closure___0_cell_contents
V1111 13:22:07.901000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 98 to getitem
V1111 13:22:07.901000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 99 to getitem_1
V1111 13:22:07.902000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 100 to eq
V1111 13:22:07.903000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 100 to and__1
V1111 13:22:07.903000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 100 to output
V1111 13:22:07.904000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 100 to mask_fn_1
V1111 13:22:07.904000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 100 to flex_attention_1
V1111 13:22:07.906000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 100 to arg0_1
V1111 13:22:07.906000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 100 to arg1_1
V1111 13:22:07.906000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 100 to arg2_1
V1111 13:22:07.907000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 100 to arg3_1
V1111 13:22:07.907000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 100 to arg4_1
V1111 13:22:07.907000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 100 to arg5_1
V1111 13:22:07.909000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 100 to output
V1111 13:22:07.911000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 101 to getitem_15
V1111 13:22:07.912000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 101 to getitem_16
V1111 13:22:07.912000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 101 to getitem_17
V1111 13:22:07.913000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 101 to transpose_7
V1111 13:22:07.914000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 102 to contiguous_1
V1111 13:22:07.914000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 102 to view_13
V1111 13:22:07.916000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 103 to l__self____export_root_layers_1_attention_wo_weight
V1111 13:22:07.917000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 103 to linear_10
V1111 13:22:07.918000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 107 to add_2
V1111 13:22:07.920000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 108 to l__self____export_root_layers_1_ffn_norm_weight
V1111 13:22:07.921000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 108 to rms_norm_5
V1111 13:22:07.924000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 109 to view_14
V1111 13:22:07.927000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 110 to l__self____export_root_layers_1_moe_expert_bias
V1111 13:22:07.930000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 110 to l__self____export_root_layers_1_moe_router_gate_weight
V1111 13:22:07.931000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 110 to linear_11
V1111 13:22:07.933000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 112 to to_4
V1111 13:22:07.934000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 112 to softmax
V1111 13:22:07.935000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 113 to add_3
V1111 13:22:07.937000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 114 to topk
V1111 13:22:07.938000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 115 to getitem_18
V1111 13:22:07.938000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 115 to getitem_19
V1111 13:22:07.938000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 115 to gather
V1111 13:22:07.940000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 116 to mul_5
V1111 13:22:07.941000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 117 to view_15
V1111 13:22:07.942000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 117 to histc
V1111 13:22:07.943000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 117 to _set_grad_enabled
V1111 13:22:07.944000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 117 to l__self____export_root_layers_1_moe_tokens_per_expert
V1111 13:22:07.945000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 117 to add_
V1111 13:22:07.946000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 117 to _set_grad_enabled_1
V1111 13:22:07.948000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 117 to view_16
V1111 13:22:07.948000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 117 to histc_1
V1111 13:22:07.949000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 117 to view_17
V1111 13:22:07.950000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 117 to argsort
V1111 13:22:07.951000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 117 to view_18
V1111 13:22:07.952000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 118 to getitem_20
V1111 13:22:07.954000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 119 to floordiv
V1111 13:22:07.956000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 119 to reshape
V1111 13:22:07.957000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 119 to expand_2
V1111 13:22:07.959000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 119 to gather_1
V1111 13:22:07.961000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 120 to l__self____export_root_layers_1_moe_experts_w1
V1111 13:22:07.963000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 120 to l__self____export_root_layers_1_moe_experts_w2
V1111 13:22:07.963000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 120 to l__self____export_root_layers_1_moe_experts_w3
V1111 13:22:07.968000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 120 to _set_grad_enabled_2
V1111 13:22:07.969000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 120 to cumsum
V1111 13:22:07.971000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 120 to sub
V1111 13:22:07.972000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 120 to view_19
V1111 13:22:07.973000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 120 to sum_1
V1111 13:22:07.974000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 120 to clamp_min
V1111 13:22:07.976000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 120 to add_4
V1111 13:22:07.976000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 120 to sub_1
V1111 13:22:07.977000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 120 to floordiv_1
V1111 13:22:07.979000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 120 to mul_6
V1111 13:22:07.980000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 120 to to_5
V1111 13:22:07.981000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 120 to cumsum_1
V1111 13:22:07.982000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 120 to sub_2
V1111 13:22:07.984000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 120 to full
V1111 13:22:07.986000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 120 to triton_kernel_wrapper_mutation
V1111 13:22:07.986000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 120 to to_6
V1111 13:22:07.987000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 120 to _set_grad_enabled_3
V1111 13:22:07.987000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 120 to new_zeros
V1111 13:22:07.988000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 120 to vstack
V1111 13:22:07.990000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 121 to getitem_21
V1111 13:22:07.992000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 122 to cumsum_2
V1111 13:22:07.994000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 122 to bfloat16
V1111 13:22:07.995000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 123 to bfloat16_1
V1111 13:22:07.996000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 124 to transpose_8
V1111 13:22:07.997000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 125 to _grouped_mm
V1111 13:22:07.998000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 126 to silu_1
V1111 13:22:07.999000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 127 to bfloat16_2
V1111 13:22:08.000000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 128 to bfloat16_3
V1111 13:22:08.000000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 129 to transpose_9
V1111 13:22:08.001000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 130 to _grouped_mm_1
V1111 13:22:08.001000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 131 to mul_7
V1111 13:22:08.003000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 132 to bfloat16_4
V1111 13:22:08.003000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 133 to transpose_10
V1111 13:22:08.004000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 134 to _grouped_mm_2
V1111 13:22:08.005000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 135 to type_as
V1111 13:22:08.007000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 136 to new_empty
V1111 13:22:08.007000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 136 to setitem
V1111 13:22:08.008000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 137 to getitem_22
V1111 13:22:08.012000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 138 to l__self____export_root_layers_1_moe_shared_experts_w1_weight
V1111 13:22:08.013000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 138 to linear_12
V1111 13:22:08.014000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 140 to silu_2
V1111 13:22:08.017000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 141 to l__self____export_root_layers_1_moe_shared_experts_w3_weight
V1111 13:22:08.018000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 141 to linear_13
V1111 13:22:08.019000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 143 to mul_8
V1111 13:22:08.020000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 144 to l__self____export_root_layers_1_moe_shared_experts_w2_weight
V1111 13:22:08.022000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 144 to linear_14
V1111 13:22:08.023000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 146 to to_7
V1111 13:22:08.024000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 146 to reshape_1
V1111 13:22:08.025000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 147 to mul_9
V1111 13:22:08.026000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 148 to to_8
V1111 13:22:08.026000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 148 to scatter_add
V1111 13:22:08.027000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 149 to reshape_2
V1111 13:22:08.028000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 150 to add_5
V1111 13:22:08.031000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 151 to l__self____export_root_layers_2_attention_norm_weight
V1111 13:22:08.032000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 151 to rms_norm_6
V1111 13:22:08.034000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 152 to l__self____export_root_layers_2_attention_wq_weight
V1111 13:22:08.035000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 152 to linear_15
V1111 13:22:08.037000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 156 to view_20
V1111 13:22:08.038000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 157 to split_6
V1111 13:22:08.039000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 158 to getitem_23
V1111 13:22:08.039000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 158 to getitem_24
V1111 13:22:08.040000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 158 to float_5
V1111 13:22:08.040000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 158 to view_21
V1111 13:22:08.041000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 159 to view_as_complex_4
V1111 13:22:08.042000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 160 to view_22
V1111 13:22:08.042000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 160 to mul_10
V1111 13:22:08.043000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 161 to view_as_real_4
V1111 13:22:08.044000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 162 to flatten_4
V1111 13:22:08.044000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 163 to to_9
V1111 13:22:08.045000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 163 to cat_4
V1111 13:22:08.046000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 164 to l__self____export_root_layers_2_attention_wkv_a_weight
V1111 13:22:08.048000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 164 to linear_16
V1111 13:22:08.049000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 168 to split_7
V1111 13:22:08.050000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 169 to getitem_25
V1111 13:22:08.050000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 169 to getitem_26
V1111 13:22:08.051000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 169 to unsqueeze_2
V1111 13:22:08.051000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 170 to float_6
V1111 13:22:08.052000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 170 to view_23
V1111 13:22:08.053000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 171 to view_as_complex_5
V1111 13:22:08.053000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 172 to view_24
V1111 13:22:08.054000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 172 to mul_11
V1111 13:22:08.055000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 173 to view_as_real_5
V1111 13:22:08.055000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 174 to flatten_5
V1111 13:22:08.056000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 175 to to_10
V1111 13:22:08.058000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 175 to l__self____export_root_layers_2_attention_kv_norm_weight
V1111 13:22:08.059000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 175 to rms_norm_7
V1111 13:22:08.060000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 176 to l__self____export_root_layers_2_attention_wkv_b_weight
V1111 13:22:08.062000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 176 to linear_17
V1111 13:22:08.063000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 180 to view_25
V1111 13:22:08.064000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 181 to split_8
V1111 13:22:08.065000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 182 to getitem_27
V1111 13:22:08.065000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 182 to getitem_28
V1111 13:22:08.066000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 182 to expand_3
V1111 13:22:08.066000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 183 to cat_5
V1111 13:22:08.067000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 184 to transpose_11
V1111 13:22:08.068000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 185 to transpose_12
V1111 13:22:08.068000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 186 to transpose_13
V1111 13:22:08.078000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to q_11
V1111 13:22:08.078000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to new_empty
V1111 13:22:08.079000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to new_empty_1
V1111 13:22:08.079000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to new_empty_2
V1111 13:22:08.080000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to new_empty_3
V1111 13:22:08.080000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to new_empty_4
/data/users/shangdiy/pytorch/torch/_dynamo/variables/user_defined.py:1815: FutureWarning: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.
  return ctor(*args, **kwargs)
V1111 13:22:08.090000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to child
V1111 13:22:08.091000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to child_1
V1111 13:22:08.091000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to child_2
V1111 13:22:08.091000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to child_3
V1111 13:22:08.092000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to child_4
V1111 13:22:08.096000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to output
V1111 13:22:08.097000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to score_mod_2
V1111 13:22:08.097000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to q_11
V1111 13:22:08.097000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to new_empty
V1111 13:22:08.098000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to new_empty_1
V1111 13:22:08.098000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to new_empty_2
V1111 13:22:08.099000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to new_empty_3
V1111 13:22:08.108000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to child
V1111 13:22:08.108000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to child_1
V1111 13:22:08.108000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to child_2
V1111 13:22:08.109000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to child_3
V1111 13:22:08.113000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to new_ones
V1111 13:22:08.114000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to ge
V1111 13:22:08.114000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to and_
V1111 13:22:08.115000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to l__self___in_spec__children_0__children_1__context_2___closure___0_cell_contents_1___closure___0_cell_contents
V1111 13:22:08.115000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 187 to getitem
V1111 13:22:08.116000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 188 to getitem_1
V1111 13:22:08.117000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 189 to eq
V1111 13:22:08.117000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 189 to and__1
V1111 13:22:08.118000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 189 to output
V1111 13:22:08.119000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 189 to mask_fn_2
V1111 13:22:08.119000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 189 to flex_attention_2
V1111 13:22:08.121000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 189 to arg0_1
V1111 13:22:08.121000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 189 to arg1_1
V1111 13:22:08.121000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 189 to arg2_1
V1111 13:22:08.121000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 189 to arg3_1
V1111 13:22:08.121000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 189 to arg4_1
V1111 13:22:08.122000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 189 to arg5_1
V1111 13:22:08.123000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 189 to output
V1111 13:22:08.126000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 190 to getitem_29
V1111 13:22:08.126000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 190 to getitem_30
V1111 13:22:08.127000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 190 to getitem_31
V1111 13:22:08.127000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 190 to transpose_14
V1111 13:22:08.128000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 191 to contiguous_2
V1111 13:22:08.128000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 191 to view_26
V1111 13:22:08.130000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 192 to l__self____export_root_layers_2_attention_wo_weight
V1111 13:22:08.131000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 192 to linear_18
V1111 13:22:08.132000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 196 to add_6
V1111 13:22:08.134000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 197 to l__self____export_root_layers_2_ffn_norm_weight
V1111 13:22:08.136000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 197 to rms_norm_8
V1111 13:22:08.137000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 198 to view_27
V1111 13:22:08.139000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 199 to l__self____export_root_layers_2_moe_expert_bias
V1111 13:22:08.141000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 199 to l__self____export_root_layers_2_moe_router_gate_weight
V1111 13:22:08.142000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 199 to linear_19
V1111 13:22:08.143000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 201 to to_11
V1111 13:22:08.144000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 201 to softmax_1
V1111 13:22:08.145000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 202 to add_7
V1111 13:22:08.146000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 203 to topk_1
V1111 13:22:08.146000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 204 to getitem_32
V1111 13:22:08.147000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 204 to getitem_33
V1111 13:22:08.147000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 204 to gather_2
V1111 13:22:08.148000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 205 to mul_12
V1111 13:22:08.149000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 206 to view_28
V1111 13:22:08.150000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 206 to histc_2
V1111 13:22:08.150000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 206 to _set_grad_enabled_4
V1111 13:22:08.151000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 206 to l__self____export_root_layers_2_moe_tokens_per_expert
V1111 13:22:08.152000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 206 to add__1
V1111 13:22:08.152000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 206 to _set_grad_enabled_5
V1111 13:22:08.154000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 206 to view_29
V1111 13:22:08.155000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 206 to histc_3
V1111 13:22:08.155000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 206 to view_30
V1111 13:22:08.156000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 206 to argsort_1
V1111 13:22:08.157000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 206 to view_31
V1111 13:22:08.157000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 207 to getitem_34
V1111 13:22:08.158000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 208 to floordiv_2
V1111 13:22:08.159000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 208 to reshape_3
V1111 13:22:08.159000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 208 to expand_4
V1111 13:22:08.161000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 208 to gather_3
V1111 13:22:08.163000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 209 to l__self____export_root_layers_2_moe_experts_w1
V1111 13:22:08.164000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 209 to l__self____export_root_layers_2_moe_experts_w2
V1111 13:22:08.165000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 209 to l__self____export_root_layers_2_moe_experts_w3
V1111 13:22:08.167000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 209 to _set_grad_enabled_6
V1111 13:22:08.168000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 209 to cumsum_3
V1111 13:22:08.168000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 209 to sub_3
V1111 13:22:08.169000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 209 to view_32
V1111 13:22:08.169000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 209 to sum_2
V1111 13:22:08.170000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 209 to clamp_min_1
V1111 13:22:08.171000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 209 to add_8
V1111 13:22:08.171000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 209 to sub_4
V1111 13:22:08.171000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 209 to floordiv_3
V1111 13:22:08.172000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 209 to mul_13
V1111 13:22:08.172000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 209 to to_12
V1111 13:22:08.173000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 209 to cumsum_4
V1111 13:22:08.174000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 209 to sub_5
V1111 13:22:08.174000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 209 to full_1
V1111 13:22:08.175000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 209 to triton_kernel_wrapper_mutation_1
V1111 13:22:08.176000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 209 to to_13
V1111 13:22:08.176000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 209 to _set_grad_enabled_7
V1111 13:22:08.176000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 209 to new_zeros_1
V1111 13:22:08.177000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 209 to vstack_1
V1111 13:22:08.178000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 210 to getitem_35
V1111 13:22:08.179000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 211 to cumsum_5
V1111 13:22:08.179000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 211 to bfloat16_5
V1111 13:22:08.180000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 212 to bfloat16_6
V1111 13:22:08.180000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 213 to transpose_15
V1111 13:22:08.181000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 214 to _grouped_mm_3
V1111 13:22:08.181000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 215 to silu_3
V1111 13:22:08.182000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 216 to bfloat16_7
V1111 13:22:08.183000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 217 to bfloat16_8
V1111 13:22:08.183000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 218 to transpose_16
V1111 13:22:08.184000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 219 to _grouped_mm_4
V1111 13:22:08.184000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 220 to mul_14
V1111 13:22:08.185000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 221 to bfloat16_9
V1111 13:22:08.186000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 222 to transpose_17
V1111 13:22:08.186000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 223 to _grouped_mm_5
V1111 13:22:08.187000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 224 to type_as_1
V1111 13:22:08.187000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 225 to new_empty_1
V1111 13:22:08.188000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 225 to setitem_1
V1111 13:22:08.188000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 226 to getitem_36
V1111 13:22:08.192000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 227 to l__self____export_root_layers_2_moe_shared_experts_w1_weight
V1111 13:22:08.193000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 227 to linear_20
V1111 13:22:08.194000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 229 to silu_4
V1111 13:22:08.196000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 230 to l__self____export_root_layers_2_moe_shared_experts_w3_weight
V1111 13:22:08.197000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 230 to linear_21
V1111 13:22:08.198000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 232 to mul_15
V1111 13:22:08.199000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 233 to l__self____export_root_layers_2_moe_shared_experts_w2_weight
V1111 13:22:08.200000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 233 to linear_22
V1111 13:22:08.201000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 235 to to_14
V1111 13:22:08.202000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 235 to reshape_4
V1111 13:22:08.202000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 236 to mul_16
V1111 13:22:08.203000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 237 to to_15
V1111 13:22:08.204000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 237 to scatter_add_1
V1111 13:22:08.204000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 238 to reshape_5
V1111 13:22:08.205000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 239 to add_9
V1111 13:22:08.208000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 240 to l__self____export_root_layers_3_attention_norm_weight
V1111 13:22:08.209000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 240 to rms_norm_9
V1111 13:22:08.211000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 241 to l__self____export_root_layers_3_attention_wq_weight
V1111 13:22:08.212000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 241 to linear_23
V1111 13:22:08.214000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 245 to view_33
V1111 13:22:08.215000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 246 to split_9
V1111 13:22:08.216000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 247 to getitem_37
V1111 13:22:08.216000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 247 to getitem_38
V1111 13:22:08.217000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 247 to float_7
V1111 13:22:08.217000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 247 to view_34
V1111 13:22:08.218000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 248 to view_as_complex_6
V1111 13:22:08.219000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 249 to view_35
V1111 13:22:08.219000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 249 to mul_17
V1111 13:22:08.220000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 250 to view_as_real_6
V1111 13:22:08.221000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 251 to flatten_6
V1111 13:22:08.222000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 252 to to_16
V1111 13:22:08.222000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 252 to cat_6
V1111 13:22:08.224000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 253 to l__self____export_root_layers_3_attention_wkv_a_weight
V1111 13:22:08.225000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 253 to linear_24
V1111 13:22:08.226000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 257 to split_10
V1111 13:22:08.227000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 258 to getitem_39
V1111 13:22:08.227000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 258 to getitem_40
V1111 13:22:08.228000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 258 to unsqueeze_3
V1111 13:22:08.229000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 259 to float_8
V1111 13:22:08.229000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 259 to view_36
V1111 13:22:08.230000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 260 to view_as_complex_7
V1111 13:22:08.231000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 261 to view_37
V1111 13:22:08.231000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 261 to mul_18
V1111 13:22:08.232000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 262 to view_as_real_7
V1111 13:22:08.233000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 263 to flatten_7
V1111 13:22:08.233000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 264 to to_17
V1111 13:22:08.235000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 264 to l__self____export_root_layers_3_attention_kv_norm_weight
V1111 13:22:08.236000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 264 to rms_norm_10
V1111 13:22:08.238000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 265 to l__self____export_root_layers_3_attention_wkv_b_weight
V1111 13:22:08.239000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 265 to linear_25
V1111 13:22:08.240000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 269 to view_38
V1111 13:22:08.241000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 270 to split_11
V1111 13:22:08.242000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 271 to getitem_41
V1111 13:22:08.242000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 271 to getitem_42
V1111 13:22:08.243000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 271 to expand_5
V1111 13:22:08.244000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 272 to cat_7
V1111 13:22:08.244000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 273 to transpose_18
V1111 13:22:08.245000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 274 to transpose_19
V1111 13:22:08.245000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 275 to transpose_20
V1111 13:22:08.255000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to q_15
V1111 13:22:08.255000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to new_empty
V1111 13:22:08.256000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to new_empty_1
V1111 13:22:08.256000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to new_empty_2
V1111 13:22:08.257000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to new_empty_3
V1111 13:22:08.257000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to new_empty_4
/data/users/shangdiy/pytorch/torch/_dynamo/variables/user_defined.py:1815: FutureWarning: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.
  return ctor(*args, **kwargs)
V1111 13:22:08.267000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to child
V1111 13:22:08.268000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to child_1
V1111 13:22:08.268000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to child_2
V1111 13:22:08.268000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to child_3
V1111 13:22:08.269000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to child_4
V1111 13:22:08.273000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to output
V1111 13:22:08.274000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to score_mod_3
V1111 13:22:08.274000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to q_15
V1111 13:22:08.274000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to new_empty
V1111 13:22:08.275000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to new_empty_1
V1111 13:22:08.276000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to new_empty_2
V1111 13:22:08.276000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to new_empty_3
V1111 13:22:08.285000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to child
V1111 13:22:08.285000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to child_1
V1111 13:22:08.286000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to child_2
V1111 13:22:08.286000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to child_3
V1111 13:22:08.290000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to new_ones
V1111 13:22:08.291000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to ge
V1111 13:22:08.292000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to and_
V1111 13:22:08.292000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to l__self___in_spec__children_0__children_1__context_2___closure___0_cell_contents_1___closure___0_cell_contents
V1111 13:22:08.293000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 276 to getitem
V1111 13:22:08.293000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 277 to getitem_1
V1111 13:22:08.294000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 278 to eq
V1111 13:22:08.295000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 278 to and__1
V1111 13:22:08.295000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 278 to output
V1111 13:22:08.296000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 278 to mask_fn_3
V1111 13:22:08.296000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 278 to flex_attention_3
V1111 13:22:08.298000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 278 to arg0_1
V1111 13:22:08.298000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 278 to arg1_1
V1111 13:22:08.299000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 278 to arg2_1
V1111 13:22:08.299000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 278 to arg3_1
V1111 13:22:08.299000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 278 to arg4_1
V1111 13:22:08.299000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 278 to arg5_1
V1111 13:22:08.301000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 278 to output
V1111 13:22:08.304000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 279 to getitem_43
V1111 13:22:08.304000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 279 to getitem_44
V1111 13:22:08.304000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 279 to getitem_45
V1111 13:22:08.305000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 279 to transpose_21
V1111 13:22:08.306000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 280 to contiguous_3
V1111 13:22:08.306000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 280 to view_39
V1111 13:22:08.308000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 281 to l__self____export_root_layers_3_attention_wo_weight
V1111 13:22:08.309000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 281 to linear_26
V1111 13:22:08.310000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 285 to add_10
V1111 13:22:08.312000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 286 to l__self____export_root_layers_3_ffn_norm_weight
V1111 13:22:08.313000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 286 to rms_norm_11
V1111 13:22:08.315000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 287 to view_40
V1111 13:22:08.317000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 288 to l__self____export_root_layers_3_moe_expert_bias
V1111 13:22:08.319000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 288 to l__self____export_root_layers_3_moe_router_gate_weight
V1111 13:22:08.320000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 288 to linear_27
V1111 13:22:08.321000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 290 to to_18
V1111 13:22:08.322000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 290 to softmax_2
V1111 13:22:08.322000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 291 to add_11
V1111 13:22:08.323000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 292 to topk_2
V1111 13:22:08.324000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 293 to getitem_46
V1111 13:22:08.324000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 293 to getitem_47
V1111 13:22:08.325000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 293 to gather_4
V1111 13:22:08.326000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 294 to mul_19
V1111 13:22:08.326000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 295 to view_41
V1111 13:22:08.327000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 295 to histc_4
V1111 13:22:08.328000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 295 to _set_grad_enabled_8
V1111 13:22:08.328000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 295 to l__self____export_root_layers_3_moe_tokens_per_expert
V1111 13:22:08.329000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 295 to add__2
V1111 13:22:08.330000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 295 to _set_grad_enabled_9
V1111 13:22:08.331000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 295 to view_42
V1111 13:22:08.332000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 295 to histc_5
V1111 13:22:08.333000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 295 to view_43
V1111 13:22:08.333000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 295 to argsort_2
V1111 13:22:08.334000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 295 to view_44
V1111 13:22:08.335000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 296 to getitem_48
V1111 13:22:08.335000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 297 to floordiv_4
V1111 13:22:08.336000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 297 to reshape_6
V1111 13:22:08.337000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 297 to expand_6
V1111 13:22:08.338000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 297 to gather_5
V1111 13:22:08.339000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 298 to l__self____export_root_layers_3_moe_experts_w1
V1111 13:22:08.340000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 298 to l__self____export_root_layers_3_moe_experts_w2
V1111 13:22:08.341000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 298 to l__self____export_root_layers_3_moe_experts_w3
V1111 13:22:08.343000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 298 to _set_grad_enabled_10
V1111 13:22:08.344000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 298 to cumsum_6
V1111 13:22:08.344000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 298 to sub_6
V1111 13:22:08.345000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 298 to view_45
V1111 13:22:08.346000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 298 to sum_3
V1111 13:22:08.346000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 298 to clamp_min_2
V1111 13:22:08.347000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 298 to add_12
V1111 13:22:08.347000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 298 to sub_7
V1111 13:22:08.348000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 298 to floordiv_5
V1111 13:22:08.348000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 298 to mul_20
V1111 13:22:08.349000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 298 to to_19
V1111 13:22:08.349000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 298 to cumsum_7
V1111 13:22:08.350000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 298 to sub_8
V1111 13:22:08.350000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 298 to full_2
V1111 13:22:08.351000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 298 to triton_kernel_wrapper_mutation_2
V1111 13:22:08.352000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 298 to to_20
V1111 13:22:08.352000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 298 to _set_grad_enabled_11
V1111 13:22:08.352000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 298 to new_zeros_2
V1111 13:22:08.353000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 298 to vstack_2
V1111 13:22:08.354000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 299 to getitem_49
V1111 13:22:08.355000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 300 to cumsum_8
V1111 13:22:08.355000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 300 to bfloat16_10
V1111 13:22:08.356000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 301 to bfloat16_11
V1111 13:22:08.356000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 302 to transpose_22
V1111 13:22:08.357000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 303 to _grouped_mm_6
V1111 13:22:08.357000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 304 to silu_5
V1111 13:22:08.358000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 305 to bfloat16_12
V1111 13:22:08.359000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 306 to bfloat16_13
V1111 13:22:08.360000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 307 to transpose_23
V1111 13:22:08.361000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 308 to _grouped_mm_7
V1111 13:22:08.361000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 309 to mul_21
V1111 13:22:08.362000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 310 to bfloat16_14
V1111 13:22:08.363000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 311 to transpose_24
V1111 13:22:08.363000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 312 to _grouped_mm_8
V1111 13:22:08.364000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 313 to type_as_2
V1111 13:22:08.364000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 314 to new_empty_2
V1111 13:22:08.365000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 314 to setitem_2
V1111 13:22:08.365000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 315 to getitem_50
V1111 13:22:08.368000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 316 to l__self____export_root_layers_3_moe_shared_experts_w1_weight
V1111 13:22:08.370000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 316 to linear_28
V1111 13:22:08.371000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 318 to silu_6
V1111 13:22:08.372000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 319 to l__self____export_root_layers_3_moe_shared_experts_w3_weight
V1111 13:22:08.373000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 319 to linear_29
V1111 13:22:08.374000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 321 to mul_22
V1111 13:22:08.375000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 322 to l__self____export_root_layers_3_moe_shared_experts_w2_weight
V1111 13:22:08.376000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 322 to linear_30
V1111 13:22:08.377000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 324 to to_21
V1111 13:22:08.378000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 324 to reshape_7
V1111 13:22:08.378000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 325 to mul_23
V1111 13:22:08.379000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 326 to to_22
V1111 13:22:08.380000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 326 to scatter_add_2
V1111 13:22:08.380000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 327 to reshape_8
V1111 13:22:08.381000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 328 to add_13
V1111 13:22:08.384000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 329 to l__self____export_root_layers_4_attention_norm_weight
V1111 13:22:08.385000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 329 to rms_norm_12
V1111 13:22:08.388000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 330 to l__self____export_root_layers_4_attention_wq_weight
V1111 13:22:08.389000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 330 to linear_31
V1111 13:22:08.390000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 334 to view_46
V1111 13:22:08.391000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 335 to split_12
V1111 13:22:08.392000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 336 to getitem_51
V1111 13:22:08.392000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 336 to getitem_52
V1111 13:22:08.393000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 336 to float_9
V1111 13:22:08.393000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 336 to view_47
V1111 13:22:08.394000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 337 to view_as_complex_8
V1111 13:22:08.395000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 338 to view_48
V1111 13:22:08.396000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 338 to mul_24
V1111 13:22:08.396000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 339 to view_as_real_8
V1111 13:22:08.397000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 340 to flatten_8
V1111 13:22:08.398000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 341 to to_23
V1111 13:22:08.398000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 341 to cat_8
V1111 13:22:08.400000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 342 to l__self____export_root_layers_4_attention_wkv_a_weight
V1111 13:22:08.401000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 342 to linear_32
V1111 13:22:08.402000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 346 to split_13
V1111 13:22:08.403000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 347 to getitem_53
V1111 13:22:08.404000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 347 to getitem_54
V1111 13:22:08.404000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 347 to unsqueeze_4
V1111 13:22:08.405000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 348 to float_10
V1111 13:22:08.405000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 348 to view_49
V1111 13:22:08.406000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 349 to view_as_complex_9
V1111 13:22:08.407000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 350 to view_50
V1111 13:22:08.408000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 350 to mul_25
V1111 13:22:08.408000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 351 to view_as_real_9
V1111 13:22:08.409000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 352 to flatten_9
V1111 13:22:08.410000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 353 to to_24
V1111 13:22:08.411000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 353 to l__self____export_root_layers_4_attention_kv_norm_weight
V1111 13:22:08.412000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 353 to rms_norm_13
V1111 13:22:08.414000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 354 to l__self____export_root_layers_4_attention_wkv_b_weight
V1111 13:22:08.415000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 354 to linear_33
V1111 13:22:08.416000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 358 to view_51
V1111 13:22:08.417000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 359 to split_14
V1111 13:22:08.418000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 360 to getitem_55
V1111 13:22:08.418000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 360 to getitem_56
V1111 13:22:08.419000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 360 to expand_7
V1111 13:22:08.420000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 361 to cat_9
V1111 13:22:08.420000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 362 to transpose_25
V1111 13:22:08.421000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 363 to transpose_26
V1111 13:22:08.421000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 364 to transpose_27
V1111 13:22:08.431000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to q_19
V1111 13:22:08.432000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to new_empty
V1111 13:22:08.432000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to new_empty_1
V1111 13:22:08.433000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to new_empty_2
V1111 13:22:08.433000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to new_empty_3
V1111 13:22:08.434000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to new_empty_4
/data/users/shangdiy/pytorch/torch/_dynamo/variables/user_defined.py:1815: FutureWarning: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.
  return ctor(*args, **kwargs)
V1111 13:22:08.444000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to child
V1111 13:22:08.444000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to child_1
V1111 13:22:08.445000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to child_2
V1111 13:22:08.445000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to child_3
V1111 13:22:08.445000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to child_4
V1111 13:22:08.450000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to output
V1111 13:22:08.450000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to score_mod_4
V1111 13:22:08.451000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to q_19
V1111 13:22:08.451000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to new_empty
V1111 13:22:08.451000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to new_empty_1
V1111 13:22:08.452000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to new_empty_2
V1111 13:22:08.452000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to new_empty_3
V1111 13:22:08.461000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to child
V1111 13:22:08.462000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to child_1
V1111 13:22:08.462000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to child_2
V1111 13:22:08.462000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to child_3
V1111 13:22:08.466000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to new_ones
V1111 13:22:08.467000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to ge
V1111 13:22:08.468000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to and_
V1111 13:22:08.469000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to l__self___in_spec__children_0__children_1__context_2___closure___0_cell_contents_1___closure___0_cell_contents
V1111 13:22:08.469000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 365 to getitem
V1111 13:22:08.470000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 366 to getitem_1
V1111 13:22:08.471000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 367 to eq
V1111 13:22:08.471000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 367 to and__1
V1111 13:22:08.472000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 367 to output
V1111 13:22:08.473000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 367 to mask_fn_4
V1111 13:22:08.473000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 367 to flex_attention_4
V1111 13:22:08.475000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 367 to arg0_1
V1111 13:22:08.475000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 367 to arg1_1
V1111 13:22:08.475000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 367 to arg2_1
V1111 13:22:08.475000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 367 to arg3_1
V1111 13:22:08.475000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 367 to arg4_1
V1111 13:22:08.475000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 367 to arg5_1
V1111 13:22:08.477000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 367 to output
V1111 13:22:08.480000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 368 to getitem_57
V1111 13:22:08.480000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 368 to getitem_58
V1111 13:22:08.480000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 368 to getitem_59
V1111 13:22:08.481000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 368 to transpose_28
V1111 13:22:08.482000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 369 to contiguous_4
V1111 13:22:08.482000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 369 to view_52
V1111 13:22:08.484000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 370 to l__self____export_root_layers_4_attention_wo_weight
V1111 13:22:08.485000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 370 to linear_34
V1111 13:22:08.486000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 374 to add_14
V1111 13:22:08.488000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 375 to l__self____export_root_layers_4_ffn_norm_weight
V1111 13:22:08.489000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 375 to rms_norm_14
V1111 13:22:08.491000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 376 to view_53
V1111 13:22:08.493000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 377 to l__self____export_root_layers_4_moe_expert_bias
V1111 13:22:08.495000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 377 to l__self____export_root_layers_4_moe_router_gate_weight
V1111 13:22:08.496000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 377 to linear_35
V1111 13:22:08.497000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 379 to to_25
V1111 13:22:08.498000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 379 to softmax_3
V1111 13:22:08.499000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 380 to add_15
V1111 13:22:08.499000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 381 to topk_3
V1111 13:22:08.500000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 382 to getitem_60
V1111 13:22:08.500000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 382 to getitem_61
V1111 13:22:08.501000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 382 to gather_6
V1111 13:22:08.502000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 383 to mul_26
V1111 13:22:08.502000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 384 to view_54
V1111 13:22:08.503000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 384 to histc_6
V1111 13:22:08.504000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 384 to _set_grad_enabled_12
V1111 13:22:08.504000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 384 to l__self____export_root_layers_4_moe_tokens_per_expert
V1111 13:22:08.505000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 384 to add__3
V1111 13:22:08.506000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 384 to _set_grad_enabled_13
V1111 13:22:08.507000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 384 to view_55
V1111 13:22:08.508000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 384 to histc_7
V1111 13:22:08.509000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 384 to view_56
V1111 13:22:08.509000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 384 to argsort_3
V1111 13:22:08.510000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 384 to view_57
V1111 13:22:08.511000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 385 to getitem_62
V1111 13:22:08.512000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 386 to floordiv_6
V1111 13:22:08.512000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 386 to reshape_9
V1111 13:22:08.513000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 386 to expand_8
V1111 13:22:08.514000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 386 to gather_7
V1111 13:22:08.515000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 387 to l__self____export_root_layers_4_moe_experts_w1
V1111 13:22:08.516000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 387 to l__self____export_root_layers_4_moe_experts_w2
V1111 13:22:08.517000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 387 to l__self____export_root_layers_4_moe_experts_w3
V1111 13:22:08.520000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 387 to _set_grad_enabled_14
V1111 13:22:08.520000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 387 to cumsum_9
V1111 13:22:08.521000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 387 to sub_9
V1111 13:22:08.521000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 387 to view_58
V1111 13:22:08.522000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 387 to sum_4
V1111 13:22:08.522000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 387 to clamp_min_3
V1111 13:22:08.523000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 387 to add_16
V1111 13:22:08.523000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 387 to sub_10
V1111 13:22:08.524000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 387 to floordiv_7
V1111 13:22:08.524000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 387 to mul_27
V1111 13:22:08.525000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 387 to to_26
V1111 13:22:08.525000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 387 to cumsum_10
V1111 13:22:08.526000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 387 to sub_11
V1111 13:22:08.526000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 387 to full_3
V1111 13:22:08.527000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 387 to triton_kernel_wrapper_mutation_3
V1111 13:22:08.528000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 387 to to_27
V1111 13:22:08.528000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 387 to _set_grad_enabled_15
V1111 13:22:08.528000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 387 to new_zeros_3
V1111 13:22:08.529000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 387 to vstack_3
V1111 13:22:08.531000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 388 to getitem_63
V1111 13:22:08.532000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 389 to cumsum_11
V1111 13:22:08.532000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 389 to bfloat16_15
V1111 13:22:08.533000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 390 to bfloat16_16
V1111 13:22:08.534000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 391 to transpose_29
V1111 13:22:08.534000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 392 to _grouped_mm_9
V1111 13:22:08.535000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 393 to silu_7
V1111 13:22:08.535000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 394 to bfloat16_17
V1111 13:22:08.536000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 395 to bfloat16_18
V1111 13:22:08.536000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 396 to transpose_30
V1111 13:22:08.537000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 397 to _grouped_mm_10
V1111 13:22:08.537000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 398 to mul_28
V1111 13:22:08.538000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 399 to bfloat16_19
V1111 13:22:08.539000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 400 to transpose_31
V1111 13:22:08.539000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 401 to _grouped_mm_11
V1111 13:22:08.540000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 402 to type_as_3
V1111 13:22:08.540000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 403 to new_empty_3
V1111 13:22:08.541000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 403 to setitem_3
V1111 13:22:08.542000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 404 to getitem_64
V1111 13:22:08.545000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 405 to l__self____export_root_layers_4_moe_shared_experts_w1_weight
V1111 13:22:08.546000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 405 to linear_36
V1111 13:22:08.546000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 407 to silu_8
V1111 13:22:08.548000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 408 to l__self____export_root_layers_4_moe_shared_experts_w3_weight
V1111 13:22:08.549000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 408 to linear_37
V1111 13:22:08.550000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 410 to mul_29
V1111 13:22:08.551000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 411 to l__self____export_root_layers_4_moe_shared_experts_w2_weight
V1111 13:22:08.553000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 411 to linear_38
V1111 13:22:08.554000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 413 to to_28
V1111 13:22:08.555000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 413 to reshape_10
V1111 13:22:08.555000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 414 to mul_30
V1111 13:22:08.556000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 415 to to_29
V1111 13:22:08.557000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 415 to scatter_add_3
V1111 13:22:08.557000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 416 to reshape_11
V1111 13:22:08.558000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 417 to add_17
V1111 13:22:08.561000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 418 to l__self____export_root_layers_5_attention_norm_weight
V1111 13:22:08.562000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 418 to rms_norm_15
V1111 13:22:08.564000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 419 to l__self____export_root_layers_5_attention_wq_weight
V1111 13:22:08.565000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 419 to linear_39
V1111 13:22:08.567000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 423 to view_59
V1111 13:22:08.568000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 424 to split_15
V1111 13:22:08.569000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 425 to getitem_65
V1111 13:22:08.569000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 425 to getitem_66
V1111 13:22:08.570000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 425 to float_11
V1111 13:22:08.570000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 425 to view_60
V1111 13:22:08.571000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 426 to view_as_complex_10
V1111 13:22:08.572000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 427 to view_61
V1111 13:22:08.572000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 427 to mul_31
V1111 13:22:08.573000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 428 to view_as_real_10
V1111 13:22:08.574000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 429 to flatten_10
V1111 13:22:08.574000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 430 to to_30
V1111 13:22:08.575000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 430 to cat_10
V1111 13:22:08.576000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 431 to l__self____export_root_layers_5_attention_wkv_a_weight
V1111 13:22:08.577000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 431 to linear_40
V1111 13:22:08.579000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 435 to split_16
V1111 13:22:08.580000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 436 to getitem_67
V1111 13:22:08.580000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 436 to getitem_68
V1111 13:22:08.581000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 436 to unsqueeze_5
V1111 13:22:08.581000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 437 to float_12
V1111 13:22:08.582000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 437 to view_62
V1111 13:22:08.583000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 438 to view_as_complex_11
V1111 13:22:08.583000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 439 to view_63
V1111 13:22:08.584000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 439 to mul_32
V1111 13:22:08.585000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 440 to view_as_real_11
V1111 13:22:08.585000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 441 to flatten_11
V1111 13:22:08.586000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 442 to to_31
V1111 13:22:08.588000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 442 to l__self____export_root_layers_5_attention_kv_norm_weight
V1111 13:22:08.589000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 442 to rms_norm_16
V1111 13:22:08.590000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 443 to l__self____export_root_layers_5_attention_wkv_b_weight
V1111 13:22:08.652000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 443 to linear_41
V1111 13:22:08.654000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 447 to view_64
V1111 13:22:08.655000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 448 to split_17
V1111 13:22:08.655000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 449 to getitem_69
V1111 13:22:08.656000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 449 to getitem_70
V1111 13:22:08.656000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 449 to expand_9
V1111 13:22:08.657000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 450 to cat_11
V1111 13:22:08.658000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 451 to transpose_32
V1111 13:22:08.658000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 452 to transpose_33
V1111 13:22:08.659000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 453 to transpose_34
V1111 13:22:08.669000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to q_23
V1111 13:22:08.669000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to new_empty
V1111 13:22:08.670000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to new_empty_1
V1111 13:22:08.670000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to new_empty_2
V1111 13:22:08.671000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to new_empty_3
V1111 13:22:08.671000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to new_empty_4
/data/users/shangdiy/pytorch/torch/_dynamo/variables/user_defined.py:1815: FutureWarning: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.
  return ctor(*args, **kwargs)
V1111 13:22:08.681000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to child
V1111 13:22:08.682000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to child_1
V1111 13:22:08.682000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to child_2
V1111 13:22:08.682000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to child_3
V1111 13:22:08.683000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to child_4
V1111 13:22:08.687000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to output
V1111 13:22:08.688000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to score_mod_5
V1111 13:22:08.688000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to q_23
V1111 13:22:08.688000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to new_empty
V1111 13:22:08.689000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to new_empty_1
V1111 13:22:08.689000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to new_empty_2
V1111 13:22:08.690000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to new_empty_3
V1111 13:22:08.699000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to child
V1111 13:22:08.699000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to child_1
V1111 13:22:08.700000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to child_2
V1111 13:22:08.700000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to child_3
V1111 13:22:08.704000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to new_ones
V1111 13:22:08.705000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to ge
V1111 13:22:08.705000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to and_
V1111 13:22:08.706000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to l__self___in_spec__children_0__children_1__context_2___closure___0_cell_contents_1___closure___0_cell_contents
V1111 13:22:08.707000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 454 to getitem
V1111 13:22:08.707000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 455 to getitem_1
V1111 13:22:08.708000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 456 to eq
V1111 13:22:08.709000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 456 to and__1
V1111 13:22:08.709000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 456 to output
V1111 13:22:08.710000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 456 to mask_fn_5
V1111 13:22:08.710000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 456 to flex_attention_5
V1111 13:22:08.712000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 456 to arg0_1
V1111 13:22:08.712000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 456 to arg1_1
V1111 13:22:08.712000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 456 to arg2_1
V1111 13:22:08.713000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 456 to arg3_1
V1111 13:22:08.713000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 456 to arg4_1
V1111 13:22:08.713000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 456 to arg5_1
V1111 13:22:08.715000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 456 to output
V1111 13:22:08.717000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 457 to getitem_71
V1111 13:22:08.718000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 457 to getitem_72
V1111 13:22:08.718000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 457 to getitem_73
V1111 13:22:08.719000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 457 to transpose_35
V1111 13:22:08.720000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 458 to contiguous_5
V1111 13:22:08.720000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 458 to view_65
V1111 13:22:08.721000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 459 to l__self____export_root_layers_5_attention_wo_weight
V1111 13:22:08.723000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 459 to linear_42
V1111 13:22:08.724000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 463 to add_18
V1111 13:22:08.726000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 464 to l__self____export_root_layers_5_ffn_norm_weight
V1111 13:22:08.727000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 464 to rms_norm_17
V1111 13:22:08.729000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 465 to view_66
V1111 13:22:08.730000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 466 to l__self____export_root_layers_5_moe_expert_bias
V1111 13:22:08.733000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 466 to l__self____export_root_layers_5_moe_router_gate_weight
V1111 13:22:08.734000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 466 to linear_43
V1111 13:22:08.735000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 468 to to_32
V1111 13:22:08.735000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 468 to softmax_4
V1111 13:22:08.736000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 469 to add_19
V1111 13:22:08.737000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 470 to topk_4
V1111 13:22:08.738000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 471 to getitem_74
V1111 13:22:08.738000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 471 to getitem_75
V1111 13:22:08.738000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 471 to gather_8
V1111 13:22:08.739000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 472 to mul_33
V1111 13:22:08.740000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 473 to view_67
V1111 13:22:08.741000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 473 to histc_8
V1111 13:22:08.742000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 473 to _set_grad_enabled_16
V1111 13:22:08.742000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 473 to l__self____export_root_layers_5_moe_tokens_per_expert
V1111 13:22:08.743000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 473 to add__4
V1111 13:22:08.744000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 473 to _set_grad_enabled_17
V1111 13:22:08.745000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 473 to view_68
V1111 13:22:08.746000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 473 to histc_9
V1111 13:22:08.746000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 473 to view_69
V1111 13:22:08.747000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 473 to argsort_4
V1111 13:22:08.748000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 473 to view_70
V1111 13:22:08.748000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 474 to getitem_76
V1111 13:22:08.749000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 475 to floordiv_8
V1111 13:22:08.750000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 475 to reshape_12
V1111 13:22:08.750000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 475 to expand_10
V1111 13:22:08.751000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 475 to gather_9
V1111 13:22:08.753000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 476 to l__self____export_root_layers_5_moe_experts_w1
V1111 13:22:08.754000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 476 to l__self____export_root_layers_5_moe_experts_w2
V1111 13:22:08.755000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 476 to l__self____export_root_layers_5_moe_experts_w3
V1111 13:22:08.757000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 476 to _set_grad_enabled_18
V1111 13:22:08.758000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 476 to cumsum_12
V1111 13:22:08.758000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 476 to sub_12
V1111 13:22:08.759000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 476 to view_71
V1111 13:22:08.759000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 476 to sum_5
V1111 13:22:08.760000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 476 to clamp_min_4
V1111 13:22:08.760000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 476 to add_20
V1111 13:22:08.761000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 476 to sub_13
V1111 13:22:08.761000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 476 to floordiv_9
V1111 13:22:08.762000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 476 to mul_34
V1111 13:22:08.762000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 476 to to_33
V1111 13:22:08.763000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 476 to cumsum_13
V1111 13:22:08.763000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 476 to sub_14
V1111 13:22:08.765000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 476 to full_4
V1111 13:22:08.766000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 476 to triton_kernel_wrapper_mutation_4
V1111 13:22:08.766000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 476 to to_34
V1111 13:22:08.767000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 476 to _set_grad_enabled_19
V1111 13:22:08.767000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 476 to new_zeros_4
V1111 13:22:08.768000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 476 to vstack_4
V1111 13:22:08.768000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 477 to getitem_77
V1111 13:22:08.769000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 478 to cumsum_14
V1111 13:22:08.770000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 478 to bfloat16_20
V1111 13:22:08.771000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 479 to bfloat16_21
V1111 13:22:08.771000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 480 to transpose_36
V1111 13:22:08.772000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 481 to _grouped_mm_12
V1111 13:22:08.772000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 482 to silu_9
V1111 13:22:08.773000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 483 to bfloat16_22
V1111 13:22:08.773000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 484 to bfloat16_23
V1111 13:22:08.774000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 485 to transpose_37
V1111 13:22:08.774000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 486 to _grouped_mm_13
V1111 13:22:08.775000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 487 to mul_35
V1111 13:22:08.776000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 488 to bfloat16_24
V1111 13:22:08.776000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 489 to transpose_38
V1111 13:22:08.777000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 490 to _grouped_mm_14
V1111 13:22:08.777000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 491 to type_as_4
V1111 13:22:08.778000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 492 to new_empty_4
V1111 13:22:08.779000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 492 to setitem_4
V1111 13:22:08.779000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 493 to getitem_78
V1111 13:22:08.782000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 494 to l__self____export_root_layers_5_moe_shared_experts_w1_weight
V1111 13:22:08.783000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 494 to linear_44
V1111 13:22:08.784000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 496 to silu_10
V1111 13:22:08.786000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 497 to l__self____export_root_layers_5_moe_shared_experts_w3_weight
V1111 13:22:08.787000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 497 to linear_45
V1111 13:22:08.788000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 499 to mul_36
V1111 13:22:08.789000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 500 to l__self____export_root_layers_5_moe_shared_experts_w2_weight
V1111 13:22:08.790000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 500 to linear_46
V1111 13:22:08.791000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 502 to to_35
V1111 13:22:08.791000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 502 to reshape_13
V1111 13:22:08.792000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 503 to mul_37
V1111 13:22:08.793000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 504 to to_36
V1111 13:22:08.793000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 504 to scatter_add_4
V1111 13:22:08.794000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 505 to reshape_14
V1111 13:22:08.795000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 506 to add_21
V1111 13:22:08.796000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 507 to l__self____export_root_norm_weight
V1111 13:22:08.798000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 507 to rms_norm_18
V1111 13:22:08.801000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 508 to l__self____export_root_output_weight
V1111 13:22:08.802000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 508 to linear_47
/data/users/shangdiy/pytorch/torch/_dynamo/variables/user_defined.py:1815: FutureWarning: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.
  return ctor(*args, **kwargs)
V1111 13:22:08.811000 86039 torch/fx/proxy.py:228] [0/0] [__annotation] Assigning new_seq_nr 512 to output_13
V1111 13:22:09.231000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_tok_embeddings_weight
V1111 13:22:09.232000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to embedding
V1111 13:22:09.232000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_freqs_cis
V1111 13:22:09.232000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_0_attention_norm_weight
V1111 13:22:09.232000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to rms_norm
V1111 13:22:09.232000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_0_attention_wq_weight
V1111 13:22:09.233000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear
V1111 13:22:09.233000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view
V1111 13:22:09.233000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to split
V1111 13:22:09.233000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem
V1111 13:22:09.233000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_1
V1111 13:22:09.233000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to float_1
V1111 13:22:09.233000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_1
V1111 13:22:09.234000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_as_complex
V1111 13:22:09.234000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_2
V1111 13:22:09.234000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul
V1111 13:22:09.234000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_as_real
V1111 13:22:09.234000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to flatten
V1111 13:22:09.234000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to
V1111 13:22:09.234000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cat
V1111 13:22:09.235000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_0_attention_wkv_a_weight
V1111 13:22:09.235000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_1
V1111 13:22:09.235000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to split_1
V1111 13:22:09.235000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_2
V1111 13:22:09.235000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_3
V1111 13:22:09.235000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to unsqueeze
V1111 13:22:09.235000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to float_2
V1111 13:22:09.236000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_3
V1111 13:22:09.236000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_as_complex_1
V1111 13:22:09.236000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_4
V1111 13:22:09.236000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_1
V1111 13:22:09.236000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_as_real_1
V1111 13:22:09.236000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to flatten_1
V1111 13:22:09.237000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_1
V1111 13:22:09.237000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_0_attention_kv_norm_weight
V1111 13:22:09.237000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to rms_norm_1
V1111 13:22:09.237000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_0_attention_wkv_b_weight
V1111 13:22:09.237000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_2
V1111 13:22:09.237000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_5
V1111 13:22:09.237000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to split_2
V1111 13:22:09.238000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_4
V1111 13:22:09.238000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_5
V1111 13:22:09.238000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to expand
V1111 13:22:09.238000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cat_1
V1111 13:22:09.238000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose
V1111 13:22:09.238000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_1
V1111 13:22:09.238000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_2
V1111 13:22:09.239000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to score_mod_0
V1111 13:22:09.239000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self___in_spec__children_0__children_1__context_2___closure___0_cell_contents_1___closure___0_cell_contents
V1111 13:22:09.239000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mask_fn_0
V1111 13:22:09.239000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to flex_attention
V1111 13:22:09.239000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_6
V1111 13:22:09.239000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_3
V1111 13:22:09.239000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to contiguous
V1111 13:22:09.240000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_6
V1111 13:22:09.240000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_0_attention_wo_weight
V1111 13:22:09.240000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_3
V1111 13:22:09.240000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add
V1111 13:22:09.240000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_0_ffn_norm_weight
V1111 13:22:09.240000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to rms_norm_2
V1111 13:22:09.240000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_0_feed_forward_w1_weight
V1111 13:22:09.240000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_4
V1111 13:22:09.241000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to silu
V1111 13:22:09.241000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_0_feed_forward_w3_weight
V1111 13:22:09.241000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_5
V1111 13:22:09.241000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_2
V1111 13:22:09.241000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_0_feed_forward_w2_weight
V1111 13:22:09.241000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_6
V1111 13:22:09.241000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add_1
V1111 13:22:09.242000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_1_attention_norm_weight
V1111 13:22:09.242000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to rms_norm_3
V1111 13:22:09.242000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_1_attention_wq_weight
V1111 13:22:09.242000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_7
V1111 13:22:09.242000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_7
V1111 13:22:09.242000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to split_3
V1111 13:22:09.242000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_7
V1111 13:22:09.242000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_8
V1111 13:22:09.243000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to float_3
V1111 13:22:09.243000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_8
V1111 13:22:09.243000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_as_complex_2
V1111 13:22:09.243000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_9
V1111 13:22:09.243000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_3
V1111 13:22:09.243000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_as_real_2
V1111 13:22:09.243000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to flatten_2
V1111 13:22:09.244000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_2
V1111 13:22:09.244000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cat_2
V1111 13:22:09.244000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_1_attention_wkv_a_weight
V1111 13:22:09.244000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_8
V1111 13:22:09.244000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to split_4
V1111 13:22:09.244000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_9
V1111 13:22:09.245000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_10
V1111 13:22:09.245000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to unsqueeze_1
V1111 13:22:09.245000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to float_4
V1111 13:22:09.245000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_10
V1111 13:22:09.245000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_as_complex_3
V1111 13:22:09.245000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_11
V1111 13:22:09.245000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_4
V1111 13:22:09.245000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_as_real_3
V1111 13:22:09.246000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to flatten_3
V1111 13:22:09.246000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_3
V1111 13:22:09.246000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_1_attention_kv_norm_weight
V1111 13:22:09.246000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to rms_norm_4
V1111 13:22:09.246000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_1_attention_wkv_b_weight
V1111 13:22:09.246000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_9
V1111 13:22:09.246000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_12
V1111 13:22:09.247000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to split_5
V1111 13:22:09.247000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_11
V1111 13:22:09.247000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_12
V1111 13:22:09.247000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to expand_1
V1111 13:22:09.247000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cat_3
V1111 13:22:09.247000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_4
V1111 13:22:09.247000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_5
V1111 13:22:09.247000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_6
V1111 13:22:09.248000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to score_mod_1
V1111 13:22:09.248000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mask_fn_1
V1111 13:22:09.248000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to flex_attention_1
V1111 13:22:09.248000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_13
V1111 13:22:09.248000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_7
V1111 13:22:09.248000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to contiguous_1
V1111 13:22:09.248000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_13
V1111 13:22:09.249000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_1_attention_wo_weight
V1111 13:22:09.249000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_10
V1111 13:22:09.249000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add_2
V1111 13:22:09.249000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_1_ffn_norm_weight
V1111 13:22:09.249000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to rms_norm_5
V1111 13:22:09.249000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_14
V1111 13:22:09.249000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_1_moe_expert_bias
V1111 13:22:09.250000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_1_moe_router_gate_weight
V1111 13:22:09.250000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_11
V1111 13:22:09.250000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_4
V1111 13:22:09.250000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to softmax
V1111 13:22:09.250000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add_3
V1111 13:22:09.250000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to topk
V1111 13:22:09.250000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_14
V1111 13:22:09.251000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to gather
V1111 13:22:09.251000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_5
V1111 13:22:09.251000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_15
V1111 13:22:09.251000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to histc
V1111 13:22:09.251000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _set_grad_enabled
V1111 13:22:09.251000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_1_moe_tokens_per_expert
V1111 13:22:09.251000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add_
V1111 13:22:09.252000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _set_grad_enabled_1
V1111 13:22:09.252000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_16
V1111 13:22:09.252000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to histc_1
V1111 13:22:09.252000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_17
V1111 13:22:09.252000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to argsort
V1111 13:22:09.252000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_18
V1111 13:22:09.252000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_15
V1111 13:22:09.252000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to floordiv
V1111 13:22:09.253000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to reshape
V1111 13:22:09.253000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to expand_2
V1111 13:22:09.253000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to gather_1
V1111 13:22:09.253000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_1_moe_experts_w1
V1111 13:22:09.253000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_1_moe_experts_w2
V1111 13:22:09.253000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_1_moe_experts_w3
V1111 13:22:09.253000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _set_grad_enabled_2
V1111 13:22:09.254000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cumsum
V1111 13:22:09.254000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to sub
V1111 13:22:09.254000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_19
V1111 13:22:09.254000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to sum_1
V1111 13:22:09.254000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to clamp_min
V1111 13:22:09.254000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add_4
V1111 13:22:09.254000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to sub_1
V1111 13:22:09.255000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to floordiv_1
V1111 13:22:09.255000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_6
V1111 13:22:09.255000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_5
V1111 13:22:09.255000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cumsum_1
V1111 13:22:09.255000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to sub_2
V1111 13:22:09.255000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to full
V1111 13:22:09.255000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to triton_kernel_wrapper_mutation
V1111 13:22:09.255000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_6
V1111 13:22:09.256000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _set_grad_enabled_3
V1111 13:22:09.256000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to new_zeros
V1111 13:22:09.256000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to vstack
V1111 13:22:09.256000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_16
V1111 13:22:09.256000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cumsum_2
V1111 13:22:09.256000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to bfloat16
V1111 13:22:09.256000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to bfloat16_1
V1111 13:22:09.257000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_8
V1111 13:22:09.257000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _grouped_mm
V1111 13:22:09.257000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to silu_1
V1111 13:22:09.257000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to bfloat16_2
V1111 13:22:09.257000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to bfloat16_3
V1111 13:22:09.257000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_9
V1111 13:22:09.258000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _grouped_mm_1
V1111 13:22:09.258000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_7
V1111 13:22:09.258000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to bfloat16_4
V1111 13:22:09.258000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_10
V1111 13:22:09.258000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _grouped_mm_2
V1111 13:22:09.258000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to type_as
V1111 13:22:09.258000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to new_empty
V1111 13:22:09.259000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to setitem
V1111 13:22:09.259000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_17
V1111 13:22:09.259000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_1_moe_shared_experts_w1_weight
V1111 13:22:09.259000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_12
V1111 13:22:09.259000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to silu_2
V1111 13:22:09.259000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_1_moe_shared_experts_w3_weight
V1111 13:22:09.259000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_13
V1111 13:22:09.260000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_8
V1111 13:22:09.260000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_1_moe_shared_experts_w2_weight
V1111 13:22:09.260000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_14
V1111 13:22:09.260000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_7
V1111 13:22:09.260000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to reshape_1
V1111 13:22:09.260000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_9
V1111 13:22:09.260000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_8
V1111 13:22:09.261000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to scatter_add
V1111 13:22:09.261000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to reshape_2
V1111 13:22:09.261000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add_5
V1111 13:22:09.261000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_2_attention_norm_weight
V1111 13:22:09.261000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to rms_norm_6
V1111 13:22:09.261000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_2_attention_wq_weight
V1111 13:22:09.261000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_15
V1111 13:22:09.262000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_20
V1111 13:22:09.262000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to split_6
V1111 13:22:09.262000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_18
V1111 13:22:09.262000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_19
V1111 13:22:09.262000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to float_5
V1111 13:22:09.262000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_21
V1111 13:22:09.262000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_as_complex_4
V1111 13:22:09.263000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_22
V1111 13:22:09.263000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_10
V1111 13:22:09.263000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_as_real_4
V1111 13:22:09.263000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to flatten_4
V1111 13:22:09.263000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_9
V1111 13:22:09.263000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cat_4
V1111 13:22:09.263000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_2_attention_wkv_a_weight
V1111 13:22:09.264000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_16
V1111 13:22:09.264000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to split_7
V1111 13:22:09.264000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_20
V1111 13:22:09.264000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_21
V1111 13:22:09.264000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to unsqueeze_2
V1111 13:22:09.264000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to float_6
V1111 13:22:09.264000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_23
V1111 13:22:09.265000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_as_complex_5
V1111 13:22:09.265000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_24
V1111 13:22:09.265000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_11
V1111 13:22:09.265000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_as_real_5
V1111 13:22:09.265000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to flatten_5
V1111 13:22:09.265000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_10
V1111 13:22:09.265000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_2_attention_kv_norm_weight
V1111 13:22:09.266000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to rms_norm_7
V1111 13:22:09.266000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_2_attention_wkv_b_weight
V1111 13:22:09.266000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_17
V1111 13:22:09.266000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_25
V1111 13:22:09.266000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to split_8
V1111 13:22:09.266000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_22
V1111 13:22:09.266000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_23
V1111 13:22:09.266000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to expand_3
V1111 13:22:09.267000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cat_5
V1111 13:22:09.267000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_11
V1111 13:22:09.267000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_12
V1111 13:22:09.267000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_13
V1111 13:22:09.267000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to score_mod_2
V1111 13:22:09.267000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mask_fn_2
V1111 13:22:09.268000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to flex_attention_2
V1111 13:22:09.268000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_24
V1111 13:22:09.268000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_14
V1111 13:22:09.268000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to contiguous_2
V1111 13:22:09.268000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_26
V1111 13:22:09.268000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_2_attention_wo_weight
V1111 13:22:09.268000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_18
V1111 13:22:09.268000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add_6
V1111 13:22:09.269000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_2_ffn_norm_weight
V1111 13:22:09.269000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to rms_norm_8
V1111 13:22:09.269000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_27
V1111 13:22:09.269000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_2_moe_expert_bias
V1111 13:22:09.269000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_2_moe_router_gate_weight
V1111 13:22:09.269000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_19
V1111 13:22:09.269000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_11
V1111 13:22:09.270000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to softmax_1
V1111 13:22:09.270000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add_7
V1111 13:22:09.270000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to topk_1
V1111 13:22:09.270000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_25
V1111 13:22:09.270000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to gather_2
V1111 13:22:09.270000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_12
V1111 13:22:09.270000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_28
V1111 13:22:09.271000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to histc_2
V1111 13:22:09.271000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _set_grad_enabled_4
V1111 13:22:09.271000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_2_moe_tokens_per_expert
V1111 13:22:09.271000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add__1
V1111 13:22:09.271000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _set_grad_enabled_5
V1111 13:22:09.271000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_29
V1111 13:22:09.271000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to histc_3
V1111 13:22:09.271000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_30
V1111 13:22:09.272000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to argsort_1
V1111 13:22:09.272000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_31
V1111 13:22:09.272000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_26
V1111 13:22:09.272000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to floordiv_2
V1111 13:22:09.272000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to reshape_3
V1111 13:22:09.272000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to expand_4
V1111 13:22:09.273000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to gather_3
V1111 13:22:09.273000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_2_moe_experts_w1
V1111 13:22:09.273000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_2_moe_experts_w2
V1111 13:22:09.273000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_2_moe_experts_w3
V1111 13:22:09.273000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _set_grad_enabled_6
V1111 13:22:09.273000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cumsum_3
V1111 13:22:09.273000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to sub_3
V1111 13:22:09.273000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_32
V1111 13:22:09.274000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to sum_2
V1111 13:22:09.274000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to clamp_min_1
V1111 13:22:09.274000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add_8
V1111 13:22:09.274000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to sub_4
V1111 13:22:09.274000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to floordiv_3
V1111 13:22:09.274000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_13
V1111 13:22:09.274000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_12
V1111 13:22:09.275000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cumsum_4
V1111 13:22:09.275000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to sub_5
V1111 13:22:09.275000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to full_1
V1111 13:22:09.275000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to triton_kernel_wrapper_mutation_1
V1111 13:22:09.275000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_13
V1111 13:22:09.275000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _set_grad_enabled_7
V1111 13:22:09.275000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to new_zeros_1
V1111 13:22:09.275000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to vstack_1
V1111 13:22:09.276000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_27
V1111 13:22:09.276000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cumsum_5
V1111 13:22:09.276000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to bfloat16_5
V1111 13:22:09.276000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to bfloat16_6
V1111 13:22:09.276000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_15
V1111 13:22:09.276000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _grouped_mm_3
V1111 13:22:09.276000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to silu_3
V1111 13:22:09.277000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to bfloat16_7
V1111 13:22:09.277000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to bfloat16_8
V1111 13:22:09.277000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_16
V1111 13:22:09.277000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _grouped_mm_4
V1111 13:22:09.277000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_14
V1111 13:22:09.277000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to bfloat16_9
V1111 13:22:09.277000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_17
V1111 13:22:09.277000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _grouped_mm_5
V1111 13:22:09.278000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to type_as_1
V1111 13:22:09.278000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to new_empty_1
V1111 13:22:09.278000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to setitem_1
V1111 13:22:09.278000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_28
V1111 13:22:09.278000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_2_moe_shared_experts_w1_weight
V1111 13:22:09.278000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_20
V1111 13:22:09.279000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to silu_4
V1111 13:22:09.279000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_2_moe_shared_experts_w3_weight
V1111 13:22:09.279000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_21
V1111 13:22:09.279000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_15
V1111 13:22:09.279000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_2_moe_shared_experts_w2_weight
V1111 13:22:09.279000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_22
V1111 13:22:09.279000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_14
V1111 13:22:09.279000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to reshape_4
V1111 13:22:09.280000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_16
V1111 13:22:09.280000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_15
V1111 13:22:09.280000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to scatter_add_1
V1111 13:22:09.280000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to reshape_5
V1111 13:22:09.280000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add_9
V1111 13:22:09.280000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_3_attention_norm_weight
V1111 13:22:09.280000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to rms_norm_9
V1111 13:22:09.281000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_3_attention_wq_weight
V1111 13:22:09.281000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_23
V1111 13:22:09.281000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_33
V1111 13:22:09.281000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to split_9
V1111 13:22:09.281000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_29
V1111 13:22:09.281000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_30
V1111 13:22:09.281000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to float_7
V1111 13:22:09.282000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_34
V1111 13:22:09.282000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_as_complex_6
V1111 13:22:09.282000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_35
V1111 13:22:09.282000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_17
V1111 13:22:09.282000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_as_real_6
V1111 13:22:09.282000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to flatten_6
V1111 13:22:09.282000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_16
V1111 13:22:09.282000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cat_6
V1111 13:22:09.283000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_3_attention_wkv_a_weight
V1111 13:22:09.283000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_24
V1111 13:22:09.283000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to split_10
V1111 13:22:09.283000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_31
V1111 13:22:09.283000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_32
V1111 13:22:09.283000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to unsqueeze_3
V1111 13:22:09.283000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to float_8
V1111 13:22:09.284000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_36
V1111 13:22:09.284000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_as_complex_7
V1111 13:22:09.284000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_37
V1111 13:22:09.284000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_18
V1111 13:22:09.284000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_as_real_7
V1111 13:22:09.284000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to flatten_7
V1111 13:22:09.284000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_17
V1111 13:22:09.284000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_3_attention_kv_norm_weight
V1111 13:22:09.285000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to rms_norm_10
V1111 13:22:09.285000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_3_attention_wkv_b_weight
V1111 13:22:09.285000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_25
V1111 13:22:09.285000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_38
V1111 13:22:09.285000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to split_11
V1111 13:22:09.285000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_33
V1111 13:22:09.285000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_34
V1111 13:22:09.286000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to expand_5
V1111 13:22:09.286000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cat_7
V1111 13:22:09.286000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_18
V1111 13:22:09.286000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_19
V1111 13:22:09.286000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_20
V1111 13:22:09.286000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to score_mod_3
V1111 13:22:09.286000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mask_fn_3
V1111 13:22:09.287000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to flex_attention_3
V1111 13:22:09.287000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_35
V1111 13:22:09.287000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_21
V1111 13:22:09.287000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to contiguous_3
V1111 13:22:09.287000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_39
V1111 13:22:09.287000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_3_attention_wo_weight
V1111 13:22:09.287000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_26
V1111 13:22:09.288000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add_10
V1111 13:22:09.288000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_3_ffn_norm_weight
V1111 13:22:09.288000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to rms_norm_11
V1111 13:22:09.288000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_40
V1111 13:22:09.288000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_3_moe_expert_bias
V1111 13:22:09.288000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_3_moe_router_gate_weight
V1111 13:22:09.288000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_27
V1111 13:22:09.289000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_18
V1111 13:22:09.289000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to softmax_2
V1111 13:22:09.289000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add_11
V1111 13:22:09.289000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to topk_2
V1111 13:22:09.289000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_36
V1111 13:22:09.289000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to gather_4
V1111 13:22:09.289000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_19
V1111 13:22:09.289000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_41
V1111 13:22:09.290000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to histc_4
V1111 13:22:09.290000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _set_grad_enabled_8
V1111 13:22:09.290000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_3_moe_tokens_per_expert
V1111 13:22:09.290000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add__2
V1111 13:22:09.290000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _set_grad_enabled_9
V1111 13:22:09.290000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_42
V1111 13:22:09.290000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to histc_5
V1111 13:22:09.291000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_43
V1111 13:22:09.291000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to argsort_2
V1111 13:22:09.291000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_44
V1111 13:22:09.291000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_37
V1111 13:22:09.291000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to floordiv_4
V1111 13:22:09.291000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to reshape_6
V1111 13:22:09.291000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to expand_6
V1111 13:22:09.291000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to gather_5
V1111 13:22:09.292000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_3_moe_experts_w1
V1111 13:22:09.292000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_3_moe_experts_w2
V1111 13:22:09.292000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_3_moe_experts_w3
V1111 13:22:09.293000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _set_grad_enabled_10
V1111 13:22:09.293000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cumsum_6
V1111 13:22:09.293000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to sub_6
V1111 13:22:09.293000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_45
V1111 13:22:09.294000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to sum_3
V1111 13:22:09.294000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to clamp_min_2
V1111 13:22:09.294000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add_12
V1111 13:22:09.294000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to sub_7
V1111 13:22:09.294000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to floordiv_5
V1111 13:22:09.294000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_20
V1111 13:22:09.294000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_19
V1111 13:22:09.295000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cumsum_7
V1111 13:22:09.295000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to sub_8
V1111 13:22:09.295000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to full_2
V1111 13:22:09.295000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to triton_kernel_wrapper_mutation_2
V1111 13:22:09.295000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_20
V1111 13:22:09.295000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _set_grad_enabled_11
V1111 13:22:09.295000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to new_zeros_2
V1111 13:22:09.296000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to vstack_2
V1111 13:22:09.296000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_38
V1111 13:22:09.296000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cumsum_8
V1111 13:22:09.296000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to bfloat16_10
V1111 13:22:09.296000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to bfloat16_11
V1111 13:22:09.296000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_22
V1111 13:22:09.296000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _grouped_mm_6
V1111 13:22:09.297000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to silu_5
V1111 13:22:09.297000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to bfloat16_12
V1111 13:22:09.297000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to bfloat16_13
V1111 13:22:09.297000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_23
V1111 13:22:09.297000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _grouped_mm_7
V1111 13:22:09.297000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_21
V1111 13:22:09.297000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to bfloat16_14
V1111 13:22:09.297000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_24
V1111 13:22:09.298000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _grouped_mm_8
V1111 13:22:09.298000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to type_as_2
V1111 13:22:09.298000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to new_empty_2
V1111 13:22:09.298000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to setitem_2
V1111 13:22:09.298000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_39
V1111 13:22:09.298000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_3_moe_shared_experts_w1_weight
V1111 13:22:09.298000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_28
V1111 13:22:09.299000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to silu_6
V1111 13:22:09.299000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_3_moe_shared_experts_w3_weight
V1111 13:22:09.299000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_29
V1111 13:22:09.299000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_22
V1111 13:22:09.299000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_3_moe_shared_experts_w2_weight
V1111 13:22:09.299000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_30
V1111 13:22:09.299000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_21
V1111 13:22:09.300000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to reshape_7
V1111 13:22:09.300000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_23
V1111 13:22:09.300000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_22
V1111 13:22:09.300000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to scatter_add_2
V1111 13:22:09.300000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to reshape_8
V1111 13:22:09.300000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add_13
V1111 13:22:09.300000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_4_attention_norm_weight
V1111 13:22:09.301000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to rms_norm_12
V1111 13:22:09.301000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_4_attention_wq_weight
V1111 13:22:09.301000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_31
V1111 13:22:09.301000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_46
V1111 13:22:09.301000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to split_12
V1111 13:22:09.301000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_40
V1111 13:22:09.301000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_41
V1111 13:22:09.301000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to float_9
V1111 13:22:09.302000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_47
V1111 13:22:09.302000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_as_complex_8
V1111 13:22:09.302000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_48
V1111 13:22:09.302000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_24
V1111 13:22:09.302000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_as_real_8
V1111 13:22:09.302000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to flatten_8
V1111 13:22:09.302000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_23
V1111 13:22:09.303000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cat_8
V1111 13:22:09.303000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_4_attention_wkv_a_weight
V1111 13:22:09.303000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_32
V1111 13:22:09.303000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to split_13
V1111 13:22:09.303000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_42
V1111 13:22:09.303000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_43
V1111 13:22:09.303000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to unsqueeze_4
V1111 13:22:09.304000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to float_10
V1111 13:22:09.304000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_49
V1111 13:22:09.304000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_as_complex_9
V1111 13:22:09.304000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_50
V1111 13:22:09.304000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_25
V1111 13:22:09.304000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_as_real_9
V1111 13:22:09.304000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to flatten_9
V1111 13:22:09.305000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_24
V1111 13:22:09.305000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_4_attention_kv_norm_weight
V1111 13:22:09.305000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to rms_norm_13
V1111 13:22:09.305000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_4_attention_wkv_b_weight
V1111 13:22:09.305000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_33
V1111 13:22:09.305000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_51
V1111 13:22:09.305000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to split_14
V1111 13:22:09.305000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_44
V1111 13:22:09.306000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_45
V1111 13:22:09.306000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to expand_7
V1111 13:22:09.306000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cat_9
V1111 13:22:09.306000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_25
V1111 13:22:09.306000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_26
V1111 13:22:09.306000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_27
V1111 13:22:09.306000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to score_mod_4
V1111 13:22:09.307000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mask_fn_4
V1111 13:22:09.307000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to flex_attention_4
V1111 13:22:09.307000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_46
V1111 13:22:09.307000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_28
V1111 13:22:09.307000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to contiguous_4
V1111 13:22:09.307000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_52
V1111 13:22:09.308000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_4_attention_wo_weight
V1111 13:22:09.308000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_34
V1111 13:22:09.308000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add_14
V1111 13:22:09.308000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_4_ffn_norm_weight
V1111 13:22:09.308000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to rms_norm_14
V1111 13:22:09.308000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_53
V1111 13:22:09.308000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_4_moe_expert_bias
V1111 13:22:09.309000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_4_moe_router_gate_weight
V1111 13:22:09.309000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_35
V1111 13:22:09.309000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_25
V1111 13:22:09.309000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to softmax_3
V1111 13:22:09.309000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add_15
V1111 13:22:09.309000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to topk_3
V1111 13:22:09.309000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_47
V1111 13:22:09.309000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to gather_6
V1111 13:22:09.310000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_26
V1111 13:22:09.310000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_54
V1111 13:22:09.310000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to histc_6
V1111 13:22:09.310000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _set_grad_enabled_12
V1111 13:22:09.310000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_4_moe_tokens_per_expert
V1111 13:22:09.310000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add__3
V1111 13:22:09.310000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _set_grad_enabled_13
V1111 13:22:09.311000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_55
V1111 13:22:09.311000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to histc_7
V1111 13:22:09.311000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_56
V1111 13:22:09.311000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to argsort_3
V1111 13:22:09.311000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_57
V1111 13:22:09.311000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_48
V1111 13:22:09.311000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to floordiv_6
V1111 13:22:09.312000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to reshape_9
V1111 13:22:09.312000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to expand_8
V1111 13:22:09.312000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to gather_7
V1111 13:22:09.312000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_4_moe_experts_w1
V1111 13:22:09.312000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_4_moe_experts_w2
V1111 13:22:09.312000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_4_moe_experts_w3
V1111 13:22:09.312000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _set_grad_enabled_14
V1111 13:22:09.313000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cumsum_9
V1111 13:22:09.313000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to sub_9
V1111 13:22:09.313000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_58
V1111 13:22:09.313000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to sum_4
V1111 13:22:09.313000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to clamp_min_3
V1111 13:22:09.313000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add_16
V1111 13:22:09.313000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to sub_10
V1111 13:22:09.313000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to floordiv_7
V1111 13:22:09.314000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_27
V1111 13:22:09.314000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_26
V1111 13:22:09.314000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cumsum_10
V1111 13:22:09.314000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to sub_11
V1111 13:22:09.314000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to full_3
V1111 13:22:09.314000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to triton_kernel_wrapper_mutation_3
V1111 13:22:09.315000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_27
V1111 13:22:09.315000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _set_grad_enabled_15
V1111 13:22:09.315000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to new_zeros_3
V1111 13:22:09.315000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to vstack_3
V1111 13:22:09.315000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_49
V1111 13:22:09.315000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cumsum_11
V1111 13:22:09.315000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to bfloat16_15
V1111 13:22:09.315000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to bfloat16_16
V1111 13:22:09.316000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_29
V1111 13:22:09.316000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _grouped_mm_9
V1111 13:22:09.316000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to silu_7
V1111 13:22:09.316000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to bfloat16_17
V1111 13:22:09.316000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to bfloat16_18
V1111 13:22:09.316000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_30
V1111 13:22:09.316000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _grouped_mm_10
V1111 13:22:09.317000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_28
V1111 13:22:09.317000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to bfloat16_19
V1111 13:22:09.317000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_31
V1111 13:22:09.317000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _grouped_mm_11
V1111 13:22:09.317000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to type_as_3
V1111 13:22:09.317000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to new_empty_3
V1111 13:22:09.317000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to setitem_3
V1111 13:22:09.318000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_50
V1111 13:22:09.318000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_4_moe_shared_experts_w1_weight
V1111 13:22:09.318000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_36
V1111 13:22:09.318000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to silu_8
V1111 13:22:09.318000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_4_moe_shared_experts_w3_weight
V1111 13:22:09.318000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_37
V1111 13:22:09.318000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_29
V1111 13:22:09.318000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_4_moe_shared_experts_w2_weight
V1111 13:22:09.319000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_38
V1111 13:22:09.319000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_28
V1111 13:22:09.319000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to reshape_10
V1111 13:22:09.319000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_30
V1111 13:22:09.319000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_29
V1111 13:22:09.319000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to scatter_add_3
V1111 13:22:09.319000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to reshape_11
V1111 13:22:09.320000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add_17
V1111 13:22:09.320000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_5_attention_norm_weight
V1111 13:22:09.320000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to rms_norm_15
V1111 13:22:09.320000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_5_attention_wq_weight
V1111 13:22:09.320000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_39
V1111 13:22:09.320000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_59
V1111 13:22:09.320000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to split_15
V1111 13:22:09.321000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_51
V1111 13:22:09.321000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_52
V1111 13:22:09.321000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to float_11
V1111 13:22:09.321000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_60
V1111 13:22:09.321000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_as_complex_10
V1111 13:22:09.321000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_61
V1111 13:22:09.321000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_31
V1111 13:22:09.322000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_as_real_10
V1111 13:22:09.322000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to flatten_10
V1111 13:22:09.322000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_30
V1111 13:22:09.322000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cat_10
V1111 13:22:09.322000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_5_attention_wkv_a_weight
V1111 13:22:09.322000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_40
V1111 13:22:09.322000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to split_16
V1111 13:22:09.322000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_53
V1111 13:22:09.323000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_54
V1111 13:22:09.323000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to unsqueeze_5
V1111 13:22:09.323000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to float_12
V1111 13:22:09.323000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_62
V1111 13:22:09.323000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_as_complex_11
V1111 13:22:09.323000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_63
V1111 13:22:09.323000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_32
V1111 13:22:09.324000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_as_real_11
V1111 13:22:09.324000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to flatten_11
V1111 13:22:09.324000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_31
V1111 13:22:09.324000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_5_attention_kv_norm_weight
V1111 13:22:09.324000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to rms_norm_16
V1111 13:22:09.324000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_5_attention_wkv_b_weight
V1111 13:22:09.324000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_41
V1111 13:22:09.325000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_64
V1111 13:22:09.325000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to split_17
V1111 13:22:09.325000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_55
V1111 13:22:09.325000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_56
V1111 13:22:09.325000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to expand_9
V1111 13:22:09.325000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cat_11
V1111 13:22:09.325000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_32
V1111 13:22:09.325000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_33
V1111 13:22:09.326000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_34
V1111 13:22:09.326000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to score_mod_5
V1111 13:22:09.326000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mask_fn_5
V1111 13:22:09.326000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to flex_attention_5
V1111 13:22:09.326000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_57
V1111 13:22:09.326000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_35
V1111 13:22:09.326000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to contiguous_5
V1111 13:22:09.327000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_65
V1111 13:22:09.327000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_5_attention_wo_weight
V1111 13:22:09.327000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_42
V1111 13:22:09.327000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add_18
V1111 13:22:09.327000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_5_ffn_norm_weight
V1111 13:22:09.327000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to rms_norm_17
V1111 13:22:09.327000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_66
V1111 13:22:09.328000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_5_moe_expert_bias
V1111 13:22:09.328000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_5_moe_router_gate_weight
V1111 13:22:09.328000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_43
V1111 13:22:09.328000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_32
V1111 13:22:09.328000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to softmax_4
V1111 13:22:09.328000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add_19
V1111 13:22:09.328000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to topk_4
V1111 13:22:09.329000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_58
V1111 13:22:09.329000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to gather_8
V1111 13:22:09.329000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_33
V1111 13:22:09.329000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_67
V1111 13:22:09.329000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to histc_8
V1111 13:22:09.329000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _set_grad_enabled_16
V1111 13:22:09.329000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_5_moe_tokens_per_expert
V1111 13:22:09.329000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add__4
V1111 13:22:09.330000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _set_grad_enabled_17
V1111 13:22:09.330000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_68
V1111 13:22:09.330000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to histc_9
V1111 13:22:09.330000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_69
V1111 13:22:09.330000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to argsort_4
V1111 13:22:09.330000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_70
V1111 13:22:09.330000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_59
V1111 13:22:09.331000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to floordiv_8
V1111 13:22:09.331000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to reshape_12
V1111 13:22:09.331000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to expand_10
V1111 13:22:09.331000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to gather_9
V1111 13:22:09.331000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_5_moe_experts_w1
V1111 13:22:09.331000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_5_moe_experts_w2
V1111 13:22:09.331000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_5_moe_experts_w3
V1111 13:22:09.331000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _set_grad_enabled_18
V1111 13:22:09.332000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cumsum_12
V1111 13:22:09.332000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to sub_12
V1111 13:22:09.332000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to view_71
V1111 13:22:09.332000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to sum_5
V1111 13:22:09.332000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to clamp_min_4
V1111 13:22:09.332000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add_20
V1111 13:22:09.332000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to sub_13
V1111 13:22:09.333000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to floordiv_9
V1111 13:22:09.333000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_34
V1111 13:22:09.333000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_33
V1111 13:22:09.333000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cumsum_13
V1111 13:22:09.333000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to sub_14
V1111 13:22:09.333000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to full_4
V1111 13:22:09.333000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to triton_kernel_wrapper_mutation_4
V1111 13:22:09.334000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_34
V1111 13:22:09.334000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _set_grad_enabled_19
V1111 13:22:09.334000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to new_zeros_4
V1111 13:22:09.334000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to vstack_4
V1111 13:22:09.334000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_60
V1111 13:22:09.334000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to cumsum_14
V1111 13:22:09.334000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to bfloat16_20
V1111 13:22:09.335000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to bfloat16_21
V1111 13:22:09.335000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_36
V1111 13:22:09.335000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _grouped_mm_12
V1111 13:22:09.335000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to silu_9
V1111 13:22:09.335000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to bfloat16_22
V1111 13:22:09.335000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to bfloat16_23
V1111 13:22:09.335000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_37
V1111 13:22:09.335000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _grouped_mm_13
V1111 13:22:09.336000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_35
V1111 13:22:09.336000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to bfloat16_24
V1111 13:22:09.336000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to transpose_38
V1111 13:22:09.336000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to _grouped_mm_14
V1111 13:22:09.336000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to type_as_4
V1111 13:22:09.336000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to new_empty_4
V1111 13:22:09.336000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to setitem_4
V1111 13:22:09.337000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to getitem_61
V1111 13:22:09.337000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_5_moe_shared_experts_w1_weight
V1111 13:22:09.337000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_44
V1111 13:22:09.337000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to silu_10
V1111 13:22:09.337000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_5_moe_shared_experts_w3_weight
V1111 13:22:09.337000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_45
V1111 13:22:09.337000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_36
V1111 13:22:09.337000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_layers_5_moe_shared_experts_w2_weight
V1111 13:22:09.338000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_46
V1111 13:22:09.338000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_35
V1111 13:22:09.338000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to reshape_13
V1111 13:22:09.338000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to mul_37
V1111 13:22:09.338000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to to_36
V1111 13:22:09.338000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to scatter_add_4
V1111 13:22:09.338000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to reshape_14
V1111 13:22:09.339000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to add_21
V1111 13:22:09.339000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_norm_weight
V1111 13:22:09.339000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to rms_norm_18
V1111 13:22:09.339000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to l__self____export_root_output_weight
V1111 13:22:09.339000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 512 to linear_47
V1111 13:22:09.454000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 715 to arg0_1
V1111 13:22:09.454000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 715 to arg1_1
V1111 13:22:09.454000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 715 to arg2_1
V1111 13:22:09.454000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 715 to arg3_1
V1111 13:22:09.454000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 715 to arg4_1
V1111 13:22:09.455000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 715 to arg5_1
V1111 13:22:09.456000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 715 to output
V1111 13:22:09.458000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 716 to arg0_1
V1111 13:22:09.458000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 716 to arg1_1
V1111 13:22:09.458000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 716 to arg2_1
V1111 13:22:09.459000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 716 to arg3_1
V1111 13:22:09.459000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 716 to arg4_1
V1111 13:22:09.460000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 716 to output
V1111 13:22:09.492000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 775 to arg0_1
V1111 13:22:09.492000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 775 to arg1_1
V1111 13:22:09.492000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 775 to arg2_1
V1111 13:22:09.492000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 775 to arg3_1
V1111 13:22:09.492000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 775 to arg4_1
V1111 13:22:09.492000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 775 to arg5_1
V1111 13:22:09.494000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 775 to output
V1111 13:22:09.496000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 776 to arg0_1
V1111 13:22:09.496000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 776 to arg1_1
V1111 13:22:09.496000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 776 to arg2_1
V1111 13:22:09.496000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 776 to arg3_1
V1111 13:22:09.496000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 776 to arg4_1
V1111 13:22:09.497000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 776 to output
V1111 13:22:09.582000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 862 to arg0_1
V1111 13:22:09.582000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 862 to arg1_1
V1111 13:22:09.582000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 862 to arg2_1
V1111 13:22:09.582000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 862 to arg3_1
V1111 13:22:09.582000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 862 to arg4_1
V1111 13:22:09.583000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 862 to arg5_1
V1111 13:22:09.584000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 862 to output
V1111 13:22:09.586000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 863 to arg0_1
V1111 13:22:09.586000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 863 to arg1_1
V1111 13:22:09.586000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 863 to arg2_1
V1111 13:22:09.587000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 863 to arg3_1
V1111 13:22:09.587000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 863 to arg4_1
V1111 13:22:09.588000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 863 to output
V1111 13:22:09.639000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 949 to arg0_1
V1111 13:22:09.640000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 949 to arg1_1
V1111 13:22:09.640000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 949 to arg2_1
V1111 13:22:09.640000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 949 to arg3_1
V1111 13:22:09.640000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 949 to arg4_1
V1111 13:22:09.640000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 949 to arg5_1
V1111 13:22:09.642000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 949 to output
V1111 13:22:09.644000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 950 to arg0_1
V1111 13:22:09.644000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 950 to arg1_1
V1111 13:22:09.644000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 950 to arg2_1
V1111 13:22:09.644000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 950 to arg3_1
V1111 13:22:09.644000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 950 to arg4_1
V1111 13:22:09.645000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 950 to output
V1111 13:22:09.698000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1036 to arg0_1
V1111 13:22:09.698000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1036 to arg1_1
V1111 13:22:09.698000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1036 to arg2_1
V1111 13:22:09.699000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1036 to arg3_1
V1111 13:22:09.699000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1036 to arg4_1
V1111 13:22:09.699000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1036 to arg5_1
V1111 13:22:09.700000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1036 to output
V1111 13:22:09.702000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1037 to arg0_1
V1111 13:22:09.702000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1037 to arg1_1
V1111 13:22:09.702000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1037 to arg2_1
V1111 13:22:09.703000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1037 to arg3_1
V1111 13:22:09.703000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1037 to arg4_1
V1111 13:22:09.704000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1037 to output
V1111 13:22:09.755000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1123 to arg0_1
V1111 13:22:09.756000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1123 to arg1_1
V1111 13:22:09.756000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1123 to arg2_1
V1111 13:22:09.756000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1123 to arg3_1
V1111 13:22:09.756000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1123 to arg4_1
V1111 13:22:09.756000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1123 to arg5_1
V1111 13:22:09.758000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1123 to output
V1111 13:22:09.760000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1124 to arg0_1
V1111 13:22:09.760000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1124 to arg1_1
V1111 13:22:09.760000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1124 to arg2_1
V1111 13:22:09.760000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1124 to arg3_1
V1111 13:22:09.760000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1124 to arg4_1
V1111 13:22:09.761000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1124 to output
V1111 13:22:09.838000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1346 to embedding
V1111 13:22:09.839000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1347 to _fused_rms_norm
V1111 13:22:09.840000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1347 to getitem
V1111 13:22:09.840000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1347 to getitem_1
V1111 13:22:09.841000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1347 to detach
V1111 13:22:09.841000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1348 to t
V1111 13:22:09.842000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1349 to view
V1111 13:22:09.843000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1350 to mm
V1111 13:22:09.843000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1351 to _unsafe_view
V1111 13:22:09.844000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1352 to view_1
V1111 13:22:09.845000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1353 to split_with_sizes
V1111 13:22:09.845000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1353 to getitem_2
V1111 13:22:09.846000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1353 to getitem_3
V1111 13:22:09.846000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1354 to view_2
V1111 13:22:09.847000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1355 to view_as_complex
V1111 13:22:09.848000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1355 to view_3
V1111 13:22:09.849000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1356 to mul
V1111 13:22:09.849000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1357 to view_as_real
V1111 13:22:09.850000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1358 to view_4
V1111 13:22:09.851000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1359 to cat
V1111 13:22:09.852000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1360 to t_1
V1111 13:22:09.852000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1361 to view_5
V1111 13:22:09.853000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1362 to mm_1
V1111 13:22:09.854000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1363 to _unsafe_view_1
V1111 13:22:09.854000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1364 to split_with_sizes_1
V1111 13:22:09.855000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1364 to getitem_4
V1111 13:22:09.855000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1364 to getitem_5
V1111 13:22:09.856000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1365 to unsqueeze
V1111 13:22:09.857000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1366 to view_6
V1111 13:22:09.857000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1367 to view_as_complex_1
V1111 13:22:09.858000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1367 to view_7
V1111 13:22:09.859000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1368 to mul_1
V1111 13:22:09.859000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1369 to view_as_real_1
V1111 13:22:09.860000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1370 to view_8
V1111 13:22:09.861000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1371 to _fused_rms_norm_1
V1111 13:22:09.861000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1371 to getitem_6
V1111 13:22:09.862000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1371 to getitem_7
V1111 13:22:09.862000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1371 to detach_1
V1111 13:22:09.863000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1372 to t_2
V1111 13:22:09.864000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1373 to view_9
V1111 13:22:09.864000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1374 to mm_2
V1111 13:22:09.865000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1375 to _unsafe_view_2
V1111 13:22:09.866000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1376 to view_10
V1111 13:22:09.866000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1377 to split_with_sizes_2
V1111 13:22:09.867000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1377 to getitem_8
V1111 13:22:09.867000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1377 to getitem_9
V1111 13:22:09.868000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1378 to expand
V1111 13:22:09.869000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1379 to cat_1
V1111 13:22:09.869000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1380 to transpose
V1111 13:22:09.870000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1381 to transpose_1
V1111 13:22:09.871000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1382 to transpose_2
V1111 13:22:09.872000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1382 to new_zeros
V1111 13:22:09.873000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1382 to new_zeros_1
V1111 13:22:09.874000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1382 to new_zeros_2
V1111 13:22:09.874000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1382 to new_zeros_3
V1111 13:22:09.875000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1382 to new_zeros_4
V1111 13:22:09.876000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1382 to arg0_1
V1111 13:22:09.877000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1382 to arg1_1
V1111 13:22:09.877000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1382 to arg2_1
V1111 13:22:09.877000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1382 to arg3_1
V1111 13:22:09.878000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1382 to arg4_1
V1111 13:22:09.878000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1382 to arg5_1
V1111 13:22:09.880000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1382 to output
V1111 13:22:09.881000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to new_zeros_5
V1111 13:22:09.881000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to new_zeros_6
V1111 13:22:09.882000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to new_zeros_7
V1111 13:22:09.883000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to new_zeros_8
V1111 13:22:09.883000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to new_zeros_9
V1111 13:22:09.884000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg0_1
V1111 13:22:09.885000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg1_1
V1111 13:22:09.885000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg2_1
V1111 13:22:09.885000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg3_1
V1111 13:22:09.885000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg4_1
V1111 13:22:09.886000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to output
V1111 13:22:09.889000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg0_1
V1111 13:22:09.890000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg1_1
V1111 13:22:09.890000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg2_1
V1111 13:22:09.890000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg3_1
V1111 13:22:09.890000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg4_1
V1111 13:22:09.892000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to output
V1111 13:22:09.893000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg0_1
V1111 13:22:09.893000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg1_1
V1111 13:22:09.894000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg2_1
V1111 13:22:09.894000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg3_1
V1111 13:22:09.894000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg4_1
V1111 13:22:09.896000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to new_ones
V1111 13:22:09.896000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to ge
V1111 13:22:09.897000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to bitwise_and
V1111 13:22:09.897000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1384 to index
V1111 13:22:09.898000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1385 to index_1
V1111 13:22:09.899000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1385 to eq
V1111 13:22:09.900000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1385 to bitwise_and_1
V1111 13:22:09.900000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1385 to output
V1111 13:22:09.902000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1385 to sdpa_score0
V1111 13:22:09.902000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1385 to sdpa_mask0
V1111 13:22:09.903000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1385 to _tensor_constant0
V1111 13:22:09.903000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1385 to flex_attention
V1111 13:22:09.903000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1385 to getitem_10
V1111 13:22:09.904000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1385 to getitem_11
V1111 13:22:09.904000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1385 to getitem_12
V1111 13:22:09.905000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1385 to detach_2
V1111 13:22:09.906000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1385 to detach_3
V1111 13:22:09.906000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1386 to transpose_3
V1111 13:22:09.907000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1387 to view_11
V1111 13:22:09.908000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1388 to t_3
V1111 13:22:09.908000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1389 to view_12
V1111 13:22:09.909000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1390 to mm_3
V1111 13:22:09.910000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1391 to _unsafe_view_3
V1111 13:22:09.911000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1392 to add
V1111 13:22:09.911000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1393 to _fused_rms_norm_2
V1111 13:22:09.912000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1393 to getitem_13
V1111 13:22:09.912000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1393 to getitem_14
V1111 13:22:09.913000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1393 to detach_4
V1111 13:22:09.913000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1394 to t_4
V1111 13:22:09.914000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1395 to view_13
V1111 13:22:09.914000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1396 to mm_4
V1111 13:22:09.915000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1397 to _unsafe_view_4
V1111 13:22:09.916000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1398 to silu
V1111 13:22:09.917000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1399 to t_5
V1111 13:22:09.917000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1400 to view_14
V1111 13:22:09.918000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1401 to mm_5
V1111 13:22:09.919000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1402 to _unsafe_view_5
V1111 13:22:09.919000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1403 to mul_2
V1111 13:22:09.920000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1404 to t_6
V1111 13:22:09.921000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1405 to view_15
V1111 13:22:09.921000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1406 to mm_6
V1111 13:22:09.922000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1407 to _unsafe_view_6
V1111 13:22:09.923000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1408 to add_1
V1111 13:22:09.924000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1409 to _fused_rms_norm_3
V1111 13:22:09.924000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1409 to getitem_15
V1111 13:22:09.924000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1409 to getitem_16
V1111 13:22:09.925000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1409 to detach_5
V1111 13:22:09.926000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1410 to t_7
V1111 13:22:09.926000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1411 to view_16
V1111 13:22:09.927000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1412 to mm_7
V1111 13:22:09.927000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1413 to _unsafe_view_7
V1111 13:22:09.928000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1414 to view_17
V1111 13:22:09.929000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1415 to split_with_sizes_3
V1111 13:22:09.930000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1415 to getitem_17
V1111 13:22:09.930000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1415 to getitem_18
V1111 13:22:09.931000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1416 to view_18
V1111 13:22:09.931000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1417 to view_as_complex_2
V1111 13:22:09.932000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1417 to view_19
V1111 13:22:09.933000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1418 to mul_3
V1111 13:22:09.933000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1419 to view_as_real_2
V1111 13:22:09.934000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1420 to view_20
V1111 13:22:09.935000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1421 to cat_2
V1111 13:22:09.936000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1422 to t_8
V1111 13:22:09.936000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1423 to view_21
V1111 13:22:09.937000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1424 to mm_8
V1111 13:22:09.938000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1425 to _unsafe_view_8
V1111 13:22:09.938000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1426 to split_with_sizes_4
V1111 13:22:09.939000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1426 to getitem_19
V1111 13:22:09.939000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1426 to getitem_20
V1111 13:22:09.940000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1427 to unsqueeze_1
V1111 13:22:09.941000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1428 to view_22
V1111 13:22:09.941000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1429 to view_as_complex_3
V1111 13:22:09.942000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1429 to view_23
V1111 13:22:09.943000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1430 to mul_4
V1111 13:22:09.943000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1431 to view_as_real_3
V1111 13:22:09.944000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1432 to view_24
V1111 13:22:09.945000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1433 to _fused_rms_norm_4
V1111 13:22:09.945000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1433 to getitem_21
V1111 13:22:09.946000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1433 to getitem_22
V1111 13:22:09.946000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1433 to detach_6
V1111 13:22:09.947000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1434 to t_9
V1111 13:22:09.947000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1435 to view_25
V1111 13:22:09.948000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1436 to mm_9
V1111 13:22:09.949000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1437 to _unsafe_view_9
V1111 13:22:09.949000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1438 to view_26
V1111 13:22:09.950000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1439 to split_with_sizes_5
V1111 13:22:09.951000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1439 to getitem_23
V1111 13:22:09.951000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1439 to getitem_24
V1111 13:22:09.952000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1440 to expand_1
V1111 13:22:09.952000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1441 to cat_3
V1111 13:22:09.953000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1442 to transpose_4
V1111 13:22:09.954000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1443 to transpose_5
V1111 13:22:09.955000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1444 to transpose_6
V1111 13:22:09.956000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1444 to new_zeros_10
V1111 13:22:09.956000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1444 to new_zeros_11
V1111 13:22:09.957000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1444 to new_zeros_12
V1111 13:22:09.957000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1444 to new_zeros_13
V1111 13:22:09.958000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1444 to new_zeros_14
V1111 13:22:09.959000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1444 to arg0_1
V1111 13:22:09.960000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1444 to arg1_1
V1111 13:22:09.960000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1444 to arg2_1
V1111 13:22:09.960000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1444 to arg3_1
V1111 13:22:09.961000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1444 to arg4_1
V1111 13:22:09.961000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1444 to arg5_1
V1111 13:22:09.963000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1444 to output
V1111 13:22:09.964000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to new_zeros_15
V1111 13:22:09.964000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to new_zeros_16
V1111 13:22:09.965000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to new_zeros_17
V1111 13:22:09.966000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to new_zeros_18
V1111 13:22:09.966000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to new_zeros_19
V1111 13:22:09.967000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg0_1
V1111 13:22:09.967000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg1_1
V1111 13:22:09.967000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg2_1
V1111 13:22:09.967000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg3_1
V1111 13:22:09.968000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg4_1
V1111 13:22:09.969000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to output
V1111 13:22:09.972000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg0_1
V1111 13:22:09.972000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg1_1
V1111 13:22:09.972000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg2_1
V1111 13:22:09.973000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg3_1
V1111 13:22:09.973000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg4_1
V1111 13:22:09.974000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to output
V1111 13:22:09.976000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg0_1
V1111 13:22:09.976000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg1_1
V1111 13:22:09.976000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg2_1
V1111 13:22:09.976000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg3_1
V1111 13:22:09.976000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg4_1
V1111 13:22:09.978000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to new_ones
V1111 13:22:09.979000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to ge
V1111 13:22:09.979000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to bitwise_and
V1111 13:22:09.980000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1446 to index
V1111 13:22:09.981000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1447 to index_1
V1111 13:22:09.982000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1447 to eq
V1111 13:22:09.982000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1447 to bitwise_and_1
V1111 13:22:09.983000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1447 to output
V1111 13:22:09.984000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1447 to sdpa_score1
V1111 13:22:09.985000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1447 to sdpa_mask1
V1111 13:22:09.985000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1447 to _tensor_constant0_1
V1111 13:22:09.985000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1447 to flex_attention_1
V1111 13:22:09.986000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1447 to getitem_25
V1111 13:22:09.986000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1447 to getitem_26
V1111 13:22:09.986000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1447 to getitem_27
V1111 13:22:09.987000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1447 to detach_7
V1111 13:22:09.988000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1447 to detach_8
V1111 13:22:09.988000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1448 to transpose_7
V1111 13:22:09.989000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1449 to view_27
V1111 13:22:09.990000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1450 to t_10
V1111 13:22:09.991000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1451 to view_28
V1111 13:22:09.991000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1452 to mm_10
V1111 13:22:09.992000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1453 to _unsafe_view_10
V1111 13:22:09.993000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1454 to add_2
V1111 13:22:09.994000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1455 to _fused_rms_norm_5
V1111 13:22:09.995000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1455 to getitem_28
V1111 13:22:09.995000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1455 to getitem_29
V1111 13:22:09.996000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1455 to detach_9
V1111 13:22:09.996000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1456 to view_29
V1111 13:22:09.997000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1457 to t_11
V1111 13:22:09.998000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1458 to mm_11
V1111 13:22:09.998000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1459 to _softmax
V1111 13:22:09.999000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1459 to detach_10
V1111 13:22:10.000000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1460 to add_3
V1111 13:22:10.000000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1461 to topk
V1111 13:22:10.001000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1461 to getitem_30
V1111 13:22:10.001000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1461 to getitem_31
V1111 13:22:10.002000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1462 to gather
V1111 13:22:10.002000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1463 to mul_5
V1111 13:22:10.003000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1463 to view_30
V1111 13:22:10.004000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1463 to histc
V1111 13:22:10.004000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1463 to add_4
V1111 13:22:10.005000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1463 to view_31
V1111 13:22:10.006000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1463 to histc_1
V1111 13:22:10.007000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1463 to view_32
V1111 13:22:10.007000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1463 to sort
V1111 13:22:10.008000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1463 to getitem_32
V1111 13:22:10.008000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1463 to getitem_33
V1111 13:22:10.009000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1464 to view_33
V1111 13:22:10.009000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1465 to index
V1111 13:22:10.010000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1465 to floor_divide
V1111 13:22:10.011000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1465 to view_34
V1111 13:22:10.012000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1465 to expand_2
V1111 13:22:10.012000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1466 to gather_1
V1111 13:22:10.013000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1466 to cumsum
V1111 13:22:10.014000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1466 to sub
V1111 13:22:10.015000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1466 to view_35
V1111 13:22:10.015000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1466 to sum_1
V1111 13:22:10.016000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1466 to clamp_min
V1111 13:22:10.017000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1466 to add_5
V1111 13:22:10.017000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1466 to sub_1
V1111 13:22:10.018000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1466 to floor_divide_1
V1111 13:22:10.019000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1466 to mul_6
V1111 13:22:10.019000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1466 to _to_copy
V1111 13:22:10.020000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1466 to cumsum_1
V1111 13:22:10.021000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1466 to sub_2
V1111 13:22:10.021000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1466 to full
V1111 13:22:10.035000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1466 to triton_kernel_wrapper_functional_proxy
V1111 13:22:10.035000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1466 to getitem_34
V1111 13:22:10.036000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1466 to _to_copy_1
V1111 13:22:10.036000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1466 to new_zeros_20
V1111 13:22:10.037000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1466 to unsqueeze_2
V1111 13:22:10.038000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1467 to cat_4
V1111 13:22:10.039000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1468 to index_1
V1111 13:22:10.039000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1468 to cumsum_2
V1111 13:22:10.040000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1469 to _to_copy_2
V1111 13:22:10.041000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1470 to _to_copy_3
V1111 13:22:10.041000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1471 to transpose_8
V1111 13:22:10.042000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1472 to _grouped_mm
V1111 13:22:10.043000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1473 to silu_1
V1111 13:22:10.044000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1474 to _to_copy_4
V1111 13:22:10.044000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1475 to _to_copy_5
V1111 13:22:10.045000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1476 to transpose_9
V1111 13:22:10.046000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1477 to _grouped_mm_1
V1111 13:22:10.047000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1478 to mul_7
V1111 13:22:10.048000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1479 to _to_copy_6
V1111 13:22:10.049000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1480 to transpose_10
V1111 13:22:10.049000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1481 to _grouped_mm_2
V1111 13:22:10.050000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1482 to _to_copy_7
V1111 13:22:10.051000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1482 to new_empty
V1111 13:22:10.052000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1483 to index_put
V1111 13:22:10.053000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1484 to slice_1
V1111 13:22:10.053000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1485 to t_12
V1111 13:22:10.054000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1486 to mm_12
V1111 13:22:10.055000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1487 to silu_2
V1111 13:22:10.055000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1488 to t_13
V1111 13:22:10.056000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1489 to mm_13
V1111 13:22:10.057000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1490 to mul_8
V1111 13:22:10.058000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1491 to t_14
V1111 13:22:10.058000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1492 to mm_14
V1111 13:22:10.059000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1493 to view_36
V1111 13:22:10.060000 86039 torch/fx/proxy.py:221] [__annotation] seq_nr from replay_node
V1111 13:22:10.060000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1484 to slice_2
V1111 13:22:10.060000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1494 to mul_9
V1111 13:22:10.061000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1495 to scatter_add
V1111 13:22:10.062000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1496 to view_37
V1111 13:22:10.062000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1497 to add_6
V1111 13:22:10.063000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1498 to _fused_rms_norm_6
V1111 13:22:10.064000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1498 to getitem_35
V1111 13:22:10.064000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1498 to getitem_36
V1111 13:22:10.065000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1498 to detach_11
V1111 13:22:10.065000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1499 to t_15
V1111 13:22:10.066000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1500 to view_38
V1111 13:22:10.067000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1501 to mm_15
V1111 13:22:10.067000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1502 to _unsafe_view_11
V1111 13:22:10.068000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1503 to view_39
V1111 13:22:10.069000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1504 to split_with_sizes_6
V1111 13:22:10.070000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1504 to getitem_37
V1111 13:22:10.070000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1504 to getitem_38
V1111 13:22:10.070000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1505 to view_40
V1111 13:22:10.071000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1506 to view_as_complex_4
V1111 13:22:10.072000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1506 to view_41
V1111 13:22:10.073000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1507 to mul_10
V1111 13:22:10.073000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1508 to view_as_real_4
V1111 13:22:10.074000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1509 to view_42
V1111 13:22:10.075000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1510 to cat_5
V1111 13:22:10.076000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1511 to t_16
V1111 13:22:10.076000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1512 to view_43
V1111 13:22:10.077000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1513 to mm_16
V1111 13:22:10.078000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1514 to _unsafe_view_12
V1111 13:22:10.079000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1515 to split_with_sizes_7
V1111 13:22:10.079000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1515 to getitem_39
V1111 13:22:10.079000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1515 to getitem_40
V1111 13:22:10.080000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1516 to unsqueeze_3
V1111 13:22:10.081000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1517 to view_44
V1111 13:22:10.081000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1518 to view_as_complex_5
V1111 13:22:10.082000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1518 to view_45
V1111 13:22:10.083000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1519 to mul_11
V1111 13:22:10.084000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1520 to view_as_real_5
V1111 13:22:10.084000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1521 to view_46
V1111 13:22:10.085000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1522 to _fused_rms_norm_7
V1111 13:22:10.086000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1522 to getitem_41
V1111 13:22:10.086000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1522 to getitem_42
V1111 13:22:10.086000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1522 to detach_12
V1111 13:22:10.087000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1523 to t_17
V1111 13:22:10.088000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1524 to view_47
V1111 13:22:10.088000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1525 to mm_17
V1111 13:22:10.089000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1526 to _unsafe_view_13
V1111 13:22:10.090000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1527 to view_48
V1111 13:22:10.091000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1528 to split_with_sizes_8
V1111 13:22:10.091000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1528 to getitem_43
V1111 13:22:10.092000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1528 to getitem_44
V1111 13:22:10.092000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1529 to expand_3
V1111 13:22:10.093000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1530 to cat_6
V1111 13:22:10.094000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1531 to transpose_11
V1111 13:22:10.095000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1532 to transpose_12
V1111 13:22:10.095000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1533 to transpose_13
V1111 13:22:10.096000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1533 to new_zeros_21
V1111 13:22:10.097000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1533 to new_zeros_22
V1111 13:22:10.098000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1533 to new_zeros_23
V1111 13:22:10.098000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1533 to new_zeros_24
V1111 13:22:10.099000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1533 to new_zeros_25
V1111 13:22:10.101000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1533 to arg0_1
V1111 13:22:10.102000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1533 to arg1_1
V1111 13:22:10.102000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1533 to arg2_1
V1111 13:22:10.102000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1533 to arg3_1
V1111 13:22:10.103000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1533 to arg4_1
V1111 13:22:10.103000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1533 to arg5_1
V1111 13:22:10.105000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1533 to output
V1111 13:22:10.106000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to new_zeros_26
V1111 13:22:10.107000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to new_zeros_27
V1111 13:22:10.107000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to new_zeros_28
V1111 13:22:10.108000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to new_zeros_29
V1111 13:22:10.108000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to new_zeros_30
V1111 13:22:10.109000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg0_1
V1111 13:22:10.109000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg1_1
V1111 13:22:10.110000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg2_1
V1111 13:22:10.110000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg3_1
V1111 13:22:10.110000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg4_1
V1111 13:22:10.111000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to output
V1111 13:22:10.114000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg0_1
V1111 13:22:10.115000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg1_1
V1111 13:22:10.115000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg2_1
V1111 13:22:10.115000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg3_1
V1111 13:22:10.115000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg4_1
V1111 13:22:10.117000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to output
V1111 13:22:10.118000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg0_1
V1111 13:22:10.119000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg1_1
V1111 13:22:10.119000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg2_1
V1111 13:22:10.119000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg3_1
V1111 13:22:10.119000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg4_1
V1111 13:22:10.121000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to new_ones
V1111 13:22:10.121000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to ge
V1111 13:22:10.122000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to bitwise_and
V1111 13:22:10.122000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1535 to index
V1111 13:22:10.123000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1536 to index_1
V1111 13:22:10.124000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1536 to eq
V1111 13:22:10.125000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1536 to bitwise_and_1
V1111 13:22:10.125000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1536 to output
V1111 13:22:10.127000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1536 to sdpa_score2
V1111 13:22:10.127000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1536 to sdpa_mask2
V1111 13:22:10.128000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1536 to _tensor_constant0_2
V1111 13:22:10.128000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1536 to flex_attention_2
V1111 13:22:10.128000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1536 to getitem_45
V1111 13:22:10.129000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1536 to getitem_46
V1111 13:22:10.129000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1536 to getitem_47
V1111 13:22:10.130000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1536 to detach_13
V1111 13:22:10.130000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1536 to detach_14
V1111 13:22:10.131000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1537 to transpose_14
V1111 13:22:10.132000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1538 to view_49
V1111 13:22:10.133000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1539 to t_18
V1111 13:22:10.133000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1540 to view_50
V1111 13:22:10.134000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1541 to mm_18
V1111 13:22:10.135000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1542 to _unsafe_view_14
V1111 13:22:10.136000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1543 to add_7
V1111 13:22:10.136000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1544 to _fused_rms_norm_8
V1111 13:22:10.137000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1544 to getitem_48
V1111 13:22:10.137000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1544 to getitem_49
V1111 13:22:10.138000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1544 to detach_15
V1111 13:22:10.138000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1545 to view_51
V1111 13:22:10.139000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1546 to t_19
V1111 13:22:10.140000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1547 to mm_19
V1111 13:22:10.140000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1548 to _softmax_1
V1111 13:22:10.141000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1548 to detach_16
V1111 13:22:10.142000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1549 to add_8
V1111 13:22:10.142000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1550 to topk_1
V1111 13:22:10.143000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1550 to getitem_50
V1111 13:22:10.143000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1550 to getitem_51
V1111 13:22:10.144000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1551 to gather_2
V1111 13:22:10.144000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1552 to mul_12
V1111 13:22:10.145000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1552 to view_52
V1111 13:22:10.146000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1552 to histc_2
V1111 13:22:10.147000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1552 to add_9
V1111 13:22:10.148000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1552 to view_53
V1111 13:22:10.149000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1552 to histc_3
V1111 13:22:10.149000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1552 to view_54
V1111 13:22:10.150000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1552 to sort_1
V1111 13:22:10.150000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1552 to getitem_52
V1111 13:22:10.151000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1552 to getitem_53
V1111 13:22:10.151000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1553 to view_55
V1111 13:22:10.152000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1554 to index_2
V1111 13:22:10.153000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1554 to floor_divide_2
V1111 13:22:10.153000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1554 to view_56
V1111 13:22:10.154000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1554 to expand_4
V1111 13:22:10.155000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1555 to gather_3
V1111 13:22:10.156000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1555 to cumsum_3
V1111 13:22:10.156000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1555 to sub_3
V1111 13:22:10.157000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1555 to view_57
V1111 13:22:10.158000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1555 to sum_2
V1111 13:22:10.158000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1555 to clamp_min_1
V1111 13:22:10.159000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1555 to add_10
V1111 13:22:10.160000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1555 to sub_4
V1111 13:22:10.160000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1555 to floor_divide_3
V1111 13:22:10.161000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1555 to mul_13
V1111 13:22:10.162000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1555 to _to_copy_8
V1111 13:22:10.162000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1555 to cumsum_4
V1111 13:22:10.163000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1555 to sub_5
V1111 13:22:10.164000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1555 to full_1
V1111 13:22:10.177000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1555 to triton_kernel_wrapper_functional_proxy_1
V1111 13:22:10.177000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1555 to getitem_54
V1111 13:22:10.178000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1555 to _to_copy_9
V1111 13:22:10.178000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1555 to new_zeros_31
V1111 13:22:10.179000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1555 to unsqueeze_4
V1111 13:22:10.180000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1556 to cat_7
V1111 13:22:10.180000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1557 to index_3
V1111 13:22:10.181000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1557 to cumsum_5
V1111 13:22:10.182000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1558 to _to_copy_10
V1111 13:22:10.183000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1559 to _to_copy_11
V1111 13:22:10.183000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1560 to transpose_15
V1111 13:22:10.184000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1561 to _grouped_mm_3
V1111 13:22:10.185000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1562 to silu_3
V1111 13:22:10.185000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1563 to _to_copy_12
V1111 13:22:10.186000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1564 to _to_copy_13
V1111 13:22:10.187000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1565 to transpose_16
V1111 13:22:10.188000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1566 to _grouped_mm_4
V1111 13:22:10.188000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1567 to mul_14
V1111 13:22:10.189000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1568 to _to_copy_14
V1111 13:22:10.190000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1569 to transpose_17
V1111 13:22:10.190000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1570 to _grouped_mm_5
V1111 13:22:10.191000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1571 to _to_copy_15
V1111 13:22:10.192000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1571 to new_empty_1
V1111 13:22:10.193000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1572 to index_put_1
V1111 13:22:10.193000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1573 to slice_3
V1111 13:22:10.194000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1574 to t_20
V1111 13:22:10.195000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1575 to mm_20
V1111 13:22:10.196000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1576 to silu_4
V1111 13:22:10.196000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1577 to t_21
V1111 13:22:10.197000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1578 to mm_21
V1111 13:22:10.198000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1579 to mul_15
V1111 13:22:10.199000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1580 to t_22
V1111 13:22:10.199000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1581 to mm_22
V1111 13:22:10.200000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1582 to view_58
V1111 13:22:10.201000 86039 torch/fx/proxy.py:221] [__annotation] seq_nr from replay_node
V1111 13:22:10.201000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1573 to slice_4
V1111 13:22:10.201000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1583 to mul_16
V1111 13:22:10.202000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1584 to scatter_add_1
V1111 13:22:10.203000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1585 to view_59
V1111 13:22:10.203000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1586 to add_11
V1111 13:22:10.204000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1587 to _fused_rms_norm_9
V1111 13:22:10.205000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1587 to getitem_55
V1111 13:22:10.205000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1587 to getitem_56
V1111 13:22:10.206000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1587 to detach_17
V1111 13:22:10.206000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1588 to t_23
V1111 13:22:10.207000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1589 to view_60
V1111 13:22:10.208000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1590 to mm_23
V1111 13:22:10.208000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1591 to _unsafe_view_15
V1111 13:22:10.209000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1592 to view_61
V1111 13:22:10.210000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1593 to split_with_sizes_9
V1111 13:22:10.210000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1593 to getitem_57
V1111 13:22:10.211000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1593 to getitem_58
V1111 13:22:10.211000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1594 to view_62
V1111 13:22:10.212000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1595 to view_as_complex_6
V1111 13:22:10.213000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1595 to view_63
V1111 13:22:10.215000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1596 to mul_17
V1111 13:22:10.215000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1597 to view_as_real_6
V1111 13:22:10.216000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1598 to view_64
V1111 13:22:10.217000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1599 to cat_8
V1111 13:22:10.218000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1600 to t_24
V1111 13:22:10.218000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1601 to view_65
V1111 13:22:10.219000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1602 to mm_24
V1111 13:22:10.220000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1603 to _unsafe_view_16
V1111 13:22:10.221000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1604 to split_with_sizes_10
V1111 13:22:10.221000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1604 to getitem_59
V1111 13:22:10.221000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1604 to getitem_60
V1111 13:22:10.222000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1605 to unsqueeze_5
V1111 13:22:10.223000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1606 to view_66
V1111 13:22:10.223000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1607 to view_as_complex_7
V1111 13:22:10.224000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1607 to view_67
V1111 13:22:10.225000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1608 to mul_18
V1111 13:22:10.434000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1609 to view_as_real_7
V1111 13:22:10.435000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1610 to view_68
V1111 13:22:10.436000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1611 to _fused_rms_norm_10
V1111 13:22:10.436000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1611 to getitem_61
V1111 13:22:10.436000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1611 to getitem_62
V1111 13:22:10.437000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1611 to detach_18
V1111 13:22:10.438000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1612 to t_25
V1111 13:22:10.438000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1613 to view_69
V1111 13:22:10.439000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1614 to mm_25
V1111 13:22:10.440000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1615 to _unsafe_view_17
V1111 13:22:10.441000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1616 to view_70
V1111 13:22:10.442000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1617 to split_with_sizes_11
V1111 13:22:10.442000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1617 to getitem_63
V1111 13:22:10.442000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1617 to getitem_64
V1111 13:22:10.443000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1618 to expand_5
V1111 13:22:10.444000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1619 to cat_9
V1111 13:22:10.445000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1620 to transpose_18
V1111 13:22:10.445000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1621 to transpose_19
V1111 13:22:10.446000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1622 to transpose_20
V1111 13:22:10.447000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1622 to new_zeros_32
V1111 13:22:10.448000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1622 to new_zeros_33
V1111 13:22:10.448000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1622 to new_zeros_34
V1111 13:22:10.449000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1622 to new_zeros_35
V1111 13:22:10.450000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1622 to new_zeros_36
V1111 13:22:10.451000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1622 to arg0_1
V1111 13:22:10.451000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1622 to arg1_1
V1111 13:22:10.452000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1622 to arg2_1
V1111 13:22:10.452000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1622 to arg3_1
V1111 13:22:10.452000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1622 to arg4_1
V1111 13:22:10.452000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1622 to arg5_1
V1111 13:22:10.454000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1622 to output
V1111 13:22:10.455000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to new_zeros_37
V1111 13:22:10.456000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to new_zeros_38
V1111 13:22:10.457000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to new_zeros_39
V1111 13:22:10.457000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to new_zeros_40
V1111 13:22:10.458000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to new_zeros_41
V1111 13:22:10.459000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg0_1
V1111 13:22:10.459000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg1_1
V1111 13:22:10.459000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg2_1
V1111 13:22:10.459000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg3_1
V1111 13:22:10.459000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg4_1
V1111 13:22:10.461000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to output
V1111 13:22:10.464000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg0_1
V1111 13:22:10.464000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg1_1
V1111 13:22:10.464000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg2_1
V1111 13:22:10.464000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg3_1
V1111 13:22:10.465000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg4_1
V1111 13:22:10.466000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to output
V1111 13:22:10.468000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg0_1
V1111 13:22:10.468000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg1_1
V1111 13:22:10.468000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg2_1
V1111 13:22:10.468000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg3_1
V1111 13:22:10.468000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg4_1
V1111 13:22:10.470000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to new_ones
V1111 13:22:10.471000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to ge
V1111 13:22:10.471000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to bitwise_and
V1111 13:22:10.472000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1624 to index
V1111 13:22:10.473000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1625 to index_1
V1111 13:22:10.474000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1625 to eq
V1111 13:22:10.474000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1625 to bitwise_and_1
V1111 13:22:10.475000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1625 to output
V1111 13:22:10.477000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1625 to sdpa_score3
V1111 13:22:10.477000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1625 to sdpa_mask3
V1111 13:22:10.477000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1625 to _tensor_constant0_3
V1111 13:22:10.477000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1625 to flex_attention_3
V1111 13:22:10.478000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1625 to getitem_65
V1111 13:22:10.478000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1625 to getitem_66
V1111 13:22:10.478000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1625 to getitem_67
V1111 13:22:10.479000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1625 to detach_19
V1111 13:22:10.480000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1625 to detach_20
V1111 13:22:10.481000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1626 to transpose_21
V1111 13:22:10.481000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1627 to view_71
V1111 13:22:10.482000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1628 to t_26
V1111 13:22:10.483000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1629 to view_72
V1111 13:22:10.484000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1630 to mm_26
V1111 13:22:10.484000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1631 to _unsafe_view_18
V1111 13:22:10.485000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1632 to add_12
V1111 13:22:10.486000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1633 to _fused_rms_norm_11
V1111 13:22:10.486000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1633 to getitem_68
V1111 13:22:10.487000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1633 to getitem_69
V1111 13:22:10.487000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1633 to detach_21
V1111 13:22:10.488000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1634 to view_73
V1111 13:22:10.489000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1635 to t_27
V1111 13:22:10.489000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1636 to mm_27
V1111 13:22:10.490000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1637 to _softmax_2
V1111 13:22:10.491000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1637 to detach_22
V1111 13:22:10.491000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1638 to add_13
V1111 13:22:10.492000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1639 to topk_2
V1111 13:22:10.492000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1639 to getitem_70
V1111 13:22:10.493000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1639 to getitem_71
V1111 13:22:10.493000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1640 to gather_4
V1111 13:22:10.494000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1641 to mul_19
V1111 13:22:10.495000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1641 to view_74
V1111 13:22:10.495000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1641 to histc_4
V1111 13:22:10.496000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1641 to add_14
V1111 13:22:10.497000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1641 to view_75
V1111 13:22:10.498000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1641 to histc_5
V1111 13:22:10.499000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1641 to view_76
V1111 13:22:10.500000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1641 to sort_2
V1111 13:22:10.500000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1641 to getitem_72
V1111 13:22:10.501000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1641 to getitem_73
V1111 13:22:10.501000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1642 to view_77
V1111 13:22:10.502000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1643 to index_4
V1111 13:22:10.503000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1643 to floor_divide_4
V1111 13:22:10.503000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1643 to view_78
V1111 13:22:10.504000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1643 to expand_6
V1111 13:22:10.505000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1644 to gather_5
V1111 13:22:10.506000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1644 to cumsum_6
V1111 13:22:10.506000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1644 to sub_6
V1111 13:22:10.507000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1644 to view_79
V1111 13:22:10.508000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1644 to sum_3
V1111 13:22:10.509000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1644 to clamp_min_2
V1111 13:22:10.509000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1644 to add_15
V1111 13:22:10.510000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1644 to sub_7
V1111 13:22:10.511000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1644 to floor_divide_5
V1111 13:22:10.511000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1644 to mul_20
V1111 13:22:10.512000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1644 to _to_copy_16
V1111 13:22:10.513000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1644 to cumsum_7
V1111 13:22:10.513000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1644 to sub_8
V1111 13:22:10.514000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1644 to full_2
V1111 13:22:10.528000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1644 to triton_kernel_wrapper_functional_proxy_2
V1111 13:22:10.528000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1644 to getitem_74
V1111 13:22:10.529000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1644 to _to_copy_17
V1111 13:22:10.529000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1644 to new_zeros_42
V1111 13:22:10.530000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1644 to unsqueeze_6
V1111 13:22:10.531000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1645 to cat_10
V1111 13:22:10.532000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1646 to index_5
V1111 13:22:10.532000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1646 to cumsum_8
V1111 13:22:10.533000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1647 to _to_copy_18
V1111 13:22:10.534000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1648 to _to_copy_19
V1111 13:22:10.534000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1649 to transpose_22
V1111 13:22:10.535000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1650 to _grouped_mm_6
V1111 13:22:10.536000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1651 to silu_5
V1111 13:22:10.537000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1652 to _to_copy_20
V1111 13:22:10.537000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1653 to _to_copy_21
V1111 13:22:10.538000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1654 to transpose_23
V1111 13:22:10.539000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1655 to _grouped_mm_7
V1111 13:22:10.540000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1656 to mul_21
V1111 13:22:10.540000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1657 to _to_copy_22
V1111 13:22:10.541000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1658 to transpose_24
V1111 13:22:10.542000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1659 to _grouped_mm_8
V1111 13:22:10.542000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1660 to _to_copy_23
V1111 13:22:10.543000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1660 to new_empty_2
V1111 13:22:10.544000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1661 to index_put_2
V1111 13:22:10.545000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1662 to slice_5
V1111 13:22:10.547000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1663 to t_28
V1111 13:22:10.548000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1664 to mm_28
V1111 13:22:10.548000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1665 to silu_6
V1111 13:22:10.549000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1666 to t_29
V1111 13:22:10.550000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1667 to mm_29
V1111 13:22:10.550000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1668 to mul_22
V1111 13:22:10.551000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1669 to t_30
V1111 13:22:10.552000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1670 to mm_30
V1111 13:22:10.553000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1671 to view_80
V1111 13:22:10.553000 86039 torch/fx/proxy.py:221] [__annotation] seq_nr from replay_node
V1111 13:22:10.554000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1662 to slice_6
V1111 13:22:10.554000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1672 to mul_23
V1111 13:22:10.555000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1673 to scatter_add_2
V1111 13:22:10.556000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1674 to view_81
V1111 13:22:10.556000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1675 to add_16
V1111 13:22:10.557000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1676 to _fused_rms_norm_12
V1111 13:22:10.558000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1676 to getitem_75
V1111 13:22:10.558000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1676 to getitem_76
V1111 13:22:10.558000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1676 to detach_23
V1111 13:22:10.559000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1677 to t_31
V1111 13:22:10.560000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1678 to view_82
V1111 13:22:10.560000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1679 to mm_31
V1111 13:22:10.561000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1680 to _unsafe_view_19
V1111 13:22:10.562000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1681 to view_83
V1111 13:22:10.563000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1682 to split_with_sizes_12
V1111 13:22:10.563000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1682 to getitem_77
V1111 13:22:10.564000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1682 to getitem_78
V1111 13:22:10.564000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1683 to view_84
V1111 13:22:10.565000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1684 to view_as_complex_8
V1111 13:22:10.566000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1684 to view_85
V1111 13:22:10.567000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1685 to mul_24
V1111 13:22:10.567000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1686 to view_as_real_8
V1111 13:22:10.568000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1687 to view_86
V1111 13:22:10.569000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1688 to cat_11
V1111 13:22:10.570000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1689 to t_32
V1111 13:22:10.570000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1690 to view_87
V1111 13:22:10.571000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1691 to mm_32
V1111 13:22:10.572000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1692 to _unsafe_view_20
V1111 13:22:10.573000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1693 to split_with_sizes_13
V1111 13:22:10.573000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1693 to getitem_79
V1111 13:22:10.573000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1693 to getitem_80
V1111 13:22:10.574000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1694 to unsqueeze_7
V1111 13:22:10.575000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1695 to view_88
V1111 13:22:10.575000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1696 to view_as_complex_9
V1111 13:22:10.576000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1696 to view_89
V1111 13:22:10.577000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1697 to mul_25
V1111 13:22:10.578000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1698 to view_as_real_9
V1111 13:22:10.578000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1699 to view_90
V1111 13:22:10.579000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1700 to _fused_rms_norm_13
V1111 13:22:10.580000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1700 to getitem_81
V1111 13:22:10.580000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1700 to getitem_82
V1111 13:22:10.580000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1700 to detach_24
V1111 13:22:10.581000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1701 to t_33
V1111 13:22:10.582000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1702 to view_91
V1111 13:22:10.582000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1703 to mm_33
V1111 13:22:10.583000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1704 to _unsafe_view_21
V1111 13:22:10.584000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1705 to view_92
V1111 13:22:10.585000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1706 to split_with_sizes_14
V1111 13:22:10.585000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1706 to getitem_83
V1111 13:22:10.585000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1706 to getitem_84
V1111 13:22:10.586000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1707 to expand_7
V1111 13:22:10.587000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1708 to cat_12
V1111 13:22:10.588000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1709 to transpose_25
V1111 13:22:10.588000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1710 to transpose_26
V1111 13:22:10.589000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1711 to transpose_27
V1111 13:22:10.590000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1711 to new_zeros_43
V1111 13:22:10.591000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1711 to new_zeros_44
V1111 13:22:10.591000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1711 to new_zeros_45
V1111 13:22:10.592000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1711 to new_zeros_46
V1111 13:22:10.593000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1711 to new_zeros_47
V1111 13:22:10.594000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1711 to arg0_1
V1111 13:22:10.594000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1711 to arg1_1
V1111 13:22:10.595000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1711 to arg2_1
V1111 13:22:10.595000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1711 to arg3_1
V1111 13:22:10.595000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1711 to arg4_1
V1111 13:22:10.596000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1711 to arg5_1
V1111 13:22:10.597000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1711 to output
V1111 13:22:10.599000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to new_zeros_48
V1111 13:22:10.599000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to new_zeros_49
V1111 13:22:10.600000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to new_zeros_50
V1111 13:22:10.600000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to new_zeros_51
V1111 13:22:10.601000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to new_zeros_52
V1111 13:22:10.602000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg0_1
V1111 13:22:10.602000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg1_1
V1111 13:22:10.602000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg2_1
V1111 13:22:10.602000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg3_1
V1111 13:22:10.603000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg4_1
V1111 13:22:10.604000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to output
V1111 13:22:10.607000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg0_1
V1111 13:22:10.607000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg1_1
V1111 13:22:10.608000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg2_1
V1111 13:22:10.608000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg3_1
V1111 13:22:10.608000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg4_1
V1111 13:22:10.610000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to output
V1111 13:22:10.611000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg0_1
V1111 13:22:10.611000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg1_1
V1111 13:22:10.612000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg2_1
V1111 13:22:10.612000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg3_1
V1111 13:22:10.612000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg4_1
V1111 13:22:10.614000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to new_ones
V1111 13:22:10.614000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to ge
V1111 13:22:10.615000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to bitwise_and
V1111 13:22:10.615000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1713 to index
V1111 13:22:10.616000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1714 to index_1
V1111 13:22:10.617000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1714 to eq
V1111 13:22:10.618000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1714 to bitwise_and_1
V1111 13:22:10.618000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1714 to output
V1111 13:22:10.620000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1714 to sdpa_score4
V1111 13:22:10.620000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1714 to sdpa_mask4
V1111 13:22:10.621000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1714 to _tensor_constant0_4
V1111 13:22:10.621000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1714 to flex_attention_4
V1111 13:22:10.621000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1714 to getitem_85
V1111 13:22:10.622000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1714 to getitem_86
V1111 13:22:10.622000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1714 to getitem_87
V1111 13:22:10.623000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1714 to detach_25
V1111 13:22:10.623000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1714 to detach_26
V1111 13:22:10.624000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1715 to transpose_28
V1111 13:22:10.625000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1716 to view_93
V1111 13:22:10.626000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1717 to t_34
V1111 13:22:10.626000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1718 to view_94
V1111 13:22:10.627000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1719 to mm_34
V1111 13:22:10.628000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1720 to _unsafe_view_22
V1111 13:22:10.629000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1721 to add_17
V1111 13:22:10.630000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1722 to _fused_rms_norm_14
V1111 13:22:10.630000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1722 to getitem_88
V1111 13:22:10.630000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1722 to getitem_89
V1111 13:22:10.631000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1722 to detach_27
V1111 13:22:10.631000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1723 to view_95
V1111 13:22:10.632000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1724 to t_35
V1111 13:22:10.633000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1725 to mm_35
V1111 13:22:10.634000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1726 to _softmax_3
V1111 13:22:10.634000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1726 to detach_28
V1111 13:22:10.635000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1727 to add_18
V1111 13:22:10.636000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1728 to topk_3
V1111 13:22:10.636000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1728 to getitem_90
V1111 13:22:10.636000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1728 to getitem_91
V1111 13:22:10.637000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1729 to gather_6
V1111 13:22:10.638000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1730 to mul_26
V1111 13:22:10.639000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1730 to view_96
V1111 13:22:10.639000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1730 to histc_6
V1111 13:22:10.640000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1730 to add_19
V1111 13:22:10.641000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1730 to view_97
V1111 13:22:10.641000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1730 to histc_7
V1111 13:22:10.642000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1730 to view_98
V1111 13:22:10.643000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1730 to sort_3
V1111 13:22:10.643000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1730 to getitem_92
V1111 13:22:10.643000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1730 to getitem_93
V1111 13:22:10.644000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1731 to view_99
V1111 13:22:10.645000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1732 to index_6
V1111 13:22:10.646000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1732 to floor_divide_6
V1111 13:22:10.646000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1732 to view_100
V1111 13:22:10.647000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1732 to expand_8
V1111 13:22:10.648000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1733 to gather_7
V1111 13:22:10.649000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1733 to cumsum_9
V1111 13:22:10.649000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1733 to sub_9
V1111 13:22:10.650000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1733 to view_101
V1111 13:22:10.651000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1733 to sum_4
V1111 13:22:10.651000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1733 to clamp_min_3
V1111 13:22:10.652000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1733 to add_20
V1111 13:22:10.653000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1733 to sub_10
V1111 13:22:10.653000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1733 to floor_divide_7
V1111 13:22:10.654000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1733 to mul_27
V1111 13:22:10.655000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1733 to _to_copy_24
V1111 13:22:10.655000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1733 to cumsum_10
V1111 13:22:10.656000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1733 to sub_11
V1111 13:22:10.657000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1733 to full_3
V1111 13:22:10.670000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1733 to triton_kernel_wrapper_functional_proxy_3
V1111 13:22:10.671000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1733 to getitem_94
V1111 13:22:10.671000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1733 to _to_copy_25
V1111 13:22:10.672000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1733 to new_zeros_53
V1111 13:22:10.673000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1733 to unsqueeze_8
V1111 13:22:10.674000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1734 to cat_13
V1111 13:22:10.674000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1735 to index_7
V1111 13:22:10.675000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1735 to cumsum_11
V1111 13:22:10.676000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1736 to _to_copy_26
V1111 13:22:10.676000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1737 to _to_copy_27
V1111 13:22:10.677000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1738 to transpose_29
V1111 13:22:10.678000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1739 to _grouped_mm_9
V1111 13:22:10.679000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1740 to silu_7
V1111 13:22:10.679000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1741 to _to_copy_28
V1111 13:22:10.680000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1742 to _to_copy_29
V1111 13:22:10.681000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1743 to transpose_30
V1111 13:22:10.681000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1744 to _grouped_mm_10
V1111 13:22:10.682000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1745 to mul_28
V1111 13:22:10.683000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1746 to _to_copy_30
V1111 13:22:10.684000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1747 to transpose_31
V1111 13:22:10.684000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1748 to _grouped_mm_11
V1111 13:22:10.685000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1749 to _to_copy_31
V1111 13:22:10.686000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1749 to new_empty_3
V1111 13:22:10.686000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1750 to index_put_3
V1111 13:22:10.687000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1751 to slice_7
V1111 13:22:10.688000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1752 to t_36
V1111 13:22:10.689000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1753 to mm_36
V1111 13:22:10.689000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1754 to silu_8
V1111 13:22:10.690000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1755 to t_37
V1111 13:22:10.691000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1756 to mm_37
V1111 13:22:10.691000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1757 to mul_29
V1111 13:22:10.692000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1758 to t_38
V1111 13:22:10.693000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1759 to mm_38
V1111 13:22:10.693000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1760 to view_102
V1111 13:22:10.694000 86039 torch/fx/proxy.py:221] [__annotation] seq_nr from replay_node
V1111 13:22:10.694000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1751 to slice_8
V1111 13:22:10.695000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1761 to mul_30
V1111 13:22:10.695000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1762 to scatter_add_3
V1111 13:22:10.696000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1763 to view_103
V1111 13:22:10.697000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1764 to add_21
V1111 13:22:10.698000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1765 to _fused_rms_norm_15
V1111 13:22:10.698000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1765 to getitem_95
V1111 13:22:10.698000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1765 to getitem_96
V1111 13:22:10.699000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1765 to detach_29
V1111 13:22:10.700000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1766 to t_39
V1111 13:22:10.700000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1767 to view_104
V1111 13:22:10.701000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1768 to mm_39
V1111 13:22:10.702000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1769 to _unsafe_view_23
V1111 13:22:10.702000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1770 to view_105
V1111 13:22:10.703000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1771 to split_with_sizes_15
V1111 13:22:10.704000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1771 to getitem_97
V1111 13:22:10.704000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1771 to getitem_98
V1111 13:22:10.705000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1772 to view_106
V1111 13:22:10.705000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1773 to view_as_complex_10
V1111 13:22:10.706000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1773 to view_107
V1111 13:22:10.707000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1774 to mul_31
V1111 13:22:10.708000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1775 to view_as_real_10
V1111 13:22:10.708000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1776 to view_108
V1111 13:22:10.709000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1777 to cat_14
V1111 13:22:10.710000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1778 to t_40
V1111 13:22:10.710000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1779 to view_109
V1111 13:22:10.711000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1780 to mm_40
V1111 13:22:10.712000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1781 to _unsafe_view_24
V1111 13:22:10.713000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1782 to split_with_sizes_16
V1111 13:22:10.713000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1782 to getitem_99
V1111 13:22:10.713000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1782 to getitem_100
V1111 13:22:10.714000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1783 to unsqueeze_9
V1111 13:22:10.715000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1784 to view_110
V1111 13:22:10.715000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1785 to view_as_complex_11
V1111 13:22:10.716000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1785 to view_111
V1111 13:22:10.717000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1786 to mul_32
V1111 13:22:10.718000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1787 to view_as_real_11
V1111 13:22:10.718000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1788 to view_112
V1111 13:22:10.719000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1789 to _fused_rms_norm_16
V1111 13:22:10.720000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1789 to getitem_101
V1111 13:22:10.720000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1789 to getitem_102
V1111 13:22:10.720000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1789 to detach_30
V1111 13:22:10.721000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1790 to t_41
V1111 13:22:10.722000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1791 to view_113
V1111 13:22:10.722000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1792 to mm_41
V1111 13:22:10.723000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1793 to _unsafe_view_25
V1111 13:22:10.724000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1794 to view_114
V1111 13:22:10.725000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1795 to split_with_sizes_17
V1111 13:22:10.725000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1795 to getitem_103
V1111 13:22:10.725000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1795 to getitem_104
V1111 13:22:10.726000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1796 to expand_9
V1111 13:22:10.727000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1797 to cat_15
V1111 13:22:10.728000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1798 to transpose_32
V1111 13:22:10.728000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1799 to transpose_33
V1111 13:22:10.729000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1800 to transpose_34
V1111 13:22:10.730000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1800 to new_zeros_54
V1111 13:22:10.731000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1800 to new_zeros_55
V1111 13:22:10.731000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1800 to new_zeros_56
V1111 13:22:10.732000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1800 to new_zeros_57
V1111 13:22:10.732000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1800 to new_zeros_58
V1111 13:22:10.734000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1800 to arg0_1
V1111 13:22:10.734000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1800 to arg1_1
V1111 13:22:10.735000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1800 to arg2_1
V1111 13:22:10.735000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1800 to arg3_1
V1111 13:22:10.735000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1800 to arg4_1
V1111 13:22:10.735000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1800 to arg5_1
V1111 13:22:10.737000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1800 to output
V1111 13:22:10.738000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to new_zeros_59
V1111 13:22:10.739000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to new_zeros_60
V1111 13:22:10.740000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to new_zeros_61
V1111 13:22:10.740000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to new_zeros_62
V1111 13:22:10.741000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to new_zeros_63
V1111 13:22:10.741000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg0_1
V1111 13:22:10.742000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg1_1
V1111 13:22:10.742000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg2_1
V1111 13:22:10.742000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg3_1
V1111 13:22:10.742000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg4_1
V1111 13:22:10.743000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to output
V1111 13:22:10.747000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg0_1
V1111 13:22:10.747000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg1_1
V1111 13:22:10.747000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg2_1
V1111 13:22:10.747000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg3_1
V1111 13:22:10.747000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg4_1
V1111 13:22:10.749000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to output
V1111 13:22:10.750000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg0_1
V1111 13:22:10.751000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg1_1
V1111 13:22:10.751000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg2_1
V1111 13:22:10.751000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg3_1
V1111 13:22:10.751000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg4_1
V1111 13:22:10.753000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to new_ones
V1111 13:22:10.753000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to ge
V1111 13:22:10.754000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to bitwise_and
V1111 13:22:10.754000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1802 to index
V1111 13:22:10.755000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1803 to index_1
V1111 13:22:10.756000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1803 to eq
V1111 13:22:10.757000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1803 to bitwise_and_1
V1111 13:22:10.757000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1803 to output
V1111 13:22:10.759000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1803 to sdpa_score5
V1111 13:22:10.759000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1803 to sdpa_mask5
V1111 13:22:10.760000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1803 to _tensor_constant0_5
V1111 13:22:10.760000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1803 to flex_attention_5
V1111 13:22:10.760000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1803 to getitem_105
V1111 13:22:10.761000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1803 to getitem_106
V1111 13:22:10.761000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1803 to getitem_107
V1111 13:22:10.762000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1803 to detach_31
V1111 13:22:10.762000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1803 to detach_32
V1111 13:22:10.763000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1804 to transpose_35
V1111 13:22:10.764000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1805 to view_115
V1111 13:22:10.765000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1806 to t_42
V1111 13:22:10.766000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1807 to view_116
V1111 13:22:10.766000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1808 to mm_42
V1111 13:22:10.767000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1809 to _unsafe_view_26
V1111 13:22:10.768000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1810 to add_22
V1111 13:22:10.769000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1811 to _fused_rms_norm_17
V1111 13:22:10.769000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1811 to getitem_108
V1111 13:22:10.769000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1811 to getitem_109
V1111 13:22:10.770000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1811 to detach_33
V1111 13:22:10.770000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1812 to view_117
V1111 13:22:10.771000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1813 to t_43
V1111 13:22:10.772000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1814 to mm_43
V1111 13:22:10.773000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1815 to _softmax_4
V1111 13:22:10.773000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1815 to detach_34
V1111 13:22:10.774000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1816 to add_23
V1111 13:22:10.775000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1817 to topk_4
V1111 13:22:10.776000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1817 to getitem_110
V1111 13:22:10.776000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1817 to getitem_111
V1111 13:22:10.777000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1818 to gather_8
V1111 13:22:10.777000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1819 to mul_33
V1111 13:22:10.778000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1819 to view_118
V1111 13:22:10.779000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1819 to histc_8
V1111 13:22:10.779000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1819 to add_24
V1111 13:22:10.780000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1819 to view_119
V1111 13:22:10.781000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1819 to histc_9
V1111 13:22:10.782000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1819 to view_120
V1111 13:22:10.782000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1819 to sort_4
V1111 13:22:10.783000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1819 to getitem_112
V1111 13:22:10.783000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1819 to getitem_113
V1111 13:22:10.784000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1820 to view_121
V1111 13:22:10.784000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1821 to index_8
V1111 13:22:10.785000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1821 to floor_divide_8
V1111 13:22:10.786000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1821 to view_122
V1111 13:22:10.786000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1821 to expand_10
V1111 13:22:10.787000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1822 to gather_9
V1111 13:22:10.788000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1822 to cumsum_12
V1111 13:22:10.789000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1822 to sub_12
V1111 13:22:10.789000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1822 to view_123
V1111 13:22:10.790000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1822 to sum_5
V1111 13:22:10.791000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1822 to clamp_min_4
V1111 13:22:10.791000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1822 to add_25
V1111 13:22:10.792000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1822 to sub_13
V1111 13:22:10.792000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1822 to floor_divide_9
V1111 13:22:10.793000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1822 to mul_34
V1111 13:22:10.794000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1822 to _to_copy_32
V1111 13:22:10.795000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1822 to cumsum_13
V1111 13:22:10.795000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1822 to sub_14
V1111 13:22:10.796000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1822 to full_4
V1111 13:22:10.809000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1822 to triton_kernel_wrapper_functional_proxy_4
V1111 13:22:10.809000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1822 to getitem_114
V1111 13:22:10.810000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1822 to _to_copy_33
V1111 13:22:10.811000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1822 to new_zeros_64
V1111 13:22:10.811000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1822 to unsqueeze_10
V1111 13:22:10.812000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1823 to cat_16
V1111 13:22:10.813000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1824 to index_9
V1111 13:22:10.813000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1824 to cumsum_14
V1111 13:22:10.814000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1825 to _to_copy_34
V1111 13:22:10.815000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1826 to _to_copy_35
V1111 13:22:10.816000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1827 to transpose_36
V1111 13:22:10.816000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1828 to _grouped_mm_12
V1111 13:22:10.817000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1829 to silu_9
V1111 13:22:10.818000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1830 to _to_copy_36
V1111 13:22:10.818000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1831 to _to_copy_37
V1111 13:22:10.819000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1832 to transpose_37
V1111 13:22:10.820000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1833 to _grouped_mm_13
V1111 13:22:10.821000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1834 to mul_35
V1111 13:22:10.821000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1835 to _to_copy_38
V1111 13:22:10.822000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1836 to transpose_38
V1111 13:22:10.823000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1837 to _grouped_mm_14
V1111 13:22:10.824000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1838 to _to_copy_39
V1111 13:22:10.824000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1838 to new_empty_4
V1111 13:22:10.825000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1839 to index_put_4
V1111 13:22:10.826000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1840 to slice_9
V1111 13:22:10.826000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1841 to t_44
V1111 13:22:10.827000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1842 to mm_44
V1111 13:22:10.828000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1843 to silu_10
V1111 13:22:10.829000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1844 to t_45
V1111 13:22:10.829000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1845 to mm_45
V1111 13:22:10.830000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1846 to mul_36
V1111 13:22:10.831000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1847 to t_46
V1111 13:22:10.831000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1848 to mm_46
V1111 13:22:10.832000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1849 to view_124
V1111 13:22:10.833000 86039 torch/fx/proxy.py:221] [__annotation] seq_nr from replay_node
V1111 13:22:10.833000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1840 to slice_10
V1111 13:22:10.833000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1850 to mul_37
V1111 13:22:10.834000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1851 to scatter_add_4
V1111 13:22:10.835000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1852 to view_125
V1111 13:22:10.835000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1853 to add_26
V1111 13:22:10.836000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1854 to _fused_rms_norm_18
V1111 13:22:10.837000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1854 to getitem_115
V1111 13:22:10.837000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1854 to getitem_116
V1111 13:22:10.837000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1854 to detach_35
V1111 13:22:10.838000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1855 to t_47
V1111 13:22:10.839000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1856 to view_126
V1111 13:22:10.839000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1857 to mm_47
V1111 13:22:10.840000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1858 to _unsafe_view_27
V1111 13:22:10.846000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.846000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1858 to view_127
V1111 13:22:10.847000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.847000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1857 to t_48
V1111 13:22:10.848000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.848000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1857 to mm_48
V1111 13:22:10.849000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.849000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1857 to t_49
V1111 13:22:10.850000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.850000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1857 to t_50
V1111 13:22:10.851000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.851000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1857 to mm_49
V1111 13:22:10.852000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.852000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1856 to view_128
V1111 13:22:10.853000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.853000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1855 to t_51
V1111 13:22:10.854000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.854000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1854 to detach_36
V1111 13:22:10.855000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.855000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1854 to _fused_rms_norm_backward
V1111 13:22:10.859000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.859000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1854 to getitem_117
V1111 13:22:10.859000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.859000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1854 to getitem_118
V1111 13:22:10.860000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.860000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1852 to view_129
V1111 13:22:10.861000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.861000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1851 to gather_10
V1111 13:22:10.861000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.862000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1850 to mul_38
V1111 13:22:10.863000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.863000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1850 to mul_39
V1111 13:22:10.864000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.864000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1850 to sum_6
V1111 13:22:10.865000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.865000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1849 to view_130
V1111 13:22:10.866000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.866000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1848 to t_52
V1111 13:22:10.867000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.867000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1848 to mm_50
V1111 13:22:10.868000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.868000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1848 to t_53
V1111 13:22:10.869000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.869000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1848 to t_54
V1111 13:22:10.870000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.870000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1848 to mm_51
V1111 13:22:10.871000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.871000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1847 to t_55
V1111 13:22:10.872000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.872000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1846 to mul_40
V1111 13:22:10.872000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.872000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1846 to mul_41
V1111 13:22:10.873000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.873000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1845 to t_56
V1111 13:22:10.874000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.874000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1845 to mm_52
V1111 13:22:10.875000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.875000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1845 to t_57
V1111 13:22:10.876000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.876000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1845 to t_58
V1111 13:22:10.877000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.877000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1845 to mm_53
V1111 13:22:10.878000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.878000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1844 to t_59
V1111 13:22:10.879000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.879000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1843 to silu_backward
V1111 13:22:10.883000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.883000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1842 to t_60
V1111 13:22:10.884000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.884000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1842 to mm_54
V1111 13:22:10.884000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.885000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1842 to t_61
V1111 13:22:10.885000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.885000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1842 to t_62
V1111 13:22:10.886000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.886000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1842 to mm_55
V1111 13:22:10.887000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1858 to add_27
V1111 13:22:10.888000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.888000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1841 to t_63
V1111 13:22:10.889000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.889000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1840 to slice_backward
V1111 13:22:10.891000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.891000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1839 to index_10
V1111 13:22:10.891000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.892000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1838 to _to_copy_40
V1111 13:22:10.892000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.893000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1837 to transpose_39
V1111 13:22:10.893000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.894000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1837 to _grouped_mm_15
V1111 13:22:10.894000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.895000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1837 to transpose_40
V1111 13:22:10.895000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.895000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1837 to transpose_41
V1111 13:22:10.896000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.896000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1837 to _grouped_mm_16
V1111 13:22:10.897000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.897000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1836 to transpose_42
V1111 13:22:10.898000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.898000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1835 to _to_copy_41
V1111 13:22:10.900000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.900000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1834 to mul_42
V1111 13:22:10.900000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.901000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1834 to mul_43
V1111 13:22:10.901000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.901000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1833 to transpose_43
V1111 13:22:10.902000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.902000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1833 to _grouped_mm_17
V1111 13:22:10.903000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.903000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1833 to transpose_44
V1111 13:22:10.903000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.904000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1833 to transpose_45
V1111 13:22:10.904000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.904000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1833 to _grouped_mm_18
V1111 13:22:10.905000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.905000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1832 to transpose_46
V1111 13:22:10.906000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.906000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1831 to _to_copy_42
V1111 13:22:10.907000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.907000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1830 to _to_copy_43
V1111 13:22:10.907000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.908000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1829 to silu_backward_1
V1111 13:22:10.912000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.912000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1828 to transpose_47
V1111 13:22:10.913000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.913000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1828 to _grouped_mm_19
V1111 13:22:10.914000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.914000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1828 to transpose_48
V1111 13:22:10.914000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.914000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1828 to transpose_49
V1111 13:22:10.915000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.915000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1828 to _grouped_mm_20
V1111 13:22:10.916000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.916000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1827 to transpose_50
V1111 13:22:10.917000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.917000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1826 to _to_copy_44
V1111 13:22:10.917000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.918000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1825 to _to_copy_45
V1111 13:22:10.918000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1858 to add_28
V1111 13:22:10.919000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.919000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1824 to new_zeros_65
V1111 13:22:10.920000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.921000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1824 to index_put_5
V1111 13:22:10.922000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.922000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1823 to slice_11
V1111 13:22:10.923000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.923000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1823 to slice_12
V1111 13:22:10.924000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.924000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1822 to new_zeros_66
V1111 13:22:10.925000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.925000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1822 to scatter_add_5
V1111 13:22:10.926000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1858 to add_29
V1111 13:22:10.927000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.927000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1821 to new_zeros_67
V1111 13:22:10.928000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.928000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1821 to index_put_6
V1111 13:22:10.929000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.929000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1820 to view_131
V1111 13:22:10.930000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.931000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1819 to mul_44
V1111 13:22:10.931000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.931000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1818 to new_zeros_68
V1111 13:22:10.932000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.932000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1818 to scatter_add_6
V1111 13:22:10.933000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.934000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1815 to detach_37
V1111 13:22:10.934000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.934000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1815 to _softmax_backward_data
V1111 13:22:10.937000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.937000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1814 to t_64
V1111 13:22:10.938000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.938000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1814 to mm_56
V1111 13:22:10.939000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.939000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1814 to t_65
V1111 13:22:10.940000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.940000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1814 to t_66
V1111 13:22:10.941000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.941000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1814 to mm_57
V1111 13:22:10.942000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1858 to add_30
V1111 13:22:10.943000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.943000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1813 to t_67
V1111 13:22:10.943000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.944000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1812 to view_132
V1111 13:22:10.944000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.944000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1811 to detach_38
V1111 13:22:10.945000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.945000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1811 to _fused_rms_norm_backward_1
V1111 13:22:10.946000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.946000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1811 to getitem_119
V1111 13:22:10.946000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.946000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1811 to getitem_120
V1111 13:22:10.947000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1858 to add_31
V1111 13:22:10.947000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.947000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1809 to view_133
V1111 13:22:10.948000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.948000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1808 to t_68
V1111 13:22:10.949000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.949000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1808 to mm_58
V1111 13:22:10.950000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.950000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1808 to t_69
V1111 13:22:10.951000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.951000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1808 to t_70
V1111 13:22:10.952000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.952000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1808 to mm_59
V1111 13:22:10.953000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.953000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1807 to view_134
V1111 13:22:10.954000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.954000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1806 to t_71
V1111 13:22:10.954000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.955000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1805 to view_135
V1111 13:22:10.956000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.956000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1804 to transpose_51
V1111 13:22:10.957000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.957000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to zeros
V1111 13:22:10.958000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.958000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to zeros_1
V1111 13:22:10.959000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.959000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to detach_39
V1111 13:22:10.960000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.960000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to detach_40
V1111 13:22:10.966000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.967000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg0_1
V1111 13:22:10.967000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.967000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg1_1
V1111 13:22:10.967000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.967000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg2_1
V1111 13:22:10.967000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.967000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg3_1
V1111 13:22:10.968000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.968000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg4_1
V1111 13:22:10.970000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.970000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to output
V1111 13:22:10.972000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.972000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg0_1
V1111 13:22:10.972000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.972000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg1_1
V1111 13:22:10.973000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.973000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg2_1
V1111 13:22:10.973000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.973000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg3_1
V1111 13:22:10.973000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.973000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg4_1
V1111 13:22:10.973000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.974000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg5_1
V1111 13:22:10.976000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.976000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to output
V1111 13:22:10.977000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.978000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg0_1
V1111 13:22:10.978000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.978000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg1_1
V1111 13:22:10.978000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.978000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg2_1
V1111 13:22:10.978000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.978000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg3_1
V1111 13:22:10.979000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.979000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to arg4_1
V1111 13:22:10.980000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1858 to new_ones
V1111 13:22:10.981000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1858 to ge
V1111 13:22:10.982000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1858 to bitwise_and
V1111 13:22:10.982000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1859 to index
V1111 13:22:10.983000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1860 to index_1
V1111 13:22:10.984000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1860 to eq
V1111 13:22:10.985000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1860 to bitwise_and_1
V1111 13:22:10.985000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.986000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to output
V1111 13:22:10.987000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.988000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to fw_graph0
V1111 13:22:10.988000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.988000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to joint_graph0
V1111 13:22:10.988000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.989000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to mask_graph0
V1111 13:22:10.989000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.989000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to _tensor_constant0_6
V1111 13:22:10.989000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.990000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to flex_attention_backward
V1111 13:22:10.990000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.990000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to getitem_121
V1111 13:22:10.990000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.990000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to getitem_122
V1111 13:22:10.991000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.991000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to getitem_123
V1111 13:22:10.991000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.991000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1801 to getitem_124
V1111 13:22:10.992000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.992000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1800 to transpose_52
V1111 13:22:10.993000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.993000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1799 to transpose_53
V1111 13:22:10.994000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.994000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1798 to transpose_54
V1111 13:22:10.995000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.995000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1797 to slice_13
V1111 13:22:10.996000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.996000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1797 to slice_14
V1111 13:22:10.997000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.997000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1796 to sum_7
V1111 13:22:10.998000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.998000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1795 to cat_17
V1111 13:22:10.999000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:10.999000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1794 to view_136
V1111 13:22:11.001000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.001000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1793 to view_137
V1111 13:22:11.002000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.002000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1792 to t_72
V1111 13:22:11.003000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.004000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1792 to mm_60
V1111 13:22:11.004000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.005000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1792 to t_73
V1111 13:22:11.005000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.005000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1792 to t_74
V1111 13:22:11.006000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.006000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1792 to mm_61
V1111 13:22:11.007000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.007000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1791 to view_138
V1111 13:22:11.009000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.009000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1790 to t_75
V1111 13:22:11.009000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.010000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1789 to detach_41
V1111 13:22:11.010000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.010000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1789 to _fused_rms_norm_backward_2
V1111 13:22:11.015000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.015000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1789 to getitem_125
V1111 13:22:11.015000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.015000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1789 to getitem_126
V1111 13:22:11.016000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.016000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1788 to view_139
V1111 13:22:11.017000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.017000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1787 to view_as_complex_12
V1111 13:22:11.018000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.018000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1786 to _conj
V1111 13:22:11.019000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.020000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1786 to clone
V1111 13:22:11.021000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.021000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1786 to mul_45
V1111 13:22:11.022000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.022000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1785 to view_as_real_12
V1111 13:22:11.023000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.023000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1784 to view_140
V1111 13:22:11.024000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.024000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1783 to squeeze
V1111 13:22:11.025000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.025000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1782 to cat_18
V1111 13:22:11.026000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.026000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1781 to view_141
V1111 13:22:11.028000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.028000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1780 to t_76
V1111 13:22:11.029000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.029000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1780 to mm_62
V1111 13:22:11.030000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.030000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1780 to t_77
V1111 13:22:11.031000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.031000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1780 to t_78
V1111 13:22:11.032000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.032000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1780 to mm_63
V1111 13:22:11.033000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.033000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1779 to view_142
V1111 13:22:11.034000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.034000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1778 to t_79
V1111 13:22:11.035000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.035000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1777 to slice_15
V1111 13:22:11.035000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.035000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1777 to slice_16
V1111 13:22:11.036000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.036000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1776 to view_143
V1111 13:22:11.037000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.037000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1775 to clone_1
V1111 13:22:11.038000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.038000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1775 to view_as_complex_13
V1111 13:22:11.039000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.039000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1774 to _conj_1
V1111 13:22:11.040000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.040000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1774 to clone_2
V1111 13:22:11.041000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.041000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1774 to mul_46
V1111 13:22:11.042000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.042000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1773 to view_as_real_13
V1111 13:22:11.043000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.043000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1772 to view_144
V1111 13:22:11.044000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.044000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1771 to cat_19
V1111 13:22:11.045000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.045000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1770 to view_145
V1111 13:22:11.046000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.047000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1769 to view_146
V1111 13:22:11.048000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.048000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1768 to t_80
V1111 13:22:11.049000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.049000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1768 to mm_64
V1111 13:22:11.050000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.050000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1768 to t_81
V1111 13:22:11.051000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.051000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1768 to t_82
V1111 13:22:11.052000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.052000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1768 to mm_65
V1111 13:22:11.053000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.053000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1767 to view_147
V1111 13:22:11.054000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1860 to add_32
V1111 13:22:11.054000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.054000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1766 to t_83
V1111 13:22:11.055000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.055000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1765 to detach_42
V1111 13:22:11.056000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.056000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1765 to _fused_rms_norm_backward_3
V1111 13:22:11.057000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.057000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1765 to getitem_127
V1111 13:22:11.057000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.057000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1765 to getitem_128
V1111 13:22:11.058000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1860 to add_33
V1111 13:22:11.058000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.058000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1763 to view_148
V1111 13:22:11.059000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.059000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1762 to gather_11
V1111 13:22:11.060000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.060000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1761 to mul_47
V1111 13:22:11.061000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.061000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1761 to mul_48
V1111 13:22:11.061000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.062000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1761 to sum_8
V1111 13:22:11.062000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.062000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1760 to view_149
V1111 13:22:11.063000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.063000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1759 to t_84
V1111 13:22:11.064000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.064000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1759 to mm_66
V1111 13:22:11.064000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.065000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1759 to t_85
V1111 13:22:11.065000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.065000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1759 to t_86
V1111 13:22:11.066000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.066000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1759 to mm_67
V1111 13:22:11.067000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.067000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1758 to t_87
V1111 13:22:11.067000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.068000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1757 to mul_49
V1111 13:22:11.068000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.068000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1757 to mul_50
V1111 13:22:11.069000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.069000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1756 to t_88
V1111 13:22:11.070000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.070000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1756 to mm_68
V1111 13:22:11.070000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.071000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1756 to t_89
V1111 13:22:11.071000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.071000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1756 to t_90
V1111 13:22:11.072000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.072000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1756 to mm_69
V1111 13:22:11.073000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.073000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1755 to t_91
V1111 13:22:11.074000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.074000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1754 to silu_backward_2
V1111 13:22:11.074000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.074000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1753 to t_92
V1111 13:22:11.075000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.075000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1753 to mm_70
V1111 13:22:11.076000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.076000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1753 to t_93
V1111 13:22:11.076000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.077000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1753 to t_94
V1111 13:22:11.077000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.077000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1753 to mm_71
V1111 13:22:11.078000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1860 to add_34
V1111 13:22:11.079000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.079000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1752 to t_95
V1111 13:22:11.080000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.080000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1751 to slice_backward_1
V1111 13:22:11.080000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.081000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1750 to index_11
V1111 13:22:11.081000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.081000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1749 to _to_copy_46
V1111 13:22:11.082000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.082000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1748 to transpose_55
V1111 13:22:11.083000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.083000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1748 to _grouped_mm_21
V1111 13:22:11.084000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.084000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1748 to transpose_56
V1111 13:22:11.084000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.084000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1748 to transpose_57
V1111 13:22:11.085000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.085000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1748 to _grouped_mm_22
V1111 13:22:11.086000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.086000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1747 to transpose_58
V1111 13:22:11.087000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.087000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1746 to _to_copy_47
V1111 13:22:11.088000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.088000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1745 to mul_51
V1111 13:22:11.088000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.089000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1745 to mul_52
V1111 13:22:11.089000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.089000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1744 to transpose_59
V1111 13:22:11.090000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.090000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1744 to _grouped_mm_23
V1111 13:22:11.091000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.091000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1744 to transpose_60
V1111 13:22:11.091000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.092000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1744 to transpose_61
V1111 13:22:11.092000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.092000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1744 to _grouped_mm_24
V1111 13:22:11.093000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.093000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1743 to transpose_62
V1111 13:22:11.094000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.094000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1742 to _to_copy_48
V1111 13:22:11.095000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.095000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1741 to _to_copy_49
V1111 13:22:11.095000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.096000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1740 to silu_backward_3
V1111 13:22:11.096000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.096000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1739 to transpose_63
V1111 13:22:11.097000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.097000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1739 to _grouped_mm_25
V1111 13:22:11.098000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.098000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1739 to transpose_64
V1111 13:22:11.099000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.099000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1739 to transpose_65
V1111 13:22:11.099000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.099000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1739 to _grouped_mm_26
V1111 13:22:11.100000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.100000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1738 to transpose_66
V1111 13:22:11.101000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.101000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1737 to _to_copy_50
V1111 13:22:11.102000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.102000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1736 to _to_copy_51
V1111 13:22:11.103000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1860 to add_35
V1111 13:22:11.103000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.104000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1735 to new_zeros_69
V1111 13:22:11.104000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.104000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1735 to index_put_7
V1111 13:22:11.105000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.105000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1734 to slice_17
V1111 13:22:11.106000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.106000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1734 to slice_18
V1111 13:22:11.107000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.107000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1733 to new_zeros_70
V1111 13:22:11.107000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.108000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1733 to scatter_add_7
V1111 13:22:11.108000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1860 to add_36
V1111 13:22:11.109000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.109000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1732 to new_zeros_71
V1111 13:22:11.110000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.110000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1732 to index_put_8
V1111 13:22:11.111000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.111000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1731 to view_150
V1111 13:22:11.112000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.112000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1730 to mul_53
V1111 13:22:11.112000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.113000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1729 to new_zeros_72
V1111 13:22:11.113000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.113000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1729 to scatter_add_8
V1111 13:22:11.114000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.114000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1726 to detach_43
V1111 13:22:11.115000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.115000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1726 to _softmax_backward_data_1
V1111 13:22:11.116000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.116000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1725 to t_96
V1111 13:22:11.116000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.116000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1725 to mm_72
V1111 13:22:11.117000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.117000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1725 to t_97
V1111 13:22:11.118000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.118000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1725 to t_98
V1111 13:22:11.119000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.119000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1725 to mm_73
V1111 13:22:11.119000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1860 to add_37
V1111 13:22:11.120000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.120000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1724 to t_99
V1111 13:22:11.121000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.121000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1723 to view_151
V1111 13:22:11.122000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.122000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1722 to detach_44
V1111 13:22:11.122000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.122000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1722 to _fused_rms_norm_backward_4
V1111 13:22:11.123000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.123000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1722 to getitem_129
V1111 13:22:11.123000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.123000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1722 to getitem_130
V1111 13:22:11.124000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1860 to add_38
V1111 13:22:11.125000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.125000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1720 to view_152
V1111 13:22:11.125000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.126000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1719 to t_100
V1111 13:22:11.126000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.126000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1719 to mm_74
V1111 13:22:11.127000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.127000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1719 to t_101
V1111 13:22:11.128000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.128000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1719 to t_102
V1111 13:22:11.128000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.129000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1719 to mm_75
V1111 13:22:11.129000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.129000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1718 to view_153
V1111 13:22:11.130000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.130000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1717 to t_103
V1111 13:22:11.131000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.131000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1716 to view_154
V1111 13:22:11.132000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.132000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1715 to transpose_67
V1111 13:22:11.132000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.133000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to zeros_2
V1111 13:22:11.133000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.133000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to zeros_3
V1111 13:22:11.135000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.135000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to detach_45
V1111 13:22:11.135000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.136000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to detach_46
V1111 13:22:11.139000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.140000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg0_1
V1111 13:22:11.140000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.140000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg1_1
V1111 13:22:11.140000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.140000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg2_1
V1111 13:22:11.140000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.141000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg3_1
V1111 13:22:11.141000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.141000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg4_1
V1111 13:22:11.143000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.143000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to output
V1111 13:22:11.145000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.145000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg0_1
V1111 13:22:11.145000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.146000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg1_1
V1111 13:22:11.146000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.146000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg2_1
V1111 13:22:11.146000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.146000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg3_1
V1111 13:22:11.147000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.147000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg4_1
V1111 13:22:11.147000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.147000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg5_1
V1111 13:22:11.149000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.150000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to output
V1111 13:22:11.151000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.151000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg0_1
V1111 13:22:11.152000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.152000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg1_1
V1111 13:22:11.152000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.152000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg2_1
V1111 13:22:11.152000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.152000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg3_1
V1111 13:22:11.153000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.153000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to arg4_1
V1111 13:22:11.154000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1860 to new_ones
V1111 13:22:11.155000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1860 to ge
V1111 13:22:11.156000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1860 to bitwise_and
V1111 13:22:11.156000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1861 to index
V1111 13:22:11.157000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1862 to index_1
V1111 13:22:11.158000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1862 to eq
V1111 13:22:11.159000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1862 to bitwise_and_1
V1111 13:22:11.160000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.160000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to output
V1111 13:22:11.162000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.162000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to fw_graph1
V1111 13:22:11.162000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.162000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to joint_graph1
V1111 13:22:11.163000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.163000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to mask_graph1
V1111 13:22:11.163000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.163000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to _tensor_constant0_7
V1111 13:22:11.164000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.164000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to flex_attention_backward_1
V1111 13:22:11.164000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.164000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to getitem_131
V1111 13:22:11.165000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.165000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to getitem_132
V1111 13:22:11.165000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.165000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to getitem_133
V1111 13:22:11.165000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.165000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1712 to getitem_134
V1111 13:22:11.166000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.166000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1711 to transpose_68
V1111 13:22:11.167000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.167000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1710 to transpose_69
V1111 13:22:11.168000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.168000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1709 to transpose_70
V1111 13:22:11.169000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.169000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1708 to slice_19
V1111 13:22:11.169000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.170000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1708 to slice_20
V1111 13:22:11.170000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.170000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1707 to sum_9
V1111 13:22:11.171000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.171000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1706 to cat_20
V1111 13:22:11.172000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.172000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1705 to view_155
V1111 13:22:11.173000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.173000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1704 to view_156
V1111 13:22:11.173000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.174000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1703 to t_104
V1111 13:22:11.174000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.174000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1703 to mm_76
V1111 13:22:11.175000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.175000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1703 to t_105
V1111 13:22:11.176000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.176000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1703 to t_106
V1111 13:22:11.176000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.177000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1703 to mm_77
V1111 13:22:11.177000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.177000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1702 to view_157
V1111 13:22:11.178000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.178000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1701 to t_107
V1111 13:22:11.179000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.179000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1700 to detach_47
V1111 13:22:11.179000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.180000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1700 to _fused_rms_norm_backward_5
V1111 13:22:11.180000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.180000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1700 to getitem_135
V1111 13:22:11.181000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.181000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1700 to getitem_136
V1111 13:22:11.181000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.182000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1699 to view_158
V1111 13:22:11.182000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.182000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1698 to view_as_complex_14
V1111 13:22:11.183000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.183000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1697 to _conj_2
V1111 13:22:11.184000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.184000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1697 to clone_3
V1111 13:22:11.184000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.185000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1697 to mul_54
V1111 13:22:11.185000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.185000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1696 to view_as_real_14
V1111 13:22:11.186000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.186000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1695 to view_159
V1111 13:22:11.187000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.187000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1694 to squeeze_1
V1111 13:22:11.188000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.188000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1693 to cat_21
V1111 13:22:11.188000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.189000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1692 to view_160
V1111 13:22:11.189000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.189000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1691 to t_108
V1111 13:22:11.190000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.190000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1691 to mm_78
V1111 13:22:11.191000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.191000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1691 to t_109
V1111 13:22:11.191000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.192000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1691 to t_110
V1111 13:22:11.192000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.192000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1691 to mm_79
V1111 13:22:11.193000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.193000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1690 to view_161
V1111 13:22:11.194000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.194000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1689 to t_111
V1111 13:22:11.194000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.195000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1688 to slice_21
V1111 13:22:11.195000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.195000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1688 to slice_22
V1111 13:22:11.196000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.196000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1687 to view_162
V1111 13:22:11.197000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.197000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1686 to clone_4
V1111 13:22:11.198000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.198000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1686 to view_as_complex_15
V1111 13:22:11.198000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.199000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1685 to _conj_3
V1111 13:22:11.199000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.199000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1685 to clone_5
V1111 13:22:11.200000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.200000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1685 to mul_55
V1111 13:22:11.201000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.201000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1684 to view_as_real_15
V1111 13:22:11.201000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.202000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1683 to view_163
V1111 13:22:11.202000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.202000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1682 to cat_22
V1111 13:22:11.203000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.203000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1681 to view_164
V1111 13:22:11.204000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.204000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1680 to view_165
V1111 13:22:11.205000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.205000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1679 to t_112
V1111 13:22:11.205000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.205000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1679 to mm_80
V1111 13:22:11.206000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.206000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1679 to t_113
V1111 13:22:11.207000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.207000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1679 to t_114
V1111 13:22:11.207000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.208000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1679 to mm_81
V1111 13:22:11.208000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.208000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1678 to view_166
V1111 13:22:11.209000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1862 to add_39
V1111 13:22:11.210000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.210000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1677 to t_115
V1111 13:22:11.210000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.211000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1676 to detach_48
V1111 13:22:11.211000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.211000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1676 to _fused_rms_norm_backward_6
V1111 13:22:11.212000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.212000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1676 to getitem_137
V1111 13:22:11.212000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.212000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1676 to getitem_138
V1111 13:22:11.213000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1862 to add_40
V1111 13:22:11.214000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.214000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1674 to view_167
V1111 13:22:11.214000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.215000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1673 to gather_12
V1111 13:22:11.215000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.215000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1672 to mul_56
V1111 13:22:11.216000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.216000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1672 to mul_57
V1111 13:22:11.217000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.217000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1672 to sum_10
V1111 13:22:11.217000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.218000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1671 to view_168
V1111 13:22:11.218000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.218000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1670 to t_116
V1111 13:22:11.219000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.219000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1670 to mm_82
V1111 13:22:11.220000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.220000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1670 to t_117
V1111 13:22:11.220000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.221000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1670 to t_118
V1111 13:22:11.221000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.221000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1670 to mm_83
V1111 13:22:11.222000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.222000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1669 to t_119
V1111 13:22:11.223000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.223000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1668 to mul_58
V1111 13:22:11.223000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.224000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1668 to mul_59
V1111 13:22:11.224000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.224000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1667 to t_120
V1111 13:22:11.225000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.225000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1667 to mm_84
V1111 13:22:11.226000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.226000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1667 to t_121
V1111 13:22:11.226000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.227000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1667 to t_122
V1111 13:22:11.227000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.227000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1667 to mm_85
V1111 13:22:11.228000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.228000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1666 to t_123
V1111 13:22:11.229000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.229000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1665 to silu_backward_4
V1111 13:22:11.229000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.230000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1664 to t_124
V1111 13:22:11.230000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.230000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1664 to mm_86
V1111 13:22:11.231000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.231000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1664 to t_125
V1111 13:22:11.232000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.232000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1664 to t_126
V1111 13:22:11.232000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.232000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1664 to mm_87
V1111 13:22:11.233000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1862 to add_41
V1111 13:22:11.234000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.234000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1663 to t_127
V1111 13:22:11.234000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.235000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1662 to slice_backward_2
V1111 13:22:11.235000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.235000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1661 to index_12
V1111 13:22:11.236000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.236000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1660 to _to_copy_52
V1111 13:22:11.237000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.237000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1659 to transpose_71
V1111 13:22:11.238000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.238000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1659 to _grouped_mm_27
V1111 13:22:11.238000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.239000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1659 to transpose_72
V1111 13:22:11.239000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.239000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1659 to transpose_73
V1111 13:22:11.240000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.240000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1659 to _grouped_mm_28
V1111 13:22:11.241000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.241000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1658 to transpose_74
V1111 13:22:11.242000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.242000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1657 to _to_copy_53
V1111 13:22:11.243000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.243000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1656 to mul_60
V1111 13:22:11.243000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.244000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1656 to mul_61
V1111 13:22:11.244000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.244000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1655 to transpose_75
V1111 13:22:11.245000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.245000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1655 to _grouped_mm_29
V1111 13:22:11.246000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.246000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1655 to transpose_76
V1111 13:22:11.246000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.247000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1655 to transpose_77
V1111 13:22:11.247000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.247000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1655 to _grouped_mm_30
V1111 13:22:11.248000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.248000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1654 to transpose_78
V1111 13:22:11.249000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.249000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1653 to _to_copy_54
V1111 13:22:11.250000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.250000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1652 to _to_copy_55
V1111 13:22:11.250000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.251000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1651 to silu_backward_5
V1111 13:22:11.251000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.251000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1650 to transpose_79
V1111 13:22:11.252000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.252000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1650 to _grouped_mm_31
V1111 13:22:11.253000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.253000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1650 to transpose_80
V1111 13:22:11.253000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.254000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1650 to transpose_81
V1111 13:22:11.254000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.254000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1650 to _grouped_mm_32
V1111 13:22:11.255000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.255000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1649 to transpose_82
V1111 13:22:11.256000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.256000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1648 to _to_copy_56
V1111 13:22:11.257000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.257000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1647 to _to_copy_57
V1111 13:22:11.257000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1862 to add_42
V1111 13:22:11.258000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.259000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1646 to new_zeros_73
V1111 13:22:11.259000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.259000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1646 to index_put_9
V1111 13:22:11.260000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.260000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1645 to slice_23
V1111 13:22:11.261000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.261000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1645 to slice_24
V1111 13:22:11.262000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.262000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1644 to new_zeros_74
V1111 13:22:11.263000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.263000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1644 to scatter_add_9
V1111 13:22:11.263000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1862 to add_43
V1111 13:22:11.264000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.264000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1643 to new_zeros_75
V1111 13:22:11.265000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.265000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1643 to index_put_10
V1111 13:22:11.266000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.266000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1642 to view_169
V1111 13:22:11.267000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.267000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1641 to mul_62
V1111 13:22:11.267000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.268000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1640 to new_zeros_76
V1111 13:22:11.268000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.268000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1640 to scatter_add_10
V1111 13:22:11.269000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.269000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1637 to detach_49
V1111 13:22:11.270000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.270000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1637 to _softmax_backward_data_2
V1111 13:22:11.271000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.271000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1636 to t_128
V1111 13:22:11.271000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.272000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1636 to mm_88
V1111 13:22:11.272000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.272000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1636 to t_129
V1111 13:22:11.273000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.273000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1636 to t_130
V1111 13:22:11.274000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.274000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1636 to mm_89
V1111 13:22:11.275000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1862 to add_44
V1111 13:22:11.275000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.275000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1635 to t_131
V1111 13:22:11.276000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.276000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1634 to view_170
V1111 13:22:11.277000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.277000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1633 to detach_50
V1111 13:22:11.278000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.278000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1633 to _fused_rms_norm_backward_7
V1111 13:22:11.279000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.279000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1633 to getitem_139
V1111 13:22:11.279000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.279000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1633 to getitem_140
V1111 13:22:11.280000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1862 to add_45
V1111 13:22:11.280000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.280000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1631 to view_171
V1111 13:22:11.281000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.281000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1630 to t_132
V1111 13:22:11.282000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.282000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1630 to mm_90
V1111 13:22:11.283000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.283000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1630 to t_133
V1111 13:22:11.283000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.283000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1630 to t_134
V1111 13:22:11.284000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.284000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1630 to mm_91
V1111 13:22:11.285000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.285000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1629 to view_172
V1111 13:22:11.286000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.286000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1628 to t_135
V1111 13:22:11.286000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.287000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1627 to view_173
V1111 13:22:11.287000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.287000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1626 to transpose_83
V1111 13:22:11.288000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.288000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to zeros_4
V1111 13:22:11.289000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.289000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to zeros_5
V1111 13:22:11.290000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.290000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to detach_51
V1111 13:22:11.291000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.291000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to detach_52
V1111 13:22:11.295000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.295000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg0_1
V1111 13:22:11.295000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.295000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg1_1
V1111 13:22:11.295000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.296000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg2_1
V1111 13:22:11.296000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.296000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg3_1
V1111 13:22:11.296000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.296000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg4_1
V1111 13:22:11.298000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.299000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to output
V1111 13:22:11.300000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.301000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg0_1
V1111 13:22:11.301000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.301000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg1_1
V1111 13:22:11.301000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.301000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg2_1
V1111 13:22:11.301000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.302000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg3_1
V1111 13:22:11.302000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.302000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg4_1
V1111 13:22:11.302000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.302000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg5_1
V1111 13:22:11.304000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.305000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to output
V1111 13:22:11.306000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.306000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg0_1
V1111 13:22:11.307000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.307000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg1_1
V1111 13:22:11.307000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.307000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg2_1
V1111 13:22:11.307000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.307000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg3_1
V1111 13:22:11.308000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.308000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to arg4_1
V1111 13:22:11.309000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1862 to new_ones
V1111 13:22:11.310000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1862 to ge
V1111 13:22:11.311000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1862 to bitwise_and
V1111 13:22:11.312000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1863 to index
V1111 13:22:11.313000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1864 to index_1
V1111 13:22:11.314000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1864 to eq
V1111 13:22:11.315000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1864 to bitwise_and_1
V1111 13:22:11.315000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.316000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to output
V1111 13:22:11.317000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.318000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to fw_graph2
V1111 13:22:11.318000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.318000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to joint_graph2
V1111 13:22:11.318000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.318000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to mask_graph2
V1111 13:22:11.319000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.319000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to _tensor_constant0_8
V1111 13:22:11.319000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.320000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to flex_attention_backward_2
V1111 13:22:11.320000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.320000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to getitem_141
V1111 13:22:11.320000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.320000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to getitem_142
V1111 13:22:11.321000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.321000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to getitem_143
V1111 13:22:11.321000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.321000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1623 to getitem_144
V1111 13:22:11.322000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.322000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1622 to transpose_84
V1111 13:22:11.323000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.323000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1621 to transpose_85
V1111 13:22:11.324000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.324000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1620 to transpose_86
V1111 13:22:11.325000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.325000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1619 to slice_25
V1111 13:22:11.325000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.326000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1619 to slice_26
V1111 13:22:11.326000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.326000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1618 to sum_11
V1111 13:22:11.327000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.327000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1617 to cat_23
V1111 13:22:11.328000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.328000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1616 to view_174
V1111 13:22:11.329000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.329000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1615 to view_175
V1111 13:22:11.330000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.330000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1614 to t_136
V1111 13:22:11.330000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.330000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1614 to mm_92
V1111 13:22:11.331000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.331000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1614 to t_137
V1111 13:22:11.332000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.332000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1614 to t_138
V1111 13:22:11.333000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.333000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1614 to mm_93
V1111 13:22:11.333000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.334000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1613 to view_176
V1111 13:22:11.334000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.334000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1612 to t_139
V1111 13:22:11.335000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.335000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1611 to detach_53
V1111 13:22:11.336000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.336000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1611 to _fused_rms_norm_backward_8
V1111 13:22:11.336000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.337000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1611 to getitem_145
V1111 13:22:11.337000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.337000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1611 to getitem_146
V1111 13:22:11.338000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.338000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1610 to view_177
V1111 13:22:11.339000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.339000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1609 to view_as_complex_16
V1111 13:22:11.339000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.340000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1608 to _conj_4
V1111 13:22:11.340000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.341000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1608 to clone_6
V1111 13:22:11.341000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.341000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1608 to mul_63
V1111 13:22:11.342000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.342000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1607 to view_as_real_16
V1111 13:22:11.343000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.343000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1606 to view_178
V1111 13:22:11.344000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.344000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1605 to squeeze_2
V1111 13:22:11.344000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.345000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1604 to cat_24
V1111 13:22:11.345000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.345000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1603 to view_179
V1111 13:22:11.346000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.346000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1602 to t_140
V1111 13:22:11.347000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.347000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1602 to mm_94
V1111 13:22:11.348000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.348000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1602 to t_141
V1111 13:22:11.348000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.348000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1602 to t_142
V1111 13:22:11.349000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.349000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1602 to mm_95
V1111 13:22:11.350000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.350000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1601 to view_180
V1111 13:22:11.351000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.351000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1600 to t_143
V1111 13:22:11.351000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.352000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1599 to slice_27
V1111 13:22:11.352000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.352000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1599 to slice_28
V1111 13:22:11.353000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.353000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1598 to view_181
V1111 13:22:11.354000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.354000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1597 to clone_7
V1111 13:22:11.355000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.355000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1597 to view_as_complex_17
V1111 13:22:11.356000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.356000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1596 to _conj_5
V1111 13:22:11.356000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.356000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1596 to clone_8
V1111 13:22:11.357000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.357000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1596 to mul_64
V1111 13:22:11.358000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.358000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1595 to view_as_real_17
V1111 13:22:11.359000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.359000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1594 to view_182
V1111 13:22:11.360000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.360000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1593 to cat_25
V1111 13:22:11.360000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.361000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1592 to view_183
V1111 13:22:11.361000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.361000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1591 to view_184
V1111 13:22:11.362000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.362000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1590 to t_144
V1111 13:22:11.363000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.363000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1590 to mm_96
V1111 13:22:11.364000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.364000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1590 to t_145
V1111 13:22:11.364000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.364000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1590 to t_146
V1111 13:22:11.365000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.365000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1590 to mm_97
V1111 13:22:11.366000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.366000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1589 to view_185
V1111 13:22:11.367000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1864 to add_46
V1111 13:22:11.367000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.367000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1588 to t_147
V1111 13:22:11.368000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.368000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1587 to detach_54
V1111 13:22:11.369000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.369000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1587 to _fused_rms_norm_backward_9
V1111 13:22:11.370000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.370000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1587 to getitem_147
V1111 13:22:11.370000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.370000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1587 to getitem_148
V1111 13:22:11.371000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1864 to add_47
V1111 13:22:11.371000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.372000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1585 to view_186
V1111 13:22:11.372000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.372000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1584 to gather_13
V1111 13:22:11.373000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.373000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1583 to mul_65
V1111 13:22:11.374000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.374000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1583 to mul_66
V1111 13:22:11.375000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.375000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1583 to sum_12
V1111 13:22:11.375000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.376000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1582 to view_187
V1111 13:22:11.376000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.376000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1581 to t_148
V1111 13:22:11.377000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.377000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1581 to mm_98
V1111 13:22:11.378000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.378000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1581 to t_149
V1111 13:22:11.378000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.379000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1581 to t_150
V1111 13:22:11.379000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.379000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1581 to mm_99
V1111 13:22:11.380000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.380000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1580 to t_151
V1111 13:22:11.381000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.381000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1579 to mul_67
V1111 13:22:11.382000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.382000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1579 to mul_68
V1111 13:22:11.382000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.382000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1578 to t_152
V1111 13:22:11.383000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.383000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1578 to mm_100
V1111 13:22:11.384000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.384000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1578 to t_153
V1111 13:22:11.385000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.385000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1578 to t_154
V1111 13:22:11.385000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.386000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1578 to mm_101
V1111 13:22:11.386000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.386000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1577 to t_155
V1111 13:22:11.387000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.387000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1576 to silu_backward_6
V1111 13:22:11.388000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.388000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1575 to t_156
V1111 13:22:11.388000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.389000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1575 to mm_102
V1111 13:22:11.389000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.389000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1575 to t_157
V1111 13:22:11.390000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.390000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1575 to t_158
V1111 13:22:11.391000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.391000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1575 to mm_103
V1111 13:22:11.391000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1864 to add_48
V1111 13:22:11.392000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.392000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1574 to t_159
V1111 13:22:11.393000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.393000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1573 to slice_backward_3
V1111 13:22:11.394000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.394000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1572 to index_13
V1111 13:22:11.395000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.395000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1571 to _to_copy_58
V1111 13:22:11.395000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.396000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1570 to transpose_87
V1111 13:22:11.396000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.396000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1570 to _grouped_mm_33
V1111 13:22:11.397000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.397000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1570 to transpose_88
V1111 13:22:11.398000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.398000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1570 to transpose_89
V1111 13:22:11.399000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.399000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1570 to _grouped_mm_34
V1111 13:22:11.399000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.400000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1569 to transpose_90
V1111 13:22:11.400000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.401000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1568 to _to_copy_59
V1111 13:22:11.401000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.401000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1567 to mul_69
V1111 13:22:11.402000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.402000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1567 to mul_70
V1111 13:22:11.403000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.403000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1566 to transpose_91
V1111 13:22:11.404000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.404000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1566 to _grouped_mm_35
V1111 13:22:11.404000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.405000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1566 to transpose_92
V1111 13:22:11.405000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.405000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1566 to transpose_93
V1111 13:22:11.406000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.406000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1566 to _grouped_mm_36
V1111 13:22:11.407000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.407000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1565 to transpose_94
V1111 13:22:11.408000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.408000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1564 to _to_copy_60
V1111 13:22:11.408000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.409000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1563 to _to_copy_61
V1111 13:22:11.409000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.409000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1562 to silu_backward_7
V1111 13:22:11.410000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.410000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1561 to transpose_95
V1111 13:22:11.411000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.411000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1561 to _grouped_mm_37
V1111 13:22:11.412000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.412000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1561 to transpose_96
V1111 13:22:11.412000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.412000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1561 to transpose_97
V1111 13:22:11.413000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.413000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1561 to _grouped_mm_38
V1111 13:22:11.414000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.414000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1560 to transpose_98
V1111 13:22:11.415000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.415000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1559 to _to_copy_62
V1111 13:22:11.416000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.416000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1558 to _to_copy_63
V1111 13:22:11.416000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1864 to add_49
V1111 13:22:11.417000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.417000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1557 to new_zeros_77
V1111 13:22:11.418000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.418000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1557 to index_put_11
V1111 13:22:11.419000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.419000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1556 to slice_29
V1111 13:22:11.420000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.420000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1556 to slice_30
V1111 13:22:11.421000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.421000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1555 to new_zeros_78
V1111 13:22:11.421000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.421000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1555 to scatter_add_11
V1111 13:22:11.422000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1864 to add_50
V1111 13:22:11.423000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.423000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1554 to new_zeros_79
V1111 13:22:11.424000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.424000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1554 to index_put_12
V1111 13:22:11.425000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.425000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1553 to view_188
V1111 13:22:11.425000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.425000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1552 to mul_71
V1111 13:22:11.426000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.426000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1551 to new_zeros_80
V1111 13:22:11.427000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.427000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1551 to scatter_add_12
V1111 13:22:11.428000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.428000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1548 to detach_55
V1111 13:22:11.429000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.429000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1548 to _softmax_backward_data_3
V1111 13:22:11.429000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.429000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1547 to t_160
V1111 13:22:11.430000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.430000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1547 to mm_104
V1111 13:22:11.431000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.431000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1547 to t_161
V1111 13:22:11.432000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.432000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1547 to t_162
V1111 13:22:11.432000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.433000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1547 to mm_105
V1111 13:22:11.433000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1864 to add_51
V1111 13:22:11.434000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.434000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1546 to t_163
V1111 13:22:11.435000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.435000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1545 to view_189
V1111 13:22:11.435000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.436000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1544 to detach_56
V1111 13:22:11.436000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.436000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1544 to _fused_rms_norm_backward_10
V1111 13:22:11.437000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.437000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1544 to getitem_149
V1111 13:22:11.437000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.437000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1544 to getitem_150
V1111 13:22:11.438000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1864 to add_52
V1111 13:22:11.439000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.439000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1542 to view_190
V1111 13:22:11.439000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.440000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1541 to t_164
V1111 13:22:11.440000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.441000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1541 to mm_106
V1111 13:22:11.441000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.441000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1541 to t_165
V1111 13:22:11.442000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.442000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1541 to t_166
V1111 13:22:11.443000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.443000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1541 to mm_107
V1111 13:22:11.444000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.444000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1540 to view_191
V1111 13:22:11.444000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.445000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1539 to t_167
V1111 13:22:11.445000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.445000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1538 to view_192
V1111 13:22:11.446000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.446000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1537 to transpose_99
V1111 13:22:11.447000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.447000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to zeros_6
V1111 13:22:11.448000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.448000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to zeros_7
V1111 13:22:11.449000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.449000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to detach_57
V1111 13:22:11.449000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.449000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to detach_58
V1111 13:22:11.453000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.454000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg0_1
V1111 13:22:11.454000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.454000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg1_1
V1111 13:22:11.454000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.454000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg2_1
V1111 13:22:11.454000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.455000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg3_1
V1111 13:22:11.455000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.455000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg4_1
V1111 13:22:11.457000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.457000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to output
V1111 13:22:11.459000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.459000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg0_1
V1111 13:22:11.459000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.460000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg1_1
V1111 13:22:11.460000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.460000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg2_1
V1111 13:22:11.460000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.460000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg3_1
V1111 13:22:11.460000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.460000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg4_1
V1111 13:22:11.461000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.461000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg5_1
V1111 13:22:11.463000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.463000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to output
V1111 13:22:11.465000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.465000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg0_1
V1111 13:22:11.465000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.465000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg1_1
V1111 13:22:11.465000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.466000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg2_1
V1111 13:22:11.466000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.466000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg3_1
V1111 13:22:11.466000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.466000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to arg4_1
V1111 13:22:11.468000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1864 to new_ones
V1111 13:22:11.468000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1864 to ge
V1111 13:22:11.469000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1864 to bitwise_and
V1111 13:22:11.470000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1865 to index
V1111 13:22:11.471000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1866 to index_1
V1111 13:22:11.472000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1866 to eq
V1111 13:22:11.473000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1866 to bitwise_and_1
V1111 13:22:11.473000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.473000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to output
V1111 13:22:11.475000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.475000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to fw_graph3
V1111 13:22:11.476000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.476000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to joint_graph3
V1111 13:22:11.476000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.476000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to mask_graph3
V1111 13:22:11.477000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.477000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to _tensor_constant0_9
V1111 13:22:11.477000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.477000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to flex_attention_backward_3
V1111 13:22:11.478000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.478000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to getitem_151
V1111 13:22:11.478000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.478000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to getitem_152
V1111 13:22:11.479000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.479000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to getitem_153
V1111 13:22:11.479000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.479000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1534 to getitem_154
V1111 13:22:11.480000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.480000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1533 to transpose_100
V1111 13:22:11.481000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.481000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1532 to transpose_101
V1111 13:22:11.482000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.482000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1531 to transpose_102
V1111 13:22:11.482000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.483000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1530 to slice_31
V1111 13:22:11.483000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.483000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1530 to slice_32
V1111 13:22:11.484000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.484000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1529 to sum_13
V1111 13:22:11.485000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.485000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1528 to cat_26
V1111 13:22:11.486000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.486000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1527 to view_193
V1111 13:22:11.487000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.487000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1526 to view_194
V1111 13:22:11.487000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.488000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1525 to t_168
V1111 13:22:11.488000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.488000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1525 to mm_108
V1111 13:22:11.489000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.489000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1525 to t_169
V1111 13:22:11.490000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.490000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1525 to t_170
V1111 13:22:11.490000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.490000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1525 to mm_109
V1111 13:22:11.491000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.491000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1524 to view_195
V1111 13:22:11.492000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.492000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1523 to t_171
V1111 13:22:11.493000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.493000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1522 to detach_59
V1111 13:22:11.494000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.494000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1522 to _fused_rms_norm_backward_11
V1111 13:22:11.494000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.494000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1522 to getitem_155
V1111 13:22:11.495000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.495000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1522 to getitem_156
V1111 13:22:11.495000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.496000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1521 to view_196
V1111 13:22:11.496000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.496000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1520 to view_as_complex_18
V1111 13:22:11.497000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.497000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1519 to _conj_6
V1111 13:22:11.498000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.498000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1519 to clone_9
V1111 13:22:11.499000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.499000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1519 to mul_72
V1111 13:22:11.499000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.500000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1518 to view_as_real_18
V1111 13:22:11.500000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.500000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1517 to view_197
V1111 13:22:11.501000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.501000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1516 to squeeze_3
V1111 13:22:11.502000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.502000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1515 to cat_27
V1111 13:22:11.503000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.503000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1514 to view_198
V1111 13:22:11.504000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.504000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1513 to t_172
V1111 13:22:11.504000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.504000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1513 to mm_110
V1111 13:22:11.505000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.505000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1513 to t_173
V1111 13:22:11.506000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.506000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1513 to t_174
V1111 13:22:11.506000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.507000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1513 to mm_111
V1111 13:22:11.507000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.507000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1512 to view_199
V1111 13:22:11.508000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.508000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1511 to t_175
V1111 13:22:11.509000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.509000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1510 to slice_33
V1111 13:22:11.510000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.510000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1510 to slice_34
V1111 13:22:11.510000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.511000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1509 to view_200
V1111 13:22:11.512000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.512000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1508 to clone_10
V1111 13:22:11.513000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.513000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1508 to view_as_complex_19
V1111 13:22:11.513000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.514000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1507 to _conj_7
V1111 13:22:11.514000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.514000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1507 to clone_11
V1111 13:22:11.515000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.515000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1507 to mul_73
V1111 13:22:11.516000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.516000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1506 to view_as_real_19
V1111 13:22:11.516000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.517000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1505 to view_201
V1111 13:22:11.517000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.517000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1504 to cat_28
V1111 13:22:11.518000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.518000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1503 to view_202
V1111 13:22:11.519000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.519000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1502 to view_203
V1111 13:22:11.520000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.520000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1501 to t_176
V1111 13:22:11.520000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.521000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1501 to mm_112
V1111 13:22:11.521000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.521000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1501 to t_177
V1111 13:22:11.522000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.522000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1501 to t_178
V1111 13:22:11.523000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.523000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1501 to mm_113
V1111 13:22:11.523000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.524000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1500 to view_204
V1111 13:22:11.524000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1866 to add_53
V1111 13:22:11.525000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.525000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1499 to t_179
V1111 13:22:11.526000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.526000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1498 to detach_60
V1111 13:22:11.526000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.527000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1498 to _fused_rms_norm_backward_12
V1111 13:22:11.527000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.527000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1498 to getitem_157
V1111 13:22:11.528000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.528000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1498 to getitem_158
V1111 13:22:11.528000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1866 to add_54
V1111 13:22:11.529000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.529000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1496 to view_205
V1111 13:22:11.530000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.530000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1495 to gather_14
V1111 13:22:11.531000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.531000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1494 to mul_74
V1111 13:22:11.531000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.532000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1494 to mul_75
V1111 13:22:11.532000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.532000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1494 to sum_14
V1111 13:22:11.533000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.533000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1493 to view_206
V1111 13:22:11.534000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.534000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1492 to t_180
V1111 13:22:11.534000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.535000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1492 to mm_114
V1111 13:22:11.535000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.535000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1492 to t_181
V1111 13:22:11.536000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.536000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1492 to t_182
V1111 13:22:11.537000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.537000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1492 to mm_115
V1111 13:22:11.537000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.538000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1491 to t_183
V1111 13:22:11.538000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.538000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1490 to mul_76
V1111 13:22:11.539000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.539000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1490 to mul_77
V1111 13:22:11.540000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.540000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1489 to t_184
V1111 13:22:11.540000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.541000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1489 to mm_116
V1111 13:22:11.541000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.541000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1489 to t_185
V1111 13:22:11.542000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.542000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1489 to t_186
V1111 13:22:11.543000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.543000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1489 to mm_117
V1111 13:22:11.544000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.544000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1488 to t_187
V1111 13:22:11.544000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.545000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1487 to silu_backward_8
V1111 13:22:11.545000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.545000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1486 to t_188
V1111 13:22:11.546000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.546000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1486 to mm_118
V1111 13:22:11.547000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.547000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1486 to t_189
V1111 13:22:11.547000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.548000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1486 to t_190
V1111 13:22:11.548000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.548000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1486 to mm_119
V1111 13:22:11.549000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1866 to add_55
V1111 13:22:11.550000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.550000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1485 to t_191
V1111 13:22:11.550000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.551000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1484 to slice_backward_4
V1111 13:22:11.551000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.551000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1483 to index_14
V1111 13:22:11.552000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.552000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1482 to _to_copy_64
V1111 13:22:11.553000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.553000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1481 to transpose_103
V1111 13:22:11.554000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.554000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1481 to _grouped_mm_39
V1111 13:22:11.554000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.554000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1481 to transpose_104
V1111 13:22:11.555000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.555000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1481 to transpose_105
V1111 13:22:11.556000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.556000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1481 to _grouped_mm_40
V1111 13:22:11.557000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.557000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1480 to transpose_106
V1111 13:22:11.557000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.558000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1479 to _to_copy_65
V1111 13:22:11.558000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.558000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1478 to mul_78
V1111 13:22:11.559000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.559000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1478 to mul_79
V1111 13:22:11.560000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.560000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1477 to transpose_107
V1111 13:22:11.560000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.561000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1477 to _grouped_mm_41
V1111 13:22:11.561000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.561000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1477 to transpose_108
V1111 13:22:11.562000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.562000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1477 to transpose_109
V1111 13:22:11.563000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.563000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1477 to _grouped_mm_42
V1111 13:22:11.564000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.564000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1476 to transpose_110
V1111 13:22:11.564000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.564000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1475 to _to_copy_66
V1111 13:22:11.565000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.565000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1474 to _to_copy_67
V1111 13:22:11.566000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.566000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1473 to silu_backward_9
V1111 13:22:11.567000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.567000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1472 to transpose_111
V1111 13:22:11.568000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.568000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1472 to _grouped_mm_43
V1111 13:22:11.568000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.568000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1472 to transpose_112
V1111 13:22:11.569000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.569000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1472 to transpose_113
V1111 13:22:11.570000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.570000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1472 to _grouped_mm_44
V1111 13:22:11.571000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.571000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1471 to transpose_114
V1111 13:22:11.571000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.572000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1470 to _to_copy_68
V1111 13:22:11.572000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.572000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1469 to _to_copy_69
V1111 13:22:11.573000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1866 to add_56
V1111 13:22:11.574000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.574000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1468 to new_zeros_81
V1111 13:22:11.575000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.575000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1468 to index_put_13
V1111 13:22:11.576000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.576000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1467 to slice_35
V1111 13:22:11.576000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.576000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1467 to slice_36
V1111 13:22:11.577000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.577000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1466 to new_zeros_82
V1111 13:22:11.578000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.578000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1466 to scatter_add_13
V1111 13:22:11.579000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1866 to add_57
V1111 13:22:11.579000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.580000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1465 to new_zeros_83
V1111 13:22:11.580000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.580000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1465 to index_put_14
V1111 13:22:11.581000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.581000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1464 to view_207
V1111 13:22:11.582000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.582000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1463 to mul_80
V1111 13:22:11.583000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.583000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1462 to new_zeros_84
V1111 13:22:11.583000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.583000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1462 to scatter_add_14
V1111 13:22:11.584000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.584000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1459 to detach_61
V1111 13:22:11.585000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.585000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1459 to _softmax_backward_data_4
V1111 13:22:11.586000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.586000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1458 to t_192
V1111 13:22:11.586000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.587000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1458 to mm_120
V1111 13:22:11.587000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.587000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1458 to t_193
V1111 13:22:11.588000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.588000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1458 to t_194
V1111 13:22:11.589000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.589000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1458 to mm_121
V1111 13:22:11.589000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1866 to add_58
V1111 13:22:11.590000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.590000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1457 to t_195
V1111 13:22:11.591000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.591000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1456 to view_208
V1111 13:22:11.592000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.592000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1455 to detach_62
V1111 13:22:11.592000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.593000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1455 to _fused_rms_norm_backward_13
V1111 13:22:11.593000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.593000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1455 to getitem_159
V1111 13:22:11.593000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.593000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1455 to getitem_160
V1111 13:22:11.594000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1866 to add_59
V1111 13:22:11.595000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.595000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1453 to view_209
V1111 13:22:11.595000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.596000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1452 to t_196
V1111 13:22:11.596000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.596000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1452 to mm_122
V1111 13:22:11.597000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.597000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1452 to t_197
V1111 13:22:11.598000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.598000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1452 to t_198
V1111 13:22:11.598000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.598000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1452 to mm_123
V1111 13:22:11.599000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.599000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1451 to view_210
V1111 13:22:11.600000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.600000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1450 to t_199
V1111 13:22:11.601000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.601000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1449 to view_211
V1111 13:22:11.601000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.602000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1448 to transpose_115
V1111 13:22:11.602000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.602000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to zeros_8
V1111 13:22:11.603000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.603000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to zeros_9
V1111 13:22:11.604000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.604000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to detach_63
V1111 13:22:11.605000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.605000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to detach_64
V1111 13:22:11.608000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.609000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg0_1
V1111 13:22:11.609000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.609000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg1_1
V1111 13:22:11.609000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.609000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg2_1
V1111 13:22:11.610000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.610000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg3_1
V1111 13:22:11.610000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.610000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg4_1
V1111 13:22:11.612000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.612000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to output
V1111 13:22:11.614000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.614000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg0_1
V1111 13:22:11.614000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.614000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg1_1
V1111 13:22:11.615000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.615000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg2_1
V1111 13:22:11.615000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.615000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg3_1
V1111 13:22:11.615000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.615000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg4_1
V1111 13:22:11.616000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.616000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg5_1
V1111 13:22:11.618000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.618000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to output
V1111 13:22:11.620000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.620000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg0_1
V1111 13:22:11.620000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.620000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg1_1
V1111 13:22:11.620000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.620000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg2_1
V1111 13:22:11.621000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.621000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg3_1
V1111 13:22:11.621000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.621000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to arg4_1
V1111 13:22:11.622000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1866 to new_ones
V1111 13:22:11.623000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1866 to ge
V1111 13:22:11.624000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1866 to bitwise_and
V1111 13:22:11.625000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1867 to index
V1111 13:22:11.626000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1868 to index_1
V1111 13:22:11.627000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1868 to eq
V1111 13:22:11.627000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1868 to bitwise_and_1
V1111 13:22:11.628000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.628000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to output
V1111 13:22:11.630000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.630000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to fw_graph4
V1111 13:22:11.630000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.630000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to joint_graph4
V1111 13:22:11.631000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.631000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to mask_graph4
V1111 13:22:11.631000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.631000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to _tensor_constant0_10
V1111 13:22:11.632000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.632000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to flex_attention_backward_4
V1111 13:22:11.632000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.632000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to getitem_161
V1111 13:22:11.633000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.633000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to getitem_162
V1111 13:22:11.633000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.633000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to getitem_163
V1111 13:22:11.633000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.634000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1445 to getitem_164
V1111 13:22:11.634000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.635000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1444 to transpose_116
V1111 13:22:11.635000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.635000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1443 to transpose_117
V1111 13:22:11.636000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.636000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1442 to transpose_118
V1111 13:22:11.637000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.637000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1441 to slice_37
V1111 13:22:11.638000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.638000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1441 to slice_38
V1111 13:22:11.638000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.639000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1440 to sum_15
V1111 13:22:11.639000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.639000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1439 to cat_29
V1111 13:22:11.640000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.640000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1438 to view_212
V1111 13:22:11.641000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.641000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1437 to view_213
V1111 13:22:11.642000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.642000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1436 to t_200
V1111 13:22:11.642000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.643000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1436 to mm_124
V1111 13:22:11.643000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.643000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1436 to t_201
V1111 13:22:11.644000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.644000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1436 to t_202
V1111 13:22:11.644000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.645000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1436 to mm_125
V1111 13:22:11.645000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.645000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1435 to view_214
V1111 13:22:11.646000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.646000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1434 to t_203
V1111 13:22:11.647000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.647000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1433 to detach_65
V1111 13:22:11.648000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.648000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1433 to _fused_rms_norm_backward_14
V1111 13:22:11.648000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.648000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1433 to getitem_165
V1111 13:22:11.649000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.649000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1433 to getitem_166
V1111 13:22:11.650000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.650000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1432 to view_215
V1111 13:22:11.650000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.650000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1431 to view_as_complex_20
V1111 13:22:11.651000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.651000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1430 to _conj_8
V1111 13:22:11.652000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.652000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1430 to clone_12
V1111 13:22:11.653000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.653000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1430 to mul_81
V1111 13:22:11.654000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.654000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1429 to view_as_real_20
V1111 13:22:11.654000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.655000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1428 to view_216
V1111 13:22:11.655000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.655000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1427 to squeeze_4
V1111 13:22:11.656000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.656000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1426 to cat_30
V1111 13:22:11.657000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.657000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1425 to view_217
V1111 13:22:11.658000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.658000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1424 to t_204
V1111 13:22:11.658000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.658000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1424 to mm_126
V1111 13:22:11.659000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.659000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1424 to t_205
V1111 13:22:11.660000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.660000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1424 to t_206
V1111 13:22:11.660000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.661000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1424 to mm_127
V1111 13:22:11.661000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.661000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1423 to view_218
V1111 13:22:11.662000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.662000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1422 to t_207
V1111 13:22:11.663000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.663000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1421 to slice_39
V1111 13:22:11.664000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.664000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1421 to slice_40
V1111 13:22:11.664000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.664000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1420 to view_219
V1111 13:22:11.665000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.665000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1419 to clone_13
V1111 13:22:11.666000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.666000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1419 to view_as_complex_21
V1111 13:22:11.667000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.667000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1418 to _conj_9
V1111 13:22:11.668000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.668000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1418 to clone_14
V1111 13:22:11.668000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.668000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1418 to mul_82
V1111 13:22:11.669000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.669000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1417 to view_as_real_21
V1111 13:22:11.670000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.670000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1416 to view_220
V1111 13:22:11.671000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.671000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1415 to cat_31
V1111 13:22:11.671000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.672000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1414 to view_221
V1111 13:22:11.672000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.672000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1413 to view_222
V1111 13:22:11.673000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.673000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1412 to t_208
V1111 13:22:11.674000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.674000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1412 to mm_128
V1111 13:22:11.674000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.675000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1412 to t_209
V1111 13:22:11.675000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.675000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1412 to t_210
V1111 13:22:11.676000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.676000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1412 to mm_129
V1111 13:22:11.677000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.677000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1411 to view_223
V1111 13:22:11.677000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1868 to add_60
V1111 13:22:11.678000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.678000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1410 to t_211
V1111 13:22:11.679000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.679000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1409 to detach_66
V1111 13:22:11.680000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.680000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1409 to _fused_rms_norm_backward_15
V1111 13:22:11.680000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.680000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1409 to getitem_167
V1111 13:22:11.681000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.681000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1409 to getitem_168
V1111 13:22:11.681000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1868 to add_61
V1111 13:22:11.682000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.682000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1407 to view_224
V1111 13:22:11.683000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.683000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1406 to t_212
V1111 13:22:11.684000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.684000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1406 to mm_130
V1111 13:22:11.685000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.685000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1406 to t_213
V1111 13:22:11.686000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.686000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1406 to t_214
V1111 13:22:11.687000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.687000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1406 to mm_131
V1111 13:22:11.688000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.688000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1405 to view_225
V1111 13:22:11.688000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.688000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1404 to t_215
V1111 13:22:11.689000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.689000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1403 to mul_83
V1111 13:22:11.690000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.690000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1403 to mul_84
V1111 13:22:11.691000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.691000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1402 to view_226
V1111 13:22:11.691000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.692000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1401 to t_216
V1111 13:22:11.692000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.693000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1401 to mm_132
V1111 13:22:11.693000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.693000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1401 to t_217
V1111 13:22:11.695000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.695000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1401 to t_218
V1111 13:22:11.696000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.696000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1401 to mm_133
V1111 13:22:11.697000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.697000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1400 to view_227
V1111 13:22:11.698000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.698000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1399 to t_219
V1111 13:22:11.699000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.699000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1398 to silu_backward_10
V1111 13:22:11.702000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.703000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1397 to view_228
V1111 13:22:11.703000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.703000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1396 to t_220
V1111 13:22:11.704000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.704000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1396 to mm_134
V1111 13:22:11.705000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.705000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1396 to t_221
V1111 13:22:11.705000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.706000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1396 to t_222
V1111 13:22:11.706000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.706000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1396 to mm_135
V1111 13:22:11.707000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.707000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1395 to view_229
V1111 13:22:11.708000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1868 to add_62
V1111 13:22:11.709000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.709000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1394 to t_223
V1111 13:22:11.709000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.709000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1393 to detach_67
V1111 13:22:11.710000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.710000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1393 to _fused_rms_norm_backward_16
V1111 13:22:11.711000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.711000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1393 to getitem_169
V1111 13:22:11.711000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.711000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1393 to getitem_170
V1111 13:22:11.712000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1868 to add_63
V1111 13:22:11.712000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.713000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1391 to view_230
V1111 13:22:11.713000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.713000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1390 to t_224
V1111 13:22:11.714000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.714000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1390 to mm_136
V1111 13:22:11.715000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.715000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1390 to t_225
V1111 13:22:11.715000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.715000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1390 to t_226
V1111 13:22:11.716000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.716000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1390 to mm_137
V1111 13:22:11.717000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.717000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1389 to view_231
V1111 13:22:11.718000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.718000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1388 to t_227
V1111 13:22:11.718000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.719000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1387 to view_232
V1111 13:22:11.719000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.719000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1386 to transpose_119
V1111 13:22:11.720000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.720000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to zeros_10
V1111 13:22:11.721000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.721000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to zeros_11
V1111 13:22:11.721000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.722000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to detach_68
V1111 13:22:11.722000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.722000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to detach_69
V1111 13:22:11.726000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.726000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg0_1
V1111 13:22:11.727000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.727000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg1_1
V1111 13:22:11.727000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.727000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg2_1
V1111 13:22:11.727000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.727000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg3_1
V1111 13:22:11.727000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.728000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg4_1
V1111 13:22:11.730000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.730000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to output
V1111 13:22:11.731000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.732000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg0_1
V1111 13:22:11.732000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.732000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg1_1
V1111 13:22:11.732000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.732000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg2_1
V1111 13:22:11.732000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.733000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg3_1
V1111 13:22:11.733000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.733000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg4_1
V1111 13:22:11.733000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.733000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg5_1
V1111 13:22:11.735000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.736000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to output
V1111 13:22:11.737000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.737000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg0_1
V1111 13:22:11.737000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.738000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg1_1
V1111 13:22:11.738000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.738000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg2_1
V1111 13:22:11.738000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.738000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg3_1
V1111 13:22:11.738000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.738000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to arg4_1
V1111 13:22:11.740000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1868 to new_ones
V1111 13:22:11.741000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1868 to ge
V1111 13:22:11.741000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1868 to bitwise_and
V1111 13:22:11.742000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1869 to index
V1111 13:22:11.743000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1870 to index_1
V1111 13:22:11.744000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1870 to eq
V1111 13:22:11.745000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1870 to bitwise_and_1
V1111 13:22:11.745000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.745000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to output
V1111 13:22:11.747000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.748000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to fw_graph5
V1111 13:22:11.748000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.748000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to joint_graph5
V1111 13:22:11.748000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.748000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to mask_graph5
V1111 13:22:11.749000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.749000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to _tensor_constant0_11
V1111 13:22:11.749000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.749000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to flex_attention_backward_5
V1111 13:22:11.750000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.750000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to getitem_171
V1111 13:22:11.750000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.750000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to getitem_172
V1111 13:22:11.751000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.751000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to getitem_173
V1111 13:22:11.751000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.751000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1383 to getitem_174
V1111 13:22:11.752000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.752000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1382 to transpose_120
V1111 13:22:11.753000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.753000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1381 to transpose_121
V1111 13:22:11.753000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.754000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1380 to transpose_122
V1111 13:22:11.754000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.754000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1379 to slice_41
V1111 13:22:11.755000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.755000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1379 to slice_42
V1111 13:22:11.756000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.756000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1378 to sum_16
V1111 13:22:11.757000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.757000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1377 to cat_32
V1111 13:22:11.758000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.758000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1376 to view_233
V1111 13:22:11.759000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.759000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1375 to view_234
V1111 13:22:11.759000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.760000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1374 to t_228
V1111 13:22:11.760000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.760000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1374 to mm_138
V1111 13:22:11.761000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.761000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1374 to t_229
V1111 13:22:11.762000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.762000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1374 to t_230
V1111 13:22:11.762000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.762000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1374 to mm_139
V1111 13:22:11.763000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.763000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1373 to view_235
V1111 13:22:11.764000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.764000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1372 to t_231
V1111 13:22:11.765000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.765000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1371 to detach_70
V1111 13:22:11.765000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.766000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1371 to _fused_rms_norm_backward_17
V1111 13:22:11.766000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.766000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1371 to getitem_175
V1111 13:22:11.766000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.766000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1371 to getitem_176
V1111 13:22:11.767000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.767000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1370 to view_236
V1111 13:22:11.768000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.768000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1369 to view_as_complex_22
V1111 13:22:11.769000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.769000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1368 to _conj_10
V1111 13:22:11.770000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.770000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1368 to clone_15
V1111 13:22:11.770000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.770000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1368 to mul_85
V1111 13:22:11.771000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.771000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1367 to view_as_real_22
V1111 13:22:11.772000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.772000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1366 to view_237
V1111 13:22:11.773000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.773000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1365 to squeeze_5
V1111 13:22:11.773000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.774000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1364 to cat_33
V1111 13:22:11.774000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.774000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1363 to view_238
V1111 13:22:11.775000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.775000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1362 to t_232
V1111 13:22:11.776000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.776000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1362 to mm_140
V1111 13:22:11.777000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.777000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1362 to t_233
V1111 13:22:11.777000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.777000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1362 to t_234
V1111 13:22:11.778000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.778000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1362 to mm_141
V1111 13:22:11.779000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.779000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1361 to view_239
V1111 13:22:11.779000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.780000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1360 to t_235
V1111 13:22:11.780000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.780000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1359 to slice_43
V1111 13:22:11.781000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.781000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1359 to slice_44
V1111 13:22:11.782000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.782000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1358 to view_240
V1111 13:22:11.783000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.783000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1357 to clone_16
V1111 13:22:11.783000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.784000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1357 to view_as_complex_23
V1111 13:22:11.784000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.784000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1356 to _conj_11
V1111 13:22:11.785000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.785000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1356 to clone_17
V1111 13:22:11.786000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.786000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1356 to mul_86
V1111 13:22:11.786000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.787000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1355 to view_as_real_23
V1111 13:22:11.787000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.787000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1354 to view_241
V1111 13:22:11.788000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.788000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1353 to cat_34
V1111 13:22:11.789000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.789000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1352 to view_242
V1111 13:22:11.790000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.790000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1351 to view_243
V1111 13:22:11.790000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.791000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1350 to t_236
V1111 13:22:11.791000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.791000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1350 to mm_142
V1111 13:22:11.792000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.792000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1350 to t_237
V1111 13:22:11.793000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.793000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1350 to t_238
V1111 13:22:11.793000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.793000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1350 to mm_143
V1111 13:22:11.794000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.794000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1349 to view_244
V1111 13:22:11.795000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1870 to add_64
V1111 13:22:11.796000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.796000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1348 to t_239
V1111 13:22:11.796000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.796000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1347 to detach_71
V1111 13:22:11.797000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.797000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1347 to _fused_rms_norm_backward_18
V1111 13:22:11.798000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.798000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1347 to getitem_177
V1111 13:22:11.798000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.798000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1347 to getitem_178
V1111 13:22:11.799000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1870 to add_65
V1111 13:22:11.800000 86039 torch/fx/proxy.py:211] [__annotation] seq_nr from current_meta
V1111 13:22:11.800000 86039 torch/fx/proxy.py:228] [__annotation] Assigning new_seq_nr 1346 to embedding_dense_backward
V1111 13:22:11.866000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1346, value: embedding
V1111 13:22:11.866000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1347, value: _fused_rms_norm
V1111 13:22:11.867000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1348, value: t
V1111 13:22:11.867000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1349, value: view
V1111 13:22:11.867000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1350, value: mm
V1111 13:22:11.867000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1351, value: _unsafe_view
V1111 13:22:11.867000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1352, value: view_1
V1111 13:22:11.867000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1353, value: split_with_sizes
V1111 13:22:11.867000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1354, value: view_2
V1111 13:22:11.867000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1355, value: view_as_complex
V1111 13:22:11.868000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1356, value: mul
V1111 13:22:11.868000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1357, value: view_as_real
V1111 13:22:11.868000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1358, value: view_4
V1111 13:22:11.868000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1359, value: cat
V1111 13:22:11.868000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1360, value: t_1
V1111 13:22:11.868000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1361, value: view_5
V1111 13:22:11.868000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1362, value: mm_1
V1111 13:22:11.868000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1363, value: _unsafe_view_1
V1111 13:22:11.868000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1364, value: split_with_sizes_1
V1111 13:22:11.869000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1365, value: unsqueeze
V1111 13:22:11.869000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1366, value: view_6
V1111 13:22:11.869000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1367, value: view_as_complex_1
V1111 13:22:11.869000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1368, value: mul_1
V1111 13:22:11.869000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1369, value: view_as_real_1
V1111 13:22:11.869000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1370, value: view_8
V1111 13:22:11.869000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1371, value: _fused_rms_norm_1
V1111 13:22:11.869000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1372, value: t_2
V1111 13:22:11.869000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1373, value: view_9
V1111 13:22:11.869000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1374, value: mm_2
V1111 13:22:11.870000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1375, value: _unsafe_view_2
V1111 13:22:11.870000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1376, value: view_10
V1111 13:22:11.870000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1377, value: split_with_sizes_2
V1111 13:22:11.870000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1378, value: expand
V1111 13:22:11.870000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1379, value: cat_1
V1111 13:22:11.870000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1380, value: transpose
V1111 13:22:11.870000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1381, value: transpose_1
V1111 13:22:11.870000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1382, value: transpose_2
V1111 13:22:11.870000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1383, value: new_zeros_5
V1111 13:22:11.871000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1385, value: sdpa_score0
V1111 13:22:11.871000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1386, value: transpose_3
V1111 13:22:11.871000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1387, value: view_11
V1111 13:22:11.871000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1388, value: t_3
V1111 13:22:11.871000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1389, value: view_12
V1111 13:22:11.871000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1390, value: mm_3
V1111 13:22:11.871000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1391, value: _unsafe_view_3
V1111 13:22:11.871000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1392, value: add
V1111 13:22:11.871000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1393, value: _fused_rms_norm_2
V1111 13:22:11.871000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1394, value: t_4
V1111 13:22:11.872000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1395, value: view_13
V1111 13:22:11.872000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1396, value: mm_4
V1111 13:22:11.872000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1397, value: _unsafe_view_4
V1111 13:22:11.872000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1398, value: silu
V1111 13:22:11.872000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1399, value: t_5
V1111 13:22:11.872000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1400, value: view_14
V1111 13:22:11.872000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1401, value: mm_5
V1111 13:22:11.872000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1402, value: _unsafe_view_5
V1111 13:22:11.872000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1403, value: mul_2
V1111 13:22:11.872000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1404, value: t_6
V1111 13:22:11.873000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1405, value: view_15
V1111 13:22:11.873000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1406, value: mm_6
V1111 13:22:11.873000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1407, value: _unsafe_view_6
V1111 13:22:11.873000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1408, value: add_1
V1111 13:22:11.873000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1409, value: _fused_rms_norm_3
V1111 13:22:11.873000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1410, value: t_7
V1111 13:22:11.873000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1411, value: view_16
V1111 13:22:11.873000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1412, value: mm_7
V1111 13:22:11.873000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1413, value: _unsafe_view_7
V1111 13:22:11.874000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1414, value: view_17
V1111 13:22:11.874000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1415, value: split_with_sizes_3
V1111 13:22:11.874000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1416, value: view_18
V1111 13:22:11.874000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1417, value: view_as_complex_2
V1111 13:22:11.874000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1418, value: mul_3
V1111 13:22:11.874000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1419, value: view_as_real_2
V1111 13:22:11.874000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1420, value: view_20
V1111 13:22:11.874000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1421, value: cat_2
V1111 13:22:11.874000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1422, value: t_8
V1111 13:22:11.874000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1423, value: view_21
V1111 13:22:11.875000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1424, value: mm_8
V1111 13:22:11.875000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1425, value: _unsafe_view_8
V1111 13:22:11.875000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1426, value: split_with_sizes_4
V1111 13:22:11.875000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1427, value: unsqueeze_1
V1111 13:22:11.875000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1428, value: view_22
V1111 13:22:11.875000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1429, value: view_as_complex_3
V1111 13:22:11.875000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1430, value: mul_4
V1111 13:22:11.875000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1431, value: view_as_real_3
V1111 13:22:11.875000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1432, value: view_24
V1111 13:22:11.875000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1433, value: _fused_rms_norm_4
V1111 13:22:11.876000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1434, value: t_9
V1111 13:22:11.876000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1435, value: view_25
V1111 13:22:11.876000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1436, value: mm_9
V1111 13:22:11.876000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1437, value: _unsafe_view_9
V1111 13:22:11.876000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1438, value: view_26
V1111 13:22:11.876000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1439, value: split_with_sizes_5
V1111 13:22:11.876000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1440, value: expand_1
V1111 13:22:11.876000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1441, value: cat_3
V1111 13:22:11.876000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1442, value: transpose_4
V1111 13:22:11.876000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1443, value: transpose_5
V1111 13:22:11.877000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1444, value: transpose_6
V1111 13:22:11.877000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1445, value: new_zeros_15
V1111 13:22:11.877000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1447, value: sdpa_score1
V1111 13:22:11.877000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1448, value: transpose_7
V1111 13:22:11.877000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1449, value: view_27
V1111 13:22:11.877000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1450, value: t_10
V1111 13:22:11.877000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1451, value: view_28
V1111 13:22:11.877000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1452, value: mm_10
V1111 13:22:11.877000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1453, value: _unsafe_view_10
V1111 13:22:11.877000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1454, value: add_2
V1111 13:22:11.878000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1455, value: _fused_rms_norm_5
V1111 13:22:11.878000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1456, value: view_29
V1111 13:22:11.878000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1457, value: t_11
V1111 13:22:11.878000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1458, value: mm_11
V1111 13:22:11.878000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1459, value: _softmax
V1111 13:22:11.878000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1460, value: add_3
V1111 13:22:11.878000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1461, value: topk
V1111 13:22:11.878000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1462, value: gather
V1111 13:22:11.878000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1463, value: mul_5
V1111 13:22:11.879000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1464, value: view_33
V1111 13:22:11.879000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1465, value: index
V1111 13:22:11.879000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1466, value: gather_1
V1111 13:22:11.879000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1467, value: cat_4
V1111 13:22:11.879000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1468, value: index_1
V1111 13:22:11.879000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1469, value: _to_copy_2
V1111 13:22:11.879000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1470, value: _to_copy_3
V1111 13:22:11.879000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1471, value: transpose_8
V1111 13:22:11.879000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1472, value: _grouped_mm
V1111 13:22:11.879000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1473, value: silu_1
V1111 13:22:11.880000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1474, value: _to_copy_4
V1111 13:22:11.880000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1475, value: _to_copy_5
V1111 13:22:11.880000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1476, value: transpose_9
V1111 13:22:11.880000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1477, value: _grouped_mm_1
V1111 13:22:11.880000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1478, value: mul_7
V1111 13:22:11.880000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1479, value: _to_copy_6
V1111 13:22:11.880000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1480, value: transpose_10
V1111 13:22:11.880000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1481, value: _grouped_mm_2
V1111 13:22:11.880000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1482, value: _to_copy_7
V1111 13:22:11.880000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1483, value: index_put
V1111 13:22:11.881000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1484, value: slice_1
V1111 13:22:11.881000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1485, value: t_12
V1111 13:22:11.881000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1486, value: mm_12
V1111 13:22:11.881000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1487, value: silu_2
V1111 13:22:11.881000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1488, value: t_13
V1111 13:22:11.881000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1489, value: mm_13
V1111 13:22:11.881000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1490, value: mul_8
V1111 13:22:11.881000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1491, value: t_14
V1111 13:22:11.881000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1492, value: mm_14
V1111 13:22:11.881000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1493, value: view_36
V1111 13:22:11.882000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1494, value: mul_9
V1111 13:22:11.882000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1495, value: scatter_add
V1111 13:22:11.882000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1496, value: view_37
V1111 13:22:11.882000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1497, value: add_6
V1111 13:22:11.882000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1498, value: _fused_rms_norm_6
V1111 13:22:11.882000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1499, value: t_15
V1111 13:22:11.882000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1500, value: view_38
V1111 13:22:11.882000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1501, value: mm_15
V1111 13:22:11.882000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1502, value: _unsafe_view_11
V1111 13:22:11.882000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1503, value: view_39
V1111 13:22:11.883000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1504, value: split_with_sizes_6
V1111 13:22:11.883000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1505, value: view_40
V1111 13:22:11.883000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1506, value: view_as_complex_4
V1111 13:22:11.883000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1507, value: mul_10
V1111 13:22:11.883000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1508, value: view_as_real_4
V1111 13:22:11.883000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1509, value: view_42
V1111 13:22:11.883000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1510, value: cat_5
V1111 13:22:11.883000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1511, value: t_16
V1111 13:22:11.883000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1512, value: view_43
V1111 13:22:11.883000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1513, value: mm_16
V1111 13:22:11.884000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1514, value: _unsafe_view_12
V1111 13:22:11.884000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1515, value: split_with_sizes_7
V1111 13:22:11.884000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1516, value: unsqueeze_3
V1111 13:22:11.884000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1517, value: view_44
V1111 13:22:11.884000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1518, value: view_as_complex_5
V1111 13:22:11.884000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1519, value: mul_11
V1111 13:22:11.884000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1520, value: view_as_real_5
V1111 13:22:11.884000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1521, value: view_46
V1111 13:22:11.884000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1522, value: _fused_rms_norm_7
V1111 13:22:11.885000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1523, value: t_17
V1111 13:22:11.885000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1524, value: view_47
V1111 13:22:11.885000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1525, value: mm_17
V1111 13:22:11.885000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1526, value: _unsafe_view_13
V1111 13:22:11.885000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1527, value: view_48
V1111 13:22:11.885000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1528, value: split_with_sizes_8
V1111 13:22:11.885000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1529, value: expand_3
V1111 13:22:11.885000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1530, value: cat_6
V1111 13:22:11.885000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1531, value: transpose_11
V1111 13:22:11.885000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1532, value: transpose_12
V1111 13:22:11.886000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1533, value: transpose_13
V1111 13:22:11.886000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1534, value: new_zeros_26
V1111 13:22:11.886000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1536, value: sdpa_score2
V1111 13:22:11.886000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1537, value: transpose_14
V1111 13:22:11.886000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1538, value: view_49
V1111 13:22:11.886000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1539, value: t_18
V1111 13:22:11.886000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1540, value: view_50
V1111 13:22:11.886000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1541, value: mm_18
V1111 13:22:11.886000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1542, value: _unsafe_view_14
V1111 13:22:11.887000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1543, value: add_7
V1111 13:22:11.887000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1544, value: _fused_rms_norm_8
V1111 13:22:11.887000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1545, value: view_51
V1111 13:22:11.887000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1546, value: t_19
V1111 13:22:11.887000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1547, value: mm_19
V1111 13:22:11.887000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1548, value: _softmax_1
V1111 13:22:11.887000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1549, value: add_8
V1111 13:22:11.887000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1550, value: topk_1
V1111 13:22:11.887000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1551, value: gather_2
V1111 13:22:11.887000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1552, value: mul_12
V1111 13:22:11.888000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1553, value: view_55
V1111 13:22:11.888000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1554, value: index_2
V1111 13:22:11.888000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1555, value: gather_3
V1111 13:22:11.888000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1556, value: cat_7
V1111 13:22:11.888000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1557, value: index_3
V1111 13:22:11.888000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1558, value: _to_copy_10
V1111 13:22:11.888000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1559, value: _to_copy_11
V1111 13:22:11.888000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1560, value: transpose_15
V1111 13:22:11.888000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1561, value: _grouped_mm_3
V1111 13:22:11.888000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1562, value: silu_3
V1111 13:22:11.889000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1563, value: _to_copy_12
V1111 13:22:11.889000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1564, value: _to_copy_13
V1111 13:22:11.889000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1565, value: transpose_16
V1111 13:22:11.889000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1566, value: _grouped_mm_4
V1111 13:22:11.889000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1567, value: mul_14
V1111 13:22:11.889000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1568, value: _to_copy_14
V1111 13:22:11.889000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1569, value: transpose_17
V1111 13:22:11.889000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1570, value: _grouped_mm_5
V1111 13:22:11.889000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1571, value: _to_copy_15
V1111 13:22:11.889000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1572, value: index_put_1
V1111 13:22:11.890000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1573, value: slice_3
V1111 13:22:11.890000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1574, value: t_20
V1111 13:22:11.890000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1575, value: mm_20
V1111 13:22:11.890000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1576, value: silu_4
V1111 13:22:11.890000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1577, value: t_21
V1111 13:22:11.890000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1578, value: mm_21
V1111 13:22:11.890000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1579, value: mul_15
V1111 13:22:11.890000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1580, value: t_22
V1111 13:22:11.890000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1581, value: mm_22
V1111 13:22:11.890000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1582, value: view_58
V1111 13:22:11.890000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1583, value: mul_16
V1111 13:22:11.891000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1584, value: scatter_add_1
V1111 13:22:11.891000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1585, value: view_59
V1111 13:22:11.891000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1586, value: add_11
V1111 13:22:11.891000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1587, value: _fused_rms_norm_9
V1111 13:22:11.891000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1588, value: t_23
V1111 13:22:11.891000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1589, value: view_60
V1111 13:22:11.891000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1590, value: mm_23
V1111 13:22:11.891000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1591, value: _unsafe_view_15
V1111 13:22:11.891000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1592, value: view_61
V1111 13:22:11.891000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1593, value: split_with_sizes_9
V1111 13:22:11.892000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1594, value: view_62
V1111 13:22:11.892000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1595, value: view_as_complex_6
V1111 13:22:11.892000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1596, value: mul_17
V1111 13:22:11.892000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1597, value: view_as_real_6
V1111 13:22:11.892000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1598, value: view_64
V1111 13:22:11.892000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1599, value: cat_8
V1111 13:22:11.892000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1600, value: t_24
V1111 13:22:11.892000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1601, value: view_65
V1111 13:22:11.892000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1602, value: mm_24
V1111 13:22:11.892000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1603, value: _unsafe_view_16
V1111 13:22:11.893000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1604, value: split_with_sizes_10
V1111 13:22:11.893000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1605, value: unsqueeze_5
V1111 13:22:11.893000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1606, value: view_66
V1111 13:22:11.893000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1607, value: view_as_complex_7
V1111 13:22:11.893000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1608, value: mul_18
V1111 13:22:11.893000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1609, value: view_as_real_7
V1111 13:22:11.893000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1610, value: view_68
V1111 13:22:11.893000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1611, value: _fused_rms_norm_10
V1111 13:22:11.893000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1612, value: t_25
V1111 13:22:11.893000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1613, value: view_69
V1111 13:22:11.894000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1614, value: mm_25
V1111 13:22:11.894000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1615, value: _unsafe_view_17
V1111 13:22:11.894000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1616, value: view_70
V1111 13:22:11.894000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1617, value: split_with_sizes_11
V1111 13:22:11.894000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1618, value: expand_5
V1111 13:22:11.894000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1619, value: cat_9
V1111 13:22:11.894000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1620, value: transpose_18
V1111 13:22:11.894000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1621, value: transpose_19
V1111 13:22:11.894000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1622, value: transpose_20
V1111 13:22:11.895000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1623, value: new_zeros_37
V1111 13:22:11.895000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1625, value: sdpa_score3
V1111 13:22:11.895000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1626, value: transpose_21
V1111 13:22:11.895000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1627, value: view_71
V1111 13:22:11.895000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1628, value: t_26
V1111 13:22:11.895000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1629, value: view_72
V1111 13:22:11.895000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1630, value: mm_26
V1111 13:22:11.895000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1631, value: _unsafe_view_18
V1111 13:22:11.895000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1632, value: add_12
V1111 13:22:11.895000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1633, value: _fused_rms_norm_11
V1111 13:22:11.896000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1634, value: view_73
V1111 13:22:11.896000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1635, value: t_27
V1111 13:22:11.896000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1636, value: mm_27
V1111 13:22:11.896000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1637, value: _softmax_2
V1111 13:22:11.896000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1638, value: add_13
V1111 13:22:11.896000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1639, value: topk_2
V1111 13:22:11.896000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1640, value: gather_4
V1111 13:22:11.896000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1641, value: mul_19
V1111 13:22:11.896000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1642, value: view_77
V1111 13:22:11.896000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1643, value: index_4
V1111 13:22:11.897000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1644, value: gather_5
V1111 13:22:11.897000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1645, value: cat_10
V1111 13:22:11.897000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1646, value: index_5
V1111 13:22:11.897000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1647, value: _to_copy_18
V1111 13:22:11.897000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1648, value: _to_copy_19
V1111 13:22:11.897000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1649, value: transpose_22
V1111 13:22:11.897000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1650, value: _grouped_mm_6
V1111 13:22:11.897000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1651, value: silu_5
V1111 13:22:11.897000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1652, value: _to_copy_20
V1111 13:22:11.897000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1653, value: _to_copy_21
V1111 13:22:11.898000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1654, value: transpose_23
V1111 13:22:11.898000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1655, value: _grouped_mm_7
V1111 13:22:11.898000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1656, value: mul_21
V1111 13:22:11.898000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1657, value: _to_copy_22
V1111 13:22:11.898000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1658, value: transpose_24
V1111 13:22:11.898000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1659, value: _grouped_mm_8
V1111 13:22:11.898000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1660, value: _to_copy_23
V1111 13:22:11.898000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1661, value: index_put_2
V1111 13:22:11.898000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1662, value: slice_5
V1111 13:22:11.898000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1663, value: t_28
V1111 13:22:11.899000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1664, value: mm_28
V1111 13:22:11.899000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1665, value: silu_6
V1111 13:22:11.899000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1666, value: t_29
V1111 13:22:11.899000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1667, value: mm_29
V1111 13:22:11.899000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1668, value: mul_22
V1111 13:22:11.899000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1669, value: t_30
V1111 13:22:11.899000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1670, value: mm_30
V1111 13:22:11.899000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1671, value: view_80
V1111 13:22:11.899000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1672, value: mul_23
V1111 13:22:11.899000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1673, value: scatter_add_2
V1111 13:22:11.900000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1674, value: view_81
V1111 13:22:11.900000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1675, value: add_16
V1111 13:22:11.900000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1676, value: _fused_rms_norm_12
V1111 13:22:11.900000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1677, value: t_31
V1111 13:22:11.900000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1678, value: view_82
V1111 13:22:11.900000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1679, value: mm_31
V1111 13:22:11.900000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1680, value: _unsafe_view_19
V1111 13:22:11.900000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1681, value: view_83
V1111 13:22:11.900000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1682, value: split_with_sizes_12
V1111 13:22:11.900000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1683, value: view_84
V1111 13:22:11.901000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1684, value: view_as_complex_8
V1111 13:22:11.901000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1685, value: mul_24
V1111 13:22:11.901000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1686, value: view_as_real_8
V1111 13:22:11.901000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1687, value: view_86
V1111 13:22:11.901000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1688, value: cat_11
V1111 13:22:11.901000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1689, value: t_32
V1111 13:22:11.901000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1690, value: view_87
V1111 13:22:11.901000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1691, value: mm_32
V1111 13:22:11.901000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1692, value: _unsafe_view_20
V1111 13:22:11.901000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1693, value: split_with_sizes_13
V1111 13:22:11.902000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1694, value: unsqueeze_7
V1111 13:22:11.902000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1695, value: view_88
V1111 13:22:11.902000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1696, value: view_as_complex_9
V1111 13:22:11.902000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1697, value: mul_25
V1111 13:22:11.902000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1698, value: view_as_real_9
V1111 13:22:11.902000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1699, value: view_90
V1111 13:22:11.902000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1700, value: _fused_rms_norm_13
V1111 13:22:11.902000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1701, value: t_33
V1111 13:22:11.902000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1702, value: view_91
V1111 13:22:11.902000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1703, value: mm_33
V1111 13:22:11.903000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1704, value: _unsafe_view_21
V1111 13:22:11.903000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1705, value: view_92
V1111 13:22:11.903000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1706, value: split_with_sizes_14
V1111 13:22:11.903000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1707, value: expand_7
V1111 13:22:11.903000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1708, value: cat_12
V1111 13:22:11.903000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1709, value: transpose_25
V1111 13:22:11.903000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1710, value: transpose_26
V1111 13:22:11.903000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1711, value: transpose_27
V1111 13:22:11.903000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1712, value: new_zeros_48
V1111 13:22:11.903000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1714, value: sdpa_score4
V1111 13:22:11.904000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1715, value: transpose_28
V1111 13:22:11.904000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1716, value: view_93
V1111 13:22:11.904000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1717, value: t_34
V1111 13:22:11.904000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1718, value: view_94
V1111 13:22:11.904000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1719, value: mm_34
V1111 13:22:11.904000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1720, value: _unsafe_view_22
V1111 13:22:11.904000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1721, value: add_17
V1111 13:22:11.904000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1722, value: _fused_rms_norm_14
V1111 13:22:11.904000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1723, value: view_95
V1111 13:22:11.904000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1724, value: t_35
V1111 13:22:11.905000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1725, value: mm_35
V1111 13:22:11.905000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1726, value: _softmax_3
V1111 13:22:11.905000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1727, value: add_18
V1111 13:22:11.905000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1728, value: topk_3
V1111 13:22:11.905000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1729, value: gather_6
V1111 13:22:11.905000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1730, value: mul_26
V1111 13:22:11.905000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1731, value: view_99
V1111 13:22:11.905000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1732, value: index_6
V1111 13:22:11.905000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1733, value: gather_7
V1111 13:22:11.905000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1734, value: cat_13
V1111 13:22:11.906000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1735, value: index_7
V1111 13:22:11.906000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1736, value: _to_copy_26
V1111 13:22:11.906000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1737, value: _to_copy_27
V1111 13:22:11.906000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1738, value: transpose_29
V1111 13:22:11.906000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1739, value: _grouped_mm_9
V1111 13:22:11.906000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1740, value: silu_7
V1111 13:22:11.906000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1741, value: _to_copy_28
V1111 13:22:11.906000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1742, value: _to_copy_29
V1111 13:22:11.906000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1743, value: transpose_30
V1111 13:22:11.906000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1744, value: _grouped_mm_10
V1111 13:22:11.907000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1745, value: mul_28
V1111 13:22:11.907000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1746, value: _to_copy_30
V1111 13:22:11.907000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1747, value: transpose_31
V1111 13:22:11.907000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1748, value: _grouped_mm_11
V1111 13:22:11.907000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1749, value: _to_copy_31
V1111 13:22:11.907000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1750, value: index_put_3
V1111 13:22:11.907000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1751, value: slice_7
V1111 13:22:11.907000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1752, value: t_36
V1111 13:22:11.907000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1753, value: mm_36
V1111 13:22:11.907000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1754, value: silu_8
V1111 13:22:11.908000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1755, value: t_37
V1111 13:22:11.908000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1756, value: mm_37
V1111 13:22:11.908000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1757, value: mul_29
V1111 13:22:11.908000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1758, value: t_38
V1111 13:22:11.908000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1759, value: mm_38
V1111 13:22:11.908000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1760, value: view_102
V1111 13:22:11.908000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1761, value: mul_30
V1111 13:22:11.908000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1762, value: scatter_add_3
V1111 13:22:11.908000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1763, value: view_103
V1111 13:22:11.908000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1764, value: add_21
V1111 13:22:11.909000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1765, value: _fused_rms_norm_15
V1111 13:22:11.909000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1766, value: t_39
V1111 13:22:11.909000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1767, value: view_104
V1111 13:22:11.909000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1768, value: mm_39
V1111 13:22:11.909000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1769, value: _unsafe_view_23
V1111 13:22:11.909000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1770, value: view_105
V1111 13:22:11.909000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1771, value: split_with_sizes_15
V1111 13:22:11.909000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1772, value: view_106
V1111 13:22:11.909000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1773, value: view_as_complex_10
V1111 13:22:11.909000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1774, value: mul_31
V1111 13:22:11.910000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1775, value: view_as_real_10
V1111 13:22:11.910000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1776, value: view_108
V1111 13:22:11.910000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1777, value: cat_14
V1111 13:22:11.910000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1778, value: t_40
V1111 13:22:11.910000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1779, value: view_109
V1111 13:22:11.910000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1780, value: mm_40
V1111 13:22:11.910000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1781, value: _unsafe_view_24
V1111 13:22:11.910000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1782, value: split_with_sizes_16
V1111 13:22:11.910000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1783, value: unsqueeze_9
V1111 13:22:11.910000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1784, value: view_110
V1111 13:22:11.911000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1785, value: view_as_complex_11
V1111 13:22:11.911000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1786, value: mul_32
V1111 13:22:11.911000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1787, value: view_as_real_11
V1111 13:22:11.911000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1788, value: view_112
V1111 13:22:11.911000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1789, value: _fused_rms_norm_16
V1111 13:22:11.911000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1790, value: t_41
V1111 13:22:11.911000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1791, value: view_113
V1111 13:22:11.911000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1792, value: mm_41
V1111 13:22:11.911000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1793, value: _unsafe_view_25
V1111 13:22:11.911000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1794, value: view_114
V1111 13:22:11.912000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1795, value: split_with_sizes_17
V1111 13:22:11.912000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1796, value: expand_9
V1111 13:22:11.912000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1797, value: cat_15
V1111 13:22:11.912000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1798, value: transpose_32
V1111 13:22:11.912000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1799, value: transpose_33
V1111 13:22:11.912000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1800, value: transpose_34
V1111 13:22:11.912000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1801, value: new_zeros_59
V1111 13:22:11.912000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1803, value: sdpa_score5
V1111 13:22:11.912000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1804, value: transpose_35
V1111 13:22:11.912000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1805, value: view_115
V1111 13:22:11.913000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1806, value: t_42
V1111 13:22:11.913000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1807, value: view_116
V1111 13:22:11.913000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1808, value: mm_42
V1111 13:22:11.913000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1809, value: _unsafe_view_26
V1111 13:22:11.913000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1810, value: add_22
V1111 13:22:11.913000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1811, value: _fused_rms_norm_17
V1111 13:22:11.913000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1812, value: view_117
V1111 13:22:11.913000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1813, value: t_43
V1111 13:22:11.913000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1814, value: mm_43
V1111 13:22:11.913000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1815, value: _softmax_4
V1111 13:22:11.914000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1816, value: add_23
V1111 13:22:11.914000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1817, value: topk_4
V1111 13:22:11.914000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1818, value: gather_8
V1111 13:22:11.914000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1819, value: mul_33
V1111 13:22:11.914000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1820, value: view_121
V1111 13:22:11.914000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1821, value: index_8
V1111 13:22:11.914000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1822, value: gather_9
V1111 13:22:11.914000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1823, value: cat_16
V1111 13:22:11.914000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1824, value: index_9
V1111 13:22:11.914000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1825, value: _to_copy_34
V1111 13:22:11.915000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1826, value: _to_copy_35
V1111 13:22:11.915000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1827, value: transpose_36
V1111 13:22:11.915000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1828, value: _grouped_mm_12
V1111 13:22:11.915000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1829, value: silu_9
V1111 13:22:11.915000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1830, value: _to_copy_36
V1111 13:22:11.915000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1831, value: _to_copy_37
V1111 13:22:11.915000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1832, value: transpose_37
V1111 13:22:11.915000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1833, value: _grouped_mm_13
V1111 13:22:11.915000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1834, value: mul_35
V1111 13:22:11.915000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1835, value: _to_copy_38
V1111 13:22:11.916000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1836, value: transpose_38
V1111 13:22:11.916000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1837, value: _grouped_mm_14
V1111 13:22:11.916000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1838, value: _to_copy_39
V1111 13:22:11.916000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1839, value: index_put_4
V1111 13:22:11.916000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1840, value: slice_9
V1111 13:22:11.916000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1841, value: t_44
V1111 13:22:11.916000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1842, value: mm_44
V1111 13:22:11.916000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1843, value: silu_10
V1111 13:22:11.916000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1844, value: t_45
V1111 13:22:11.916000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1845, value: mm_45
V1111 13:22:11.917000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1846, value: mul_36
V1111 13:22:11.917000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1847, value: t_46
V1111 13:22:11.917000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1848, value: mm_46
V1111 13:22:11.917000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1849, value: view_124
V1111 13:22:11.917000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1850, value: mul_37
V1111 13:22:11.917000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1851, value: scatter_add_4
V1111 13:22:11.917000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1852, value: view_125
V1111 13:22:11.917000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1853, value: add_26
V1111 13:22:11.917000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1854, value: _fused_rms_norm_18
V1111 13:22:11.917000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1855, value: t_47
V1111 13:22:11.918000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1856, value: view_126
V1111 13:22:11.918000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1857, value: mm_47
V1111 13:22:11.918000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1858, value: _unsafe_view_27
V1111 13:22:11.918000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1384, value: index
V1111 13:22:11.918000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1446, value: index
V1111 13:22:11.918000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1535, value: index
V1111 13:22:11.918000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1624, value: index
V1111 13:22:11.918000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1713, value: index
V1111 13:22:11.918000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1802, value: index
V1111 13:22:11.918000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1859, value: index
V1111 13:22:11.919000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1860, value: index_1
V1111 13:22:11.919000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1861, value: index
V1111 13:22:11.919000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1862, value: index_1
V1111 13:22:11.919000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1863, value: index
V1111 13:22:11.919000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1864, value: index_1
V1111 13:22:11.919000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1865, value: index
V1111 13:22:11.919000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1866, value: index_1
V1111 13:22:11.919000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1867, value: index
V1111 13:22:11.919000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1868, value: index_1
V1111 13:22:11.919000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1869, value: index
V1111 13:22:11.920000 86039 torch/_functorch/_aot_autograd/utils.py:498] [__annotation] forward:: key: 1870, value: index_1
V1111 13:22:11.920000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_1
V1111 13:22:11.920000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.920000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_2
V1111 13:22:11.920000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.920000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_3
V1111 13:22:11.921000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.921000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_4
V1111 13:22:11.921000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.921000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_5
V1111 13:22:11.921000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.921000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_6
V1111 13:22:11.921000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.921000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_7
V1111 13:22:11.921000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.921000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_8
V1111 13:22:11.922000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.922000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_9
V1111 13:22:11.922000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.922000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_10
V1111 13:22:11.922000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.922000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_11
V1111 13:22:11.922000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.922000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_12
V1111 13:22:11.922000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.922000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_13
V1111 13:22:11.923000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.923000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_14
V1111 13:22:11.923000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.923000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_15
V1111 13:22:11.923000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.923000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_16
V1111 13:22:11.923000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.923000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_17
V1111 13:22:11.923000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.924000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_18
V1111 13:22:11.924000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.924000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_19
V1111 13:22:11.924000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.924000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_20
V1111 13:22:11.924000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.924000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_21
V1111 13:22:11.924000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.924000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_22
V1111 13:22:11.924000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.925000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_23
V1111 13:22:11.925000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.925000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_24
V1111 13:22:11.925000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.925000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_25
V1111 13:22:11.925000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.925000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_26
V1111 13:22:11.925000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.925000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_27
V1111 13:22:11.925000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.926000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_28
V1111 13:22:11.926000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.926000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_29
V1111 13:22:11.926000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.926000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_30
V1111 13:22:11.926000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.926000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_31
V1111 13:22:11.926000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.926000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_32
V1111 13:22:11.926000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.927000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_33
V1111 13:22:11.927000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.927000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_34
V1111 13:22:11.927000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.927000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_35
V1111 13:22:11.927000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.927000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_36
V1111 13:22:11.927000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.927000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_37
V1111 13:22:11.928000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.928000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_38
V1111 13:22:11.928000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.928000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_39
V1111 13:22:11.928000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.928000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_40
V1111 13:22:11.928000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.928000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_41
V1111 13:22:11.928000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.928000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_42
V1111 13:22:11.929000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.929000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_43
V1111 13:22:11.929000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.929000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_44
V1111 13:22:11.929000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.929000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_45
V1111 13:22:11.929000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.929000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_46
V1111 13:22:11.929000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.929000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_47
V1111 13:22:11.930000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.930000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_48
V1111 13:22:11.930000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.930000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_49
V1111 13:22:11.930000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.930000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_50
V1111 13:22:11.930000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.930000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_51
V1111 13:22:11.930000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.930000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_52
V1111 13:22:11.931000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.931000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_53
V1111 13:22:11.931000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.931000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_54
V1111 13:22:11.931000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.931000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_55
V1111 13:22:11.931000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.931000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_56
V1111 13:22:11.931000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.931000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_57
V1111 13:22:11.932000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.932000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_58
V1111 13:22:11.932000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.932000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_59
V1111 13:22:11.932000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.932000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_60
V1111 13:22:11.932000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.932000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_61
V1111 13:22:11.932000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.932000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_62
V1111 13:22:11.933000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.933000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_63
V1111 13:22:11.933000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.933000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_64
V1111 13:22:11.933000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.933000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_65
V1111 13:22:11.933000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.933000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_66
V1111 13:22:11.933000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.934000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_67
V1111 13:22:11.934000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.934000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_68
V1111 13:22:11.934000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.934000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_69
V1111 13:22:11.934000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.934000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_70
V1111 13:22:11.934000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.934000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_71
V1111 13:22:11.934000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.935000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_72
V1111 13:22:11.935000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.935000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_73
V1111 13:22:11.935000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.935000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_74
V1111 13:22:11.935000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.935000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_75
V1111 13:22:11.935000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.935000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_76
V1111 13:22:11.935000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.936000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_77
V1111 13:22:11.936000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.936000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_78
V1111 13:22:11.936000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.936000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_79
V1111 13:22:11.936000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.936000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_80
V1111 13:22:11.936000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.936000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_81
V1111 13:22:11.936000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.937000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_82
V1111 13:22:11.937000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.937000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_83
V1111 13:22:11.937000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.937000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_84
V1111 13:22:11.937000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.937000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_85
V1111 13:22:11.937000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.937000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_86
V1111 13:22:11.937000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.938000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_87
V1111 13:22:11.938000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.938000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_88
V1111 13:22:11.938000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.938000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_89
V1111 13:22:11.938000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.938000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_90
V1111 13:22:11.938000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.938000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_91
V1111 13:22:11.939000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.939000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_92
V1111 13:22:11.939000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.939000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_93
V1111 13:22:11.939000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.939000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_94
V1111 13:22:11.939000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.939000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_95
V1111 13:22:11.939000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.939000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_96
V1111 13:22:11.940000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.940000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_97
V1111 13:22:11.940000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.940000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_98
V1111 13:22:11.940000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.940000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_99
V1111 13:22:11.940000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.940000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_100
V1111 13:22:11.940000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.940000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_101
V1111 13:22:11.941000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.941000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_102
V1111 13:22:11.941000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.941000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: primals_103
V1111 13:22:11.941000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.941000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: tangents_1
V1111 13:22:11.941000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:11.941000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: embedding
V1111 13:22:11.941000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1346
V1111 13:22:11.942000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm
V1111 13:22:11.942000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1347
V1111 13:22:11.942000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem
V1111 13:22:11.942000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1347
V1111 13:22:11.942000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_1
V1111 13:22:11.943000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1347
V1111 13:22:11.943000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach
V1111 13:22:11.943000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1347
V1111 13:22:11.943000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t
V1111 13:22:11.943000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1348
V1111 13:22:11.943000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view
V1111 13:22:11.943000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1349
V1111 13:22:11.943000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm
V1111 13:22:11.943000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1350
V1111 13:22:11.943000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view
V1111 13:22:11.944000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1351
V1111 13:22:11.944000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_1
V1111 13:22:11.944000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1352
V1111 13:22:11.944000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: split_with_sizes
V1111 13:22:11.944000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1353
V1111 13:22:11.944000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_2
V1111 13:22:11.944000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1353
V1111 13:22:11.944000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_3
V1111 13:22:11.944000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1353
V1111 13:22:11.944000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_2
V1111 13:22:11.945000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1354
V1111 13:22:11.945000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_complex
V1111 13:22:11.945000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1355
V1111 13:22:11.945000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_3
V1111 13:22:11.945000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1355
V1111 13:22:11.945000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul
V1111 13:22:11.945000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1356
V1111 13:22:11.945000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_real
V1111 13:22:11.945000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1357
V1111 13:22:11.945000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_4
V1111 13:22:11.946000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1358
V1111 13:22:11.946000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat
V1111 13:22:11.946000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1359
V1111 13:22:11.946000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_1
V1111 13:22:11.946000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1360
V1111 13:22:11.946000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_5
V1111 13:22:11.946000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1361
V1111 13:22:11.946000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_1
V1111 13:22:11.946000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1362
V1111 13:22:11.946000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_1
V1111 13:22:11.947000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1363
V1111 13:22:11.947000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: split_with_sizes_1
V1111 13:22:11.947000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1364
V1111 13:22:11.947000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_4
V1111 13:22:11.947000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1364
V1111 13:22:11.947000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_5
V1111 13:22:11.947000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1364
V1111 13:22:11.947000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: unsqueeze
V1111 13:22:11.947000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1365
V1111 13:22:11.948000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_6
V1111 13:22:11.948000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1366
V1111 13:22:11.948000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_complex_1
V1111 13:22:11.948000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1367
V1111 13:22:11.948000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_7
V1111 13:22:11.948000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1367
V1111 13:22:11.948000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_1
V1111 13:22:11.948000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1368
V1111 13:22:11.948000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_real_1
V1111 13:22:11.948000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1369
V1111 13:22:11.949000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_8
V1111 13:22:11.949000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1370
V1111 13:22:11.949000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_1
V1111 13:22:11.949000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1371
V1111 13:22:11.949000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_6
V1111 13:22:11.949000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1371
V1111 13:22:11.949000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_7
V1111 13:22:11.949000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1371
V1111 13:22:11.949000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_1
V1111 13:22:11.949000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1371
V1111 13:22:11.950000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_2
V1111 13:22:11.950000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1372
V1111 13:22:11.950000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_9
V1111 13:22:11.950000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1373
V1111 13:22:11.950000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_2
V1111 13:22:11.950000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1374
V1111 13:22:11.950000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_2
V1111 13:22:11.950000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1375
V1111 13:22:11.950000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_10
V1111 13:22:11.950000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1376
V1111 13:22:11.951000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: split_with_sizes_2
V1111 13:22:11.951000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1377
V1111 13:22:11.951000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_8
V1111 13:22:11.951000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1377
V1111 13:22:11.951000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_9
V1111 13:22:11.951000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1377
V1111 13:22:11.951000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: expand
V1111 13:22:11.951000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1378
V1111 13:22:11.951000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_1
V1111 13:22:11.951000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1379
V1111 13:22:11.952000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose
V1111 13:22:11.952000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1380
V1111 13:22:11.952000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_1
V1111 13:22:11.952000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1381
V1111 13:22:11.952000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_2
V1111 13:22:11.952000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1382
V1111 13:22:11.952000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros
V1111 13:22:11.952000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1382
V1111 13:22:11.952000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_1
V1111 13:22:11.953000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1382
V1111 13:22:11.953000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_2
V1111 13:22:11.953000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1382
V1111 13:22:11.953000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_3
V1111 13:22:11.953000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1382
V1111 13:22:11.953000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_4
V1111 13:22:11.953000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1382
V1111 13:22:11.953000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_5
V1111 13:22:11.953000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:11.953000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_6
V1111 13:22:11.954000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:11.954000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_7
V1111 13:22:11.954000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:11.954000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_8
V1111 13:22:11.954000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:11.954000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_9
V1111 13:22:11.954000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:11.954000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sdpa_score0
V1111 13:22:11.954000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1385
V1111 13:22:11.954000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sdpa_mask0
V1111 13:22:11.955000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1385
V1111 13:22:11.955000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _tensor_constant0
V1111 13:22:11.955000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1385
V1111 13:22:11.955000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: flex_attention
V1111 13:22:11.955000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1385
V1111 13:22:11.955000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_10
V1111 13:22:11.955000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1385
V1111 13:22:11.955000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_11
V1111 13:22:11.955000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1385
V1111 13:22:11.955000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_12
V1111 13:22:11.956000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1385
V1111 13:22:11.956000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_2
V1111 13:22:11.956000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1385
V1111 13:22:11.956000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_3
V1111 13:22:11.956000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1385
V1111 13:22:11.956000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_3
V1111 13:22:11.956000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1386
V1111 13:22:11.956000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_11
V1111 13:22:11.956000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1387
V1111 13:22:11.956000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_3
V1111 13:22:11.957000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1388
V1111 13:22:11.957000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_12
V1111 13:22:11.957000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1389
V1111 13:22:11.957000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_3
V1111 13:22:11.957000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1390
V1111 13:22:11.957000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_3
V1111 13:22:11.957000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1391
V1111 13:22:11.957000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add
V1111 13:22:11.957000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1392
V1111 13:22:11.958000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_2
V1111 13:22:11.958000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1393
V1111 13:22:11.958000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_13
V1111 13:22:11.958000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1393
V1111 13:22:11.958000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_14
V1111 13:22:11.958000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1393
V1111 13:22:11.958000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_4
V1111 13:22:11.958000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1393
V1111 13:22:11.958000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_4
V1111 13:22:11.958000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1394
V1111 13:22:11.959000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_13
V1111 13:22:11.959000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1395
V1111 13:22:11.959000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_4
V1111 13:22:11.959000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1396
V1111 13:22:11.959000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_4
V1111 13:22:11.959000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1397
V1111 13:22:11.959000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: silu
V1111 13:22:11.959000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1398
V1111 13:22:11.959000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_5
V1111 13:22:11.959000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1399
V1111 13:22:11.960000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_14
V1111 13:22:11.960000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1400
V1111 13:22:11.960000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_5
V1111 13:22:11.960000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1401
V1111 13:22:11.960000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_5
V1111 13:22:11.960000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1402
V1111 13:22:11.960000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_2
V1111 13:22:11.960000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1403
V1111 13:22:11.960000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_6
V1111 13:22:11.960000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1404
V1111 13:22:11.961000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_15
V1111 13:22:11.961000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1405
V1111 13:22:11.961000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_6
V1111 13:22:11.961000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1406
V1111 13:22:11.961000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_6
V1111 13:22:11.961000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1407
V1111 13:22:11.961000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_1
V1111 13:22:11.961000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1408
V1111 13:22:11.961000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_3
V1111 13:22:11.961000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1409
V1111 13:22:11.962000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_15
V1111 13:22:11.962000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1409
V1111 13:22:11.962000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_16
V1111 13:22:11.962000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1409
V1111 13:22:11.962000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_5
V1111 13:22:11.962000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1409
V1111 13:22:11.962000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_7
V1111 13:22:11.962000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1410
V1111 13:22:11.962000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_16
V1111 13:22:11.962000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1411
V1111 13:22:11.963000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_7
V1111 13:22:11.963000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1412
V1111 13:22:11.963000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_7
V1111 13:22:11.963000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1413
V1111 13:22:11.963000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_17
V1111 13:22:11.963000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1414
V1111 13:22:11.963000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: split_with_sizes_3
V1111 13:22:11.963000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1415
V1111 13:22:11.964000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_17
V1111 13:22:11.964000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1415
V1111 13:22:11.964000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_18
V1111 13:22:11.964000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1415
V1111 13:22:11.964000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_18
V1111 13:22:11.964000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1416
V1111 13:22:11.964000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_complex_2
V1111 13:22:11.964000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1417
V1111 13:22:11.964000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_19
V1111 13:22:11.964000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1417
V1111 13:22:11.965000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_3
V1111 13:22:11.965000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1418
V1111 13:22:11.965000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_real_2
V1111 13:22:11.965000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1419
V1111 13:22:11.965000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_20
V1111 13:22:11.965000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1420
V1111 13:22:11.965000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_2
V1111 13:22:11.965000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1421
V1111 13:22:11.965000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_8
V1111 13:22:11.966000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1422
V1111 13:22:11.966000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_21
V1111 13:22:11.966000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1423
V1111 13:22:11.966000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_8
V1111 13:22:11.966000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1424
V1111 13:22:11.966000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_8
V1111 13:22:11.966000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1425
V1111 13:22:11.966000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: split_with_sizes_4
V1111 13:22:11.966000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1426
V1111 13:22:11.966000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_19
V1111 13:22:11.967000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1426
V1111 13:22:11.967000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_20
V1111 13:22:11.967000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1426
V1111 13:22:11.967000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: unsqueeze_1
V1111 13:22:11.967000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1427
V1111 13:22:11.967000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_22
V1111 13:22:11.967000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1428
V1111 13:22:11.967000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_complex_3
V1111 13:22:11.967000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1429
V1111 13:22:11.967000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_23
V1111 13:22:11.968000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1429
V1111 13:22:11.968000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_4
V1111 13:22:11.968000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1430
V1111 13:22:11.968000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_real_3
V1111 13:22:11.968000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1431
V1111 13:22:11.968000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_24
V1111 13:22:11.968000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1432
V1111 13:22:11.968000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_4
V1111 13:22:11.968000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1433
V1111 13:22:11.968000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_21
V1111 13:22:11.969000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1433
V1111 13:22:11.969000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_22
V1111 13:22:11.969000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1433
V1111 13:22:11.969000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_6
V1111 13:22:11.969000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1433
V1111 13:22:11.969000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_9
V1111 13:22:11.969000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1434
V1111 13:22:11.969000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_25
V1111 13:22:11.969000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1435
V1111 13:22:11.969000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_9
V1111 13:22:11.970000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1436
V1111 13:22:11.970000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_9
V1111 13:22:11.970000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1437
V1111 13:22:11.970000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_26
V1111 13:22:11.970000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1438
V1111 13:22:11.970000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: split_with_sizes_5
V1111 13:22:11.970000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1439
V1111 13:22:11.970000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_23
V1111 13:22:11.970000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1439
V1111 13:22:11.970000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_24
V1111 13:22:11.971000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1439
V1111 13:22:11.971000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: expand_1
V1111 13:22:11.971000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1440
V1111 13:22:11.971000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_3
V1111 13:22:11.971000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1441
V1111 13:22:11.971000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_4
V1111 13:22:11.971000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1442
V1111 13:22:11.971000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_5
V1111 13:22:11.971000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1443
V1111 13:22:11.971000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_6
V1111 13:22:11.972000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1444
V1111 13:22:11.972000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_10
V1111 13:22:11.972000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1444
V1111 13:22:11.972000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_11
V1111 13:22:11.972000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1444
V1111 13:22:11.972000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_12
V1111 13:22:11.972000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1444
V1111 13:22:11.972000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_13
V1111 13:22:11.972000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1444
V1111 13:22:11.972000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_14
V1111 13:22:11.973000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1444
V1111 13:22:11.973000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_15
V1111 13:22:11.973000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:11.973000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_16
V1111 13:22:11.973000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:11.973000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_17
V1111 13:22:11.973000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:11.973000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_18
V1111 13:22:11.973000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:11.973000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_19
V1111 13:22:11.974000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:11.974000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sdpa_score1
V1111 13:22:11.974000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1447
V1111 13:22:11.974000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sdpa_mask1
V1111 13:22:11.974000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1447
V1111 13:22:11.974000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _tensor_constant0_1
V1111 13:22:11.974000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1447
V1111 13:22:11.974000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: flex_attention_1
V1111 13:22:11.974000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1447
V1111 13:22:11.974000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_25
V1111 13:22:11.975000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1447
V1111 13:22:11.975000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_26
V1111 13:22:11.975000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1447
V1111 13:22:11.975000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_27
V1111 13:22:11.975000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1447
V1111 13:22:11.975000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_7
V1111 13:22:11.975000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1447
V1111 13:22:11.975000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_8
V1111 13:22:11.975000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1447
V1111 13:22:11.976000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_7
V1111 13:22:11.976000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1448
V1111 13:22:11.976000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_27
V1111 13:22:11.976000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1449
V1111 13:22:11.976000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_10
V1111 13:22:11.976000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1450
V1111 13:22:11.976000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_28
V1111 13:22:11.976000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1451
V1111 13:22:11.976000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_10
V1111 13:22:11.976000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1452
V1111 13:22:11.977000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_10
V1111 13:22:11.977000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1453
V1111 13:22:11.977000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_2
V1111 13:22:11.977000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1454
V1111 13:22:11.977000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_5
V1111 13:22:11.977000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1455
V1111 13:22:11.977000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_28
V1111 13:22:11.977000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1455
V1111 13:22:11.977000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_29
V1111 13:22:11.977000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1455
V1111 13:22:11.978000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_9
V1111 13:22:11.978000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1455
V1111 13:22:11.978000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_29
V1111 13:22:11.978000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1456
V1111 13:22:11.978000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_11
V1111 13:22:11.978000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1457
V1111 13:22:11.978000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_11
V1111 13:22:11.978000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1458
V1111 13:22:11.978000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _softmax
V1111 13:22:11.978000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1459
V1111 13:22:11.979000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_10
V1111 13:22:11.979000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1459
V1111 13:22:11.979000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_3
V1111 13:22:11.979000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1460
V1111 13:22:11.979000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: topk
V1111 13:22:11.979000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1461
V1111 13:22:11.979000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_30
V1111 13:22:11.979000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1461
V1111 13:22:11.979000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_31
V1111 13:22:11.979000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1461
V1111 13:22:11.980000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: gather
V1111 13:22:11.980000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1462
V1111 13:22:11.980000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_5
V1111 13:22:11.980000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1463
V1111 13:22:11.980000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_30
V1111 13:22:11.980000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1463
V1111 13:22:11.980000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: histc
V1111 13:22:11.980000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1463
V1111 13:22:11.980000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_4
V1111 13:22:11.980000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1463
V1111 13:22:11.981000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_31
V1111 13:22:11.981000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1463
V1111 13:22:11.981000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: histc_1
V1111 13:22:11.981000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1463
V1111 13:22:11.981000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_32
V1111 13:22:11.981000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1463
V1111 13:22:11.981000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sort
V1111 13:22:11.981000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1463
V1111 13:22:11.981000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_32
V1111 13:22:11.981000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1463
V1111 13:22:11.982000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_33
V1111 13:22:11.982000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1463
V1111 13:22:11.982000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_33
V1111 13:22:11.982000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1464
V1111 13:22:11.982000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index
V1111 13:22:11.982000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1465
V1111 13:22:11.982000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: floor_divide
V1111 13:22:11.982000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1465
V1111 13:22:11.982000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_34
V1111 13:22:11.982000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1465
V1111 13:22:11.983000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: expand_2
V1111 13:22:11.983000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1465
V1111 13:22:11.983000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: gather_1
V1111 13:22:11.983000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1466
V1111 13:22:11.983000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cumsum
V1111 13:22:11.983000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1466
V1111 13:22:11.983000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sub
V1111 13:22:11.983000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1466
V1111 13:22:11.983000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_35
V1111 13:22:11.983000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1466
V1111 13:22:11.984000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sum_1
V1111 13:22:11.984000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1466
V1111 13:22:11.984000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: clamp_min
V1111 13:22:11.984000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1466
V1111 13:22:11.984000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_5
V1111 13:22:11.984000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1466
V1111 13:22:11.984000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sub_1
V1111 13:22:11.984000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1466
V1111 13:22:11.984000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: floor_divide_1
V1111 13:22:11.984000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1466
V1111 13:22:11.985000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_6
V1111 13:22:11.985000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1466
V1111 13:22:11.985000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy
V1111 13:22:11.985000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1466
V1111 13:22:11.985000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cumsum_1
V1111 13:22:11.985000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1466
V1111 13:22:11.985000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sub_2
V1111 13:22:11.985000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1466
V1111 13:22:11.985000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: full
V1111 13:22:11.985000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1466
V1111 13:22:11.986000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: triton_kernel_wrapper_functional_proxy
V1111 13:22:11.986000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1466
V1111 13:22:11.986000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_34
V1111 13:22:11.986000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1466
V1111 13:22:11.986000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_1
V1111 13:22:11.986000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1466
V1111 13:22:11.986000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_20
V1111 13:22:11.986000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1466
V1111 13:22:11.986000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: unsqueeze_2
V1111 13:22:11.987000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1466
V1111 13:22:11.987000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_4
V1111 13:22:11.987000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1467
V1111 13:22:11.987000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_1
V1111 13:22:11.987000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1468
V1111 13:22:11.987000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cumsum_2
V1111 13:22:11.987000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1468
V1111 13:22:11.987000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_2
V1111 13:22:11.987000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1469
V1111 13:22:11.987000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_3
V1111 13:22:11.988000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1470
V1111 13:22:11.988000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_8
V1111 13:22:11.988000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1471
V1111 13:22:11.988000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm
V1111 13:22:11.988000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1472
V1111 13:22:11.988000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: silu_1
V1111 13:22:11.988000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1473
V1111 13:22:11.988000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_4
V1111 13:22:11.988000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1474
V1111 13:22:11.988000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_5
V1111 13:22:11.989000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1475
V1111 13:22:11.989000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_9
V1111 13:22:11.989000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1476
V1111 13:22:11.989000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_1
V1111 13:22:11.989000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1477
V1111 13:22:11.989000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_7
V1111 13:22:11.989000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1478
V1111 13:22:11.989000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_6
V1111 13:22:11.989000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1479
V1111 13:22:11.989000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_10
V1111 13:22:11.990000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1480
V1111 13:22:11.990000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_2
V1111 13:22:11.990000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1481
V1111 13:22:11.990000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_7
V1111 13:22:11.990000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1482
V1111 13:22:11.990000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_empty
V1111 13:22:11.990000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1482
V1111 13:22:11.990000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_put
V1111 13:22:11.990000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1483
V1111 13:22:11.990000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_1
V1111 13:22:11.991000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1484
V1111 13:22:11.991000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_12
V1111 13:22:11.991000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1485
V1111 13:22:11.991000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_12
V1111 13:22:11.991000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1486
V1111 13:22:11.991000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: silu_2
V1111 13:22:11.991000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1487
V1111 13:22:11.991000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_13
V1111 13:22:11.991000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1488
V1111 13:22:11.991000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_13
V1111 13:22:11.992000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1489
V1111 13:22:11.992000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_8
V1111 13:22:11.992000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1490
V1111 13:22:11.992000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_14
V1111 13:22:11.992000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1491
V1111 13:22:11.992000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_14
V1111 13:22:11.992000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1492
V1111 13:22:11.992000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_36
V1111 13:22:11.992000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1493
V1111 13:22:11.992000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_2
V1111 13:22:11.993000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1484
V1111 13:22:11.993000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_9
V1111 13:22:11.993000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1494
V1111 13:22:11.993000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: scatter_add
V1111 13:22:11.993000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1495
V1111 13:22:11.993000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_37
V1111 13:22:11.993000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1496
V1111 13:22:11.993000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_6
V1111 13:22:11.993000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1497
V1111 13:22:11.993000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_6
V1111 13:22:11.994000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1498
V1111 13:22:11.994000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_35
V1111 13:22:11.994000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1498
V1111 13:22:11.994000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_36
V1111 13:22:11.994000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1498
V1111 13:22:11.994000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_11
V1111 13:22:11.994000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1498
V1111 13:22:11.994000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_15
V1111 13:22:11.994000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1499
V1111 13:22:11.994000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_38
V1111 13:22:11.995000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1500
V1111 13:22:11.995000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_15
V1111 13:22:11.995000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1501
V1111 13:22:11.995000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_11
V1111 13:22:11.995000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1502
V1111 13:22:11.995000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_39
V1111 13:22:11.995000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1503
V1111 13:22:11.995000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: split_with_sizes_6
V1111 13:22:11.995000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1504
V1111 13:22:11.995000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_37
V1111 13:22:11.996000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1504
V1111 13:22:11.996000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_38
V1111 13:22:11.996000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1504
V1111 13:22:11.996000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_40
V1111 13:22:11.996000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1505
V1111 13:22:11.996000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_complex_4
V1111 13:22:11.996000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1506
V1111 13:22:11.996000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_41
V1111 13:22:11.996000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1506
V1111 13:22:11.997000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_10
V1111 13:22:11.997000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1507
V1111 13:22:11.997000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_real_4
V1111 13:22:11.997000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1508
V1111 13:22:11.997000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_42
V1111 13:22:11.997000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1509
V1111 13:22:11.997000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_5
V1111 13:22:11.997000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1510
V1111 13:22:11.997000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_16
V1111 13:22:11.997000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1511
V1111 13:22:11.998000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_43
V1111 13:22:11.998000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1512
V1111 13:22:11.998000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_16
V1111 13:22:11.998000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1513
V1111 13:22:11.998000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_12
V1111 13:22:11.998000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1514
V1111 13:22:11.998000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: split_with_sizes_7
V1111 13:22:11.998000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1515
V1111 13:22:11.998000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_39
V1111 13:22:11.998000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1515
V1111 13:22:11.999000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_40
V1111 13:22:11.999000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1515
V1111 13:22:11.999000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: unsqueeze_3
V1111 13:22:11.999000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1516
V1111 13:22:11.999000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_44
V1111 13:22:11.999000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1517
V1111 13:22:11.999000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_complex_5
V1111 13:22:11.999000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1518
V1111 13:22:11.999000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_45
V1111 13:22:11.999000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1518
V1111 13:22:12.000000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_11
V1111 13:22:12.000000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1519
V1111 13:22:12.000000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_real_5
V1111 13:22:12.000000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1520
V1111 13:22:12.000000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_46
V1111 13:22:12.000000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1521
V1111 13:22:12.000000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_7
V1111 13:22:12.000000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1522
V1111 13:22:12.000000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_41
V1111 13:22:12.000000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1522
V1111 13:22:12.001000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_42
V1111 13:22:12.001000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1522
V1111 13:22:12.001000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_12
V1111 13:22:12.001000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1522
V1111 13:22:12.001000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_17
V1111 13:22:12.001000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1523
V1111 13:22:12.001000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_47
V1111 13:22:12.001000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1524
V1111 13:22:12.001000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_17
V1111 13:22:12.001000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1525
V1111 13:22:12.002000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_13
V1111 13:22:12.002000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1526
V1111 13:22:12.002000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_48
V1111 13:22:12.002000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1527
V1111 13:22:12.002000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: split_with_sizes_8
V1111 13:22:12.002000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1528
V1111 13:22:12.002000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_43
V1111 13:22:12.002000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1528
V1111 13:22:12.002000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_44
V1111 13:22:12.002000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1528
V1111 13:22:12.003000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: expand_3
V1111 13:22:12.003000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1529
V1111 13:22:12.003000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_6
V1111 13:22:12.003000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1530
V1111 13:22:12.003000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_11
V1111 13:22:12.003000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1531
V1111 13:22:12.003000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_12
V1111 13:22:12.003000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1532
V1111 13:22:12.003000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_13
V1111 13:22:12.003000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1533
V1111 13:22:12.004000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_21
V1111 13:22:12.004000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1533
V1111 13:22:12.004000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_22
V1111 13:22:12.004000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1533
V1111 13:22:12.004000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_23
V1111 13:22:12.004000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1533
V1111 13:22:12.004000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_24
V1111 13:22:12.004000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1533
V1111 13:22:12.004000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_25
V1111 13:22:12.004000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1533
V1111 13:22:12.005000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_26
V1111 13:22:12.005000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.005000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_27
V1111 13:22:12.005000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.005000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_28
V1111 13:22:12.005000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.005000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_29
V1111 13:22:12.005000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.005000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_30
V1111 13:22:12.005000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.006000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sdpa_score2
V1111 13:22:12.006000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1536
V1111 13:22:12.006000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sdpa_mask2
V1111 13:22:12.006000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1536
V1111 13:22:12.006000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _tensor_constant0_2
V1111 13:22:12.006000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1536
V1111 13:22:12.006000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: flex_attention_2
V1111 13:22:12.006000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1536
V1111 13:22:12.006000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_45
V1111 13:22:12.007000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1536
V1111 13:22:12.007000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_46
V1111 13:22:12.007000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1536
V1111 13:22:12.007000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_47
V1111 13:22:12.007000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1536
V1111 13:22:12.007000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_13
V1111 13:22:12.007000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1536
V1111 13:22:12.007000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_14
V1111 13:22:12.007000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1536
V1111 13:22:12.007000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_14
V1111 13:22:12.008000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1537
V1111 13:22:12.008000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_49
V1111 13:22:12.008000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1538
V1111 13:22:12.008000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_18
V1111 13:22:12.008000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1539
V1111 13:22:12.008000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_50
V1111 13:22:12.008000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1540
V1111 13:22:12.008000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_18
V1111 13:22:12.008000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1541
V1111 13:22:12.008000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_14
V1111 13:22:12.009000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1542
V1111 13:22:12.009000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_7
V1111 13:22:12.009000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1543
V1111 13:22:12.009000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_8
V1111 13:22:12.009000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1544
V1111 13:22:12.009000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_48
V1111 13:22:12.009000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1544
V1111 13:22:12.009000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_49
V1111 13:22:12.009000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1544
V1111 13:22:12.010000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_15
V1111 13:22:12.010000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1544
V1111 13:22:12.010000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_51
V1111 13:22:12.010000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1545
V1111 13:22:12.010000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_19
V1111 13:22:12.010000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1546
V1111 13:22:12.010000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_19
V1111 13:22:12.010000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1547
V1111 13:22:12.010000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _softmax_1
V1111 13:22:12.010000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1548
V1111 13:22:12.011000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_16
V1111 13:22:12.011000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1548
V1111 13:22:12.011000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_8
V1111 13:22:12.011000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1549
V1111 13:22:12.011000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: topk_1
V1111 13:22:12.011000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1550
V1111 13:22:12.011000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_50
V1111 13:22:12.011000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1550
V1111 13:22:12.011000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_51
V1111 13:22:12.011000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1550
V1111 13:22:12.012000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: gather_2
V1111 13:22:12.012000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1551
V1111 13:22:12.012000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_12
V1111 13:22:12.012000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1552
V1111 13:22:12.012000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_52
V1111 13:22:12.012000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1552
V1111 13:22:12.012000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: histc_2
V1111 13:22:12.012000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1552
V1111 13:22:12.012000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_9
V1111 13:22:12.012000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1552
V1111 13:22:12.013000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_53
V1111 13:22:12.013000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1552
V1111 13:22:12.013000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: histc_3
V1111 13:22:12.013000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1552
V1111 13:22:12.013000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_54
V1111 13:22:12.013000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1552
V1111 13:22:12.013000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sort_1
V1111 13:22:12.013000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1552
V1111 13:22:12.013000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_52
V1111 13:22:12.013000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1552
V1111 13:22:12.014000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_53
V1111 13:22:12.014000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1552
V1111 13:22:12.014000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_55
V1111 13:22:12.014000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1553
V1111 13:22:12.014000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_2
V1111 13:22:12.014000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1554
V1111 13:22:12.014000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: floor_divide_2
V1111 13:22:12.014000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1554
V1111 13:22:12.014000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_56
V1111 13:22:12.015000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1554
V1111 13:22:12.015000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: expand_4
V1111 13:22:12.015000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1554
V1111 13:22:12.015000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: gather_3
V1111 13:22:12.015000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1555
V1111 13:22:12.015000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cumsum_3
V1111 13:22:12.015000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1555
V1111 13:22:12.015000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sub_3
V1111 13:22:12.015000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1555
V1111 13:22:12.015000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_57
V1111 13:22:12.016000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1555
V1111 13:22:12.016000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sum_2
V1111 13:22:12.016000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1555
V1111 13:22:12.016000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: clamp_min_1
V1111 13:22:12.016000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1555
V1111 13:22:12.016000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_10
V1111 13:22:12.016000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1555
V1111 13:22:12.016000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sub_4
V1111 13:22:12.016000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1555
V1111 13:22:12.016000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: floor_divide_3
V1111 13:22:12.017000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1555
V1111 13:22:12.017000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_13
V1111 13:22:12.017000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1555
V1111 13:22:12.017000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_8
V1111 13:22:12.017000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1555
V1111 13:22:12.017000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cumsum_4
V1111 13:22:12.017000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1555
V1111 13:22:12.017000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sub_5
V1111 13:22:12.017000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1555
V1111 13:22:12.017000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: full_1
V1111 13:22:12.018000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1555
V1111 13:22:12.018000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: triton_kernel_wrapper_functional_proxy_1
V1111 13:22:12.018000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1555
V1111 13:22:12.018000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_54
V1111 13:22:12.018000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1555
V1111 13:22:12.018000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_9
V1111 13:22:12.018000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1555
V1111 13:22:12.018000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_31
V1111 13:22:12.018000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1555
V1111 13:22:12.018000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: unsqueeze_4
V1111 13:22:12.019000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1555
V1111 13:22:12.019000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_7
V1111 13:22:12.019000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1556
V1111 13:22:12.019000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_3
V1111 13:22:12.019000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1557
V1111 13:22:12.019000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cumsum_5
V1111 13:22:12.019000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1557
V1111 13:22:12.019000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_10
V1111 13:22:12.019000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1558
V1111 13:22:12.019000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_11
V1111 13:22:12.020000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1559
V1111 13:22:12.020000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_15
V1111 13:22:12.020000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1560
V1111 13:22:12.020000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_3
V1111 13:22:12.020000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1561
V1111 13:22:12.020000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: silu_3
V1111 13:22:12.020000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1562
V1111 13:22:12.020000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_12
V1111 13:22:12.020000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1563
V1111 13:22:12.020000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_13
V1111 13:22:12.021000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1564
V1111 13:22:12.021000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_16
V1111 13:22:12.021000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1565
V1111 13:22:12.021000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_4
V1111 13:22:12.021000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1566
V1111 13:22:12.021000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_14
V1111 13:22:12.021000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1567
V1111 13:22:12.021000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_14
V1111 13:22:12.021000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1568
V1111 13:22:12.021000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_17
V1111 13:22:12.022000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1569
V1111 13:22:12.022000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_5
V1111 13:22:12.022000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1570
V1111 13:22:12.022000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_15
V1111 13:22:12.022000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1571
V1111 13:22:12.022000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_empty_1
V1111 13:22:12.022000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1571
V1111 13:22:12.022000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_put_1
V1111 13:22:12.022000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1572
V1111 13:22:12.022000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_3
V1111 13:22:12.023000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1573
V1111 13:22:12.023000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_20
V1111 13:22:12.023000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1574
V1111 13:22:12.023000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_20
V1111 13:22:12.023000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1575
V1111 13:22:12.023000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: silu_4
V1111 13:22:12.023000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1576
V1111 13:22:12.023000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_21
V1111 13:22:12.023000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1577
V1111 13:22:12.023000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_21
V1111 13:22:12.024000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1578
V1111 13:22:12.024000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_15
V1111 13:22:12.024000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1579
V1111 13:22:12.024000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_22
V1111 13:22:12.024000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1580
V1111 13:22:12.024000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_22
V1111 13:22:12.024000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1581
V1111 13:22:12.024000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_58
V1111 13:22:12.024000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1582
V1111 13:22:12.024000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_4
V1111 13:22:12.025000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1573
V1111 13:22:12.025000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_16
V1111 13:22:12.025000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1583
V1111 13:22:12.025000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: scatter_add_1
V1111 13:22:12.025000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1584
V1111 13:22:12.025000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_59
V1111 13:22:12.025000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1585
V1111 13:22:12.025000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_11
V1111 13:22:12.025000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1586
V1111 13:22:12.025000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_9
V1111 13:22:12.026000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1587
V1111 13:22:12.026000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_55
V1111 13:22:12.026000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1587
V1111 13:22:12.026000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_56
V1111 13:22:12.026000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1587
V1111 13:22:12.026000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_17
V1111 13:22:12.026000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1587
V1111 13:22:12.026000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_23
V1111 13:22:12.026000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1588
V1111 13:22:12.026000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_60
V1111 13:22:12.027000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1589
V1111 13:22:12.027000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_23
V1111 13:22:12.027000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1590
V1111 13:22:12.027000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_15
V1111 13:22:12.027000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1591
V1111 13:22:12.027000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_61
V1111 13:22:12.027000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1592
V1111 13:22:12.027000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: split_with_sizes_9
V1111 13:22:12.027000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1593
V1111 13:22:12.028000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_57
V1111 13:22:12.028000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1593
V1111 13:22:12.028000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_58
V1111 13:22:12.028000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1593
V1111 13:22:12.028000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_62
V1111 13:22:12.028000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1594
V1111 13:22:12.028000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_complex_6
V1111 13:22:12.028000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1595
V1111 13:22:12.028000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_63
V1111 13:22:12.028000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1595
V1111 13:22:12.029000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_17
V1111 13:22:12.029000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1596
V1111 13:22:12.029000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_real_6
V1111 13:22:12.029000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1597
V1111 13:22:12.029000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_64
V1111 13:22:12.029000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1598
V1111 13:22:12.029000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_8
V1111 13:22:12.029000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1599
V1111 13:22:12.029000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_24
V1111 13:22:12.029000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1600
V1111 13:22:12.030000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_65
V1111 13:22:12.030000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1601
V1111 13:22:12.030000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_24
V1111 13:22:12.030000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1602
V1111 13:22:12.030000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_16
V1111 13:22:12.030000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1603
V1111 13:22:12.030000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: split_with_sizes_10
V1111 13:22:12.030000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1604
V1111 13:22:12.030000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_59
V1111 13:22:12.030000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1604
V1111 13:22:12.031000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_60
V1111 13:22:12.031000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1604
V1111 13:22:12.031000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: unsqueeze_5
V1111 13:22:12.031000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1605
V1111 13:22:12.031000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_66
V1111 13:22:12.031000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1606
V1111 13:22:12.031000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_complex_7
V1111 13:22:12.031000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1607
V1111 13:22:12.031000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_67
V1111 13:22:12.031000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1607
V1111 13:22:12.032000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_18
V1111 13:22:12.032000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1608
V1111 13:22:12.032000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_real_7
V1111 13:22:12.032000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1609
V1111 13:22:12.032000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_68
V1111 13:22:12.032000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1610
V1111 13:22:12.032000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_10
V1111 13:22:12.032000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1611
V1111 13:22:12.032000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_61
V1111 13:22:12.032000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1611
V1111 13:22:12.033000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_62
V1111 13:22:12.033000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1611
V1111 13:22:12.033000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_18
V1111 13:22:12.033000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1611
V1111 13:22:12.033000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_25
V1111 13:22:12.033000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1612
V1111 13:22:12.033000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_69
V1111 13:22:12.033000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1613
V1111 13:22:12.033000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_25
V1111 13:22:12.033000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1614
V1111 13:22:12.034000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_17
V1111 13:22:12.034000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1615
V1111 13:22:12.034000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_70
V1111 13:22:12.034000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1616
V1111 13:22:12.034000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: split_with_sizes_11
V1111 13:22:12.034000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1617
V1111 13:22:12.034000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_63
V1111 13:22:12.034000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1617
V1111 13:22:12.034000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_64
V1111 13:22:12.034000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1617
V1111 13:22:12.035000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: expand_5
V1111 13:22:12.035000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1618
V1111 13:22:12.035000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_9
V1111 13:22:12.035000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1619
V1111 13:22:12.035000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_18
V1111 13:22:12.035000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1620
V1111 13:22:12.035000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_19
V1111 13:22:12.035000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1621
V1111 13:22:12.035000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_20
V1111 13:22:12.035000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1622
V1111 13:22:12.036000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_32
V1111 13:22:12.036000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1622
V1111 13:22:12.036000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_33
V1111 13:22:12.036000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1622
V1111 13:22:12.036000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_34
V1111 13:22:12.036000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1622
V1111 13:22:12.036000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_35
V1111 13:22:12.036000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1622
V1111 13:22:12.036000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_36
V1111 13:22:12.036000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1622
V1111 13:22:12.037000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_37
V1111 13:22:12.037000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.037000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_38
V1111 13:22:12.037000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.037000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_39
V1111 13:22:12.037000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.037000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_40
V1111 13:22:12.037000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.037000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_41
V1111 13:22:12.038000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.038000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sdpa_score3
V1111 13:22:12.038000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1625
V1111 13:22:12.038000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sdpa_mask3
V1111 13:22:12.038000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1625
V1111 13:22:12.038000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _tensor_constant0_3
V1111 13:22:12.038000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1625
V1111 13:22:12.038000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: flex_attention_3
V1111 13:22:12.038000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1625
V1111 13:22:12.038000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_65
V1111 13:22:12.039000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1625
V1111 13:22:12.039000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_66
V1111 13:22:12.039000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1625
V1111 13:22:12.039000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_67
V1111 13:22:12.039000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1625
V1111 13:22:12.039000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_19
V1111 13:22:12.039000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1625
V1111 13:22:12.039000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_20
V1111 13:22:12.039000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1625
V1111 13:22:12.039000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_21
V1111 13:22:12.040000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1626
V1111 13:22:12.040000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_71
V1111 13:22:12.040000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1627
V1111 13:22:12.040000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_26
V1111 13:22:12.040000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1628
V1111 13:22:12.040000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_72
V1111 13:22:12.040000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1629
V1111 13:22:12.040000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_26
V1111 13:22:12.040000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1630
V1111 13:22:12.040000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_18
V1111 13:22:12.041000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1631
V1111 13:22:12.041000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_12
V1111 13:22:12.041000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1632
V1111 13:22:12.041000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_11
V1111 13:22:12.041000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1633
V1111 13:22:12.041000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_68
V1111 13:22:12.041000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1633
V1111 13:22:12.041000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_69
V1111 13:22:12.041000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1633
V1111 13:22:12.041000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_21
V1111 13:22:12.042000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1633
V1111 13:22:12.042000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_73
V1111 13:22:12.042000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1634
V1111 13:22:12.042000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_27
V1111 13:22:12.042000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1635
V1111 13:22:12.042000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_27
V1111 13:22:12.042000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1636
V1111 13:22:12.042000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _softmax_2
V1111 13:22:12.042000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1637
V1111 13:22:12.042000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_22
V1111 13:22:12.043000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1637
V1111 13:22:12.043000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_13
V1111 13:22:12.043000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1638
V1111 13:22:12.043000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: topk_2
V1111 13:22:12.043000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1639
V1111 13:22:12.043000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_70
V1111 13:22:12.043000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1639
V1111 13:22:12.043000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_71
V1111 13:22:12.043000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1639
V1111 13:22:12.043000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: gather_4
V1111 13:22:12.044000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1640
V1111 13:22:12.044000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_19
V1111 13:22:12.044000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1641
V1111 13:22:12.044000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_74
V1111 13:22:12.044000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1641
V1111 13:22:12.044000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: histc_4
V1111 13:22:12.044000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1641
V1111 13:22:12.044000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_14
V1111 13:22:12.044000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1641
V1111 13:22:12.045000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_75
V1111 13:22:12.045000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1641
V1111 13:22:12.045000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: histc_5
V1111 13:22:12.045000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1641
V1111 13:22:12.045000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_76
V1111 13:22:12.045000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1641
V1111 13:22:12.045000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sort_2
V1111 13:22:12.045000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1641
V1111 13:22:12.045000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_72
V1111 13:22:12.045000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1641
V1111 13:22:12.046000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_73
V1111 13:22:12.046000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1641
V1111 13:22:12.046000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_77
V1111 13:22:12.046000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1642
V1111 13:22:12.046000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_4
V1111 13:22:12.046000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1643
V1111 13:22:12.046000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: floor_divide_4
V1111 13:22:12.046000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1643
V1111 13:22:12.046000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_78
V1111 13:22:12.046000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1643
V1111 13:22:12.047000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: expand_6
V1111 13:22:12.047000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1643
V1111 13:22:12.047000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: gather_5
V1111 13:22:12.047000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1644
V1111 13:22:12.047000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cumsum_6
V1111 13:22:12.047000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1644
V1111 13:22:12.047000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sub_6
V1111 13:22:12.047000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1644
V1111 13:22:12.047000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_79
V1111 13:22:12.047000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1644
V1111 13:22:12.048000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sum_3
V1111 13:22:12.048000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1644
V1111 13:22:12.048000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: clamp_min_2
V1111 13:22:12.048000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1644
V1111 13:22:12.048000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_15
V1111 13:22:12.048000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1644
V1111 13:22:12.048000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sub_7
V1111 13:22:12.048000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1644
V1111 13:22:12.048000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: floor_divide_5
V1111 13:22:12.049000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1644
V1111 13:22:12.049000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_20
V1111 13:22:12.049000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1644
V1111 13:22:12.049000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_16
V1111 13:22:12.049000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1644
V1111 13:22:12.049000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cumsum_7
V1111 13:22:12.049000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1644
V1111 13:22:12.049000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sub_8
V1111 13:22:12.049000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1644
V1111 13:22:12.049000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: full_2
V1111 13:22:12.050000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1644
V1111 13:22:12.050000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: triton_kernel_wrapper_functional_proxy_2
V1111 13:22:12.050000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1644
V1111 13:22:12.050000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_74
V1111 13:22:12.050000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1644
V1111 13:22:12.050000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_17
V1111 13:22:12.050000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1644
V1111 13:22:12.050000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_42
V1111 13:22:12.050000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1644
V1111 13:22:12.051000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: unsqueeze_6
V1111 13:22:12.051000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1644
V1111 13:22:12.051000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_10
V1111 13:22:12.051000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1645
V1111 13:22:12.051000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_5
V1111 13:22:12.051000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1646
V1111 13:22:12.051000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cumsum_8
V1111 13:22:12.051000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1646
V1111 13:22:12.051000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_18
V1111 13:22:12.051000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1647
V1111 13:22:12.052000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_19
V1111 13:22:12.052000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1648
V1111 13:22:12.052000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_22
V1111 13:22:12.052000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1649
V1111 13:22:12.052000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_6
V1111 13:22:12.052000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1650
V1111 13:22:12.052000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: silu_5
V1111 13:22:12.052000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1651
V1111 13:22:12.052000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_20
V1111 13:22:12.052000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1652
V1111 13:22:12.053000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_21
V1111 13:22:12.053000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1653
V1111 13:22:12.053000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_23
V1111 13:22:12.053000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1654
V1111 13:22:12.053000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_7
V1111 13:22:12.053000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1655
V1111 13:22:12.053000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_21
V1111 13:22:12.053000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1656
V1111 13:22:12.053000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_22
V1111 13:22:12.054000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1657
V1111 13:22:12.054000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_24
V1111 13:22:12.054000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1658
V1111 13:22:12.054000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_8
V1111 13:22:12.054000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1659
V1111 13:22:12.054000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_23
V1111 13:22:12.054000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1660
V1111 13:22:12.054000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_empty_2
V1111 13:22:12.054000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1660
V1111 13:22:12.055000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_put_2
V1111 13:22:12.055000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1661
V1111 13:22:12.055000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_5
V1111 13:22:12.055000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1662
V1111 13:22:12.055000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_28
V1111 13:22:12.055000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1663
V1111 13:22:12.055000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_28
V1111 13:22:12.055000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1664
V1111 13:22:12.055000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: silu_6
V1111 13:22:12.055000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1665
V1111 13:22:12.056000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_29
V1111 13:22:12.056000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1666
V1111 13:22:12.056000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_29
V1111 13:22:12.056000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1667
V1111 13:22:12.056000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_22
V1111 13:22:12.056000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1668
V1111 13:22:12.056000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_30
V1111 13:22:12.056000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1669
V1111 13:22:12.056000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_30
V1111 13:22:12.057000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1670
V1111 13:22:12.057000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_80
V1111 13:22:12.057000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1671
V1111 13:22:12.057000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_6
V1111 13:22:12.057000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1662
V1111 13:22:12.057000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_23
V1111 13:22:12.057000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1672
V1111 13:22:12.057000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: scatter_add_2
V1111 13:22:12.057000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1673
V1111 13:22:12.057000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_81
V1111 13:22:12.058000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1674
V1111 13:22:12.058000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_16
V1111 13:22:12.058000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1675
V1111 13:22:12.058000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_12
V1111 13:22:12.058000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1676
V1111 13:22:12.058000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_75
V1111 13:22:12.058000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1676
V1111 13:22:12.058000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_76
V1111 13:22:12.058000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1676
V1111 13:22:12.058000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_23
V1111 13:22:12.059000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1676
V1111 13:22:12.059000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_31
V1111 13:22:12.059000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1677
V1111 13:22:12.059000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_82
V1111 13:22:12.059000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1678
V1111 13:22:12.059000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_31
V1111 13:22:12.059000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1679
V1111 13:22:12.059000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_19
V1111 13:22:12.059000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1680
V1111 13:22:12.059000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_83
V1111 13:22:12.060000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1681
V1111 13:22:12.060000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: split_with_sizes_12
V1111 13:22:12.060000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1682
V1111 13:22:12.060000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_77
V1111 13:22:12.060000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1682
V1111 13:22:12.060000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_78
V1111 13:22:12.060000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1682
V1111 13:22:12.060000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_84
V1111 13:22:12.060000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1683
V1111 13:22:12.060000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_complex_8
V1111 13:22:12.061000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1684
V1111 13:22:12.061000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_85
V1111 13:22:12.061000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1684
V1111 13:22:12.061000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_24
V1111 13:22:12.061000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1685
V1111 13:22:12.061000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_real_8
V1111 13:22:12.061000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1686
V1111 13:22:12.061000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_86
V1111 13:22:12.061000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1687
V1111 13:22:12.062000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_11
V1111 13:22:12.062000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1688
V1111 13:22:12.062000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_32
V1111 13:22:12.062000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1689
V1111 13:22:12.062000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_87
V1111 13:22:12.062000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1690
V1111 13:22:12.062000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_32
V1111 13:22:12.062000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1691
V1111 13:22:12.062000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_20
V1111 13:22:12.062000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1692
V1111 13:22:12.063000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: split_with_sizes_13
V1111 13:22:12.063000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1693
V1111 13:22:12.063000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_79
V1111 13:22:12.063000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1693
V1111 13:22:12.063000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_80
V1111 13:22:12.063000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1693
V1111 13:22:12.063000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: unsqueeze_7
V1111 13:22:12.063000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1694
V1111 13:22:12.063000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_88
V1111 13:22:12.063000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1695
V1111 13:22:12.064000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_complex_9
V1111 13:22:12.064000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1696
V1111 13:22:12.064000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_89
V1111 13:22:12.064000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1696
V1111 13:22:12.064000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_25
V1111 13:22:12.064000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1697
V1111 13:22:12.064000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_real_9
V1111 13:22:12.064000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1698
V1111 13:22:12.064000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_90
V1111 13:22:12.064000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1699
V1111 13:22:12.065000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_13
V1111 13:22:12.065000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1700
V1111 13:22:12.065000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_81
V1111 13:22:12.065000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1700
V1111 13:22:12.065000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_82
V1111 13:22:12.065000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1700
V1111 13:22:12.065000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_24
V1111 13:22:12.065000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1700
V1111 13:22:12.065000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_33
V1111 13:22:12.066000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1701
V1111 13:22:12.066000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_91
V1111 13:22:12.066000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1702
V1111 13:22:12.066000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_33
V1111 13:22:12.066000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1703
V1111 13:22:12.066000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_21
V1111 13:22:12.066000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1704
V1111 13:22:12.066000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_92
V1111 13:22:12.066000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1705
V1111 13:22:12.066000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: split_with_sizes_14
V1111 13:22:12.067000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1706
V1111 13:22:12.067000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_83
V1111 13:22:12.067000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1706
V1111 13:22:12.067000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_84
V1111 13:22:12.067000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1706
V1111 13:22:12.067000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: expand_7
V1111 13:22:12.067000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1707
V1111 13:22:12.067000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_12
V1111 13:22:12.067000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1708
V1111 13:22:12.068000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_25
V1111 13:22:12.068000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1709
V1111 13:22:12.068000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_26
V1111 13:22:12.068000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1710
V1111 13:22:12.068000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_27
V1111 13:22:12.068000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1711
V1111 13:22:12.068000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_43
V1111 13:22:12.068000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1711
V1111 13:22:12.068000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_44
V1111 13:22:12.069000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1711
V1111 13:22:12.069000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_45
V1111 13:22:12.069000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1711
V1111 13:22:12.069000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_46
V1111 13:22:12.069000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1711
V1111 13:22:12.069000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_47
V1111 13:22:12.069000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1711
V1111 13:22:12.069000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_48
V1111 13:22:12.069000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.069000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_49
V1111 13:22:12.070000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.070000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_50
V1111 13:22:12.070000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.070000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_51
V1111 13:22:12.070000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.070000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_52
V1111 13:22:12.070000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.070000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sdpa_score4
V1111 13:22:12.070000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1714
V1111 13:22:12.071000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sdpa_mask4
V1111 13:22:12.071000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1714
V1111 13:22:12.071000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _tensor_constant0_4
V1111 13:22:12.071000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1714
V1111 13:22:12.071000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: flex_attention_4
V1111 13:22:12.071000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1714
V1111 13:22:12.071000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_85
V1111 13:22:12.071000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1714
V1111 13:22:12.071000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_86
V1111 13:22:12.071000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1714
V1111 13:22:12.072000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_87
V1111 13:22:12.072000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1714
V1111 13:22:12.072000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_25
V1111 13:22:12.072000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1714
V1111 13:22:12.072000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_26
V1111 13:22:12.072000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1714
V1111 13:22:12.072000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_28
V1111 13:22:12.072000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1715
V1111 13:22:12.072000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_93
V1111 13:22:12.072000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1716
V1111 13:22:12.073000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_34
V1111 13:22:12.073000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1717
V1111 13:22:12.073000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_94
V1111 13:22:12.073000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1718
V1111 13:22:12.073000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_34
V1111 13:22:12.073000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1719
V1111 13:22:12.073000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_22
V1111 13:22:12.073000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1720
V1111 13:22:12.073000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_17
V1111 13:22:12.073000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1721
V1111 13:22:12.074000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_14
V1111 13:22:12.074000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1722
V1111 13:22:12.074000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_88
V1111 13:22:12.074000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1722
V1111 13:22:12.074000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_89
V1111 13:22:12.074000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1722
V1111 13:22:12.074000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_27
V1111 13:22:12.074000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1722
V1111 13:22:12.074000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_95
V1111 13:22:12.074000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1723
V1111 13:22:12.075000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_35
V1111 13:22:12.075000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1724
V1111 13:22:12.075000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_35
V1111 13:22:12.075000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1725
V1111 13:22:12.075000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _softmax_3
V1111 13:22:12.075000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1726
V1111 13:22:12.075000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_28
V1111 13:22:12.075000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1726
V1111 13:22:12.075000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_18
V1111 13:22:12.075000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1727
V1111 13:22:12.076000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: topk_3
V1111 13:22:12.076000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1728
V1111 13:22:12.076000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_90
V1111 13:22:12.076000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1728
V1111 13:22:12.076000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_91
V1111 13:22:12.076000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1728
V1111 13:22:12.076000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: gather_6
V1111 13:22:12.076000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1729
V1111 13:22:12.076000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_26
V1111 13:22:12.077000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1730
V1111 13:22:12.077000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_96
V1111 13:22:12.077000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1730
V1111 13:22:12.077000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: histc_6
V1111 13:22:12.077000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1730
V1111 13:22:12.077000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_19
V1111 13:22:12.077000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1730
V1111 13:22:12.077000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_97
V1111 13:22:12.077000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1730
V1111 13:22:12.077000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: histc_7
V1111 13:22:12.078000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1730
V1111 13:22:12.078000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_98
V1111 13:22:12.078000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1730
V1111 13:22:12.078000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sort_3
V1111 13:22:12.078000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1730
V1111 13:22:12.078000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_92
V1111 13:22:12.078000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1730
V1111 13:22:12.078000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_93
V1111 13:22:12.078000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1730
V1111 13:22:12.078000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_99
V1111 13:22:12.079000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1731
V1111 13:22:12.079000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_6
V1111 13:22:12.079000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1732
V1111 13:22:12.079000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: floor_divide_6
V1111 13:22:12.079000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1732
V1111 13:22:12.079000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_100
V1111 13:22:12.079000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1732
V1111 13:22:12.079000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: expand_8
V1111 13:22:12.080000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1732
V1111 13:22:12.080000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: gather_7
V1111 13:22:12.080000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1733
V1111 13:22:12.080000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cumsum_9
V1111 13:22:12.080000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1733
V1111 13:22:12.080000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sub_9
V1111 13:22:12.080000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1733
V1111 13:22:12.080000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_101
V1111 13:22:12.080000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1733
V1111 13:22:12.080000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sum_4
V1111 13:22:12.081000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1733
V1111 13:22:12.081000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: clamp_min_3
V1111 13:22:12.081000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1733
V1111 13:22:12.081000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_20
V1111 13:22:12.081000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1733
V1111 13:22:12.081000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sub_10
V1111 13:22:12.081000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1733
V1111 13:22:12.081000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: floor_divide_7
V1111 13:22:12.081000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1733
V1111 13:22:12.081000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_27
V1111 13:22:12.082000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1733
V1111 13:22:12.082000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_24
V1111 13:22:12.082000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1733
V1111 13:22:12.082000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cumsum_10
V1111 13:22:12.082000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1733
V1111 13:22:12.082000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sub_11
V1111 13:22:12.082000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1733
V1111 13:22:12.082000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: full_3
V1111 13:22:12.082000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1733
V1111 13:22:12.082000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: triton_kernel_wrapper_functional_proxy_3
V1111 13:22:12.083000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1733
V1111 13:22:12.083000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_94
V1111 13:22:12.083000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1733
V1111 13:22:12.083000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_25
V1111 13:22:12.083000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1733
V1111 13:22:12.083000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_53
V1111 13:22:12.083000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1733
V1111 13:22:12.083000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: unsqueeze_8
V1111 13:22:12.083000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1733
V1111 13:22:12.084000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_13
V1111 13:22:12.084000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1734
V1111 13:22:12.084000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_7
V1111 13:22:12.084000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1735
V1111 13:22:12.084000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cumsum_11
V1111 13:22:12.084000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1735
V1111 13:22:12.084000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_26
V1111 13:22:12.084000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1736
V1111 13:22:12.084000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_27
V1111 13:22:12.084000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1737
V1111 13:22:12.085000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_29
V1111 13:22:12.085000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1738
V1111 13:22:12.085000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_9
V1111 13:22:12.085000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1739
V1111 13:22:12.085000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: silu_7
V1111 13:22:12.085000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1740
V1111 13:22:12.085000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_28
V1111 13:22:12.085000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1741
V1111 13:22:12.085000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_29
V1111 13:22:12.085000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1742
V1111 13:22:12.086000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_30
V1111 13:22:12.086000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1743
V1111 13:22:12.086000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_10
V1111 13:22:12.086000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1744
V1111 13:22:12.086000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_28
V1111 13:22:12.086000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1745
V1111 13:22:12.086000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_30
V1111 13:22:12.086000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1746
V1111 13:22:12.086000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_31
V1111 13:22:12.086000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1747
V1111 13:22:12.087000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_11
V1111 13:22:12.087000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1748
V1111 13:22:12.087000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_31
V1111 13:22:12.087000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1749
V1111 13:22:12.087000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_empty_3
V1111 13:22:12.087000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1749
V1111 13:22:12.087000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_put_3
V1111 13:22:12.087000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1750
V1111 13:22:12.087000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_7
V1111 13:22:12.087000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1751
V1111 13:22:12.088000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_36
V1111 13:22:12.088000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1752
V1111 13:22:12.088000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_36
V1111 13:22:12.088000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1753
V1111 13:22:12.088000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: silu_8
V1111 13:22:12.088000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1754
V1111 13:22:12.088000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_37
V1111 13:22:12.088000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1755
V1111 13:22:12.088000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_37
V1111 13:22:12.089000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1756
V1111 13:22:12.089000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_29
V1111 13:22:12.089000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1757
V1111 13:22:12.089000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_38
V1111 13:22:12.089000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1758
V1111 13:22:12.089000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_38
V1111 13:22:12.089000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1759
V1111 13:22:12.089000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_102
V1111 13:22:12.089000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1760
V1111 13:22:12.089000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_8
V1111 13:22:12.090000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1751
V1111 13:22:12.090000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_30
V1111 13:22:12.090000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1761
V1111 13:22:12.090000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: scatter_add_3
V1111 13:22:12.090000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1762
V1111 13:22:12.090000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_103
V1111 13:22:12.090000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1763
V1111 13:22:12.090000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_21
V1111 13:22:12.090000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1764
V1111 13:22:12.090000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_15
V1111 13:22:12.091000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1765
V1111 13:22:12.091000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_95
V1111 13:22:12.091000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1765
V1111 13:22:12.091000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_96
V1111 13:22:12.091000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1765
V1111 13:22:12.091000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_29
V1111 13:22:12.091000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1765
V1111 13:22:12.091000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_39
V1111 13:22:12.091000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1766
V1111 13:22:12.092000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_104
V1111 13:22:12.092000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1767
V1111 13:22:12.092000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_39
V1111 13:22:12.092000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1768
V1111 13:22:12.092000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_23
V1111 13:22:12.092000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1769
V1111 13:22:12.092000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_105
V1111 13:22:12.092000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1770
V1111 13:22:12.092000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: split_with_sizes_15
V1111 13:22:12.092000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1771
V1111 13:22:12.093000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_97
V1111 13:22:12.093000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1771
V1111 13:22:12.093000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_98
V1111 13:22:12.093000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1771
V1111 13:22:12.093000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_106
V1111 13:22:12.093000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1772
V1111 13:22:12.093000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_complex_10
V1111 13:22:12.093000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1773
V1111 13:22:12.093000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_107
V1111 13:22:12.093000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1773
V1111 13:22:12.094000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_31
V1111 13:22:12.094000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1774
V1111 13:22:12.094000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_real_10
V1111 13:22:12.094000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1775
V1111 13:22:12.094000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_108
V1111 13:22:12.094000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1776
V1111 13:22:12.094000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_14
V1111 13:22:12.094000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1777
V1111 13:22:12.094000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_40
V1111 13:22:12.094000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1778
V1111 13:22:12.095000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_109
V1111 13:22:12.095000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1779
V1111 13:22:12.095000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_40
V1111 13:22:12.095000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1780
V1111 13:22:12.095000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_24
V1111 13:22:12.095000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1781
V1111 13:22:12.095000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: split_with_sizes_16
V1111 13:22:12.095000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1782
V1111 13:22:12.095000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_99
V1111 13:22:12.095000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1782
V1111 13:22:12.096000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_100
V1111 13:22:12.096000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1782
V1111 13:22:12.096000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: unsqueeze_9
V1111 13:22:12.096000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1783
V1111 13:22:12.096000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_110
V1111 13:22:12.096000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1784
V1111 13:22:12.096000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_complex_11
V1111 13:22:12.096000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1785
V1111 13:22:12.096000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_111
V1111 13:22:12.096000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1785
V1111 13:22:12.097000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_32
V1111 13:22:12.097000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1786
V1111 13:22:12.097000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_real_11
V1111 13:22:12.097000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1787
V1111 13:22:12.097000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_112
V1111 13:22:12.097000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1788
V1111 13:22:12.097000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_16
V1111 13:22:12.097000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1789
V1111 13:22:12.097000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_101
V1111 13:22:12.097000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1789
V1111 13:22:12.098000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_102
V1111 13:22:12.098000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1789
V1111 13:22:12.098000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_30
V1111 13:22:12.098000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1789
V1111 13:22:12.098000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_41
V1111 13:22:12.098000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1790
V1111 13:22:12.098000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_113
V1111 13:22:12.098000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1791
V1111 13:22:12.098000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_41
V1111 13:22:12.098000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1792
V1111 13:22:12.099000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_25
V1111 13:22:12.099000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1793
V1111 13:22:12.099000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_114
V1111 13:22:12.099000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1794
V1111 13:22:12.099000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: split_with_sizes_17
V1111 13:22:12.099000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1795
V1111 13:22:12.099000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_103
V1111 13:22:12.099000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1795
V1111 13:22:12.099000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_104
V1111 13:22:12.099000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1795
V1111 13:22:12.100000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: expand_9
V1111 13:22:12.100000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1796
V1111 13:22:12.100000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_15
V1111 13:22:12.100000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1797
V1111 13:22:12.100000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_32
V1111 13:22:12.100000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1798
V1111 13:22:12.100000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_33
V1111 13:22:12.100000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1799
V1111 13:22:12.100000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_34
V1111 13:22:12.100000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1800
V1111 13:22:12.101000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_54
V1111 13:22:12.101000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1800
V1111 13:22:12.101000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_55
V1111 13:22:12.101000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1800
V1111 13:22:12.101000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_56
V1111 13:22:12.101000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1800
V1111 13:22:12.101000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_57
V1111 13:22:12.101000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1800
V1111 13:22:12.101000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_58
V1111 13:22:12.101000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1800
V1111 13:22:12.102000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_59
V1111 13:22:12.102000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.102000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_60
V1111 13:22:12.102000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.102000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_61
V1111 13:22:12.102000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.102000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_62
V1111 13:22:12.102000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.102000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_63
V1111 13:22:12.102000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.103000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sdpa_score5
V1111 13:22:12.103000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1803
V1111 13:22:12.103000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sdpa_mask5
V1111 13:22:12.103000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1803
V1111 13:22:12.103000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _tensor_constant0_5
V1111 13:22:12.103000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1803
V1111 13:22:12.103000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: flex_attention_5
V1111 13:22:12.103000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1803
V1111 13:22:12.103000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_105
V1111 13:22:12.103000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1803
V1111 13:22:12.104000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_106
V1111 13:22:12.104000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1803
V1111 13:22:12.104000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_107
V1111 13:22:12.104000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1803
V1111 13:22:12.104000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_31
V1111 13:22:12.104000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1803
V1111 13:22:12.104000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_32
V1111 13:22:12.104000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1803
V1111 13:22:12.104000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_35
V1111 13:22:12.104000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1804
V1111 13:22:12.105000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_115
V1111 13:22:12.105000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1805
V1111 13:22:12.105000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_42
V1111 13:22:12.105000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1806
V1111 13:22:12.105000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_116
V1111 13:22:12.105000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1807
V1111 13:22:12.105000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_42
V1111 13:22:12.105000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1808
V1111 13:22:12.105000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_26
V1111 13:22:12.105000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1809
V1111 13:22:12.106000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_22
V1111 13:22:12.106000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1810
V1111 13:22:12.106000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_17
V1111 13:22:12.106000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1811
V1111 13:22:12.106000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_108
V1111 13:22:12.106000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1811
V1111 13:22:12.106000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_109
V1111 13:22:12.106000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1811
V1111 13:22:12.106000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_33
V1111 13:22:12.107000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1811
V1111 13:22:12.107000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_117
V1111 13:22:12.107000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1812
V1111 13:22:12.107000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_43
V1111 13:22:12.107000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1813
V1111 13:22:12.107000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_43
V1111 13:22:12.107000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1814
V1111 13:22:12.107000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _softmax_4
V1111 13:22:12.107000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1815
V1111 13:22:12.107000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_34
V1111 13:22:12.108000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1815
V1111 13:22:12.108000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_23
V1111 13:22:12.108000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1816
V1111 13:22:12.108000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: topk_4
V1111 13:22:12.108000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1817
V1111 13:22:12.108000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_110
V1111 13:22:12.108000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1817
V1111 13:22:12.108000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_111
V1111 13:22:12.108000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1817
V1111 13:22:12.108000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: gather_8
V1111 13:22:12.109000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1818
V1111 13:22:12.109000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_33
V1111 13:22:12.109000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1819
V1111 13:22:12.109000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_118
V1111 13:22:12.109000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1819
V1111 13:22:12.109000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: histc_8
V1111 13:22:12.109000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1819
V1111 13:22:12.109000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_24
V1111 13:22:12.109000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1819
V1111 13:22:12.109000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_119
V1111 13:22:12.110000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1819
V1111 13:22:12.110000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: histc_9
V1111 13:22:12.110000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1819
V1111 13:22:12.110000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_120
V1111 13:22:12.110000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1819
V1111 13:22:12.110000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sort_4
V1111 13:22:12.110000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1819
V1111 13:22:12.110000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_112
V1111 13:22:12.110000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1819
V1111 13:22:12.110000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_113
V1111 13:22:12.111000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1819
V1111 13:22:12.111000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_121
V1111 13:22:12.111000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1820
V1111 13:22:12.111000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_8
V1111 13:22:12.111000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1821
V1111 13:22:12.111000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: floor_divide_8
V1111 13:22:12.111000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1821
V1111 13:22:12.111000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_122
V1111 13:22:12.111000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1821
V1111 13:22:12.111000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: expand_10
V1111 13:22:12.112000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1821
V1111 13:22:12.112000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: gather_9
V1111 13:22:12.112000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1822
V1111 13:22:12.112000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cumsum_12
V1111 13:22:12.112000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1822
V1111 13:22:12.112000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sub_12
V1111 13:22:12.112000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1822
V1111 13:22:12.112000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_123
V1111 13:22:12.112000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1822
V1111 13:22:12.112000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sum_5
V1111 13:22:12.113000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1822
V1111 13:22:12.113000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: clamp_min_4
V1111 13:22:12.113000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1822
V1111 13:22:12.113000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_25
V1111 13:22:12.113000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1822
V1111 13:22:12.113000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sub_13
V1111 13:22:12.113000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1822
V1111 13:22:12.113000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: floor_divide_9
V1111 13:22:12.113000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1822
V1111 13:22:12.113000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_34
V1111 13:22:12.114000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1822
V1111 13:22:12.114000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_32
V1111 13:22:12.114000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1822
V1111 13:22:12.114000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cumsum_13
V1111 13:22:12.114000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1822
V1111 13:22:12.114000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sub_14
V1111 13:22:12.114000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1822
V1111 13:22:12.114000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: full_4
V1111 13:22:12.114000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1822
V1111 13:22:12.114000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: triton_kernel_wrapper_functional_proxy_4
V1111 13:22:12.115000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1822
V1111 13:22:12.115000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_114
V1111 13:22:12.115000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1822
V1111 13:22:12.115000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_33
V1111 13:22:12.115000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1822
V1111 13:22:12.115000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_64
V1111 13:22:12.115000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1822
V1111 13:22:12.115000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: unsqueeze_10
V1111 13:22:12.115000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1822
V1111 13:22:12.115000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_16
V1111 13:22:12.116000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1823
V1111 13:22:12.116000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_9
V1111 13:22:12.116000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1824
V1111 13:22:12.116000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cumsum_14
V1111 13:22:12.116000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1824
V1111 13:22:12.116000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_34
V1111 13:22:12.116000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1825
V1111 13:22:12.116000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_35
V1111 13:22:12.116000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1826
V1111 13:22:12.116000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_36
V1111 13:22:12.117000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1827
V1111 13:22:12.117000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_12
V1111 13:22:12.117000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1828
V1111 13:22:12.117000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: silu_9
V1111 13:22:12.117000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1829
V1111 13:22:12.117000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_36
V1111 13:22:12.117000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1830
V1111 13:22:12.117000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_37
V1111 13:22:12.117000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1831
V1111 13:22:12.117000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_37
V1111 13:22:12.118000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1832
V1111 13:22:12.118000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_13
V1111 13:22:12.118000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1833
V1111 13:22:12.118000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_35
V1111 13:22:12.118000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1834
V1111 13:22:12.118000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_38
V1111 13:22:12.118000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1835
V1111 13:22:12.118000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_38
V1111 13:22:12.118000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1836
V1111 13:22:12.118000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_14
V1111 13:22:12.119000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1837
V1111 13:22:12.119000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_39
V1111 13:22:12.119000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1838
V1111 13:22:12.119000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_empty_4
V1111 13:22:12.119000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1838
V1111 13:22:12.119000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_put_4
V1111 13:22:12.119000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1839
V1111 13:22:12.119000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_9
V1111 13:22:12.119000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1840
V1111 13:22:12.119000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_44
V1111 13:22:12.120000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1841
V1111 13:22:12.120000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_44
V1111 13:22:12.120000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1842
V1111 13:22:12.120000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: silu_10
V1111 13:22:12.120000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1843
V1111 13:22:12.120000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_45
V1111 13:22:12.120000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1844
V1111 13:22:12.120000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_45
V1111 13:22:12.120000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1845
V1111 13:22:12.120000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_36
V1111 13:22:12.121000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1846
V1111 13:22:12.121000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_46
V1111 13:22:12.121000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1847
V1111 13:22:12.121000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_46
V1111 13:22:12.121000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1848
V1111 13:22:12.121000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_124
V1111 13:22:12.121000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1849
V1111 13:22:12.121000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_10
V1111 13:22:12.121000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1840
V1111 13:22:12.121000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_37
V1111 13:22:12.122000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1850
V1111 13:22:12.122000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: scatter_add_4
V1111 13:22:12.122000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1851
V1111 13:22:12.122000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_125
V1111 13:22:12.122000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1852
V1111 13:22:12.122000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_26
V1111 13:22:12.122000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1853
V1111 13:22:12.122000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_18
V1111 13:22:12.122000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1854
V1111 13:22:12.122000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_115
V1111 13:22:12.123000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1854
V1111 13:22:12.123000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_116
V1111 13:22:12.123000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1854
V1111 13:22:12.123000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_35
V1111 13:22:12.123000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1854
V1111 13:22:12.123000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_47
V1111 13:22:12.123000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1855
V1111 13:22:12.123000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_126
V1111 13:22:12.123000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1856
V1111 13:22:12.123000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_47
V1111 13:22:12.124000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1857
V1111 13:22:12.124000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _unsafe_view_27
V1111 13:22:12.124000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1858
V1111 13:22:12.124000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_127
V1111 13:22:12.124000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1858
V1111 13:22:12.124000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_48
V1111 13:22:12.124000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1857
V1111 13:22:12.124000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_48
V1111 13:22:12.124000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1857
V1111 13:22:12.124000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_49
V1111 13:22:12.125000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1857
V1111 13:22:12.125000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_50
V1111 13:22:12.125000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1857
V1111 13:22:12.125000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_49
V1111 13:22:12.125000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1857
V1111 13:22:12.125000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_128
V1111 13:22:12.125000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1856
V1111 13:22:12.125000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_51
V1111 13:22:12.125000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1855
V1111 13:22:12.125000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_36
V1111 13:22:12.126000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1854
V1111 13:22:12.126000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_backward
V1111 13:22:12.126000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1854
V1111 13:22:12.126000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_117
V1111 13:22:12.126000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1854
V1111 13:22:12.126000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_118
V1111 13:22:12.126000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1854
V1111 13:22:12.126000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_129
V1111 13:22:12.126000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1852
V1111 13:22:12.126000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: gather_10
V1111 13:22:12.127000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1851
V1111 13:22:12.127000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_38
V1111 13:22:12.127000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1850
V1111 13:22:12.127000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_39
V1111 13:22:12.127000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1850
V1111 13:22:12.127000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sum_6
V1111 13:22:12.127000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1850
V1111 13:22:12.127000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_130
V1111 13:22:12.127000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1849
V1111 13:22:12.128000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_52
V1111 13:22:12.128000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1848
V1111 13:22:12.128000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_50
V1111 13:22:12.128000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1848
V1111 13:22:12.128000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_53
V1111 13:22:12.128000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1848
V1111 13:22:12.128000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_54
V1111 13:22:12.128000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1848
V1111 13:22:12.128000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_51
V1111 13:22:12.128000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1848
V1111 13:22:12.129000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_55
V1111 13:22:12.129000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1847
V1111 13:22:12.129000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_40
V1111 13:22:12.129000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1846
V1111 13:22:12.129000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_41
V1111 13:22:12.129000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1846
V1111 13:22:12.129000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_56
V1111 13:22:12.129000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1845
V1111 13:22:12.129000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_52
V1111 13:22:12.129000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1845
V1111 13:22:12.130000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_57
V1111 13:22:12.130000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1845
V1111 13:22:12.130000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_58
V1111 13:22:12.130000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1845
V1111 13:22:12.130000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_53
V1111 13:22:12.130000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1845
V1111 13:22:12.130000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_59
V1111 13:22:12.130000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1844
V1111 13:22:12.130000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: silu_backward
V1111 13:22:12.130000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1843
V1111 13:22:12.131000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_60
V1111 13:22:12.131000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1842
V1111 13:22:12.131000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_54
V1111 13:22:12.131000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1842
V1111 13:22:12.131000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_61
V1111 13:22:12.131000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1842
V1111 13:22:12.131000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_62
V1111 13:22:12.131000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1842
V1111 13:22:12.131000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_55
V1111 13:22:12.132000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1842
V1111 13:22:12.132000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_27
V1111 13:22:12.132000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1858
V1111 13:22:12.132000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.132000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_63
V1111 13:22:12.132000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1841
V1111 13:22:12.132000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_backward
V1111 13:22:12.132000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1840
V1111 13:22:12.132000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_10
V1111 13:22:12.132000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1839
V1111 13:22:12.133000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_40
V1111 13:22:12.133000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1838
V1111 13:22:12.133000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_39
V1111 13:22:12.133000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1837
V1111 13:22:12.133000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_15
V1111 13:22:12.133000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1837
V1111 13:22:12.133000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_40
V1111 13:22:12.133000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1837
V1111 13:22:12.133000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_41
V1111 13:22:12.133000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1837
V1111 13:22:12.134000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_16
V1111 13:22:12.134000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1837
V1111 13:22:12.134000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_42
V1111 13:22:12.134000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1836
V1111 13:22:12.134000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_41
V1111 13:22:12.134000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1835
V1111 13:22:12.134000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_42
V1111 13:22:12.134000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1834
V1111 13:22:12.134000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_43
V1111 13:22:12.134000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1834
V1111 13:22:12.135000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_43
V1111 13:22:12.135000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1833
V1111 13:22:12.135000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_17
V1111 13:22:12.135000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1833
V1111 13:22:12.135000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_44
V1111 13:22:12.135000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1833
V1111 13:22:12.135000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_45
V1111 13:22:12.135000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1833
V1111 13:22:12.135000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_18
V1111 13:22:12.136000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1833
V1111 13:22:12.136000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_46
V1111 13:22:12.136000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1832
V1111 13:22:12.136000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_42
V1111 13:22:12.136000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1831
V1111 13:22:12.136000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_43
V1111 13:22:12.136000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1830
V1111 13:22:12.136000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: silu_backward_1
V1111 13:22:12.136000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1829
V1111 13:22:12.136000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_47
V1111 13:22:12.137000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1828
V1111 13:22:12.137000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_19
V1111 13:22:12.137000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1828
V1111 13:22:12.137000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_48
V1111 13:22:12.137000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1828
V1111 13:22:12.137000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_49
V1111 13:22:12.137000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1828
V1111 13:22:12.137000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_20
V1111 13:22:12.137000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1828
V1111 13:22:12.137000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_50
V1111 13:22:12.138000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1827
V1111 13:22:12.138000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_44
V1111 13:22:12.138000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1826
V1111 13:22:12.138000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_45
V1111 13:22:12.138000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1825
V1111 13:22:12.138000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_28
V1111 13:22:12.138000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1858
V1111 13:22:12.138000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.138000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_65
V1111 13:22:12.138000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1824
V1111 13:22:12.139000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_put_5
V1111 13:22:12.139000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1824
V1111 13:22:12.139000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_11
V1111 13:22:12.139000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1823
V1111 13:22:12.139000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_12
V1111 13:22:12.139000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1823
V1111 13:22:12.139000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_66
V1111 13:22:12.139000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1822
V1111 13:22:12.139000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: scatter_add_5
V1111 13:22:12.140000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1822
V1111 13:22:12.140000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_29
V1111 13:22:12.140000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1858
V1111 13:22:12.140000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.140000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_67
V1111 13:22:12.140000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1821
V1111 13:22:12.140000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_put_6
V1111 13:22:12.140000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1821
V1111 13:22:12.140000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_131
V1111 13:22:12.140000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1820
V1111 13:22:12.141000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_44
V1111 13:22:12.141000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1819
V1111 13:22:12.141000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_68
V1111 13:22:12.141000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1818
V1111 13:22:12.141000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: scatter_add_6
V1111 13:22:12.141000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1818
V1111 13:22:12.141000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_37
V1111 13:22:12.141000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1815
V1111 13:22:12.141000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _softmax_backward_data
V1111 13:22:12.141000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1815
V1111 13:22:12.142000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_64
V1111 13:22:12.142000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1814
V1111 13:22:12.142000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_56
V1111 13:22:12.142000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1814
V1111 13:22:12.142000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_65
V1111 13:22:12.142000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1814
V1111 13:22:12.142000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_66
V1111 13:22:12.142000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1814
V1111 13:22:12.142000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_57
V1111 13:22:12.143000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1814
V1111 13:22:12.143000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_30
V1111 13:22:12.143000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1858
V1111 13:22:12.143000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.143000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_67
V1111 13:22:12.143000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1813
V1111 13:22:12.143000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_132
V1111 13:22:12.143000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1812
V1111 13:22:12.143000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_38
V1111 13:22:12.143000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1811
V1111 13:22:12.144000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_backward_1
V1111 13:22:12.144000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1811
V1111 13:22:12.144000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_119
V1111 13:22:12.144000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1811
V1111 13:22:12.144000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_120
V1111 13:22:12.144000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1811
V1111 13:22:12.144000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_31
V1111 13:22:12.144000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1858
V1111 13:22:12.144000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.144000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_133
V1111 13:22:12.145000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1809
V1111 13:22:12.145000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_68
V1111 13:22:12.145000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1808
V1111 13:22:12.145000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_58
V1111 13:22:12.145000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1808
V1111 13:22:12.145000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_69
V1111 13:22:12.145000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1808
V1111 13:22:12.145000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_70
V1111 13:22:12.145000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1808
V1111 13:22:12.145000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_59
V1111 13:22:12.146000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1808
V1111 13:22:12.146000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_134
V1111 13:22:12.146000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1807
V1111 13:22:12.146000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_71
V1111 13:22:12.146000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1806
V1111 13:22:12.146000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_135
V1111 13:22:12.146000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1805
V1111 13:22:12.146000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_51
V1111 13:22:12.146000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1804
V1111 13:22:12.147000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: zeros
V1111 13:22:12.147000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.147000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: zeros_1
V1111 13:22:12.147000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.147000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_39
V1111 13:22:12.147000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.148000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_40
V1111 13:22:12.148000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.148000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: fw_graph0
V1111 13:22:12.148000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.148000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: joint_graph0
V1111 13:22:12.148000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.148000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mask_graph0
V1111 13:22:12.148000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.149000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _tensor_constant0_6
V1111 13:22:12.149000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.149000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: flex_attention_backward
V1111 13:22:12.149000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.149000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_121
V1111 13:22:12.149000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.149000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_122
V1111 13:22:12.149000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.149000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_123
V1111 13:22:12.149000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.150000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_124
V1111 13:22:12.150000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.150000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_52
V1111 13:22:12.150000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1800
V1111 13:22:12.150000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_53
V1111 13:22:12.150000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1799
V1111 13:22:12.150000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_54
V1111 13:22:12.150000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1798
V1111 13:22:12.150000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_13
V1111 13:22:12.151000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1797
V1111 13:22:12.151000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_14
V1111 13:22:12.151000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1797
V1111 13:22:12.151000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sum_7
V1111 13:22:12.151000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1796
V1111 13:22:12.151000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_17
V1111 13:22:12.151000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1795
V1111 13:22:12.151000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_136
V1111 13:22:12.151000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1794
V1111 13:22:12.151000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_137
V1111 13:22:12.152000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1793
V1111 13:22:12.152000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_72
V1111 13:22:12.152000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1792
V1111 13:22:12.152000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_60
V1111 13:22:12.152000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1792
V1111 13:22:12.152000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_73
V1111 13:22:12.152000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1792
V1111 13:22:12.152000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_74
V1111 13:22:12.152000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1792
V1111 13:22:12.152000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_61
V1111 13:22:12.153000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1792
V1111 13:22:12.153000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_138
V1111 13:22:12.153000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1791
V1111 13:22:12.153000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_75
V1111 13:22:12.153000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1790
V1111 13:22:12.153000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_41
V1111 13:22:12.153000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1789
V1111 13:22:12.153000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_backward_2
V1111 13:22:12.153000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1789
V1111 13:22:12.153000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_125
V1111 13:22:12.154000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1789
V1111 13:22:12.154000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_126
V1111 13:22:12.154000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1789
V1111 13:22:12.154000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_139
V1111 13:22:12.154000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1788
V1111 13:22:12.154000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_complex_12
V1111 13:22:12.154000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1787
V1111 13:22:12.154000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _conj
V1111 13:22:12.154000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1786
V1111 13:22:12.154000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: clone
V1111 13:22:12.155000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1786
V1111 13:22:12.155000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_45
V1111 13:22:12.155000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1786
V1111 13:22:12.155000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_real_12
V1111 13:22:12.155000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1785
V1111 13:22:12.155000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_140
V1111 13:22:12.155000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1784
V1111 13:22:12.155000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: squeeze
V1111 13:22:12.155000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1783
V1111 13:22:12.155000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_18
V1111 13:22:12.156000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1782
V1111 13:22:12.156000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_141
V1111 13:22:12.156000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1781
V1111 13:22:12.156000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_76
V1111 13:22:12.156000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1780
V1111 13:22:12.156000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_62
V1111 13:22:12.156000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1780
V1111 13:22:12.156000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_77
V1111 13:22:12.156000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1780
V1111 13:22:12.156000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_78
V1111 13:22:12.157000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1780
V1111 13:22:12.157000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_63
V1111 13:22:12.157000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1780
V1111 13:22:12.157000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_142
V1111 13:22:12.157000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1779
V1111 13:22:12.157000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_79
V1111 13:22:12.157000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1778
V1111 13:22:12.157000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_15
V1111 13:22:12.157000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1777
V1111 13:22:12.157000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_16
V1111 13:22:12.158000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1777
V1111 13:22:12.158000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_143
V1111 13:22:12.158000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1776
V1111 13:22:12.158000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: clone_1
V1111 13:22:12.158000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1775
V1111 13:22:12.158000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_complex_13
V1111 13:22:12.158000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1775
V1111 13:22:12.158000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _conj_1
V1111 13:22:12.158000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1774
V1111 13:22:12.158000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: clone_2
V1111 13:22:12.159000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1774
V1111 13:22:12.159000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_46
V1111 13:22:12.159000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1774
V1111 13:22:12.159000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_real_13
V1111 13:22:12.159000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1773
V1111 13:22:12.159000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_144
V1111 13:22:12.159000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1772
V1111 13:22:12.159000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_19
V1111 13:22:12.159000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1771
V1111 13:22:12.159000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_145
V1111 13:22:12.160000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1770
V1111 13:22:12.160000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_146
V1111 13:22:12.160000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1769
V1111 13:22:12.160000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_80
V1111 13:22:12.160000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1768
V1111 13:22:12.160000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_64
V1111 13:22:12.160000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1768
V1111 13:22:12.160000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_81
V1111 13:22:12.160000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1768
V1111 13:22:12.160000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_82
V1111 13:22:12.161000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1768
V1111 13:22:12.161000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_65
V1111 13:22:12.161000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1768
V1111 13:22:12.161000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_147
V1111 13:22:12.161000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1767
V1111 13:22:12.161000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_32
V1111 13:22:12.161000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1860
V1111 13:22:12.161000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.161000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_83
V1111 13:22:12.161000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1766
V1111 13:22:12.162000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_42
V1111 13:22:12.162000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1765
V1111 13:22:12.162000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_backward_3
V1111 13:22:12.162000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1765
V1111 13:22:12.162000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_127
V1111 13:22:12.162000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1765
V1111 13:22:12.162000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_128
V1111 13:22:12.162000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1765
V1111 13:22:12.162000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_33
V1111 13:22:12.162000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1860
V1111 13:22:12.162000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.163000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_148
V1111 13:22:12.163000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1763
V1111 13:22:12.163000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: gather_11
V1111 13:22:12.163000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1762
V1111 13:22:12.163000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_47
V1111 13:22:12.163000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1761
V1111 13:22:12.163000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_48
V1111 13:22:12.163000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1761
V1111 13:22:12.163000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sum_8
V1111 13:22:12.164000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1761
V1111 13:22:12.164000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_149
V1111 13:22:12.164000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1760
V1111 13:22:12.164000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_84
V1111 13:22:12.164000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1759
V1111 13:22:12.164000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_66
V1111 13:22:12.164000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1759
V1111 13:22:12.164000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_85
V1111 13:22:12.164000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1759
V1111 13:22:12.164000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_86
V1111 13:22:12.165000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1759
V1111 13:22:12.165000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_67
V1111 13:22:12.165000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1759
V1111 13:22:12.165000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_87
V1111 13:22:12.165000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1758
V1111 13:22:12.165000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_49
V1111 13:22:12.165000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1757
V1111 13:22:12.165000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_50
V1111 13:22:12.165000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1757
V1111 13:22:12.165000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_88
V1111 13:22:12.166000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1756
V1111 13:22:12.166000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_68
V1111 13:22:12.166000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1756
V1111 13:22:12.166000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_89
V1111 13:22:12.166000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1756
V1111 13:22:12.166000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_90
V1111 13:22:12.166000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1756
V1111 13:22:12.166000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_69
V1111 13:22:12.166000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1756
V1111 13:22:12.166000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_91
V1111 13:22:12.167000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1755
V1111 13:22:12.167000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: silu_backward_2
V1111 13:22:12.167000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1754
V1111 13:22:12.167000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_92
V1111 13:22:12.167000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1753
V1111 13:22:12.167000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_70
V1111 13:22:12.167000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1753
V1111 13:22:12.167000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_93
V1111 13:22:12.167000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1753
V1111 13:22:12.167000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_94
V1111 13:22:12.167000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1753
V1111 13:22:12.168000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_71
V1111 13:22:12.168000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1753
V1111 13:22:12.168000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_34
V1111 13:22:12.168000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1860
V1111 13:22:12.168000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.168000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_95
V1111 13:22:12.168000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1752
V1111 13:22:12.168000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_backward_1
V1111 13:22:12.168000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1751
V1111 13:22:12.168000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_11
V1111 13:22:12.169000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1750
V1111 13:22:12.169000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_46
V1111 13:22:12.169000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1749
V1111 13:22:12.169000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_55
V1111 13:22:12.169000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1748
V1111 13:22:12.169000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_21
V1111 13:22:12.169000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1748
V1111 13:22:12.169000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_56
V1111 13:22:12.169000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1748
V1111 13:22:12.170000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_57
V1111 13:22:12.170000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1748
V1111 13:22:12.170000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_22
V1111 13:22:12.170000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1748
V1111 13:22:12.170000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_58
V1111 13:22:12.170000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1747
V1111 13:22:12.170000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_47
V1111 13:22:12.170000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1746
V1111 13:22:12.170000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_51
V1111 13:22:12.170000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1745
V1111 13:22:12.171000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_52
V1111 13:22:12.171000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1745
V1111 13:22:12.171000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_59
V1111 13:22:12.171000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1744
V1111 13:22:12.171000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_23
V1111 13:22:12.171000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1744
V1111 13:22:12.171000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_60
V1111 13:22:12.171000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1744
V1111 13:22:12.171000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_61
V1111 13:22:12.172000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1744
V1111 13:22:12.172000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_24
V1111 13:22:12.172000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1744
V1111 13:22:12.172000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_62
V1111 13:22:12.172000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1743
V1111 13:22:12.172000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_48
V1111 13:22:12.172000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1742
V1111 13:22:12.172000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_49
V1111 13:22:12.172000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1741
V1111 13:22:12.173000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: silu_backward_3
V1111 13:22:12.173000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1740
V1111 13:22:12.173000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_63
V1111 13:22:12.173000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1739
V1111 13:22:12.173000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_25
V1111 13:22:12.173000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1739
V1111 13:22:12.173000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_64
V1111 13:22:12.173000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1739
V1111 13:22:12.173000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_65
V1111 13:22:12.173000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1739
V1111 13:22:12.174000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_26
V1111 13:22:12.174000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1739
V1111 13:22:12.174000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_66
V1111 13:22:12.174000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1738
V1111 13:22:12.174000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_50
V1111 13:22:12.174000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1737
V1111 13:22:12.174000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_51
V1111 13:22:12.174000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1736
V1111 13:22:12.174000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_35
V1111 13:22:12.174000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1860
V1111 13:22:12.175000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.175000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_69
V1111 13:22:12.175000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1735
V1111 13:22:12.175000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_put_7
V1111 13:22:12.175000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1735
V1111 13:22:12.175000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_17
V1111 13:22:12.175000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1734
V1111 13:22:12.175000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_18
V1111 13:22:12.175000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1734
V1111 13:22:12.175000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_70
V1111 13:22:12.176000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1733
V1111 13:22:12.176000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: scatter_add_7
V1111 13:22:12.176000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1733
V1111 13:22:12.176000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_36
V1111 13:22:12.176000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1860
V1111 13:22:12.176000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.176000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_71
V1111 13:22:12.176000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1732
V1111 13:22:12.176000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_put_8
V1111 13:22:12.176000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1732
V1111 13:22:12.177000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_150
V1111 13:22:12.177000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1731
V1111 13:22:12.177000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_53
V1111 13:22:12.177000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1730
V1111 13:22:12.177000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_72
V1111 13:22:12.177000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1729
V1111 13:22:12.177000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: scatter_add_8
V1111 13:22:12.177000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1729
V1111 13:22:12.177000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_43
V1111 13:22:12.178000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1726
V1111 13:22:12.178000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _softmax_backward_data_1
V1111 13:22:12.178000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1726
V1111 13:22:12.178000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_96
V1111 13:22:12.178000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1725
V1111 13:22:12.178000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_72
V1111 13:22:12.178000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1725
V1111 13:22:12.178000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_97
V1111 13:22:12.178000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1725
V1111 13:22:12.178000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_98
V1111 13:22:12.179000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1725
V1111 13:22:12.179000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_73
V1111 13:22:12.179000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1725
V1111 13:22:12.179000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_37
V1111 13:22:12.179000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1860
V1111 13:22:12.179000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.179000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_99
V1111 13:22:12.179000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1724
V1111 13:22:12.179000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_151
V1111 13:22:12.179000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1723
V1111 13:22:12.180000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_44
V1111 13:22:12.180000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1722
V1111 13:22:12.180000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_backward_4
V1111 13:22:12.180000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1722
V1111 13:22:12.180000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_129
V1111 13:22:12.180000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1722
V1111 13:22:12.180000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_130
V1111 13:22:12.180000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1722
V1111 13:22:12.180000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_38
V1111 13:22:12.180000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1860
V1111 13:22:12.180000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.181000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_152
V1111 13:22:12.181000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1720
V1111 13:22:12.181000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_100
V1111 13:22:12.181000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1719
V1111 13:22:12.181000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_74
V1111 13:22:12.181000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1719
V1111 13:22:12.181000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_101
V1111 13:22:12.181000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1719
V1111 13:22:12.181000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_102
V1111 13:22:12.181000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1719
V1111 13:22:12.182000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_75
V1111 13:22:12.182000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1719
V1111 13:22:12.182000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_153
V1111 13:22:12.182000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1718
V1111 13:22:12.182000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_103
V1111 13:22:12.182000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1717
V1111 13:22:12.182000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_154
V1111 13:22:12.182000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1716
V1111 13:22:12.182000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_67
V1111 13:22:12.182000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1715
V1111 13:22:12.183000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: zeros_2
V1111 13:22:12.183000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.183000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: zeros_3
V1111 13:22:12.183000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.183000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_45
V1111 13:22:12.183000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.183000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_46
V1111 13:22:12.183000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.183000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: fw_graph1
V1111 13:22:12.183000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.184000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: joint_graph1
V1111 13:22:12.184000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.184000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mask_graph1
V1111 13:22:12.184000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.184000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _tensor_constant0_7
V1111 13:22:12.184000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.184000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: flex_attention_backward_1
V1111 13:22:12.184000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.184000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_131
V1111 13:22:12.184000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.185000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_132
V1111 13:22:12.185000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.185000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_133
V1111 13:22:12.185000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.185000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_134
V1111 13:22:12.185000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.185000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_68
V1111 13:22:12.185000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1711
V1111 13:22:12.185000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_69
V1111 13:22:12.185000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1710
V1111 13:22:12.186000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_70
V1111 13:22:12.186000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1709
V1111 13:22:12.186000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_19
V1111 13:22:12.186000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1708
V1111 13:22:12.186000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_20
V1111 13:22:12.186000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1708
V1111 13:22:12.186000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sum_9
V1111 13:22:12.186000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1707
V1111 13:22:12.186000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_20
V1111 13:22:12.186000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1706
V1111 13:22:12.187000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_155
V1111 13:22:12.187000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1705
V1111 13:22:12.187000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_156
V1111 13:22:12.187000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1704
V1111 13:22:12.187000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_104
V1111 13:22:12.187000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1703
V1111 13:22:12.187000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_76
V1111 13:22:12.187000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1703
V1111 13:22:12.187000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_105
V1111 13:22:12.187000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1703
V1111 13:22:12.188000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_106
V1111 13:22:12.188000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1703
V1111 13:22:12.188000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_77
V1111 13:22:12.188000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1703
V1111 13:22:12.188000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_157
V1111 13:22:12.188000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1702
V1111 13:22:12.188000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_107
V1111 13:22:12.188000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1701
V1111 13:22:12.188000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_47
V1111 13:22:12.188000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1700
V1111 13:22:12.189000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_backward_5
V1111 13:22:12.189000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1700
V1111 13:22:12.189000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_135
V1111 13:22:12.189000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1700
V1111 13:22:12.189000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_136
V1111 13:22:12.189000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1700
V1111 13:22:12.189000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_158
V1111 13:22:12.189000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1699
V1111 13:22:12.189000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_complex_14
V1111 13:22:12.190000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1698
V1111 13:22:12.190000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _conj_2
V1111 13:22:12.190000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1697
V1111 13:22:12.190000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: clone_3
V1111 13:22:12.190000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1697
V1111 13:22:12.190000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_54
V1111 13:22:12.190000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1697
V1111 13:22:12.190000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_real_14
V1111 13:22:12.190000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1696
V1111 13:22:12.190000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_159
V1111 13:22:12.191000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1695
V1111 13:22:12.191000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: squeeze_1
V1111 13:22:12.191000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1694
V1111 13:22:12.191000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_21
V1111 13:22:12.191000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1693
V1111 13:22:12.191000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_160
V1111 13:22:12.191000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1692
V1111 13:22:12.191000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_108
V1111 13:22:12.191000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1691
V1111 13:22:12.191000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_78
V1111 13:22:12.192000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1691
V1111 13:22:12.192000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_109
V1111 13:22:12.192000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1691
V1111 13:22:12.192000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_110
V1111 13:22:12.192000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1691
V1111 13:22:12.192000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_79
V1111 13:22:12.192000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1691
V1111 13:22:12.192000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_161
V1111 13:22:12.192000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1690
V1111 13:22:12.192000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_111
V1111 13:22:12.193000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1689
V1111 13:22:12.193000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_21
V1111 13:22:12.193000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1688
V1111 13:22:12.193000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_22
V1111 13:22:12.193000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1688
V1111 13:22:12.193000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_162
V1111 13:22:12.193000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1687
V1111 13:22:12.193000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: clone_4
V1111 13:22:12.193000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1686
V1111 13:22:12.193000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_complex_15
V1111 13:22:12.194000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1686
V1111 13:22:12.194000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _conj_3
V1111 13:22:12.194000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1685
V1111 13:22:12.194000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: clone_5
V1111 13:22:12.194000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1685
V1111 13:22:12.194000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_55
V1111 13:22:12.194000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1685
V1111 13:22:12.194000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_real_15
V1111 13:22:12.194000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1684
V1111 13:22:12.194000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_163
V1111 13:22:12.195000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1683
V1111 13:22:12.195000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_22
V1111 13:22:12.195000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1682
V1111 13:22:12.195000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_164
V1111 13:22:12.195000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1681
V1111 13:22:12.195000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_165
V1111 13:22:12.195000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1680
V1111 13:22:12.195000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_112
V1111 13:22:12.195000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1679
V1111 13:22:12.195000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_80
V1111 13:22:12.195000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1679
V1111 13:22:12.196000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_113
V1111 13:22:12.196000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1679
V1111 13:22:12.196000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_114
V1111 13:22:12.196000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1679
V1111 13:22:12.196000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_81
V1111 13:22:12.196000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1679
V1111 13:22:12.196000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_166
V1111 13:22:12.196000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1678
V1111 13:22:12.196000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_39
V1111 13:22:12.196000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1862
V1111 13:22:12.197000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.197000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_115
V1111 13:22:12.197000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1677
V1111 13:22:12.197000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_48
V1111 13:22:12.197000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1676
V1111 13:22:12.197000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_backward_6
V1111 13:22:12.197000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1676
V1111 13:22:12.197000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_137
V1111 13:22:12.197000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1676
V1111 13:22:12.198000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_138
V1111 13:22:12.198000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1676
V1111 13:22:12.198000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_40
V1111 13:22:12.198000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1862
V1111 13:22:12.198000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.198000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_167
V1111 13:22:12.198000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1674
V1111 13:22:12.198000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: gather_12
V1111 13:22:12.198000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1673
V1111 13:22:12.198000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_56
V1111 13:22:12.199000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1672
V1111 13:22:12.199000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_57
V1111 13:22:12.199000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1672
V1111 13:22:12.199000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sum_10
V1111 13:22:12.199000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1672
V1111 13:22:12.199000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_168
V1111 13:22:12.199000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1671
V1111 13:22:12.199000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_116
V1111 13:22:12.199000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1670
V1111 13:22:12.199000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_82
V1111 13:22:12.200000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1670
V1111 13:22:12.200000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_117
V1111 13:22:12.200000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1670
V1111 13:22:12.200000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_118
V1111 13:22:12.200000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1670
V1111 13:22:12.200000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_83
V1111 13:22:12.200000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1670
V1111 13:22:12.200000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_119
V1111 13:22:12.200000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1669
V1111 13:22:12.200000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_58
V1111 13:22:12.201000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1668
V1111 13:22:12.201000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_59
V1111 13:22:12.201000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1668
V1111 13:22:12.201000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_120
V1111 13:22:12.201000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1667
V1111 13:22:12.201000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_84
V1111 13:22:12.201000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1667
V1111 13:22:12.201000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_121
V1111 13:22:12.201000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1667
V1111 13:22:12.201000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_122
V1111 13:22:12.202000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1667
V1111 13:22:12.202000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_85
V1111 13:22:12.202000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1667
V1111 13:22:12.202000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_123
V1111 13:22:12.202000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1666
V1111 13:22:12.202000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: silu_backward_4
V1111 13:22:12.202000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1665
V1111 13:22:12.202000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_124
V1111 13:22:12.202000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1664
V1111 13:22:12.202000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_86
V1111 13:22:12.203000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1664
V1111 13:22:12.203000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_125
V1111 13:22:12.203000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1664
V1111 13:22:12.203000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_126
V1111 13:22:12.203000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1664
V1111 13:22:12.203000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_87
V1111 13:22:12.203000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1664
V1111 13:22:12.203000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_41
V1111 13:22:12.203000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1862
V1111 13:22:12.203000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.204000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_127
V1111 13:22:12.204000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1663
V1111 13:22:12.204000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_backward_2
V1111 13:22:12.204000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1662
V1111 13:22:12.204000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_12
V1111 13:22:12.204000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1661
V1111 13:22:12.204000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_52
V1111 13:22:12.204000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1660
V1111 13:22:12.204000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_71
V1111 13:22:12.204000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1659
V1111 13:22:12.205000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_27
V1111 13:22:12.205000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1659
V1111 13:22:12.205000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_72
V1111 13:22:12.205000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1659
V1111 13:22:12.205000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_73
V1111 13:22:12.205000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1659
V1111 13:22:12.205000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_28
V1111 13:22:12.205000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1659
V1111 13:22:12.205000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_74
V1111 13:22:12.205000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1658
V1111 13:22:12.206000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_53
V1111 13:22:12.206000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1657
V1111 13:22:12.206000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_60
V1111 13:22:12.206000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1656
V1111 13:22:12.206000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_61
V1111 13:22:12.206000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1656
V1111 13:22:12.206000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_75
V1111 13:22:12.206000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1655
V1111 13:22:12.206000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_29
V1111 13:22:12.206000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1655
V1111 13:22:12.207000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_76
V1111 13:22:12.207000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1655
V1111 13:22:12.207000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_77
V1111 13:22:12.207000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1655
V1111 13:22:12.207000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_30
V1111 13:22:12.207000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1655
V1111 13:22:12.207000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_78
V1111 13:22:12.207000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1654
V1111 13:22:12.207000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_54
V1111 13:22:12.207000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1653
V1111 13:22:12.208000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_55
V1111 13:22:12.208000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1652
V1111 13:22:12.208000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: silu_backward_5
V1111 13:22:12.208000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1651
V1111 13:22:12.208000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_79
V1111 13:22:12.208000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1650
V1111 13:22:12.208000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_31
V1111 13:22:12.208000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1650
V1111 13:22:12.208000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_80
V1111 13:22:12.209000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1650
V1111 13:22:12.209000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_81
V1111 13:22:12.209000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1650
V1111 13:22:12.209000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_32
V1111 13:22:12.209000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1650
V1111 13:22:12.209000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_82
V1111 13:22:12.209000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1649
V1111 13:22:12.209000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_56
V1111 13:22:12.209000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1648
V1111 13:22:12.209000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_57
V1111 13:22:12.210000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1647
V1111 13:22:12.210000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_42
V1111 13:22:12.210000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1862
V1111 13:22:12.210000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.210000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_73
V1111 13:22:12.210000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1646
V1111 13:22:12.210000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_put_9
V1111 13:22:12.210000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1646
V1111 13:22:12.210000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_23
V1111 13:22:12.210000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1645
V1111 13:22:12.211000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_24
V1111 13:22:12.211000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1645
V1111 13:22:12.211000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_74
V1111 13:22:12.211000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1644
V1111 13:22:12.211000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: scatter_add_9
V1111 13:22:12.211000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1644
V1111 13:22:12.211000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_43
V1111 13:22:12.211000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1862
V1111 13:22:12.211000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.211000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_75
V1111 13:22:12.212000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1643
V1111 13:22:12.212000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_put_10
V1111 13:22:12.212000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1643
V1111 13:22:12.212000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_169
V1111 13:22:12.212000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1642
V1111 13:22:12.212000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_62
V1111 13:22:12.212000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1641
V1111 13:22:12.212000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_76
V1111 13:22:12.212000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1640
V1111 13:22:12.212000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: scatter_add_10
V1111 13:22:12.213000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1640
V1111 13:22:12.213000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_49
V1111 13:22:12.213000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1637
V1111 13:22:12.213000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _softmax_backward_data_2
V1111 13:22:12.213000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1637
V1111 13:22:12.213000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_128
V1111 13:22:12.213000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1636
V1111 13:22:12.213000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_88
V1111 13:22:12.213000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1636
V1111 13:22:12.213000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_129
V1111 13:22:12.214000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1636
V1111 13:22:12.214000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_130
V1111 13:22:12.214000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1636
V1111 13:22:12.214000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_89
V1111 13:22:12.214000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1636
V1111 13:22:12.214000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_44
V1111 13:22:12.214000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1862
V1111 13:22:12.214000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.214000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_131
V1111 13:22:12.214000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1635
V1111 13:22:12.215000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_170
V1111 13:22:12.215000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1634
V1111 13:22:12.215000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_50
V1111 13:22:12.215000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1633
V1111 13:22:12.215000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_backward_7
V1111 13:22:12.215000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1633
V1111 13:22:12.215000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_139
V1111 13:22:12.215000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1633
V1111 13:22:12.215000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_140
V1111 13:22:12.215000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1633
V1111 13:22:12.216000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_45
V1111 13:22:12.216000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1862
V1111 13:22:12.216000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.216000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_171
V1111 13:22:12.216000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1631
V1111 13:22:12.216000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_132
V1111 13:22:12.216000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1630
V1111 13:22:12.216000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_90
V1111 13:22:12.216000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1630
V1111 13:22:12.216000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_133
V1111 13:22:12.217000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1630
V1111 13:22:12.217000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_134
V1111 13:22:12.217000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1630
V1111 13:22:12.217000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_91
V1111 13:22:12.217000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1630
V1111 13:22:12.217000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_172
V1111 13:22:12.217000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1629
V1111 13:22:12.217000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_135
V1111 13:22:12.217000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1628
V1111 13:22:12.217000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_173
V1111 13:22:12.217000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1627
V1111 13:22:12.218000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_83
V1111 13:22:12.218000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1626
V1111 13:22:12.218000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: zeros_4
V1111 13:22:12.218000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.218000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: zeros_5
V1111 13:22:12.218000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.218000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_51
V1111 13:22:12.218000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.218000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_52
V1111 13:22:12.218000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.219000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: fw_graph2
V1111 13:22:12.219000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.219000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: joint_graph2
V1111 13:22:12.219000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.219000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mask_graph2
V1111 13:22:12.219000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.219000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _tensor_constant0_8
V1111 13:22:12.219000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.219000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: flex_attention_backward_2
V1111 13:22:12.220000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.220000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_141
V1111 13:22:12.220000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.220000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_142
V1111 13:22:12.220000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.220000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_143
V1111 13:22:12.220000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.220000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_144
V1111 13:22:12.220000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.220000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_84
V1111 13:22:12.221000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1622
V1111 13:22:12.221000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_85
V1111 13:22:12.221000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1621
V1111 13:22:12.221000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_86
V1111 13:22:12.221000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1620
V1111 13:22:12.221000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_25
V1111 13:22:12.221000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1619
V1111 13:22:12.221000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_26
V1111 13:22:12.221000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1619
V1111 13:22:12.221000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sum_11
V1111 13:22:12.222000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1618
V1111 13:22:12.222000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_23
V1111 13:22:12.222000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1617
V1111 13:22:12.222000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_174
V1111 13:22:12.222000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1616
V1111 13:22:12.222000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_175
V1111 13:22:12.222000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1615
V1111 13:22:12.222000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_136
V1111 13:22:12.222000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1614
V1111 13:22:12.222000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_92
V1111 13:22:12.223000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1614
V1111 13:22:12.223000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_137
V1111 13:22:12.223000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1614
V1111 13:22:12.223000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_138
V1111 13:22:12.223000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1614
V1111 13:22:12.223000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_93
V1111 13:22:12.223000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1614
V1111 13:22:12.223000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_176
V1111 13:22:12.223000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1613
V1111 13:22:12.223000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_139
V1111 13:22:12.224000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1612
V1111 13:22:12.224000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_53
V1111 13:22:12.224000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1611
V1111 13:22:12.224000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_backward_8
V1111 13:22:12.224000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1611
V1111 13:22:12.224000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_145
V1111 13:22:12.224000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1611
V1111 13:22:12.224000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_146
V1111 13:22:12.224000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1611
V1111 13:22:12.224000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_177
V1111 13:22:12.224000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1610
V1111 13:22:12.225000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_complex_16
V1111 13:22:12.225000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1609
V1111 13:22:12.225000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _conj_4
V1111 13:22:12.225000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1608
V1111 13:22:12.225000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: clone_6
V1111 13:22:12.225000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1608
V1111 13:22:12.225000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_63
V1111 13:22:12.225000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1608
V1111 13:22:12.225000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_real_16
V1111 13:22:12.225000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1607
V1111 13:22:12.226000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_178
V1111 13:22:12.226000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1606
V1111 13:22:12.226000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: squeeze_2
V1111 13:22:12.226000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1605
V1111 13:22:12.226000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_24
V1111 13:22:12.226000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1604
V1111 13:22:12.226000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_179
V1111 13:22:12.226000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1603
V1111 13:22:12.226000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_140
V1111 13:22:12.226000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1602
V1111 13:22:12.227000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_94
V1111 13:22:12.227000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1602
V1111 13:22:12.227000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_141
V1111 13:22:12.227000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1602
V1111 13:22:12.227000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_142
V1111 13:22:12.227000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1602
V1111 13:22:12.227000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_95
V1111 13:22:12.227000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1602
V1111 13:22:12.227000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_180
V1111 13:22:12.227000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1601
V1111 13:22:12.228000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_143
V1111 13:22:12.228000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1600
V1111 13:22:12.228000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_27
V1111 13:22:12.228000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1599
V1111 13:22:12.228000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_28
V1111 13:22:12.228000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1599
V1111 13:22:12.228000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_181
V1111 13:22:12.228000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1598
V1111 13:22:12.228000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: clone_7
V1111 13:22:12.228000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1597
V1111 13:22:12.229000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_complex_17
V1111 13:22:12.229000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1597
V1111 13:22:12.229000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _conj_5
V1111 13:22:12.229000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1596
V1111 13:22:12.229000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: clone_8
V1111 13:22:12.229000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1596
V1111 13:22:12.229000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_64
V1111 13:22:12.229000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1596
V1111 13:22:12.229000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_real_17
V1111 13:22:12.229000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1595
V1111 13:22:12.230000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_182
V1111 13:22:12.230000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1594
V1111 13:22:12.230000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_25
V1111 13:22:12.230000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1593
V1111 13:22:12.230000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_183
V1111 13:22:12.230000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1592
V1111 13:22:12.230000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_184
V1111 13:22:12.230000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1591
V1111 13:22:12.230000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_144
V1111 13:22:12.230000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1590
V1111 13:22:12.231000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_96
V1111 13:22:12.231000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1590
V1111 13:22:12.231000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_145
V1111 13:22:12.231000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1590
V1111 13:22:12.231000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_146
V1111 13:22:12.231000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1590
V1111 13:22:12.231000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_97
V1111 13:22:12.231000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1590
V1111 13:22:12.231000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_185
V1111 13:22:12.231000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1589
V1111 13:22:12.232000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_46
V1111 13:22:12.232000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1864
V1111 13:22:12.232000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.232000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_147
V1111 13:22:12.232000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1588
V1111 13:22:12.232000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_54
V1111 13:22:12.232000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1587
V1111 13:22:12.232000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_backward_9
V1111 13:22:12.232000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1587
V1111 13:22:12.232000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_147
V1111 13:22:12.233000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1587
V1111 13:22:12.233000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_148
V1111 13:22:12.233000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1587
V1111 13:22:12.233000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_47
V1111 13:22:12.233000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1864
V1111 13:22:12.233000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.233000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_186
V1111 13:22:12.233000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1585
V1111 13:22:12.233000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: gather_13
V1111 13:22:12.233000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1584
V1111 13:22:12.234000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_65
V1111 13:22:12.234000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1583
V1111 13:22:12.234000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_66
V1111 13:22:12.234000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1583
V1111 13:22:12.234000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sum_12
V1111 13:22:12.234000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1583
V1111 13:22:12.234000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_187
V1111 13:22:12.234000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1582
V1111 13:22:12.234000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_148
V1111 13:22:12.234000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1581
V1111 13:22:12.235000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_98
V1111 13:22:12.235000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1581
V1111 13:22:12.235000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_149
V1111 13:22:12.235000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1581
V1111 13:22:12.235000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_150
V1111 13:22:12.235000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1581
V1111 13:22:12.235000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_99
V1111 13:22:12.235000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1581
V1111 13:22:12.235000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_151
V1111 13:22:12.235000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1580
V1111 13:22:12.236000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_67
V1111 13:22:12.236000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1579
V1111 13:22:12.236000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_68
V1111 13:22:12.236000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1579
V1111 13:22:12.236000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_152
V1111 13:22:12.236000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1578
V1111 13:22:12.236000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_100
V1111 13:22:12.236000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1578
V1111 13:22:12.236000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_153
V1111 13:22:12.236000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1578
V1111 13:22:12.237000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_154
V1111 13:22:12.237000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1578
V1111 13:22:12.237000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_101
V1111 13:22:12.237000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1578
V1111 13:22:12.237000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_155
V1111 13:22:12.237000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1577
V1111 13:22:12.237000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: silu_backward_6
V1111 13:22:12.237000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1576
V1111 13:22:12.237000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_156
V1111 13:22:12.237000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1575
V1111 13:22:12.238000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_102
V1111 13:22:12.238000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1575
V1111 13:22:12.238000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_157
V1111 13:22:12.238000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1575
V1111 13:22:12.238000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_158
V1111 13:22:12.238000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1575
V1111 13:22:12.238000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_103
V1111 13:22:12.238000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1575
V1111 13:22:12.238000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_48
V1111 13:22:12.238000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1864
V1111 13:22:12.239000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.239000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_159
V1111 13:22:12.239000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1574
V1111 13:22:12.239000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_backward_3
V1111 13:22:12.239000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1573
V1111 13:22:12.239000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_13
V1111 13:22:12.239000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1572
V1111 13:22:12.239000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_58
V1111 13:22:12.239000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1571
V1111 13:22:12.239000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_87
V1111 13:22:12.240000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1570
V1111 13:22:12.240000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_33
V1111 13:22:12.240000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1570
V1111 13:22:12.240000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_88
V1111 13:22:12.240000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1570
V1111 13:22:12.240000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_89
V1111 13:22:12.240000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1570
V1111 13:22:12.240000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_34
V1111 13:22:12.240000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1570
V1111 13:22:12.240000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_90
V1111 13:22:12.241000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1569
V1111 13:22:12.241000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_59
V1111 13:22:12.241000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1568
V1111 13:22:12.241000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_69
V1111 13:22:12.241000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1567
V1111 13:22:12.241000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_70
V1111 13:22:12.241000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1567
V1111 13:22:12.241000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_91
V1111 13:22:12.241000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1566
V1111 13:22:12.242000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_35
V1111 13:22:12.242000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1566
V1111 13:22:12.242000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_92
V1111 13:22:12.242000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1566
V1111 13:22:12.242000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_93
V1111 13:22:12.242000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1566
V1111 13:22:12.242000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_36
V1111 13:22:12.242000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1566
V1111 13:22:12.242000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_94
V1111 13:22:12.242000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1565
V1111 13:22:12.243000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_60
V1111 13:22:12.243000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1564
V1111 13:22:12.243000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_61
V1111 13:22:12.243000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1563
V1111 13:22:12.243000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: silu_backward_7
V1111 13:22:12.243000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1562
V1111 13:22:12.243000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_95
V1111 13:22:12.243000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1561
V1111 13:22:12.243000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_37
V1111 13:22:12.243000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1561
V1111 13:22:12.244000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_96
V1111 13:22:12.244000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1561
V1111 13:22:12.244000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_97
V1111 13:22:12.244000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1561
V1111 13:22:12.244000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_38
V1111 13:22:12.244000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1561
V1111 13:22:12.244000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_98
V1111 13:22:12.244000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1560
V1111 13:22:12.244000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_62
V1111 13:22:12.244000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1559
V1111 13:22:12.245000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_63
V1111 13:22:12.245000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1558
V1111 13:22:12.245000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_49
V1111 13:22:12.245000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1864
V1111 13:22:12.245000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.245000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_77
V1111 13:22:12.245000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1557
V1111 13:22:12.245000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_put_11
V1111 13:22:12.245000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1557
V1111 13:22:12.245000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_29
V1111 13:22:12.246000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1556
V1111 13:22:12.246000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_30
V1111 13:22:12.246000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1556
V1111 13:22:12.246000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_78
V1111 13:22:12.246000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1555
V1111 13:22:12.246000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: scatter_add_11
V1111 13:22:12.246000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1555
V1111 13:22:12.246000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_50
V1111 13:22:12.246000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1864
V1111 13:22:12.246000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.247000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_79
V1111 13:22:12.247000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1554
V1111 13:22:12.247000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_put_12
V1111 13:22:12.247000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1554
V1111 13:22:12.247000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_188
V1111 13:22:12.247000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1553
V1111 13:22:12.247000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_71
V1111 13:22:12.247000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1552
V1111 13:22:12.247000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_80
V1111 13:22:12.247000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1551
V1111 13:22:12.248000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: scatter_add_12
V1111 13:22:12.248000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1551
V1111 13:22:12.248000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_55
V1111 13:22:12.248000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1548
V1111 13:22:12.248000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _softmax_backward_data_3
V1111 13:22:12.248000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1548
V1111 13:22:12.248000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_160
V1111 13:22:12.248000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1547
V1111 13:22:12.248000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_104
V1111 13:22:12.248000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1547
V1111 13:22:12.249000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_161
V1111 13:22:12.249000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1547
V1111 13:22:12.249000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_162
V1111 13:22:12.249000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1547
V1111 13:22:12.249000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_105
V1111 13:22:12.249000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1547
V1111 13:22:12.249000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_51
V1111 13:22:12.249000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1864
V1111 13:22:12.249000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.249000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_163
V1111 13:22:12.250000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1546
V1111 13:22:12.250000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_189
V1111 13:22:12.250000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1545
V1111 13:22:12.250000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_56
V1111 13:22:12.250000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1544
V1111 13:22:12.250000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_backward_10
V1111 13:22:12.250000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1544
V1111 13:22:12.250000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_149
V1111 13:22:12.250000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1544
V1111 13:22:12.250000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_150
V1111 13:22:12.251000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1544
V1111 13:22:12.251000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_52
V1111 13:22:12.251000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1864
V1111 13:22:12.251000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.251000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_190
V1111 13:22:12.251000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1542
V1111 13:22:12.251000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_164
V1111 13:22:12.251000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1541
V1111 13:22:12.251000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_106
V1111 13:22:12.251000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1541
V1111 13:22:12.252000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_165
V1111 13:22:12.252000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1541
V1111 13:22:12.252000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_166
V1111 13:22:12.252000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1541
V1111 13:22:12.252000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_107
V1111 13:22:12.252000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1541
V1111 13:22:12.252000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_191
V1111 13:22:12.252000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1540
V1111 13:22:12.252000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_167
V1111 13:22:12.252000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1539
V1111 13:22:12.253000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_192
V1111 13:22:12.253000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1538
V1111 13:22:12.253000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_99
V1111 13:22:12.253000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1537
V1111 13:22:12.253000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: zeros_6
V1111 13:22:12.253000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.253000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: zeros_7
V1111 13:22:12.253000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.253000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_57
V1111 13:22:12.253000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.254000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_58
V1111 13:22:12.254000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.254000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: fw_graph3
V1111 13:22:12.254000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.254000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: joint_graph3
V1111 13:22:12.254000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.254000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mask_graph3
V1111 13:22:12.254000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.254000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _tensor_constant0_9
V1111 13:22:12.254000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.255000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: flex_attention_backward_3
V1111 13:22:12.255000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.255000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_151
V1111 13:22:12.255000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.255000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_152
V1111 13:22:12.255000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.255000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_153
V1111 13:22:12.255000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.255000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_154
V1111 13:22:12.255000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.256000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_100
V1111 13:22:12.256000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1533
V1111 13:22:12.256000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_101
V1111 13:22:12.256000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1532
V1111 13:22:12.256000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_102
V1111 13:22:12.256000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1531
V1111 13:22:12.256000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_31
V1111 13:22:12.256000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1530
V1111 13:22:12.256000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_32
V1111 13:22:12.256000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1530
V1111 13:22:12.257000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sum_13
V1111 13:22:12.257000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1529
V1111 13:22:12.257000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_26
V1111 13:22:12.257000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1528
V1111 13:22:12.257000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_193
V1111 13:22:12.257000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1527
V1111 13:22:12.257000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_194
V1111 13:22:12.257000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1526
V1111 13:22:12.257000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_168
V1111 13:22:12.257000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1525
V1111 13:22:12.258000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_108
V1111 13:22:12.258000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1525
V1111 13:22:12.258000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_169
V1111 13:22:12.258000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1525
V1111 13:22:12.258000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_170
V1111 13:22:12.258000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1525
V1111 13:22:12.258000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_109
V1111 13:22:12.258000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1525
V1111 13:22:12.258000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_195
V1111 13:22:12.258000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1524
V1111 13:22:12.259000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_171
V1111 13:22:12.259000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1523
V1111 13:22:12.259000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_59
V1111 13:22:12.259000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1522
V1111 13:22:12.259000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_backward_11
V1111 13:22:12.259000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1522
V1111 13:22:12.259000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_155
V1111 13:22:12.259000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1522
V1111 13:22:12.259000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_156
V1111 13:22:12.260000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1522
V1111 13:22:12.260000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_196
V1111 13:22:12.260000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1521
V1111 13:22:12.260000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_complex_18
V1111 13:22:12.260000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1520
V1111 13:22:12.260000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _conj_6
V1111 13:22:12.260000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1519
V1111 13:22:12.260000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: clone_9
V1111 13:22:12.260000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1519
V1111 13:22:12.260000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_72
V1111 13:22:12.261000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1519
V1111 13:22:12.261000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_real_18
V1111 13:22:12.261000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1518
V1111 13:22:12.261000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_197
V1111 13:22:12.261000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1517
V1111 13:22:12.261000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: squeeze_3
V1111 13:22:12.261000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1516
V1111 13:22:12.261000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_27
V1111 13:22:12.261000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1515
V1111 13:22:12.261000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_198
V1111 13:22:12.262000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1514
V1111 13:22:12.262000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_172
V1111 13:22:12.262000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1513
V1111 13:22:12.262000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_110
V1111 13:22:12.262000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1513
V1111 13:22:12.262000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_173
V1111 13:22:12.262000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1513
V1111 13:22:12.262000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_174
V1111 13:22:12.262000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1513
V1111 13:22:12.262000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_111
V1111 13:22:12.263000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1513
V1111 13:22:12.263000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_199
V1111 13:22:12.263000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1512
V1111 13:22:12.263000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_175
V1111 13:22:12.263000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1511
V1111 13:22:12.263000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_33
V1111 13:22:12.263000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1510
V1111 13:22:12.263000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_34
V1111 13:22:12.263000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1510
V1111 13:22:12.263000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_200
V1111 13:22:12.264000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1509
V1111 13:22:12.264000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: clone_10
V1111 13:22:12.264000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1508
V1111 13:22:12.264000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_complex_19
V1111 13:22:12.264000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1508
V1111 13:22:12.264000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _conj_7
V1111 13:22:12.264000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1507
V1111 13:22:12.264000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: clone_11
V1111 13:22:12.264000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1507
V1111 13:22:12.264000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_73
V1111 13:22:12.265000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1507
V1111 13:22:12.265000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_real_19
V1111 13:22:12.265000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1506
V1111 13:22:12.265000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_201
V1111 13:22:12.265000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1505
V1111 13:22:12.265000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_28
V1111 13:22:12.265000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1504
V1111 13:22:12.265000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_202
V1111 13:22:12.265000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1503
V1111 13:22:12.265000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_203
V1111 13:22:12.266000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1502
V1111 13:22:12.266000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_176
V1111 13:22:12.266000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1501
V1111 13:22:12.266000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_112
V1111 13:22:12.266000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1501
V1111 13:22:12.266000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_177
V1111 13:22:12.266000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1501
V1111 13:22:12.266000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_178
V1111 13:22:12.266000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1501
V1111 13:22:12.266000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_113
V1111 13:22:12.267000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1501
V1111 13:22:12.267000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_204
V1111 13:22:12.267000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1500
V1111 13:22:12.267000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_53
V1111 13:22:12.267000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1866
V1111 13:22:12.267000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.267000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_179
V1111 13:22:12.267000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1499
V1111 13:22:12.267000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_60
V1111 13:22:12.267000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1498
V1111 13:22:12.268000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_backward_12
V1111 13:22:12.268000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1498
V1111 13:22:12.268000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_157
V1111 13:22:12.268000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1498
V1111 13:22:12.268000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_158
V1111 13:22:12.268000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1498
V1111 13:22:12.268000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_54
V1111 13:22:12.268000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1866
V1111 13:22:12.268000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.268000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_205
V1111 13:22:12.269000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1496
V1111 13:22:12.269000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: gather_14
V1111 13:22:12.269000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1495
V1111 13:22:12.269000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_74
V1111 13:22:12.269000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1494
V1111 13:22:12.269000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_75
V1111 13:22:12.269000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1494
V1111 13:22:12.269000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sum_14
V1111 13:22:12.269000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1494
V1111 13:22:12.270000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_206
V1111 13:22:12.270000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1493
V1111 13:22:12.270000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_180
V1111 13:22:12.270000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1492
V1111 13:22:12.270000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_114
V1111 13:22:12.270000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1492
V1111 13:22:12.270000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_181
V1111 13:22:12.270000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1492
V1111 13:22:12.270000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_182
V1111 13:22:12.270000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1492
V1111 13:22:12.271000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_115
V1111 13:22:12.271000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1492
V1111 13:22:12.271000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_183
V1111 13:22:12.271000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1491
V1111 13:22:12.271000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_76
V1111 13:22:12.271000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1490
V1111 13:22:12.271000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_77
V1111 13:22:12.271000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1490
V1111 13:22:12.271000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_184
V1111 13:22:12.271000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1489
V1111 13:22:12.272000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_116
V1111 13:22:12.272000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1489
V1111 13:22:12.272000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_185
V1111 13:22:12.272000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1489
V1111 13:22:12.272000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_186
V1111 13:22:12.272000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1489
V1111 13:22:12.272000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_117
V1111 13:22:12.272000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1489
V1111 13:22:12.272000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_187
V1111 13:22:12.272000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1488
V1111 13:22:12.273000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: silu_backward_8
V1111 13:22:12.273000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1487
V1111 13:22:12.273000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_188
V1111 13:22:12.273000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1486
V1111 13:22:12.273000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_118
V1111 13:22:12.273000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1486
V1111 13:22:12.273000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_189
V1111 13:22:12.273000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1486
V1111 13:22:12.273000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_190
V1111 13:22:12.273000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1486
V1111 13:22:12.274000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_119
V1111 13:22:12.274000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1486
V1111 13:22:12.274000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_55
V1111 13:22:12.274000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1866
V1111 13:22:12.274000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.274000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_191
V1111 13:22:12.274000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1485
V1111 13:22:12.274000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_backward_4
V1111 13:22:12.274000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1484
V1111 13:22:12.274000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_14
V1111 13:22:12.275000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1483
V1111 13:22:12.275000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_64
V1111 13:22:12.275000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1482
V1111 13:22:12.275000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_103
V1111 13:22:12.275000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1481
V1111 13:22:12.275000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_39
V1111 13:22:12.275000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1481
V1111 13:22:12.275000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_104
V1111 13:22:12.275000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1481
V1111 13:22:12.276000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_105
V1111 13:22:12.276000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1481
V1111 13:22:12.276000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_40
V1111 13:22:12.276000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1481
V1111 13:22:12.276000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_106
V1111 13:22:12.276000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1480
V1111 13:22:12.276000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_65
V1111 13:22:12.276000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1479
V1111 13:22:12.276000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_78
V1111 13:22:12.276000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1478
V1111 13:22:12.277000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_79
V1111 13:22:12.277000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1478
V1111 13:22:12.277000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_107
V1111 13:22:12.277000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1477
V1111 13:22:12.277000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_41
V1111 13:22:12.277000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1477
V1111 13:22:12.277000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_108
V1111 13:22:12.277000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1477
V1111 13:22:12.277000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_109
V1111 13:22:12.278000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1477
V1111 13:22:12.278000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_42
V1111 13:22:12.278000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1477
V1111 13:22:12.278000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_110
V1111 13:22:12.278000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1476
V1111 13:22:12.278000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_66
V1111 13:22:12.278000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1475
V1111 13:22:12.278000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_67
V1111 13:22:12.278000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1474
V1111 13:22:12.278000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: silu_backward_9
V1111 13:22:12.279000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1473
V1111 13:22:12.279000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_111
V1111 13:22:12.279000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1472
V1111 13:22:12.279000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_43
V1111 13:22:12.279000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1472
V1111 13:22:12.279000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_112
V1111 13:22:12.279000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1472
V1111 13:22:12.279000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_113
V1111 13:22:12.279000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1472
V1111 13:22:12.279000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _grouped_mm_44
V1111 13:22:12.280000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1472
V1111 13:22:12.280000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_114
V1111 13:22:12.280000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1471
V1111 13:22:12.280000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_68
V1111 13:22:12.280000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1470
V1111 13:22:12.280000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _to_copy_69
V1111 13:22:12.280000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1469
V1111 13:22:12.280000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_56
V1111 13:22:12.280000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1866
V1111 13:22:12.280000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.281000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_81
V1111 13:22:12.281000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1468
V1111 13:22:12.281000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_put_13
V1111 13:22:12.281000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1468
V1111 13:22:12.281000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_35
V1111 13:22:12.281000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1467
V1111 13:22:12.281000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_36
V1111 13:22:12.281000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1467
V1111 13:22:12.281000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_82
V1111 13:22:12.281000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1466
V1111 13:22:12.282000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: scatter_add_13
V1111 13:22:12.282000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1466
V1111 13:22:12.282000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_57
V1111 13:22:12.282000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1866
V1111 13:22:12.282000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.282000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_83
V1111 13:22:12.282000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1465
V1111 13:22:12.282000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_put_14
V1111 13:22:12.282000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1465
V1111 13:22:12.282000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_207
V1111 13:22:12.283000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1464
V1111 13:22:12.283000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_80
V1111 13:22:12.283000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1463
V1111 13:22:12.283000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_zeros_84
V1111 13:22:12.283000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1462
V1111 13:22:12.283000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: scatter_add_14
V1111 13:22:12.283000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1462
V1111 13:22:12.283000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_61
V1111 13:22:12.283000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1459
V1111 13:22:12.283000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _softmax_backward_data_4
V1111 13:22:12.284000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1459
V1111 13:22:12.284000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_192
V1111 13:22:12.284000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1458
V1111 13:22:12.284000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_120
V1111 13:22:12.284000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1458
V1111 13:22:12.284000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_193
V1111 13:22:12.284000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1458
V1111 13:22:12.284000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_194
V1111 13:22:12.284000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1458
V1111 13:22:12.285000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_121
V1111 13:22:12.285000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1458
V1111 13:22:12.285000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_58
V1111 13:22:12.285000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1866
V1111 13:22:12.285000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.285000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_195
V1111 13:22:12.285000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1457
V1111 13:22:12.285000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_208
V1111 13:22:12.285000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1456
V1111 13:22:12.285000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_62
V1111 13:22:12.286000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1455
V1111 13:22:12.286000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_backward_13
V1111 13:22:12.286000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1455
V1111 13:22:12.286000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_159
V1111 13:22:12.286000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1455
V1111 13:22:12.286000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_160
V1111 13:22:12.286000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1455
V1111 13:22:12.286000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_59
V1111 13:22:12.286000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1866
V1111 13:22:12.286000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.287000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_209
V1111 13:22:12.287000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1453
V1111 13:22:12.287000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_196
V1111 13:22:12.287000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1452
V1111 13:22:12.287000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_122
V1111 13:22:12.287000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1452
V1111 13:22:12.287000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_197
V1111 13:22:12.287000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1452
V1111 13:22:12.287000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_198
V1111 13:22:12.287000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1452
V1111 13:22:12.288000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_123
V1111 13:22:12.288000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1452
V1111 13:22:12.288000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_210
V1111 13:22:12.288000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1451
V1111 13:22:12.288000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_199
V1111 13:22:12.288000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1450
V1111 13:22:12.288000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_211
V1111 13:22:12.288000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1449
V1111 13:22:12.288000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_115
V1111 13:22:12.288000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1448
V1111 13:22:12.289000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: zeros_8
V1111 13:22:12.289000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.289000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: zeros_9
V1111 13:22:12.289000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.289000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_63
V1111 13:22:12.289000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.289000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_64
V1111 13:22:12.289000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.289000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: fw_graph4
V1111 13:22:12.289000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.290000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: joint_graph4
V1111 13:22:12.290000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.290000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mask_graph4
V1111 13:22:12.290000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.290000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _tensor_constant0_10
V1111 13:22:12.290000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.290000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: flex_attention_backward_4
V1111 13:22:12.290000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.290000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_161
V1111 13:22:12.290000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.291000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_162
V1111 13:22:12.291000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.291000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_163
V1111 13:22:12.291000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.291000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_164
V1111 13:22:12.291000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.291000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_116
V1111 13:22:12.291000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1444
V1111 13:22:12.291000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_117
V1111 13:22:12.291000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1443
V1111 13:22:12.292000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_118
V1111 13:22:12.292000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1442
V1111 13:22:12.292000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_37
V1111 13:22:12.292000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1441
V1111 13:22:12.292000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_38
V1111 13:22:12.292000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1441
V1111 13:22:12.292000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sum_15
V1111 13:22:12.292000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1440
V1111 13:22:12.292000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_29
V1111 13:22:12.292000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1439
V1111 13:22:12.293000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_212
V1111 13:22:12.293000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1438
V1111 13:22:12.293000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_213
V1111 13:22:12.293000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1437
V1111 13:22:12.293000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_200
V1111 13:22:12.293000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1436
V1111 13:22:12.293000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_124
V1111 13:22:12.293000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1436
V1111 13:22:12.293000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_201
V1111 13:22:12.293000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1436
V1111 13:22:12.294000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_202
V1111 13:22:12.294000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1436
V1111 13:22:12.294000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_125
V1111 13:22:12.294000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1436
V1111 13:22:12.294000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_214
V1111 13:22:12.294000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1435
V1111 13:22:12.294000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_203
V1111 13:22:12.294000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1434
V1111 13:22:12.294000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_65
V1111 13:22:12.294000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1433
V1111 13:22:12.295000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_backward_14
V1111 13:22:12.295000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1433
V1111 13:22:12.295000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_165
V1111 13:22:12.295000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1433
V1111 13:22:12.295000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_166
V1111 13:22:12.295000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1433
V1111 13:22:12.295000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_215
V1111 13:22:12.295000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1432
V1111 13:22:12.295000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_complex_20
V1111 13:22:12.295000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1431
V1111 13:22:12.296000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _conj_8
V1111 13:22:12.296000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1430
V1111 13:22:12.296000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: clone_12
V1111 13:22:12.296000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1430
V1111 13:22:12.296000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_81
V1111 13:22:12.296000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1430
V1111 13:22:12.296000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_real_20
V1111 13:22:12.296000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1429
V1111 13:22:12.296000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_216
V1111 13:22:12.296000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1428
V1111 13:22:12.297000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: squeeze_4
V1111 13:22:12.297000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1427
V1111 13:22:12.297000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_30
V1111 13:22:12.297000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1426
V1111 13:22:12.297000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_217
V1111 13:22:12.297000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1425
V1111 13:22:12.297000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_204
V1111 13:22:12.297000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1424
V1111 13:22:12.297000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_126
V1111 13:22:12.297000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1424
V1111 13:22:12.298000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_205
V1111 13:22:12.298000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1424
V1111 13:22:12.298000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_206
V1111 13:22:12.298000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1424
V1111 13:22:12.298000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_127
V1111 13:22:12.298000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1424
V1111 13:22:12.298000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_218
V1111 13:22:12.298000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1423
V1111 13:22:12.298000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_207
V1111 13:22:12.298000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1422
V1111 13:22:12.299000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_39
V1111 13:22:12.299000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1421
V1111 13:22:12.299000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_40
V1111 13:22:12.299000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1421
V1111 13:22:12.299000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_219
V1111 13:22:12.299000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1420
V1111 13:22:12.299000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: clone_13
V1111 13:22:12.299000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1419
V1111 13:22:12.299000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_complex_21
V1111 13:22:12.299000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1419
V1111 13:22:12.300000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _conj_9
V1111 13:22:12.300000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1418
V1111 13:22:12.300000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: clone_14
V1111 13:22:12.300000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1418
V1111 13:22:12.300000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_82
V1111 13:22:12.300000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1418
V1111 13:22:12.300000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_real_21
V1111 13:22:12.300000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1417
V1111 13:22:12.300000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_220
V1111 13:22:12.300000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1416
V1111 13:22:12.301000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_31
V1111 13:22:12.301000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1415
V1111 13:22:12.301000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_221
V1111 13:22:12.301000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1414
V1111 13:22:12.301000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_222
V1111 13:22:12.301000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1413
V1111 13:22:12.301000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_208
V1111 13:22:12.301000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1412
V1111 13:22:12.301000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_128
V1111 13:22:12.301000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1412
V1111 13:22:12.302000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_209
V1111 13:22:12.302000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1412
V1111 13:22:12.302000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_210
V1111 13:22:12.302000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1412
V1111 13:22:12.302000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_129
V1111 13:22:12.302000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1412
V1111 13:22:12.302000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_223
V1111 13:22:12.302000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1411
V1111 13:22:12.302000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_60
V1111 13:22:12.302000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1868
V1111 13:22:12.303000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.303000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_211
V1111 13:22:12.303000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1410
V1111 13:22:12.303000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_66
V1111 13:22:12.303000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1409
V1111 13:22:12.303000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_backward_15
V1111 13:22:12.303000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1409
V1111 13:22:12.303000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_167
V1111 13:22:12.303000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1409
V1111 13:22:12.303000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_168
V1111 13:22:12.304000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1409
V1111 13:22:12.304000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_61
V1111 13:22:12.304000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1868
V1111 13:22:12.304000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.304000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_224
V1111 13:22:12.304000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1407
V1111 13:22:12.304000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_212
V1111 13:22:12.304000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1406
V1111 13:22:12.304000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_130
V1111 13:22:12.305000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1406
V1111 13:22:12.305000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_213
V1111 13:22:12.305000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1406
V1111 13:22:12.305000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_214
V1111 13:22:12.305000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1406
V1111 13:22:12.305000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_131
V1111 13:22:12.305000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1406
V1111 13:22:12.305000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_225
V1111 13:22:12.305000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1405
V1111 13:22:12.305000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_215
V1111 13:22:12.306000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1404
V1111 13:22:12.306000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_83
V1111 13:22:12.306000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1403
V1111 13:22:12.306000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_84
V1111 13:22:12.306000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1403
V1111 13:22:12.306000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_226
V1111 13:22:12.306000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1402
V1111 13:22:12.306000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_216
V1111 13:22:12.306000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1401
V1111 13:22:12.306000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_132
V1111 13:22:12.307000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1401
V1111 13:22:12.307000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_217
V1111 13:22:12.307000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1401
V1111 13:22:12.307000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_218
V1111 13:22:12.307000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1401
V1111 13:22:12.307000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_133
V1111 13:22:12.307000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1401
V1111 13:22:12.307000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_227
V1111 13:22:12.307000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1400
V1111 13:22:12.307000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_219
V1111 13:22:12.308000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1399
V1111 13:22:12.308000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: silu_backward_10
V1111 13:22:12.308000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1398
V1111 13:22:12.308000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_228
V1111 13:22:12.308000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1397
V1111 13:22:12.308000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_220
V1111 13:22:12.308000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1396
V1111 13:22:12.308000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_134
V1111 13:22:12.308000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1396
V1111 13:22:12.308000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_221
V1111 13:22:12.309000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1396
V1111 13:22:12.309000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_222
V1111 13:22:12.309000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1396
V1111 13:22:12.309000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_135
V1111 13:22:12.309000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1396
V1111 13:22:12.309000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_229
V1111 13:22:12.309000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1395
V1111 13:22:12.309000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_62
V1111 13:22:12.309000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1868
V1111 13:22:12.309000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.309000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_223
V1111 13:22:12.310000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1394
V1111 13:22:12.310000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_67
V1111 13:22:12.310000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1393
V1111 13:22:12.310000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_backward_16
V1111 13:22:12.310000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1393
V1111 13:22:12.310000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_169
V1111 13:22:12.310000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1393
V1111 13:22:12.310000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_170
V1111 13:22:12.310000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1393
V1111 13:22:12.310000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_63
V1111 13:22:12.311000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1868
V1111 13:22:12.311000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.311000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_230
V1111 13:22:12.311000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1391
V1111 13:22:12.311000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_224
V1111 13:22:12.311000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1390
V1111 13:22:12.311000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_136
V1111 13:22:12.311000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1390
V1111 13:22:12.311000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_225
V1111 13:22:12.311000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1390
V1111 13:22:12.312000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_226
V1111 13:22:12.312000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1390
V1111 13:22:12.312000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_137
V1111 13:22:12.312000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1390
V1111 13:22:12.312000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_231
V1111 13:22:12.312000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1389
V1111 13:22:12.312000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_227
V1111 13:22:12.312000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1388
V1111 13:22:12.312000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_232
V1111 13:22:12.312000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1387
V1111 13:22:12.313000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_119
V1111 13:22:12.313000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1386
V1111 13:22:12.313000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: zeros_10
V1111 13:22:12.313000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.313000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: zeros_11
V1111 13:22:12.313000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.313000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_68
V1111 13:22:12.313000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.313000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_69
V1111 13:22:12.313000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.314000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: fw_graph5
V1111 13:22:12.314000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.314000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: joint_graph5
V1111 13:22:12.314000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.314000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mask_graph5
V1111 13:22:12.314000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.314000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _tensor_constant0_11
V1111 13:22:12.314000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.314000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: flex_attention_backward_5
V1111 13:22:12.314000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.315000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_171
V1111 13:22:12.315000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.315000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_172
V1111 13:22:12.315000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.315000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_173
V1111 13:22:12.315000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.315000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_174
V1111 13:22:12.315000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.315000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_120
V1111 13:22:12.315000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1382
V1111 13:22:12.316000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_121
V1111 13:22:12.316000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1381
V1111 13:22:12.316000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: transpose_122
V1111 13:22:12.316000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1380
V1111 13:22:12.316000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_41
V1111 13:22:12.316000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1379
V1111 13:22:12.316000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_42
V1111 13:22:12.316000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1379
V1111 13:22:12.316000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: sum_16
V1111 13:22:12.316000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1378
V1111 13:22:12.317000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_32
V1111 13:22:12.317000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1377
V1111 13:22:12.317000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_233
V1111 13:22:12.317000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1376
V1111 13:22:12.317000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_234
V1111 13:22:12.317000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1375
V1111 13:22:12.317000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_228
V1111 13:22:12.317000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1374
V1111 13:22:12.317000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_138
V1111 13:22:12.317000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1374
V1111 13:22:12.318000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_229
V1111 13:22:12.318000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1374
V1111 13:22:12.318000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_230
V1111 13:22:12.318000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1374
V1111 13:22:12.318000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_139
V1111 13:22:12.318000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1374
V1111 13:22:12.318000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_235
V1111 13:22:12.318000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1373
V1111 13:22:12.318000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_231
V1111 13:22:12.318000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1372
V1111 13:22:12.319000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_70
V1111 13:22:12.319000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1371
V1111 13:22:12.319000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_backward_17
V1111 13:22:12.319000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1371
V1111 13:22:12.319000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_175
V1111 13:22:12.319000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1371
V1111 13:22:12.319000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_176
V1111 13:22:12.319000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1371
V1111 13:22:12.319000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_236
V1111 13:22:12.319000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1370
V1111 13:22:12.320000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_complex_22
V1111 13:22:12.320000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1369
V1111 13:22:12.320000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _conj_10
V1111 13:22:12.320000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1368
V1111 13:22:12.320000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: clone_15
V1111 13:22:12.320000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1368
V1111 13:22:12.320000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_85
V1111 13:22:12.320000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1368
V1111 13:22:12.320000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_real_22
V1111 13:22:12.320000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1367
V1111 13:22:12.321000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_237
V1111 13:22:12.321000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1366
V1111 13:22:12.321000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: squeeze_5
V1111 13:22:12.321000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1365
V1111 13:22:12.321000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_33
V1111 13:22:12.321000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1364
V1111 13:22:12.321000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_238
V1111 13:22:12.321000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1363
V1111 13:22:12.321000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_232
V1111 13:22:12.321000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1362
V1111 13:22:12.322000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_140
V1111 13:22:12.322000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1362
V1111 13:22:12.322000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_233
V1111 13:22:12.322000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1362
V1111 13:22:12.322000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_234
V1111 13:22:12.322000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1362
V1111 13:22:12.322000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_141
V1111 13:22:12.322000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1362
V1111 13:22:12.322000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_239
V1111 13:22:12.322000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1361
V1111 13:22:12.323000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_235
V1111 13:22:12.323000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1360
V1111 13:22:12.323000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_43
V1111 13:22:12.323000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1359
V1111 13:22:12.323000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: slice_44
V1111 13:22:12.323000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1359
V1111 13:22:12.323000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_240
V1111 13:22:12.323000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1358
V1111 13:22:12.323000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: clone_16
V1111 13:22:12.323000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1357
V1111 13:22:12.324000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_complex_23
V1111 13:22:12.324000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1357
V1111 13:22:12.324000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _conj_11
V1111 13:22:12.324000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1356
V1111 13:22:12.324000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: clone_17
V1111 13:22:12.324000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1356
V1111 13:22:12.324000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mul_86
V1111 13:22:12.324000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1356
V1111 13:22:12.324000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_as_real_23
V1111 13:22:12.324000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1355
V1111 13:22:12.325000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_241
V1111 13:22:12.325000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1354
V1111 13:22:12.325000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: cat_34
V1111 13:22:12.325000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1353
V1111 13:22:12.325000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_242
V1111 13:22:12.325000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1352
V1111 13:22:12.325000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_243
V1111 13:22:12.325000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1351
V1111 13:22:12.325000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_236
V1111 13:22:12.325000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1350
V1111 13:22:12.325000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_142
V1111 13:22:12.326000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1350
V1111 13:22:12.326000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_237
V1111 13:22:12.326000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1350
V1111 13:22:12.326000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_238
V1111 13:22:12.326000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1350
V1111 13:22:12.326000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: mm_143
V1111 13:22:12.326000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1350
V1111 13:22:12.326000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: view_244
V1111 13:22:12.326000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1349
V1111 13:22:12.326000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_64
V1111 13:22:12.327000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1870
V1111 13:22:12.327000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.327000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: t_239
V1111 13:22:12.327000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1348
V1111 13:22:12.327000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: detach_71
V1111 13:22:12.327000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1347
V1111 13:22:12.327000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: _fused_rms_norm_backward_18
V1111 13:22:12.327000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1347
V1111 13:22:12.327000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_177
V1111 13:22:12.327000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1347
V1111 13:22:12.328000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: getitem_178
V1111 13:22:12.328000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1347
V1111 13:22:12.328000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: add_65
V1111 13:22:12.328000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1870
V1111 13:22:12.328000 86039 torch/_functorch/_aot_autograd/utils.py:459] [__annotation] is_gradient_acc
V1111 13:22:12.328000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: embedding_dense_backward
V1111 13:22:12.328000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1346
V1111 13:22:12.328000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.328000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: None
V1111 13:22:12.328000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.329000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.329000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.329000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.329000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.329000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.329000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.329000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.329000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.329000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.329000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.330000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.330000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.330000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.330000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.330000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.330000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.330000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.330000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.330000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.330000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.331000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.331000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_ones
V1111 13:22:12.331000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.331000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: ge
V1111 13:22:12.331000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.331000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: bitwise_and
V1111 13:22:12.331000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.331000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index
V1111 13:22:12.331000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1384
V1111 13:22:12.331000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_1
V1111 13:22:12.332000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1385
V1111 13:22:12.332000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: eq
V1111 13:22:12.332000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1385
V1111 13:22:12.332000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: bitwise_and_1
V1111 13:22:12.332000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1385
V1111 13:22:12.332000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.332000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1385
V1111 13:22:12.332000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.332000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.333000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.333000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.333000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.333000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.333000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.333000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.333000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.333000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.333000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.333000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.333000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.334000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.334000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.334000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.334000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.334000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.334000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.334000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.334000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.334000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.335000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_ones
V1111 13:22:12.335000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.335000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: ge
V1111 13:22:12.335000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.335000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: bitwise_and
V1111 13:22:12.335000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.335000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index
V1111 13:22:12.335000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1446
V1111 13:22:12.335000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_1
V1111 13:22:12.335000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1447
V1111 13:22:12.335000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: eq
V1111 13:22:12.336000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1447
V1111 13:22:12.336000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: bitwise_and_1
V1111 13:22:12.336000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1447
V1111 13:22:12.336000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.336000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1447
V1111 13:22:12.336000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.336000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.336000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.336000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.336000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.337000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.337000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.337000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.337000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.337000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.337000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.337000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.337000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.337000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.338000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.338000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.338000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.338000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.338000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.338000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.338000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.338000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.338000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_ones
V1111 13:22:12.338000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.338000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: ge
V1111 13:22:12.339000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.339000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: bitwise_and
V1111 13:22:12.339000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.339000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index
V1111 13:22:12.339000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1535
V1111 13:22:12.339000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_1
V1111 13:22:12.339000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1536
V1111 13:22:12.339000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: eq
V1111 13:22:12.339000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1536
V1111 13:22:12.339000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: bitwise_and_1
V1111 13:22:12.340000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1536
V1111 13:22:12.340000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.340000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1536
V1111 13:22:12.340000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.340000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.340000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.340000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.340000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.340000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.340000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.341000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.341000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.341000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.341000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.341000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.341000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.341000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.341000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.341000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.341000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.342000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.342000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.342000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.342000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.342000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.342000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_ones
V1111 13:22:12.342000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.342000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: ge
V1111 13:22:12.342000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.342000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: bitwise_and
V1111 13:22:12.343000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.343000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index
V1111 13:22:12.343000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1624
V1111 13:22:12.343000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_1
V1111 13:22:12.343000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1625
V1111 13:22:12.343000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: eq
V1111 13:22:12.343000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1625
V1111 13:22:12.343000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: bitwise_and_1
V1111 13:22:12.343000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1625
V1111 13:22:12.343000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.344000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1625
V1111 13:22:12.344000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.344000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.344000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.344000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.344000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.344000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.344000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.344000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.344000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.345000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.345000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.345000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.345000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.345000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.345000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.345000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.345000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.345000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.345000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.346000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.346000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.346000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.346000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_ones
V1111 13:22:12.346000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.346000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: ge
V1111 13:22:12.346000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.346000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: bitwise_and
V1111 13:22:12.346000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.346000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index
V1111 13:22:12.347000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1713
V1111 13:22:12.347000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_1
V1111 13:22:12.347000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1714
V1111 13:22:12.347000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: eq
V1111 13:22:12.347000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1714
V1111 13:22:12.347000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: bitwise_and_1
V1111 13:22:12.347000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1714
V1111 13:22:12.347000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.347000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1714
V1111 13:22:12.347000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.348000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.348000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.348000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.348000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.348000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.348000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.348000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.348000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.348000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.348000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.349000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.349000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.349000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.349000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.349000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.349000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.349000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.349000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.349000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.349000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.350000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.350000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_ones
V1111 13:22:12.350000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.350000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: ge
V1111 13:22:12.350000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.350000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: bitwise_and
V1111 13:22:12.350000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.350000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index
V1111 13:22:12.350000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1802
V1111 13:22:12.350000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_1
V1111 13:22:12.351000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1803
V1111 13:22:12.351000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: eq
V1111 13:22:12.351000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1803
V1111 13:22:12.351000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: bitwise_and_1
V1111 13:22:12.351000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1803
V1111 13:22:12.351000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.351000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1803
V1111 13:22:12.351000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.351000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.351000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.352000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.352000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.352000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.352000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.352000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.352000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.352000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.352000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.352000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.352000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.353000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.353000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.353000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.353000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.353000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.353000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.353000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.353000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.353000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.353000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg5_1
V1111 13:22:12.354000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.354000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.354000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.354000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.354000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.354000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.354000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.354000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.354000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.355000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.355000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.355000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.355000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.355000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_ones
V1111 13:22:12.355000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1858
V1111 13:22:12.355000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: ge
V1111 13:22:12.355000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1858
V1111 13:22:12.355000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: bitwise_and
V1111 13:22:12.355000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1858
V1111 13:22:12.356000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index
V1111 13:22:12.356000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1859
V1111 13:22:12.356000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_1
V1111 13:22:12.356000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1860
V1111 13:22:12.356000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: eq
V1111 13:22:12.356000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1860
V1111 13:22:12.356000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: bitwise_and_1
V1111 13:22:12.356000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1860
V1111 13:22:12.356000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.356000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1801
V1111 13:22:12.357000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.357000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.357000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.357000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.357000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.357000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.357000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.357000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.357000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.357000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.358000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.358000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.358000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.358000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.358000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.358000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.358000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.358000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.358000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.358000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.359000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.359000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.359000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg5_1
V1111 13:22:12.359000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.359000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.359000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.359000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.359000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.359000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.360000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.360000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.360000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.360000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.360000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.360000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.360000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.360000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_ones
V1111 13:22:12.360000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1860
V1111 13:22:12.360000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: ge
V1111 13:22:12.361000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1860
V1111 13:22:12.361000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: bitwise_and
V1111 13:22:12.361000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1860
V1111 13:22:12.361000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index
V1111 13:22:12.361000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1861
V1111 13:22:12.361000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_1
V1111 13:22:12.361000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1862
V1111 13:22:12.361000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: eq
V1111 13:22:12.361000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1862
V1111 13:22:12.361000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: bitwise_and_1
V1111 13:22:12.362000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1862
V1111 13:22:12.362000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.362000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1712
V1111 13:22:12.362000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.362000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.362000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.362000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.362000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.362000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.362000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.363000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.363000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.363000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.363000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.363000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.363000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.363000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.363000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.363000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.364000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.364000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.364000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.364000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.364000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.364000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.364000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg5_1
V1111 13:22:12.364000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.364000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.364000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.365000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.365000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.365000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.365000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.365000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.365000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.365000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.365000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.365000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.365000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.366000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_ones
V1111 13:22:12.366000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1862
V1111 13:22:12.366000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: ge
V1111 13:22:12.366000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1862
V1111 13:22:12.366000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: bitwise_and
V1111 13:22:12.366000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1862
V1111 13:22:12.366000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index
V1111 13:22:12.366000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1863
V1111 13:22:12.366000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_1
V1111 13:22:12.366000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1864
V1111 13:22:12.367000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: eq
V1111 13:22:12.367000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1864
V1111 13:22:12.367000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: bitwise_and_1
V1111 13:22:12.367000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1864
V1111 13:22:12.367000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.367000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1623
V1111 13:22:12.367000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.367000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.367000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.367000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.368000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.368000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.368000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.368000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.368000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.368000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.368000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.368000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.368000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.368000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.369000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.369000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.369000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.369000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.369000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.369000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.369000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.369000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.369000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg5_1
V1111 13:22:12.370000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.370000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.370000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.370000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.370000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.370000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.370000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.370000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.370000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.370000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.371000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.371000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.371000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.371000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_ones
V1111 13:22:12.371000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1864
V1111 13:22:12.371000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: ge
V1111 13:22:12.371000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1864
V1111 13:22:12.371000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: bitwise_and
V1111 13:22:12.371000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1864
V1111 13:22:12.371000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index
V1111 13:22:12.372000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1865
V1111 13:22:12.372000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_1
V1111 13:22:12.372000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1866
V1111 13:22:12.372000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: eq
V1111 13:22:12.372000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1866
V1111 13:22:12.372000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: bitwise_and_1
V1111 13:22:12.372000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1866
V1111 13:22:12.372000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.372000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1534
V1111 13:22:12.372000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.373000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.373000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.373000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.373000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.373000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.373000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.373000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.373000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.373000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.373000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.374000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.374000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.374000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.374000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.374000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.374000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.374000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.374000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.374000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.375000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.375000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.375000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg5_1
V1111 13:22:12.375000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.375000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.375000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.375000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.375000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.375000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.375000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.376000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.376000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.376000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.376000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.376000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.376000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.376000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_ones
V1111 13:22:12.376000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1866
V1111 13:22:12.376000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: ge
V1111 13:22:12.376000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1866
V1111 13:22:12.377000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: bitwise_and
V1111 13:22:12.377000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1866
V1111 13:22:12.377000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index
V1111 13:22:12.377000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1867
V1111 13:22:12.377000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_1
V1111 13:22:12.377000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1868
V1111 13:22:12.377000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: eq
V1111 13:22:12.377000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1868
V1111 13:22:12.377000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: bitwise_and_1
V1111 13:22:12.377000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1868
V1111 13:22:12.378000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.378000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1445
V1111 13:22:12.378000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.378000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.378000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.378000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.378000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.378000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.378000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.378000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.379000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.379000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.379000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.379000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.379000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.379000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.379000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.379000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.379000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.380000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.380000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.380000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.380000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.380000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.380000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg5_1
V1111 13:22:12.380000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.380000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.380000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.381000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg0_1
V1111 13:22:12.381000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.381000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg1_1
V1111 13:22:12.381000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.381000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg2_1
V1111 13:22:12.381000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.381000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg3_1
V1111 13:22:12.381000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.381000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: arg4_1
V1111 13:22:12.381000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
V1111 13:22:12.382000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: new_ones
V1111 13:22:12.382000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1868
V1111 13:22:12.382000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: ge
V1111 13:22:12.382000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1868
V1111 13:22:12.382000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: bitwise_and
V1111 13:22:12.382000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1868
V1111 13:22:12.382000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index
V1111 13:22:12.382000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1869
V1111 13:22:12.382000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: index_1
V1111 13:22:12.382000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1870
V1111 13:22:12.383000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: eq
V1111 13:22:12.383000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1870
V1111 13:22:12.383000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: bitwise_and_1
V1111 13:22:12.383000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1870
V1111 13:22:12.383000 86039 torch/_functorch/_aot_autograd/utils.py:450] [__annotation] node: output
V1111 13:22:12.383000 86039 torch/_functorch/_aot_autograd/utils.py:452] [__annotation] seq_nr: 1383
Model: DeepSeekV3Model
  Layers: 6
  Dim: 256
  Heads: 16
  MoE experts: 8

Input shape: torch.Size([8, 2048])

Capturing joint graph with export_joint...

Graph captured successfully!
Joint graph module:

class inner_f(torch.nn.Module):
    def forward(self, primals, tangents):
        primals_1: "f32[2048, 256]"; primals_2: "f32[3072, 256]"; primals_3: "f32[576, 256]"; primals_4: "f32[512]"; primals_5: "f32[4096, 512]"; primals_6: "f32[256, 2048]"; primals_7: "f32[256]"; primals_8: "f32[256]"; primals_9: "f32[1024, 256]"; primals_10: "f32[256, 1024]"; primals_11: "f32[1024, 256]"; primals_12: "f32[3072, 256]"; primals_13: "f32[576, 256]"; primals_14: "f32[512]"; primals_15: "f32[4096, 512]"; primals_16: "f32[256, 2048]"; primals_17: "f32[256]"; primals_18: "f32[256]"; primals_19: "f32[8, 256, 256]"; primals_20: "f32[8, 256, 256]"; primals_21: "f32[8, 256, 256]"; primals_22: "f32[8, 256]"; primals_23: "f32[512, 256]"; primals_24: "f32[256, 512]"; primals_25: "f32[512, 256]"; primals_26: "f32[3072, 256]"; primals_27: "f32[576, 256]"; primals_28: "f32[512]"; primals_29: "f32[4096, 512]"; primals_30: "f32[256, 2048]"; primals_31: "f32[256]"; primals_32: "f32[256]"; primals_33: "f32[8, 256, 256]"; primals_34: "f32[8, 256, 256]"; primals_35: "f32[8, 256, 256]"; primals_36: "f32[8, 256]"; primals_37: "f32[512, 256]"; primals_38: "f32[256, 512]"; primals_39: "f32[512, 256]"; primals_40: "f32[3072, 256]"; primals_41: "f32[576, 256]"; primals_42: "f32[512]"; primals_43: "f32[4096, 512]"; primals_44: "f32[256, 2048]"; primals_45: "f32[256]"; primals_46: "f32[256]"; primals_47: "f32[8, 256, 256]"; primals_48: "f32[8, 256, 256]"; primals_49: "f32[8, 256, 256]"; primals_50: "f32[8, 256]"; primals_51: "f32[512, 256]"; primals_52: "f32[256, 512]"; primals_53: "f32[512, 256]"; primals_54: "f32[3072, 256]"; primals_55: "f32[576, 256]"; primals_56: "f32[512]"; primals_57: "f32[4096, 512]"; primals_58: "f32[256, 2048]"; primals_59: "f32[256]"; primals_60: "f32[256]"; primals_61: "f32[8, 256, 256]"; primals_62: "f32[8, 256, 256]"; primals_63: "f32[8, 256, 256]"; primals_64: "f32[8, 256]"; primals_65: "f32[512, 256]"; primals_66: "f32[256, 512]"; primals_67: "f32[512, 256]"; primals_68: "f32[3072, 256]"; primals_69: "f32[576, 256]"; primals_70: "f32[512]"; primals_71: "f32[4096, 512]"; primals_72: "f32[256, 2048]"; primals_73: "f32[256]"; primals_74: "f32[256]"; primals_75: "f32[8, 256, 256]"; primals_76: "f32[8, 256, 256]"; primals_77: "f32[8, 256, 256]"; primals_78: "f32[8, 256]"; primals_79: "f32[512, 256]"; primals_80: "f32[256, 512]"; primals_81: "f32[512, 256]"; primals_82: "f32[256]"; primals_83: "f32[2048, 256]"; primals_84: "c64[2048, 32]"; primals_85: "f32[8]"; primals_86: "f32[8]"; primals_87: "f32[8]"; primals_88: "f32[8]"; primals_89: "f32[8]"; primals_90: "f32[8]"; primals_91: "f32[8]"; primals_92: "f32[8]"; primals_93: "f32[8]"; primals_94: "f32[8]"; primals_95: "i64[8, 2048]"; primals_96: "i32[8, 1, 16]"; primals_97: "i32[8, 1, 16, 16]"; primals_98: "i32[8, 1, 16]"; primals_99: "i32[8, 1, 16, 16]"; primals_100: "i32[8, 1, 16]"; primals_101: "i32[8, 1, 16, 16]"; primals_102: "i32[8, 1, 16]"; primals_103: "i32[8, 1, 16, 16]"; tangents_1: "f32[8, 2048, 2048]"; 
    
        primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_62, primals_63, primals_64, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_74, primals_75, primals_76, primals_77, primals_78, primals_79, primals_80, primals_81, primals_82, primals_83, primals_84, primals_85, primals_86, primals_87, primals_88, primals_89, primals_90, primals_91, primals_92, primals_93, primals_94, primals_95, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, tangents_1, = fx_pytree.tree_flatten_spec([primals, tangents], self._in_spec)
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:428 in forward, code: h = self.tok_embeddings(tokens) if self.tok_embeddings is not None else tokens
        embedding: "f32[8, 2048, 256]" = torch.ops.aten.embedding.default(primals_1, primals_95);  primals_1 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        _fused_rms_norm = torch.ops.aten._fused_rms_norm.default(embedding, [256], primals_7, 1e-05)
        getitem: "f32[8, 2048, 256]" = _fused_rms_norm[0]
        getitem_1: "f32[8, 2048, 1]" = _fused_rms_norm[1];  _fused_rms_norm = None
        detach: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(getitem_1);  getitem_1 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:213 in forward, code: q = self.wq(x)  # (bsz, seqlen, n_heads * qk_head_dim)
        t: "f32[256, 3072]" = torch.ops.aten.t.default(primals_2);  primals_2 = None
        view: "f32[16384, 256]" = torch.ops.aten.view.default(getitem, [16384, 256])
        mm: "f32[16384, 3072]" = torch.ops.aten.mm.default(view, t)
        _unsafe_view: "f32[8, 2048, 3072]" = torch.ops.aten._unsafe_view.default(mm, [8, 2048, 3072]);  mm = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:220 in forward, code: q = q.view(bsz, seqlen, -1, self.qk_head_dim)
        view_1: "f32[8, 2048, 16, 192]" = torch.ops.aten.view.default(_unsafe_view, [8, 2048, -1, 192]);  _unsafe_view = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:221 in forward, code: q_nope, q_pe = torch.split(
        split_with_sizes = torch.ops.aten.split_with_sizes.default(view_1, [128, 64], -1);  view_1 = None
        getitem_2: "f32[8, 2048, 16, 128]" = split_with_sizes[0]
        getitem_3: "f32[8, 2048, 16, 64]" = split_with_sizes[1];  split_with_sizes = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:141 in apply_rotary_emb, code: x = torch.view_as_complex(x.float().view(*x.shape[:-1], -1, 2))
        view_2: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.view.default(getitem_3, [8, 2048, 16, -1, 2]);  getitem_3 = None
        view_as_complex: "c64[8, 2048, 16, 32]" = torch.ops.aten.view_as_complex.default(view_2);  view_2 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:142 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(1, x.size(1), 1, x.size(-1))
        view_3: "c64[1, 2048, 1, 32]" = torch.ops.aten.view.default(primals_84, [1, 2048, 1, 32])
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:143 in apply_rotary_emb, code: y = torch.view_as_real(x * freqs_cis).flatten(3)
        mul: "c64[8, 2048, 16, 32]" = torch.ops.aten.mul.Tensor(view_as_complex, view_3);  view_as_complex = None
        view_as_real: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.view_as_real.default(mul);  mul = None
        view_4: "f32[8, 2048, 16, 64]" = torch.ops.aten.view.default(view_as_real, [8, 2048, 16, 64]);  view_as_real = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:225 in forward, code: q = torch.cat([q_nope, q_pe], dim=-1)  # (bsz, seqlen, n_heads, qk_head_dim)
        cat: "f32[8, 2048, 16, 192]" = torch.ops.aten.cat.default([getitem_2, view_4], -1);  getitem_2 = view_4 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:228 in forward, code: kv = self.wkv_a(x)  # (bsz, seqlen, kv_lora_rank + qk_rope_head_dim)
        t_1: "f32[256, 576]" = torch.ops.aten.t.default(primals_3);  primals_3 = None
        view_5: "f32[16384, 256]" = torch.ops.aten.view.default(getitem, [16384, 256]);  getitem = None
        mm_1: "f32[16384, 576]" = torch.ops.aten.mm.default(view_5, t_1)
        _unsafe_view_1: "f32[8, 2048, 576]" = torch.ops.aten._unsafe_view.default(mm_1, [8, 2048, 576]);  mm_1 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:229 in forward, code: kv, k_pe = torch.split(kv, [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1)
        split_with_sizes_1 = torch.ops.aten.split_with_sizes.default(_unsafe_view_1, [512, 64], -1);  _unsafe_view_1 = None
        getitem_4: "f32[8, 2048, 512]" = split_with_sizes_1[0]
        getitem_5: "f32[8, 2048, 64]" = split_with_sizes_1[1];  split_with_sizes_1 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:232 in forward, code: k_pe.unsqueeze(2), freqs_cis
        unsqueeze: "f32[8, 2048, 1, 64]" = torch.ops.aten.unsqueeze.default(getitem_5, 2);  getitem_5 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:141 in apply_rotary_emb, code: x = torch.view_as_complex(x.float().view(*x.shape[:-1], -1, 2))
        view_6: "f32[8, 2048, 1, 32, 2]" = torch.ops.aten.view.default(unsqueeze, [8, 2048, 1, -1, 2]);  unsqueeze = None
        view_as_complex_1: "c64[8, 2048, 1, 32]" = torch.ops.aten.view_as_complex.default(view_6);  view_6 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:142 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(1, x.size(1), 1, x.size(-1))
        view_7: "c64[1, 2048, 1, 32]" = torch.ops.aten.view.default(primals_84, [1, 2048, 1, 32])
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:143 in apply_rotary_emb, code: y = torch.view_as_real(x * freqs_cis).flatten(3)
        mul_1: "c64[8, 2048, 1, 32]" = torch.ops.aten.mul.Tensor(view_as_complex_1, view_7);  view_as_complex_1 = None
        view_as_real_1: "f32[8, 2048, 1, 32, 2]" = torch.ops.aten.view_as_real.default(mul_1);  mul_1 = None
        view_8: "f32[8, 2048, 1, 64]" = torch.ops.aten.view.default(view_as_real_1, [8, 2048, 1, 64]);  view_as_real_1 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        _fused_rms_norm_1 = torch.ops.aten._fused_rms_norm.default(getitem_4, [512], primals_4, 1e-05)
        getitem_6: "f32[8, 2048, 512]" = _fused_rms_norm_1[0]
        getitem_7: "f32[8, 2048, 1]" = _fused_rms_norm_1[1];  _fused_rms_norm_1 = None
        detach_1: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(getitem_7);  getitem_7 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:235 in forward, code: kv = self.wkv_b(
        t_2: "f32[512, 4096]" = torch.ops.aten.t.default(primals_5);  primals_5 = None
        view_9: "f32[16384, 512]" = torch.ops.aten.view.default(getitem_6, [16384, 512]);  getitem_6 = None
        mm_2: "f32[16384, 4096]" = torch.ops.aten.mm.default(view_9, t_2)
        _unsafe_view_2: "f32[8, 2048, 4096]" = torch.ops.aten._unsafe_view.default(mm_2, [8, 2048, 4096]);  mm_2 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:238 in forward, code: kv = kv.view(bsz, seqlen, -1, self.qk_nope_head_dim + self.v_head_dim)
        view_10: "f32[8, 2048, 16, 256]" = torch.ops.aten.view.default(_unsafe_view_2, [8, 2048, -1, 256]);  _unsafe_view_2 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:239 in forward, code: k_nope, v = torch.split(kv, [self.qk_nope_head_dim, self.v_head_dim], dim=-1)
        split_with_sizes_2 = torch.ops.aten.split_with_sizes.default(view_10, [128, 128], -1);  view_10 = None
        getitem_8: "f32[8, 2048, 16, 128]" = split_with_sizes_2[0]
        getitem_9: "f32[8, 2048, 16, 128]" = split_with_sizes_2[1];  split_with_sizes_2 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:241 in forward, code: [k_nope, k_pe.expand(-1, -1, self.n_heads, -1)], dim=-1
        expand: "f32[8, 2048, 16, 64]" = torch.ops.aten.expand.default(view_8, [-1, -1, 16, -1]);  view_8 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:240 in forward, code: k = torch.cat(
        cat_1: "f32[8, 2048, 16, 192]" = torch.ops.aten.cat.default([getitem_8, expand], -1);  getitem_8 = expand = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:244 in forward, code: q = q.transpose(1, 2)  # (bsz, n_heads, seqlen, qk_head_dim)
        transpose: "f32[8, 16, 2048, 192]" = torch.ops.aten.transpose.int(cat, 1, 2);  cat = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:245 in forward, code: k = k.transpose(1, 2)  # (bsz, n_heads, seqlen, qk_head_dim)
        transpose_1: "f32[8, 16, 2048, 192]" = torch.ops.aten.transpose.int(cat_1, 1, 2);  cat_1 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:246 in forward, code: v = v.transpose(1, 2)  # (bsz, n_heads, seqlen, v_head_dim)
        transpose_2: "f32[8, 16, 2048, 128]" = torch.ops.aten.transpose.int(getitem_9, 1, 2);  getitem_9 = None
        
        # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1585 in flex_attention, code: out, lse, max_scores = flex_attention_hop(
        sdpa_score0 = self.sdpa_score0
        sdpa_mask0 = self.sdpa_mask0
        _tensor_constant0: "i32[8, 2048]" = self._tensor_constant0
        flex_attention = torch.ops.higher_order.flex_attention(transpose, transpose_1, transpose_2, sdpa_score0, (2048, 2048, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, 128, 128, sdpa_mask0), 0.07216878364870322, {'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (_tensor_constant0,));  sdpa_score0 = sdpa_mask0 = _tensor_constant0 = None
        getitem_10: "f32[8, 16, 2048, 128]" = flex_attention[0]
        getitem_11: "f32[8, 16, 2048]" = flex_attention[1];  flex_attention = None
        detach_2: "f32[8, 16, 2048, 128]" = torch.ops.aten.detach.default(getitem_10)
        detach_3: "f32[8, 16, 2048]" = torch.ops.aten.detach.default(getitem_11);  getitem_11 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:258 in forward, code: output = output.transpose(
        transpose_3: "f32[8, 2048, 16, 128]" = torch.ops.aten.transpose.int(getitem_10, 1, 2);  getitem_10 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:261 in forward, code: output = output.view(bsz, seqlen, -1)  # (bsz, seqlen, n_heads * v_head_dim)
        view_11: "f32[8, 2048, 2048]" = torch.ops.aten.view.default(transpose_3, [8, 2048, -1]);  transpose_3 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:262 in forward, code: return self.wo(output)  # (bsz, seqlen, dim)
        t_3: "f32[2048, 256]" = torch.ops.aten.t.default(primals_6);  primals_6 = None
        view_12: "f32[16384, 2048]" = torch.ops.aten.view.default(view_11, [16384, 2048]);  view_11 = None
        mm_3: "f32[16384, 256]" = torch.ops.aten.mm.default(view_12, t_3)
        _unsafe_view_3: "f32[8, 2048, 256]" = torch.ops.aten._unsafe_view.default(mm_3, [8, 2048, 256]);  mm_3 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:324 in forward, code: x = x + self.attention(self.attention_norm(x), freqs_cis, attention_masks)
        add: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(embedding, _unsafe_view_3);  _unsafe_view_3 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        _fused_rms_norm_2 = torch.ops.aten._fused_rms_norm.default(add, [256], primals_8, 1e-05)
        getitem_13: "f32[8, 2048, 256]" = _fused_rms_norm_2[0]
        getitem_14: "f32[8, 2048, 1]" = _fused_rms_norm_2[1];  _fused_rms_norm_2 = None
        detach_4: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(getitem_14);  getitem_14 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:62 in forward, code: return self.w2(F.silu(self.w1(x)) * self.w3(x))
        t_4: "f32[256, 1024]" = torch.ops.aten.t.default(primals_9);  primals_9 = None
        view_13: "f32[16384, 256]" = torch.ops.aten.view.default(getitem_13, [16384, 256])
        mm_4: "f32[16384, 1024]" = torch.ops.aten.mm.default(view_13, t_4)
        _unsafe_view_4: "f32[8, 2048, 1024]" = torch.ops.aten._unsafe_view.default(mm_4, [8, 2048, 1024]);  mm_4 = None
        silu: "f32[8, 2048, 1024]" = torch.ops.aten.silu.default(_unsafe_view_4)
        t_5: "f32[256, 1024]" = torch.ops.aten.t.default(primals_11);  primals_11 = None
        view_14: "f32[16384, 256]" = torch.ops.aten.view.default(getitem_13, [16384, 256]);  getitem_13 = None
        mm_5: "f32[16384, 1024]" = torch.ops.aten.mm.default(view_14, t_5)
        _unsafe_view_5: "f32[8, 2048, 1024]" = torch.ops.aten._unsafe_view.default(mm_5, [8, 2048, 1024]);  mm_5 = None
        mul_2: "f32[8, 2048, 1024]" = torch.ops.aten.mul.Tensor(silu, _unsafe_view_5)
        t_6: "f32[1024, 256]" = torch.ops.aten.t.default(primals_10);  primals_10 = None
        view_15: "f32[16384, 1024]" = torch.ops.aten.view.default(mul_2, [16384, 1024]);  mul_2 = None
        mm_6: "f32[16384, 256]" = torch.ops.aten.mm.default(view_15, t_6)
        _unsafe_view_6: "f32[8, 2048, 256]" = torch.ops.aten._unsafe_view.default(mm_6, [8, 2048, 256]);  mm_6 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:328 in forward, code: x = x + self.feed_forward(self.ffn_norm(x))
        add_1: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(add, _unsafe_view_6);  _unsafe_view_6 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        _fused_rms_norm_3 = torch.ops.aten._fused_rms_norm.default(add_1, [256], primals_17, 1e-05)
        getitem_15: "f32[8, 2048, 256]" = _fused_rms_norm_3[0]
        getitem_16: "f32[8, 2048, 1]" = _fused_rms_norm_3[1];  _fused_rms_norm_3 = None
        detach_5: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(getitem_16);  getitem_16 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:213 in forward, code: q = self.wq(x)  # (bsz, seqlen, n_heads * qk_head_dim)
        t_7: "f32[256, 3072]" = torch.ops.aten.t.default(primals_12);  primals_12 = None
        view_16: "f32[16384, 256]" = torch.ops.aten.view.default(getitem_15, [16384, 256])
        mm_7: "f32[16384, 3072]" = torch.ops.aten.mm.default(view_16, t_7)
        _unsafe_view_7: "f32[8, 2048, 3072]" = torch.ops.aten._unsafe_view.default(mm_7, [8, 2048, 3072]);  mm_7 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:220 in forward, code: q = q.view(bsz, seqlen, -1, self.qk_head_dim)
        view_17: "f32[8, 2048, 16, 192]" = torch.ops.aten.view.default(_unsafe_view_7, [8, 2048, -1, 192]);  _unsafe_view_7 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:221 in forward, code: q_nope, q_pe = torch.split(
        split_with_sizes_3 = torch.ops.aten.split_with_sizes.default(view_17, [128, 64], -1);  view_17 = None
        getitem_17: "f32[8, 2048, 16, 128]" = split_with_sizes_3[0]
        getitem_18: "f32[8, 2048, 16, 64]" = split_with_sizes_3[1];  split_with_sizes_3 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:141 in apply_rotary_emb, code: x = torch.view_as_complex(x.float().view(*x.shape[:-1], -1, 2))
        view_18: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.view.default(getitem_18, [8, 2048, 16, -1, 2]);  getitem_18 = None
        view_as_complex_2: "c64[8, 2048, 16, 32]" = torch.ops.aten.view_as_complex.default(view_18);  view_18 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:142 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(1, x.size(1), 1, x.size(-1))
        view_19: "c64[1, 2048, 1, 32]" = torch.ops.aten.view.default(primals_84, [1, 2048, 1, 32])
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:143 in apply_rotary_emb, code: y = torch.view_as_real(x * freqs_cis).flatten(3)
        mul_3: "c64[8, 2048, 16, 32]" = torch.ops.aten.mul.Tensor(view_as_complex_2, view_19);  view_as_complex_2 = None
        view_as_real_2: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.view_as_real.default(mul_3);  mul_3 = None
        view_20: "f32[8, 2048, 16, 64]" = torch.ops.aten.view.default(view_as_real_2, [8, 2048, 16, 64]);  view_as_real_2 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:225 in forward, code: q = torch.cat([q_nope, q_pe], dim=-1)  # (bsz, seqlen, n_heads, qk_head_dim)
        cat_2: "f32[8, 2048, 16, 192]" = torch.ops.aten.cat.default([getitem_17, view_20], -1);  getitem_17 = view_20 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:228 in forward, code: kv = self.wkv_a(x)  # (bsz, seqlen, kv_lora_rank + qk_rope_head_dim)
        t_8: "f32[256, 576]" = torch.ops.aten.t.default(primals_13);  primals_13 = None
        view_21: "f32[16384, 256]" = torch.ops.aten.view.default(getitem_15, [16384, 256]);  getitem_15 = None
        mm_8: "f32[16384, 576]" = torch.ops.aten.mm.default(view_21, t_8)
        _unsafe_view_8: "f32[8, 2048, 576]" = torch.ops.aten._unsafe_view.default(mm_8, [8, 2048, 576]);  mm_8 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:229 in forward, code: kv, k_pe = torch.split(kv, [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1)
        split_with_sizes_4 = torch.ops.aten.split_with_sizes.default(_unsafe_view_8, [512, 64], -1);  _unsafe_view_8 = None
        getitem_19: "f32[8, 2048, 512]" = split_with_sizes_4[0]
        getitem_20: "f32[8, 2048, 64]" = split_with_sizes_4[1];  split_with_sizes_4 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:232 in forward, code: k_pe.unsqueeze(2), freqs_cis
        unsqueeze_1: "f32[8, 2048, 1, 64]" = torch.ops.aten.unsqueeze.default(getitem_20, 2);  getitem_20 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:141 in apply_rotary_emb, code: x = torch.view_as_complex(x.float().view(*x.shape[:-1], -1, 2))
        view_22: "f32[8, 2048, 1, 32, 2]" = torch.ops.aten.view.default(unsqueeze_1, [8, 2048, 1, -1, 2]);  unsqueeze_1 = None
        view_as_complex_3: "c64[8, 2048, 1, 32]" = torch.ops.aten.view_as_complex.default(view_22);  view_22 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:142 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(1, x.size(1), 1, x.size(-1))
        view_23: "c64[1, 2048, 1, 32]" = torch.ops.aten.view.default(primals_84, [1, 2048, 1, 32])
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:143 in apply_rotary_emb, code: y = torch.view_as_real(x * freqs_cis).flatten(3)
        mul_4: "c64[8, 2048, 1, 32]" = torch.ops.aten.mul.Tensor(view_as_complex_3, view_23);  view_as_complex_3 = None
        view_as_real_3: "f32[8, 2048, 1, 32, 2]" = torch.ops.aten.view_as_real.default(mul_4);  mul_4 = None
        view_24: "f32[8, 2048, 1, 64]" = torch.ops.aten.view.default(view_as_real_3, [8, 2048, 1, 64]);  view_as_real_3 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        _fused_rms_norm_4 = torch.ops.aten._fused_rms_norm.default(getitem_19, [512], primals_14, 1e-05)
        getitem_21: "f32[8, 2048, 512]" = _fused_rms_norm_4[0]
        getitem_22: "f32[8, 2048, 1]" = _fused_rms_norm_4[1];  _fused_rms_norm_4 = None
        detach_6: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(getitem_22);  getitem_22 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:235 in forward, code: kv = self.wkv_b(
        t_9: "f32[512, 4096]" = torch.ops.aten.t.default(primals_15);  primals_15 = None
        view_25: "f32[16384, 512]" = torch.ops.aten.view.default(getitem_21, [16384, 512]);  getitem_21 = None
        mm_9: "f32[16384, 4096]" = torch.ops.aten.mm.default(view_25, t_9)
        _unsafe_view_9: "f32[8, 2048, 4096]" = torch.ops.aten._unsafe_view.default(mm_9, [8, 2048, 4096]);  mm_9 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:238 in forward, code: kv = kv.view(bsz, seqlen, -1, self.qk_nope_head_dim + self.v_head_dim)
        view_26: "f32[8, 2048, 16, 256]" = torch.ops.aten.view.default(_unsafe_view_9, [8, 2048, -1, 256]);  _unsafe_view_9 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:239 in forward, code: k_nope, v = torch.split(kv, [self.qk_nope_head_dim, self.v_head_dim], dim=-1)
        split_with_sizes_5 = torch.ops.aten.split_with_sizes.default(view_26, [128, 128], -1);  view_26 = None
        getitem_23: "f32[8, 2048, 16, 128]" = split_with_sizes_5[0]
        getitem_24: "f32[8, 2048, 16, 128]" = split_with_sizes_5[1];  split_with_sizes_5 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:241 in forward, code: [k_nope, k_pe.expand(-1, -1, self.n_heads, -1)], dim=-1
        expand_1: "f32[8, 2048, 16, 64]" = torch.ops.aten.expand.default(view_24, [-1, -1, 16, -1]);  view_24 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:240 in forward, code: k = torch.cat(
        cat_3: "f32[8, 2048, 16, 192]" = torch.ops.aten.cat.default([getitem_23, expand_1], -1);  getitem_23 = expand_1 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:244 in forward, code: q = q.transpose(1, 2)  # (bsz, n_heads, seqlen, qk_head_dim)
        transpose_4: "f32[8, 16, 2048, 192]" = torch.ops.aten.transpose.int(cat_2, 1, 2);  cat_2 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:245 in forward, code: k = k.transpose(1, 2)  # (bsz, n_heads, seqlen, qk_head_dim)
        transpose_5: "f32[8, 16, 2048, 192]" = torch.ops.aten.transpose.int(cat_3, 1, 2);  cat_3 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:246 in forward, code: v = v.transpose(1, 2)  # (bsz, n_heads, seqlen, v_head_dim)
        transpose_6: "f32[8, 16, 2048, 128]" = torch.ops.aten.transpose.int(getitem_24, 1, 2);  getitem_24 = None
        
        # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1585 in flex_attention, code: out, lse, max_scores = flex_attention_hop(
        sdpa_score1 = self.sdpa_score1
        sdpa_mask1 = self.sdpa_mask1
        _tensor_constant0_1: "i32[8, 2048]" = self._tensor_constant0
        flex_attention_1 = torch.ops.higher_order.flex_attention(transpose_4, transpose_5, transpose_6, sdpa_score1, (2048, 2048, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, 128, 128, sdpa_mask1), 0.07216878364870322, {'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (_tensor_constant0_1,));  sdpa_score1 = sdpa_mask1 = _tensor_constant0_1 = None
        getitem_25: "f32[8, 16, 2048, 128]" = flex_attention_1[0]
        getitem_26: "f32[8, 16, 2048]" = flex_attention_1[1];  flex_attention_1 = None
        detach_7: "f32[8, 16, 2048, 128]" = torch.ops.aten.detach.default(getitem_25)
        detach_8: "f32[8, 16, 2048]" = torch.ops.aten.detach.default(getitem_26);  getitem_26 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:258 in forward, code: output = output.transpose(
        transpose_7: "f32[8, 2048, 16, 128]" = torch.ops.aten.transpose.int(getitem_25, 1, 2);  getitem_25 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:261 in forward, code: output = output.view(bsz, seqlen, -1)  # (bsz, seqlen, n_heads * v_head_dim)
        view_27: "f32[8, 2048, 2048]" = torch.ops.aten.view.default(transpose_7, [8, 2048, -1]);  transpose_7 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:262 in forward, code: return self.wo(output)  # (bsz, seqlen, dim)
        t_10: "f32[2048, 256]" = torch.ops.aten.t.default(primals_16);  primals_16 = None
        view_28: "f32[16384, 2048]" = torch.ops.aten.view.default(view_27, [16384, 2048]);  view_27 = None
        mm_10: "f32[16384, 256]" = torch.ops.aten.mm.default(view_28, t_10)
        _unsafe_view_10: "f32[8, 2048, 256]" = torch.ops.aten._unsafe_view.default(mm_10, [8, 2048, 256]);  mm_10 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:324 in forward, code: x = x + self.attention(self.attention_norm(x), freqs_cis, attention_masks)
        add_2: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(add_1, _unsafe_view_10);  _unsafe_view_10 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        _fused_rms_norm_5 = torch.ops.aten._fused_rms_norm.default(add_2, [256], primals_18, 1e-05)
        getitem_28: "f32[8, 2048, 256]" = _fused_rms_norm_5[0]
        getitem_29: "f32[8, 2048, 1]" = _fused_rms_norm_5[1];  _fused_rms_norm_5 = None
        detach_9: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(getitem_29);  getitem_29 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:415 in forward, code: x = x.view(-1, dim)
        view_29: "f32[16384, 256]" = torch.ops.aten.view.default(getitem_28, [-1, 256]);  getitem_28 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:247 in forward, code: scores = self.gate(x)
        t_11: "f32[256, 8]" = torch.ops.aten.t.default(primals_22);  primals_22 = None
        mm_11: "f32[16384, 8]" = torch.ops.aten.mm.default(view_29, t_11)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:253 in forward, code: scores = F.softmax(scores.to(torch.float32), dim=1)
        _softmax: "f32[16384, 8]" = torch.ops.aten._softmax.default(mm_11, 1, False);  mm_11 = None
        detach_10: "f32[16384, 8]" = torch.ops.aten.detach.default(_softmax)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:262 in forward, code: scores + expert_bias, k=self.top_k, dim=1
        add_3: "f32[16384, 8]" = torch.ops.aten.add.Tensor(_softmax, primals_85);  primals_85 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:261 in forward, code: _, selected_experts_indices = torch.topk(
        topk = torch.ops.aten.topk.default(add_3, 3, 1);  add_3 = None
        getitem_31: "i64[16384, 3]" = topk[1];  topk = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:264 in forward, code: top_scores = scores.gather(dim=1, index=selected_experts_indices)
        gather: "f32[16384, 3]" = torch.ops.aten.gather.default(_softmax, 1, getitem_31);  _softmax = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:280 in forward, code: top_scores = top_scores * self.route_scale
        mul_5: "f32[16384, 3]" = torch.ops.aten.mul.Tensor(gather, 1.0);  gather = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:284 in forward, code: selected_experts_indices.view(-1),
        view_30: "i64[49152]" = torch.ops.aten.view.default(getitem_31, [-1])
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:283 in forward, code: num_tokens_per_expert = torch.histc(
        histc: "i64[8]" = torch.ops.aten.histc.default(view_30, 8, 0, 8);  view_30 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:431 in forward, code: self.tokens_per_expert.add_(num_tokens_per_expert)
        add_4: "f32[8]" = torch.ops.aten.add.Tensor(primals_86, histc);  primals_86 = histc = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:335 in forward, code: selected_experts_indices.view(-1),
        view_31: "i64[49152]" = torch.ops.aten.view.default(getitem_31, [-1])
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:334 in forward, code: num_tokens_per_expert = torch.histc(
        histc_1: "i64[8]" = torch.ops.aten.histc.default(view_31, 8, 0, 8);  view_31 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:344 in forward, code: selected_experts_indices.view(-1), stable=True
        view_32: "i64[49152]" = torch.ops.aten.view.default(getitem_31, [-1])
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:343 in forward, code: token_indices_experts_sorted = torch.argsort(
        sort = torch.ops.aten.sort.stable(view_32, stable = True);  view_32 = None
        getitem_33: "i64[49152]" = sort[1];  sort = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:347 in forward, code: top_scores_experts_sorted = top_scores.view(-1)[token_indices_experts_sorted]
        view_33: "f32[49152]" = torch.ops.aten.view.default(mul_5, [-1]);  mul_5 = None
        index: "f32[49152]" = torch.ops.aten.index.Tensor(view_33, [getitem_33]);  view_33 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:348 in forward, code: token_indices_experts_sorted = token_indices_experts_sorted // self.top_k
        floor_divide: "i64[49152]" = torch.ops.aten.floor_divide.default(getitem_33, 3)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:448 in forward, code: token_indices_experts_sorted = token_indices_experts_sorted.reshape(
        view_34: "i64[49152, 1]" = torch.ops.aten.view.default(floor_divide, [-1, 1]);  floor_divide = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:450 in forward, code: ).expand(-1, dim)
        expand_2: "i64[49152, 256]" = torch.ops.aten.expand.default(view_34, [-1, 256]);  view_34 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:453 in forward, code: routed_input = torch.gather(x, dim=0, index=token_indices_experts_sorted)
        gather_1: "f32[49152, 256]" = torch.ops.aten.gather.default(view_29, 0, expand_2)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:174 in generate_permute_indices, code: torch.cumsum(tokens_per_expert_group, 0) - tokens_per_expert_group
        cumsum: "i64[8]" = torch.ops.aten.cumsum.default(histc_1, 0)
        sub: "i64[8]" = torch.ops.aten.sub.Tensor(cumsum, histc_1);  cumsum = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:178 in generate_permute_indices, code: total_tokens_per_expert = tokens_per_expert_group.view(num_ranks, -1).sum(0)
        view_35: "i64[1, 8]" = torch.ops.aten.view.default(histc_1, [1, -1])
        sum_1: "i64[8]" = torch.ops.aten.sum.dim_IntList(view_35, [0]);  view_35 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:181 in generate_permute_indices, code: total_tokens_per_expert = torch.clamp_min(total_tokens_per_expert, alignment)
        clamp_min: "i64[8]" = torch.ops.aten.clamp_min.default(sum_1, 8);  sum_1 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:184 in generate_permute_indices, code: m_sizes = ((total_tokens_per_expert + alignment - 1) // alignment * alignment).to(
        add_5: "i64[8]" = torch.ops.aten.add.Tensor(clamp_min, 8);  clamp_min = None
        sub_1: "i64[8]" = torch.ops.aten.sub.Tensor(add_5, 1);  add_5 = None
        floor_divide_1: "i64[8]" = torch.ops.aten.floor_divide.default(sub_1, 8);  sub_1 = None
        mul_6: "i64[8]" = torch.ops.aten.mul.Tensor(floor_divide_1, 8);  floor_divide_1 = None
        _to_copy: "i32[8]" = torch.ops.aten._to_copy.default(mul_6, dtype = torch.int32);  mul_6 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:190 in generate_permute_indices, code: m_offsets = torch.cumsum(m_sizes, 0)
        cumsum_1: "i64[8]" = torch.ops.aten.cumsum.default(_to_copy, 0)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:191 in generate_permute_indices, code: write_offsets = m_offsets - m_sizes
        sub_2: "i64[8]" = torch.ops.aten.sub.Tensor(cumsum_1, _to_copy);  cumsum_1 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:80 in fill_indices_wrapper, code: permuted_indices = torch.full(
        full: "i32[49216]" = torch.ops.aten.full.default([49216], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:90 in fill_indices_wrapper, code: _fill_indices_kernel[grid](
        triton_kernel_wrapper_functional_proxy = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 0, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': histc_1, 'start_index_values_ptr': sub, 'write_offsets_ptr': sub_2, 'output_ptr': full}, tensors_to_clone = ['output_ptr']);  histc_1 = sub = sub_2 = full = None
        getitem_34: "i32[49216]" = triton_kernel_wrapper_functional_proxy['output_ptr'];  triton_kernel_wrapper_functional_proxy = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:55 in _permute, code: x = torch.vstack((x, x.new_zeros((x.shape[-1]))))
        new_zeros_20: "f32[256]" = torch.ops.aten.new_zeros.default(gather_1, [256], pin_memory = False)
        unsqueeze_2: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(new_zeros_20, 0);  new_zeros_20 = None
        cat_4: "f32[49153, 256]" = torch.ops.aten.cat.default([gather_1, unsqueeze_2]);  gather_1 = unsqueeze_2 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:57 in _permute, code: x = x[permuted_indices, :]
        index_1: "f32[49216, 256]" = torch.ops.aten.index.Tensor(cat_4, [getitem_34]);  cat_4 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:114 in _run_experts_grouped_mm, code: offsets = torch.cumsum(num_tokens_per_expert, dim=0, dtype=torch.int32)
        cumsum_2: "i32[8]" = torch.ops.aten.cumsum.default(_to_copy, 0, dtype = torch.int32);  _to_copy = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:117 in _run_experts_grouped_mm, code: torch._grouped_mm(x.bfloat16(), w1.bfloat16().transpose(-2, -1), offs=offsets)
        _to_copy_2: "bf16[49216, 256]" = torch.ops.aten._to_copy.default(index_1, dtype = torch.bfloat16)
        _to_copy_3: "bf16[8, 256, 256]" = torch.ops.aten._to_copy.default(primals_19, dtype = torch.bfloat16);  primals_19 = None
        transpose_8: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_to_copy_3, -2, -1);  _to_copy_3 = None
        _grouped_mm: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(_to_copy_2, transpose_8, cumsum_2)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:116 in _run_experts_grouped_mm, code: h = F.silu(
        silu_1: "bf16[49216, 256]" = torch.ops.aten.silu.default(_grouped_mm)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:120 in _run_experts_grouped_mm, code: x.bfloat16(), w3.bfloat16().transpose(-2, -1), offs=offsets
        _to_copy_4: "bf16[49216, 256]" = torch.ops.aten._to_copy.default(index_1, dtype = torch.bfloat16);  index_1 = None
        _to_copy_5: "bf16[8, 256, 256]" = torch.ops.aten._to_copy.default(primals_21, dtype = torch.bfloat16);  primals_21 = None
        transpose_9: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_to_copy_5, -2, -1);  _to_copy_5 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:119 in _run_experts_grouped_mm, code: h = h * torch._grouped_mm(
        _grouped_mm_1: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(_to_copy_4, transpose_9, cumsum_2)
        mul_7: "bf16[49216, 256]" = torch.ops.aten.mul.Tensor(silu_1, _grouped_mm_1)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:122 in _run_experts_grouped_mm, code: out = torch._grouped_mm(h, w2.bfloat16().transpose(-2, -1), offs=offsets).type_as(x)
        _to_copy_6: "bf16[8, 256, 256]" = torch.ops.aten._to_copy.default(primals_20, dtype = torch.bfloat16);  primals_20 = None
        transpose_10: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_to_copy_6, -2, -1);  _to_copy_6 = None
        _grouped_mm_2: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(mul_7, transpose_10, cumsum_2)
        _to_copy_7: "f32[49216, 256]" = torch.ops.aten._to_copy.default(_grouped_mm_2, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  _grouped_mm_2 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:63 in _unpermute, code: out_unpermuted = out.new_empty(input_shape)
        new_empty: "f32[49153, 256]" = torch.ops.aten.new_empty.default(_to_copy_7, [49153, 256], pin_memory = False)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:64 in _unpermute, code: out_unpermuted[permuted_indices, :] = out
        index_put: "f32[49153, 256]" = torch.ops.aten.index_put.default(new_empty, [getitem_34], _to_copy_7);  new_empty = _to_copy_7 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:62 in forward, code: return self.w2(F.silu(self.w1(x)) * self.w3(x))
        t_12: "f32[256, 512]" = torch.ops.aten.t.default(primals_23);  primals_23 = None
        mm_12: "f32[16384, 512]" = torch.ops.aten.mm.default(view_29, t_12)
        silu_2: "f32[16384, 512]" = torch.ops.aten.silu.default(mm_12)
        t_13: "f32[256, 512]" = torch.ops.aten.t.default(primals_25);  primals_25 = None
        mm_13: "f32[16384, 512]" = torch.ops.aten.mm.default(view_29, t_13)
        mul_8: "f32[16384, 512]" = torch.ops.aten.mul.Tensor(silu_2, mm_13)
        t_14: "f32[512, 256]" = torch.ops.aten.t.default(primals_24);  primals_24 = None
        mm_14: "f32[16384, 256]" = torch.ops.aten.mm.default(mul_8, t_14)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:475 in forward, code: * top_scores_experts_sorted.reshape(-1, 1)
        view_36: "f32[49152, 1]" = torch.ops.aten.view.default(index, [-1, 1]);  index = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:65 in _unpermute, code: out = out_unpermuted[:-1]
        slice_2: "f32[49152, 256]" = torch.ops.aten.slice.Tensor(index_put, 0, 0, -1);  index_put = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:474 in forward, code: routed_output.to(torch.float32)
        mul_9: "f32[49152, 256]" = torch.ops.aten.mul.Tensor(slice_2, view_36)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:478 in forward, code: out = out.scatter_add(
        scatter_add: "f32[16384, 256]" = torch.ops.aten.scatter_add.default(mm_14, 0, expand_2, mul_9);  mm_14 = mul_9 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:481 in forward, code: out = out.reshape(bs, slen, dim)
        view_37: "f32[8, 2048, 256]" = torch.ops.aten.view.default(scatter_add, [8, 2048, 256]);  scatter_add = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:326 in forward, code: x = x + self.moe(self.ffn_norm(x))
        add_6: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(add_2, view_37);  view_37 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        _fused_rms_norm_6 = torch.ops.aten._fused_rms_norm.default(add_6, [256], primals_31, 1e-05)
        getitem_35: "f32[8, 2048, 256]" = _fused_rms_norm_6[0]
        getitem_36: "f32[8, 2048, 1]" = _fused_rms_norm_6[1];  _fused_rms_norm_6 = None
        detach_11: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(getitem_36);  getitem_36 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:213 in forward, code: q = self.wq(x)  # (bsz, seqlen, n_heads * qk_head_dim)
        t_15: "f32[256, 3072]" = torch.ops.aten.t.default(primals_26);  primals_26 = None
        view_38: "f32[16384, 256]" = torch.ops.aten.view.default(getitem_35, [16384, 256])
        mm_15: "f32[16384, 3072]" = torch.ops.aten.mm.default(view_38, t_15)
        _unsafe_view_11: "f32[8, 2048, 3072]" = torch.ops.aten._unsafe_view.default(mm_15, [8, 2048, 3072]);  mm_15 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:220 in forward, code: q = q.view(bsz, seqlen, -1, self.qk_head_dim)
        view_39: "f32[8, 2048, 16, 192]" = torch.ops.aten.view.default(_unsafe_view_11, [8, 2048, -1, 192]);  _unsafe_view_11 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:221 in forward, code: q_nope, q_pe = torch.split(
        split_with_sizes_6 = torch.ops.aten.split_with_sizes.default(view_39, [128, 64], -1);  view_39 = None
        getitem_37: "f32[8, 2048, 16, 128]" = split_with_sizes_6[0]
        getitem_38: "f32[8, 2048, 16, 64]" = split_with_sizes_6[1];  split_with_sizes_6 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:141 in apply_rotary_emb, code: x = torch.view_as_complex(x.float().view(*x.shape[:-1], -1, 2))
        view_40: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.view.default(getitem_38, [8, 2048, 16, -1, 2]);  getitem_38 = None
        view_as_complex_4: "c64[8, 2048, 16, 32]" = torch.ops.aten.view_as_complex.default(view_40);  view_40 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:142 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(1, x.size(1), 1, x.size(-1))
        view_41: "c64[1, 2048, 1, 32]" = torch.ops.aten.view.default(primals_84, [1, 2048, 1, 32])
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:143 in apply_rotary_emb, code: y = torch.view_as_real(x * freqs_cis).flatten(3)
        mul_10: "c64[8, 2048, 16, 32]" = torch.ops.aten.mul.Tensor(view_as_complex_4, view_41);  view_as_complex_4 = None
        view_as_real_4: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.view_as_real.default(mul_10);  mul_10 = None
        view_42: "f32[8, 2048, 16, 64]" = torch.ops.aten.view.default(view_as_real_4, [8, 2048, 16, 64]);  view_as_real_4 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:225 in forward, code: q = torch.cat([q_nope, q_pe], dim=-1)  # (bsz, seqlen, n_heads, qk_head_dim)
        cat_5: "f32[8, 2048, 16, 192]" = torch.ops.aten.cat.default([getitem_37, view_42], -1);  getitem_37 = view_42 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:228 in forward, code: kv = self.wkv_a(x)  # (bsz, seqlen, kv_lora_rank + qk_rope_head_dim)
        t_16: "f32[256, 576]" = torch.ops.aten.t.default(primals_27);  primals_27 = None
        view_43: "f32[16384, 256]" = torch.ops.aten.view.default(getitem_35, [16384, 256]);  getitem_35 = None
        mm_16: "f32[16384, 576]" = torch.ops.aten.mm.default(view_43, t_16)
        _unsafe_view_12: "f32[8, 2048, 576]" = torch.ops.aten._unsafe_view.default(mm_16, [8, 2048, 576]);  mm_16 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:229 in forward, code: kv, k_pe = torch.split(kv, [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1)
        split_with_sizes_7 = torch.ops.aten.split_with_sizes.default(_unsafe_view_12, [512, 64], -1);  _unsafe_view_12 = None
        getitem_39: "f32[8, 2048, 512]" = split_with_sizes_7[0]
        getitem_40: "f32[8, 2048, 64]" = split_with_sizes_7[1];  split_with_sizes_7 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:232 in forward, code: k_pe.unsqueeze(2), freqs_cis
        unsqueeze_3: "f32[8, 2048, 1, 64]" = torch.ops.aten.unsqueeze.default(getitem_40, 2);  getitem_40 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:141 in apply_rotary_emb, code: x = torch.view_as_complex(x.float().view(*x.shape[:-1], -1, 2))
        view_44: "f32[8, 2048, 1, 32, 2]" = torch.ops.aten.view.default(unsqueeze_3, [8, 2048, 1, -1, 2]);  unsqueeze_3 = None
        view_as_complex_5: "c64[8, 2048, 1, 32]" = torch.ops.aten.view_as_complex.default(view_44);  view_44 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:142 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(1, x.size(1), 1, x.size(-1))
        view_45: "c64[1, 2048, 1, 32]" = torch.ops.aten.view.default(primals_84, [1, 2048, 1, 32])
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:143 in apply_rotary_emb, code: y = torch.view_as_real(x * freqs_cis).flatten(3)
        mul_11: "c64[8, 2048, 1, 32]" = torch.ops.aten.mul.Tensor(view_as_complex_5, view_45);  view_as_complex_5 = None
        view_as_real_5: "f32[8, 2048, 1, 32, 2]" = torch.ops.aten.view_as_real.default(mul_11);  mul_11 = None
        view_46: "f32[8, 2048, 1, 64]" = torch.ops.aten.view.default(view_as_real_5, [8, 2048, 1, 64]);  view_as_real_5 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        _fused_rms_norm_7 = torch.ops.aten._fused_rms_norm.default(getitem_39, [512], primals_28, 1e-05)
        getitem_41: "f32[8, 2048, 512]" = _fused_rms_norm_7[0]
        getitem_42: "f32[8, 2048, 1]" = _fused_rms_norm_7[1];  _fused_rms_norm_7 = None
        detach_12: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(getitem_42);  getitem_42 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:235 in forward, code: kv = self.wkv_b(
        t_17: "f32[512, 4096]" = torch.ops.aten.t.default(primals_29);  primals_29 = None
        view_47: "f32[16384, 512]" = torch.ops.aten.view.default(getitem_41, [16384, 512]);  getitem_41 = None
        mm_17: "f32[16384, 4096]" = torch.ops.aten.mm.default(view_47, t_17)
        _unsafe_view_13: "f32[8, 2048, 4096]" = torch.ops.aten._unsafe_view.default(mm_17, [8, 2048, 4096]);  mm_17 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:238 in forward, code: kv = kv.view(bsz, seqlen, -1, self.qk_nope_head_dim + self.v_head_dim)
        view_48: "f32[8, 2048, 16, 256]" = torch.ops.aten.view.default(_unsafe_view_13, [8, 2048, -1, 256]);  _unsafe_view_13 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:239 in forward, code: k_nope, v = torch.split(kv, [self.qk_nope_head_dim, self.v_head_dim], dim=-1)
        split_with_sizes_8 = torch.ops.aten.split_with_sizes.default(view_48, [128, 128], -1);  view_48 = None
        getitem_43: "f32[8, 2048, 16, 128]" = split_with_sizes_8[0]
        getitem_44: "f32[8, 2048, 16, 128]" = split_with_sizes_8[1];  split_with_sizes_8 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:241 in forward, code: [k_nope, k_pe.expand(-1, -1, self.n_heads, -1)], dim=-1
        expand_3: "f32[8, 2048, 16, 64]" = torch.ops.aten.expand.default(view_46, [-1, -1, 16, -1]);  view_46 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:240 in forward, code: k = torch.cat(
        cat_6: "f32[8, 2048, 16, 192]" = torch.ops.aten.cat.default([getitem_43, expand_3], -1);  getitem_43 = expand_3 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:244 in forward, code: q = q.transpose(1, 2)  # (bsz, n_heads, seqlen, qk_head_dim)
        transpose_11: "f32[8, 16, 2048, 192]" = torch.ops.aten.transpose.int(cat_5, 1, 2);  cat_5 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:245 in forward, code: k = k.transpose(1, 2)  # (bsz, n_heads, seqlen, qk_head_dim)
        transpose_12: "f32[8, 16, 2048, 192]" = torch.ops.aten.transpose.int(cat_6, 1, 2);  cat_6 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:246 in forward, code: v = v.transpose(1, 2)  # (bsz, n_heads, seqlen, v_head_dim)
        transpose_13: "f32[8, 16, 2048, 128]" = torch.ops.aten.transpose.int(getitem_44, 1, 2);  getitem_44 = None
        
        # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1585 in flex_attention, code: out, lse, max_scores = flex_attention_hop(
        sdpa_score2 = self.sdpa_score2
        sdpa_mask2 = self.sdpa_mask2
        _tensor_constant0_2: "i32[8, 2048]" = self._tensor_constant0
        flex_attention_2 = torch.ops.higher_order.flex_attention(transpose_11, transpose_12, transpose_13, sdpa_score2, (2048, 2048, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, 128, 128, sdpa_mask2), 0.07216878364870322, {'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (_tensor_constant0_2,));  sdpa_score2 = sdpa_mask2 = _tensor_constant0_2 = None
        getitem_45: "f32[8, 16, 2048, 128]" = flex_attention_2[0]
        getitem_46: "f32[8, 16, 2048]" = flex_attention_2[1];  flex_attention_2 = None
        detach_13: "f32[8, 16, 2048, 128]" = torch.ops.aten.detach.default(getitem_45)
        detach_14: "f32[8, 16, 2048]" = torch.ops.aten.detach.default(getitem_46);  getitem_46 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:258 in forward, code: output = output.transpose(
        transpose_14: "f32[8, 2048, 16, 128]" = torch.ops.aten.transpose.int(getitem_45, 1, 2);  getitem_45 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:261 in forward, code: output = output.view(bsz, seqlen, -1)  # (bsz, seqlen, n_heads * v_head_dim)
        view_49: "f32[8, 2048, 2048]" = torch.ops.aten.view.default(transpose_14, [8, 2048, -1]);  transpose_14 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:262 in forward, code: return self.wo(output)  # (bsz, seqlen, dim)
        t_18: "f32[2048, 256]" = torch.ops.aten.t.default(primals_30);  primals_30 = None
        view_50: "f32[16384, 2048]" = torch.ops.aten.view.default(view_49, [16384, 2048]);  view_49 = None
        mm_18: "f32[16384, 256]" = torch.ops.aten.mm.default(view_50, t_18)
        _unsafe_view_14: "f32[8, 2048, 256]" = torch.ops.aten._unsafe_view.default(mm_18, [8, 2048, 256]);  mm_18 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:324 in forward, code: x = x + self.attention(self.attention_norm(x), freqs_cis, attention_masks)
        add_7: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(add_6, _unsafe_view_14);  _unsafe_view_14 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        _fused_rms_norm_8 = torch.ops.aten._fused_rms_norm.default(add_7, [256], primals_32, 1e-05)
        getitem_48: "f32[8, 2048, 256]" = _fused_rms_norm_8[0]
        getitem_49: "f32[8, 2048, 1]" = _fused_rms_norm_8[1];  _fused_rms_norm_8 = None
        detach_15: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(getitem_49);  getitem_49 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:415 in forward, code: x = x.view(-1, dim)
        view_51: "f32[16384, 256]" = torch.ops.aten.view.default(getitem_48, [-1, 256]);  getitem_48 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:247 in forward, code: scores = self.gate(x)
        t_19: "f32[256, 8]" = torch.ops.aten.t.default(primals_36);  primals_36 = None
        mm_19: "f32[16384, 8]" = torch.ops.aten.mm.default(view_51, t_19)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:253 in forward, code: scores = F.softmax(scores.to(torch.float32), dim=1)
        _softmax_1: "f32[16384, 8]" = torch.ops.aten._softmax.default(mm_19, 1, False);  mm_19 = None
        detach_16: "f32[16384, 8]" = torch.ops.aten.detach.default(_softmax_1)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:262 in forward, code: scores + expert_bias, k=self.top_k, dim=1
        add_8: "f32[16384, 8]" = torch.ops.aten.add.Tensor(_softmax_1, primals_87);  primals_87 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:261 in forward, code: _, selected_experts_indices = torch.topk(
        topk_1 = torch.ops.aten.topk.default(add_8, 3, 1);  add_8 = None
        getitem_51: "i64[16384, 3]" = topk_1[1];  topk_1 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:264 in forward, code: top_scores = scores.gather(dim=1, index=selected_experts_indices)
        gather_2: "f32[16384, 3]" = torch.ops.aten.gather.default(_softmax_1, 1, getitem_51);  _softmax_1 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:280 in forward, code: top_scores = top_scores * self.route_scale
        mul_12: "f32[16384, 3]" = torch.ops.aten.mul.Tensor(gather_2, 1.0);  gather_2 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:284 in forward, code: selected_experts_indices.view(-1),
        view_52: "i64[49152]" = torch.ops.aten.view.default(getitem_51, [-1])
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:283 in forward, code: num_tokens_per_expert = torch.histc(
        histc_2: "i64[8]" = torch.ops.aten.histc.default(view_52, 8, 0, 8);  view_52 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:431 in forward, code: self.tokens_per_expert.add_(num_tokens_per_expert)
        add_9: "f32[8]" = torch.ops.aten.add.Tensor(primals_88, histc_2);  primals_88 = histc_2 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:335 in forward, code: selected_experts_indices.view(-1),
        view_53: "i64[49152]" = torch.ops.aten.view.default(getitem_51, [-1])
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:334 in forward, code: num_tokens_per_expert = torch.histc(
        histc_3: "i64[8]" = torch.ops.aten.histc.default(view_53, 8, 0, 8);  view_53 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:344 in forward, code: selected_experts_indices.view(-1), stable=True
        view_54: "i64[49152]" = torch.ops.aten.view.default(getitem_51, [-1])
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:343 in forward, code: token_indices_experts_sorted = torch.argsort(
        sort_1 = torch.ops.aten.sort.stable(view_54, stable = True);  view_54 = None
        getitem_53: "i64[49152]" = sort_1[1];  sort_1 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:347 in forward, code: top_scores_experts_sorted = top_scores.view(-1)[token_indices_experts_sorted]
        view_55: "f32[49152]" = torch.ops.aten.view.default(mul_12, [-1]);  mul_12 = None
        index_2: "f32[49152]" = torch.ops.aten.index.Tensor(view_55, [getitem_53]);  view_55 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:348 in forward, code: token_indices_experts_sorted = token_indices_experts_sorted // self.top_k
        floor_divide_2: "i64[49152]" = torch.ops.aten.floor_divide.default(getitem_53, 3)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:448 in forward, code: token_indices_experts_sorted = token_indices_experts_sorted.reshape(
        view_56: "i64[49152, 1]" = torch.ops.aten.view.default(floor_divide_2, [-1, 1]);  floor_divide_2 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:450 in forward, code: ).expand(-1, dim)
        expand_4: "i64[49152, 256]" = torch.ops.aten.expand.default(view_56, [-1, 256]);  view_56 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:453 in forward, code: routed_input = torch.gather(x, dim=0, index=token_indices_experts_sorted)
        gather_3: "f32[49152, 256]" = torch.ops.aten.gather.default(view_51, 0, expand_4)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:174 in generate_permute_indices, code: torch.cumsum(tokens_per_expert_group, 0) - tokens_per_expert_group
        cumsum_3: "i64[8]" = torch.ops.aten.cumsum.default(histc_3, 0)
        sub_3: "i64[8]" = torch.ops.aten.sub.Tensor(cumsum_3, histc_3);  cumsum_3 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:178 in generate_permute_indices, code: total_tokens_per_expert = tokens_per_expert_group.view(num_ranks, -1).sum(0)
        view_57: "i64[1, 8]" = torch.ops.aten.view.default(histc_3, [1, -1])
        sum_2: "i64[8]" = torch.ops.aten.sum.dim_IntList(view_57, [0]);  view_57 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:181 in generate_permute_indices, code: total_tokens_per_expert = torch.clamp_min(total_tokens_per_expert, alignment)
        clamp_min_1: "i64[8]" = torch.ops.aten.clamp_min.default(sum_2, 8);  sum_2 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:184 in generate_permute_indices, code: m_sizes = ((total_tokens_per_expert + alignment - 1) // alignment * alignment).to(
        add_10: "i64[8]" = torch.ops.aten.add.Tensor(clamp_min_1, 8);  clamp_min_1 = None
        sub_4: "i64[8]" = torch.ops.aten.sub.Tensor(add_10, 1);  add_10 = None
        floor_divide_3: "i64[8]" = torch.ops.aten.floor_divide.default(sub_4, 8);  sub_4 = None
        mul_13: "i64[8]" = torch.ops.aten.mul.Tensor(floor_divide_3, 8);  floor_divide_3 = None
        _to_copy_8: "i32[8]" = torch.ops.aten._to_copy.default(mul_13, dtype = torch.int32);  mul_13 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:190 in generate_permute_indices, code: m_offsets = torch.cumsum(m_sizes, 0)
        cumsum_4: "i64[8]" = torch.ops.aten.cumsum.default(_to_copy_8, 0)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:191 in generate_permute_indices, code: write_offsets = m_offsets - m_sizes
        sub_5: "i64[8]" = torch.ops.aten.sub.Tensor(cumsum_4, _to_copy_8);  cumsum_4 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:80 in fill_indices_wrapper, code: permuted_indices = torch.full(
        full_1: "i32[49216]" = torch.ops.aten.full.default([49216], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:90 in fill_indices_wrapper, code: _fill_indices_kernel[grid](
        triton_kernel_wrapper_functional_proxy_1 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 1, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': histc_3, 'start_index_values_ptr': sub_3, 'write_offsets_ptr': sub_5, 'output_ptr': full_1}, tensors_to_clone = ['output_ptr']);  histc_3 = sub_3 = sub_5 = full_1 = None
        getitem_54: "i32[49216]" = triton_kernel_wrapper_functional_proxy_1['output_ptr'];  triton_kernel_wrapper_functional_proxy_1 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:55 in _permute, code: x = torch.vstack((x, x.new_zeros((x.shape[-1]))))
        new_zeros_31: "f32[256]" = torch.ops.aten.new_zeros.default(gather_3, [256], pin_memory = False)
        unsqueeze_4: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(new_zeros_31, 0);  new_zeros_31 = None
        cat_7: "f32[49153, 256]" = torch.ops.aten.cat.default([gather_3, unsqueeze_4]);  gather_3 = unsqueeze_4 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:57 in _permute, code: x = x[permuted_indices, :]
        index_3: "f32[49216, 256]" = torch.ops.aten.index.Tensor(cat_7, [getitem_54]);  cat_7 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:114 in _run_experts_grouped_mm, code: offsets = torch.cumsum(num_tokens_per_expert, dim=0, dtype=torch.int32)
        cumsum_5: "i32[8]" = torch.ops.aten.cumsum.default(_to_copy_8, 0, dtype = torch.int32);  _to_copy_8 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:117 in _run_experts_grouped_mm, code: torch._grouped_mm(x.bfloat16(), w1.bfloat16().transpose(-2, -1), offs=offsets)
        _to_copy_10: "bf16[49216, 256]" = torch.ops.aten._to_copy.default(index_3, dtype = torch.bfloat16)
        _to_copy_11: "bf16[8, 256, 256]" = torch.ops.aten._to_copy.default(primals_33, dtype = torch.bfloat16);  primals_33 = None
        transpose_15: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_to_copy_11, -2, -1);  _to_copy_11 = None
        _grouped_mm_3: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(_to_copy_10, transpose_15, cumsum_5)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:116 in _run_experts_grouped_mm, code: h = F.silu(
        silu_3: "bf16[49216, 256]" = torch.ops.aten.silu.default(_grouped_mm_3)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:120 in _run_experts_grouped_mm, code: x.bfloat16(), w3.bfloat16().transpose(-2, -1), offs=offsets
        _to_copy_12: "bf16[49216, 256]" = torch.ops.aten._to_copy.default(index_3, dtype = torch.bfloat16);  index_3 = None
        _to_copy_13: "bf16[8, 256, 256]" = torch.ops.aten._to_copy.default(primals_35, dtype = torch.bfloat16);  primals_35 = None
        transpose_16: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_to_copy_13, -2, -1);  _to_copy_13 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:119 in _run_experts_grouped_mm, code: h = h * torch._grouped_mm(
        _grouped_mm_4: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(_to_copy_12, transpose_16, cumsum_5)
        mul_14: "bf16[49216, 256]" = torch.ops.aten.mul.Tensor(silu_3, _grouped_mm_4)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:122 in _run_experts_grouped_mm, code: out = torch._grouped_mm(h, w2.bfloat16().transpose(-2, -1), offs=offsets).type_as(x)
        _to_copy_14: "bf16[8, 256, 256]" = torch.ops.aten._to_copy.default(primals_34, dtype = torch.bfloat16);  primals_34 = None
        transpose_17: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_to_copy_14, -2, -1);  _to_copy_14 = None
        _grouped_mm_5: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(mul_14, transpose_17, cumsum_5)
        _to_copy_15: "f32[49216, 256]" = torch.ops.aten._to_copy.default(_grouped_mm_5, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  _grouped_mm_5 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:63 in _unpermute, code: out_unpermuted = out.new_empty(input_shape)
        new_empty_1: "f32[49153, 256]" = torch.ops.aten.new_empty.default(_to_copy_15, [49153, 256], pin_memory = False)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:64 in _unpermute, code: out_unpermuted[permuted_indices, :] = out
        index_put_1: "f32[49153, 256]" = torch.ops.aten.index_put.default(new_empty_1, [getitem_54], _to_copy_15);  new_empty_1 = _to_copy_15 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:62 in forward, code: return self.w2(F.silu(self.w1(x)) * self.w3(x))
        t_20: "f32[256, 512]" = torch.ops.aten.t.default(primals_37);  primals_37 = None
        mm_20: "f32[16384, 512]" = torch.ops.aten.mm.default(view_51, t_20)
        silu_4: "f32[16384, 512]" = torch.ops.aten.silu.default(mm_20)
        t_21: "f32[256, 512]" = torch.ops.aten.t.default(primals_39);  primals_39 = None
        mm_21: "f32[16384, 512]" = torch.ops.aten.mm.default(view_51, t_21)
        mul_15: "f32[16384, 512]" = torch.ops.aten.mul.Tensor(silu_4, mm_21)
        t_22: "f32[512, 256]" = torch.ops.aten.t.default(primals_38);  primals_38 = None
        mm_22: "f32[16384, 256]" = torch.ops.aten.mm.default(mul_15, t_22)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:475 in forward, code: * top_scores_experts_sorted.reshape(-1, 1)
        view_58: "f32[49152, 1]" = torch.ops.aten.view.default(index_2, [-1, 1]);  index_2 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:65 in _unpermute, code: out = out_unpermuted[:-1]
        slice_4: "f32[49152, 256]" = torch.ops.aten.slice.Tensor(index_put_1, 0, 0, -1);  index_put_1 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:474 in forward, code: routed_output.to(torch.float32)
        mul_16: "f32[49152, 256]" = torch.ops.aten.mul.Tensor(slice_4, view_58)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:478 in forward, code: out = out.scatter_add(
        scatter_add_1: "f32[16384, 256]" = torch.ops.aten.scatter_add.default(mm_22, 0, expand_4, mul_16);  mm_22 = mul_16 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:481 in forward, code: out = out.reshape(bs, slen, dim)
        view_59: "f32[8, 2048, 256]" = torch.ops.aten.view.default(scatter_add_1, [8, 2048, 256]);  scatter_add_1 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:326 in forward, code: x = x + self.moe(self.ffn_norm(x))
        add_11: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(add_7, view_59);  view_59 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        _fused_rms_norm_9 = torch.ops.aten._fused_rms_norm.default(add_11, [256], primals_45, 1e-05)
        getitem_55: "f32[8, 2048, 256]" = _fused_rms_norm_9[0]
        getitem_56: "f32[8, 2048, 1]" = _fused_rms_norm_9[1];  _fused_rms_norm_9 = None
        detach_17: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(getitem_56);  getitem_56 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:213 in forward, code: q = self.wq(x)  # (bsz, seqlen, n_heads * qk_head_dim)
        t_23: "f32[256, 3072]" = torch.ops.aten.t.default(primals_40);  primals_40 = None
        view_60: "f32[16384, 256]" = torch.ops.aten.view.default(getitem_55, [16384, 256])
        mm_23: "f32[16384, 3072]" = torch.ops.aten.mm.default(view_60, t_23)
        _unsafe_view_15: "f32[8, 2048, 3072]" = torch.ops.aten._unsafe_view.default(mm_23, [8, 2048, 3072]);  mm_23 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:220 in forward, code: q = q.view(bsz, seqlen, -1, self.qk_head_dim)
        view_61: "f32[8, 2048, 16, 192]" = torch.ops.aten.view.default(_unsafe_view_15, [8, 2048, -1, 192]);  _unsafe_view_15 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:221 in forward, code: q_nope, q_pe = torch.split(
        split_with_sizes_9 = torch.ops.aten.split_with_sizes.default(view_61, [128, 64], -1);  view_61 = None
        getitem_57: "f32[8, 2048, 16, 128]" = split_with_sizes_9[0]
        getitem_58: "f32[8, 2048, 16, 64]" = split_with_sizes_9[1];  split_with_sizes_9 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:141 in apply_rotary_emb, code: x = torch.view_as_complex(x.float().view(*x.shape[:-1], -1, 2))
        view_62: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.view.default(getitem_58, [8, 2048, 16, -1, 2]);  getitem_58 = None
        view_as_complex_6: "c64[8, 2048, 16, 32]" = torch.ops.aten.view_as_complex.default(view_62);  view_62 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:142 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(1, x.size(1), 1, x.size(-1))
        view_63: "c64[1, 2048, 1, 32]" = torch.ops.aten.view.default(primals_84, [1, 2048, 1, 32])
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:143 in apply_rotary_emb, code: y = torch.view_as_real(x * freqs_cis).flatten(3)
        mul_17: "c64[8, 2048, 16, 32]" = torch.ops.aten.mul.Tensor(view_as_complex_6, view_63);  view_as_complex_6 = None
        view_as_real_6: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.view_as_real.default(mul_17);  mul_17 = None
        view_64: "f32[8, 2048, 16, 64]" = torch.ops.aten.view.default(view_as_real_6, [8, 2048, 16, 64]);  view_as_real_6 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:225 in forward, code: q = torch.cat([q_nope, q_pe], dim=-1)  # (bsz, seqlen, n_heads, qk_head_dim)
        cat_8: "f32[8, 2048, 16, 192]" = torch.ops.aten.cat.default([getitem_57, view_64], -1);  getitem_57 = view_64 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:228 in forward, code: kv = self.wkv_a(x)  # (bsz, seqlen, kv_lora_rank + qk_rope_head_dim)
        t_24: "f32[256, 576]" = torch.ops.aten.t.default(primals_41);  primals_41 = None
        view_65: "f32[16384, 256]" = torch.ops.aten.view.default(getitem_55, [16384, 256]);  getitem_55 = None
        mm_24: "f32[16384, 576]" = torch.ops.aten.mm.default(view_65, t_24)
        _unsafe_view_16: "f32[8, 2048, 576]" = torch.ops.aten._unsafe_view.default(mm_24, [8, 2048, 576]);  mm_24 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:229 in forward, code: kv, k_pe = torch.split(kv, [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1)
        split_with_sizes_10 = torch.ops.aten.split_with_sizes.default(_unsafe_view_16, [512, 64], -1);  _unsafe_view_16 = None
        getitem_59: "f32[8, 2048, 512]" = split_with_sizes_10[0]
        getitem_60: "f32[8, 2048, 64]" = split_with_sizes_10[1];  split_with_sizes_10 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:232 in forward, code: k_pe.unsqueeze(2), freqs_cis
        unsqueeze_5: "f32[8, 2048, 1, 64]" = torch.ops.aten.unsqueeze.default(getitem_60, 2);  getitem_60 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:141 in apply_rotary_emb, code: x = torch.view_as_complex(x.float().view(*x.shape[:-1], -1, 2))
        view_66: "f32[8, 2048, 1, 32, 2]" = torch.ops.aten.view.default(unsqueeze_5, [8, 2048, 1, -1, 2]);  unsqueeze_5 = None
        view_as_complex_7: "c64[8, 2048, 1, 32]" = torch.ops.aten.view_as_complex.default(view_66);  view_66 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:142 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(1, x.size(1), 1, x.size(-1))
        view_67: "c64[1, 2048, 1, 32]" = torch.ops.aten.view.default(primals_84, [1, 2048, 1, 32])
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:143 in apply_rotary_emb, code: y = torch.view_as_real(x * freqs_cis).flatten(3)
        mul_18: "c64[8, 2048, 1, 32]" = torch.ops.aten.mul.Tensor(view_as_complex_7, view_67);  view_as_complex_7 = None
        view_as_real_7: "f32[8, 2048, 1, 32, 2]" = torch.ops.aten.view_as_real.default(mul_18);  mul_18 = None
        view_68: "f32[8, 2048, 1, 64]" = torch.ops.aten.view.default(view_as_real_7, [8, 2048, 1, 64]);  view_as_real_7 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        _fused_rms_norm_10 = torch.ops.aten._fused_rms_norm.default(getitem_59, [512], primals_42, 1e-05)
        getitem_61: "f32[8, 2048, 512]" = _fused_rms_norm_10[0]
        getitem_62: "f32[8, 2048, 1]" = _fused_rms_norm_10[1];  _fused_rms_norm_10 = None
        detach_18: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(getitem_62);  getitem_62 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:235 in forward, code: kv = self.wkv_b(
        t_25: "f32[512, 4096]" = torch.ops.aten.t.default(primals_43);  primals_43 = None
        view_69: "f32[16384, 512]" = torch.ops.aten.view.default(getitem_61, [16384, 512]);  getitem_61 = None
        mm_25: "f32[16384, 4096]" = torch.ops.aten.mm.default(view_69, t_25)
        _unsafe_view_17: "f32[8, 2048, 4096]" = torch.ops.aten._unsafe_view.default(mm_25, [8, 2048, 4096]);  mm_25 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:238 in forward, code: kv = kv.view(bsz, seqlen, -1, self.qk_nope_head_dim + self.v_head_dim)
        view_70: "f32[8, 2048, 16, 256]" = torch.ops.aten.view.default(_unsafe_view_17, [8, 2048, -1, 256]);  _unsafe_view_17 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:239 in forward, code: k_nope, v = torch.split(kv, [self.qk_nope_head_dim, self.v_head_dim], dim=-1)
        split_with_sizes_11 = torch.ops.aten.split_with_sizes.default(view_70, [128, 128], -1);  view_70 = None
        getitem_63: "f32[8, 2048, 16, 128]" = split_with_sizes_11[0]
        getitem_64: "f32[8, 2048, 16, 128]" = split_with_sizes_11[1];  split_with_sizes_11 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:241 in forward, code: [k_nope, k_pe.expand(-1, -1, self.n_heads, -1)], dim=-1
        expand_5: "f32[8, 2048, 16, 64]" = torch.ops.aten.expand.default(view_68, [-1, -1, 16, -1]);  view_68 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:240 in forward, code: k = torch.cat(
        cat_9: "f32[8, 2048, 16, 192]" = torch.ops.aten.cat.default([getitem_63, expand_5], -1);  getitem_63 = expand_5 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:244 in forward, code: q = q.transpose(1, 2)  # (bsz, n_heads, seqlen, qk_head_dim)
        transpose_18: "f32[8, 16, 2048, 192]" = torch.ops.aten.transpose.int(cat_8, 1, 2);  cat_8 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:245 in forward, code: k = k.transpose(1, 2)  # (bsz, n_heads, seqlen, qk_head_dim)
        transpose_19: "f32[8, 16, 2048, 192]" = torch.ops.aten.transpose.int(cat_9, 1, 2);  cat_9 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:246 in forward, code: v = v.transpose(1, 2)  # (bsz, n_heads, seqlen, v_head_dim)
        transpose_20: "f32[8, 16, 2048, 128]" = torch.ops.aten.transpose.int(getitem_64, 1, 2);  getitem_64 = None
        
        # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1585 in flex_attention, code: out, lse, max_scores = flex_attention_hop(
        sdpa_score3 = self.sdpa_score3
        sdpa_mask3 = self.sdpa_mask3
        _tensor_constant0_3: "i32[8, 2048]" = self._tensor_constant0
        flex_attention_3 = torch.ops.higher_order.flex_attention(transpose_18, transpose_19, transpose_20, sdpa_score3, (2048, 2048, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, 128, 128, sdpa_mask3), 0.07216878364870322, {'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (_tensor_constant0_3,));  sdpa_score3 = sdpa_mask3 = _tensor_constant0_3 = None
        getitem_65: "f32[8, 16, 2048, 128]" = flex_attention_3[0]
        getitem_66: "f32[8, 16, 2048]" = flex_attention_3[1];  flex_attention_3 = None
        detach_19: "f32[8, 16, 2048, 128]" = torch.ops.aten.detach.default(getitem_65)
        detach_20: "f32[8, 16, 2048]" = torch.ops.aten.detach.default(getitem_66);  getitem_66 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:258 in forward, code: output = output.transpose(
        transpose_21: "f32[8, 2048, 16, 128]" = torch.ops.aten.transpose.int(getitem_65, 1, 2);  getitem_65 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:261 in forward, code: output = output.view(bsz, seqlen, -1)  # (bsz, seqlen, n_heads * v_head_dim)
        view_71: "f32[8, 2048, 2048]" = torch.ops.aten.view.default(transpose_21, [8, 2048, -1]);  transpose_21 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:262 in forward, code: return self.wo(output)  # (bsz, seqlen, dim)
        t_26: "f32[2048, 256]" = torch.ops.aten.t.default(primals_44);  primals_44 = None
        view_72: "f32[16384, 2048]" = torch.ops.aten.view.default(view_71, [16384, 2048]);  view_71 = None
        mm_26: "f32[16384, 256]" = torch.ops.aten.mm.default(view_72, t_26)
        _unsafe_view_18: "f32[8, 2048, 256]" = torch.ops.aten._unsafe_view.default(mm_26, [8, 2048, 256]);  mm_26 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:324 in forward, code: x = x + self.attention(self.attention_norm(x), freqs_cis, attention_masks)
        add_12: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(add_11, _unsafe_view_18);  _unsafe_view_18 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        _fused_rms_norm_11 = torch.ops.aten._fused_rms_norm.default(add_12, [256], primals_46, 1e-05)
        getitem_68: "f32[8, 2048, 256]" = _fused_rms_norm_11[0]
        getitem_69: "f32[8, 2048, 1]" = _fused_rms_norm_11[1];  _fused_rms_norm_11 = None
        detach_21: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(getitem_69);  getitem_69 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:415 in forward, code: x = x.view(-1, dim)
        view_73: "f32[16384, 256]" = torch.ops.aten.view.default(getitem_68, [-1, 256]);  getitem_68 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:247 in forward, code: scores = self.gate(x)
        t_27: "f32[256, 8]" = torch.ops.aten.t.default(primals_50);  primals_50 = None
        mm_27: "f32[16384, 8]" = torch.ops.aten.mm.default(view_73, t_27)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:253 in forward, code: scores = F.softmax(scores.to(torch.float32), dim=1)
        _softmax_2: "f32[16384, 8]" = torch.ops.aten._softmax.default(mm_27, 1, False);  mm_27 = None
        detach_22: "f32[16384, 8]" = torch.ops.aten.detach.default(_softmax_2)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:262 in forward, code: scores + expert_bias, k=self.top_k, dim=1
        add_13: "f32[16384, 8]" = torch.ops.aten.add.Tensor(_softmax_2, primals_89);  primals_89 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:261 in forward, code: _, selected_experts_indices = torch.topk(
        topk_2 = torch.ops.aten.topk.default(add_13, 3, 1);  add_13 = None
        getitem_71: "i64[16384, 3]" = topk_2[1];  topk_2 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:264 in forward, code: top_scores = scores.gather(dim=1, index=selected_experts_indices)
        gather_4: "f32[16384, 3]" = torch.ops.aten.gather.default(_softmax_2, 1, getitem_71);  _softmax_2 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:280 in forward, code: top_scores = top_scores * self.route_scale
        mul_19: "f32[16384, 3]" = torch.ops.aten.mul.Tensor(gather_4, 1.0);  gather_4 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:284 in forward, code: selected_experts_indices.view(-1),
        view_74: "i64[49152]" = torch.ops.aten.view.default(getitem_71, [-1])
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:283 in forward, code: num_tokens_per_expert = torch.histc(
        histc_4: "i64[8]" = torch.ops.aten.histc.default(view_74, 8, 0, 8);  view_74 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:431 in forward, code: self.tokens_per_expert.add_(num_tokens_per_expert)
        add_14: "f32[8]" = torch.ops.aten.add.Tensor(primals_90, histc_4);  primals_90 = histc_4 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:335 in forward, code: selected_experts_indices.view(-1),
        view_75: "i64[49152]" = torch.ops.aten.view.default(getitem_71, [-1])
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:334 in forward, code: num_tokens_per_expert = torch.histc(
        histc_5: "i64[8]" = torch.ops.aten.histc.default(view_75, 8, 0, 8);  view_75 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:344 in forward, code: selected_experts_indices.view(-1), stable=True
        view_76: "i64[49152]" = torch.ops.aten.view.default(getitem_71, [-1])
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:343 in forward, code: token_indices_experts_sorted = torch.argsort(
        sort_2 = torch.ops.aten.sort.stable(view_76, stable = True);  view_76 = None
        getitem_73: "i64[49152]" = sort_2[1];  sort_2 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:347 in forward, code: top_scores_experts_sorted = top_scores.view(-1)[token_indices_experts_sorted]
        view_77: "f32[49152]" = torch.ops.aten.view.default(mul_19, [-1]);  mul_19 = None
        index_4: "f32[49152]" = torch.ops.aten.index.Tensor(view_77, [getitem_73]);  view_77 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:348 in forward, code: token_indices_experts_sorted = token_indices_experts_sorted // self.top_k
        floor_divide_4: "i64[49152]" = torch.ops.aten.floor_divide.default(getitem_73, 3)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:448 in forward, code: token_indices_experts_sorted = token_indices_experts_sorted.reshape(
        view_78: "i64[49152, 1]" = torch.ops.aten.view.default(floor_divide_4, [-1, 1]);  floor_divide_4 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:450 in forward, code: ).expand(-1, dim)
        expand_6: "i64[49152, 256]" = torch.ops.aten.expand.default(view_78, [-1, 256]);  view_78 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:453 in forward, code: routed_input = torch.gather(x, dim=0, index=token_indices_experts_sorted)
        gather_5: "f32[49152, 256]" = torch.ops.aten.gather.default(view_73, 0, expand_6)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:174 in generate_permute_indices, code: torch.cumsum(tokens_per_expert_group, 0) - tokens_per_expert_group
        cumsum_6: "i64[8]" = torch.ops.aten.cumsum.default(histc_5, 0)
        sub_6: "i64[8]" = torch.ops.aten.sub.Tensor(cumsum_6, histc_5);  cumsum_6 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:178 in generate_permute_indices, code: total_tokens_per_expert = tokens_per_expert_group.view(num_ranks, -1).sum(0)
        view_79: "i64[1, 8]" = torch.ops.aten.view.default(histc_5, [1, -1])
        sum_3: "i64[8]" = torch.ops.aten.sum.dim_IntList(view_79, [0]);  view_79 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:181 in generate_permute_indices, code: total_tokens_per_expert = torch.clamp_min(total_tokens_per_expert, alignment)
        clamp_min_2: "i64[8]" = torch.ops.aten.clamp_min.default(sum_3, 8);  sum_3 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:184 in generate_permute_indices, code: m_sizes = ((total_tokens_per_expert + alignment - 1) // alignment * alignment).to(
        add_15: "i64[8]" = torch.ops.aten.add.Tensor(clamp_min_2, 8);  clamp_min_2 = None
        sub_7: "i64[8]" = torch.ops.aten.sub.Tensor(add_15, 1);  add_15 = None
        floor_divide_5: "i64[8]" = torch.ops.aten.floor_divide.default(sub_7, 8);  sub_7 = None
        mul_20: "i64[8]" = torch.ops.aten.mul.Tensor(floor_divide_5, 8);  floor_divide_5 = None
        _to_copy_16: "i32[8]" = torch.ops.aten._to_copy.default(mul_20, dtype = torch.int32);  mul_20 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:190 in generate_permute_indices, code: m_offsets = torch.cumsum(m_sizes, 0)
        cumsum_7: "i64[8]" = torch.ops.aten.cumsum.default(_to_copy_16, 0)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:191 in generate_permute_indices, code: write_offsets = m_offsets - m_sizes
        sub_8: "i64[8]" = torch.ops.aten.sub.Tensor(cumsum_7, _to_copy_16);  cumsum_7 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:80 in fill_indices_wrapper, code: permuted_indices = torch.full(
        full_2: "i32[49216]" = torch.ops.aten.full.default([49216], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:90 in fill_indices_wrapper, code: _fill_indices_kernel[grid](
        triton_kernel_wrapper_functional_proxy_2 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 2, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': histc_5, 'start_index_values_ptr': sub_6, 'write_offsets_ptr': sub_8, 'output_ptr': full_2}, tensors_to_clone = ['output_ptr']);  histc_5 = sub_6 = sub_8 = full_2 = None
        getitem_74: "i32[49216]" = triton_kernel_wrapper_functional_proxy_2['output_ptr'];  triton_kernel_wrapper_functional_proxy_2 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:55 in _permute, code: x = torch.vstack((x, x.new_zeros((x.shape[-1]))))
        new_zeros_42: "f32[256]" = torch.ops.aten.new_zeros.default(gather_5, [256], pin_memory = False)
        unsqueeze_6: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(new_zeros_42, 0);  new_zeros_42 = None
        cat_10: "f32[49153, 256]" = torch.ops.aten.cat.default([gather_5, unsqueeze_6]);  gather_5 = unsqueeze_6 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:57 in _permute, code: x = x[permuted_indices, :]
        index_5: "f32[49216, 256]" = torch.ops.aten.index.Tensor(cat_10, [getitem_74]);  cat_10 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:114 in _run_experts_grouped_mm, code: offsets = torch.cumsum(num_tokens_per_expert, dim=0, dtype=torch.int32)
        cumsum_8: "i32[8]" = torch.ops.aten.cumsum.default(_to_copy_16, 0, dtype = torch.int32);  _to_copy_16 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:117 in _run_experts_grouped_mm, code: torch._grouped_mm(x.bfloat16(), w1.bfloat16().transpose(-2, -1), offs=offsets)
        _to_copy_18: "bf16[49216, 256]" = torch.ops.aten._to_copy.default(index_5, dtype = torch.bfloat16)
        _to_copy_19: "bf16[8, 256, 256]" = torch.ops.aten._to_copy.default(primals_47, dtype = torch.bfloat16);  primals_47 = None
        transpose_22: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_to_copy_19, -2, -1);  _to_copy_19 = None
        _grouped_mm_6: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(_to_copy_18, transpose_22, cumsum_8)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:116 in _run_experts_grouped_mm, code: h = F.silu(
        silu_5: "bf16[49216, 256]" = torch.ops.aten.silu.default(_grouped_mm_6)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:120 in _run_experts_grouped_mm, code: x.bfloat16(), w3.bfloat16().transpose(-2, -1), offs=offsets
        _to_copy_20: "bf16[49216, 256]" = torch.ops.aten._to_copy.default(index_5, dtype = torch.bfloat16);  index_5 = None
        _to_copy_21: "bf16[8, 256, 256]" = torch.ops.aten._to_copy.default(primals_49, dtype = torch.bfloat16);  primals_49 = None
        transpose_23: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_to_copy_21, -2, -1);  _to_copy_21 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:119 in _run_experts_grouped_mm, code: h = h * torch._grouped_mm(
        _grouped_mm_7: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(_to_copy_20, transpose_23, cumsum_8)
        mul_21: "bf16[49216, 256]" = torch.ops.aten.mul.Tensor(silu_5, _grouped_mm_7)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:122 in _run_experts_grouped_mm, code: out = torch._grouped_mm(h, w2.bfloat16().transpose(-2, -1), offs=offsets).type_as(x)
        _to_copy_22: "bf16[8, 256, 256]" = torch.ops.aten._to_copy.default(primals_48, dtype = torch.bfloat16);  primals_48 = None
        transpose_24: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_to_copy_22, -2, -1);  _to_copy_22 = None
        _grouped_mm_8: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(mul_21, transpose_24, cumsum_8)
        _to_copy_23: "f32[49216, 256]" = torch.ops.aten._to_copy.default(_grouped_mm_8, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  _grouped_mm_8 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:63 in _unpermute, code: out_unpermuted = out.new_empty(input_shape)
        new_empty_2: "f32[49153, 256]" = torch.ops.aten.new_empty.default(_to_copy_23, [49153, 256], pin_memory = False)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:64 in _unpermute, code: out_unpermuted[permuted_indices, :] = out
        index_put_2: "f32[49153, 256]" = torch.ops.aten.index_put.default(new_empty_2, [getitem_74], _to_copy_23);  new_empty_2 = _to_copy_23 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:62 in forward, code: return self.w2(F.silu(self.w1(x)) * self.w3(x))
        t_28: "f32[256, 512]" = torch.ops.aten.t.default(primals_51);  primals_51 = None
        mm_28: "f32[16384, 512]" = torch.ops.aten.mm.default(view_73, t_28)
        silu_6: "f32[16384, 512]" = torch.ops.aten.silu.default(mm_28)
        t_29: "f32[256, 512]" = torch.ops.aten.t.default(primals_53);  primals_53 = None
        mm_29: "f32[16384, 512]" = torch.ops.aten.mm.default(view_73, t_29)
        mul_22: "f32[16384, 512]" = torch.ops.aten.mul.Tensor(silu_6, mm_29)
        t_30: "f32[512, 256]" = torch.ops.aten.t.default(primals_52);  primals_52 = None
        mm_30: "f32[16384, 256]" = torch.ops.aten.mm.default(mul_22, t_30)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:475 in forward, code: * top_scores_experts_sorted.reshape(-1, 1)
        view_80: "f32[49152, 1]" = torch.ops.aten.view.default(index_4, [-1, 1]);  index_4 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:65 in _unpermute, code: out = out_unpermuted[:-1]
        slice_6: "f32[49152, 256]" = torch.ops.aten.slice.Tensor(index_put_2, 0, 0, -1);  index_put_2 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:474 in forward, code: routed_output.to(torch.float32)
        mul_23: "f32[49152, 256]" = torch.ops.aten.mul.Tensor(slice_6, view_80)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:478 in forward, code: out = out.scatter_add(
        scatter_add_2: "f32[16384, 256]" = torch.ops.aten.scatter_add.default(mm_30, 0, expand_6, mul_23);  mm_30 = mul_23 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:481 in forward, code: out = out.reshape(bs, slen, dim)
        view_81: "f32[8, 2048, 256]" = torch.ops.aten.view.default(scatter_add_2, [8, 2048, 256]);  scatter_add_2 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:326 in forward, code: x = x + self.moe(self.ffn_norm(x))
        add_16: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(add_12, view_81);  view_81 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        _fused_rms_norm_12 = torch.ops.aten._fused_rms_norm.default(add_16, [256], primals_59, 1e-05)
        getitem_75: "f32[8, 2048, 256]" = _fused_rms_norm_12[0]
        getitem_76: "f32[8, 2048, 1]" = _fused_rms_norm_12[1];  _fused_rms_norm_12 = None
        detach_23: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(getitem_76);  getitem_76 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:213 in forward, code: q = self.wq(x)  # (bsz, seqlen, n_heads * qk_head_dim)
        t_31: "f32[256, 3072]" = torch.ops.aten.t.default(primals_54);  primals_54 = None
        view_82: "f32[16384, 256]" = torch.ops.aten.view.default(getitem_75, [16384, 256])
        mm_31: "f32[16384, 3072]" = torch.ops.aten.mm.default(view_82, t_31)
        _unsafe_view_19: "f32[8, 2048, 3072]" = torch.ops.aten._unsafe_view.default(mm_31, [8, 2048, 3072]);  mm_31 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:220 in forward, code: q = q.view(bsz, seqlen, -1, self.qk_head_dim)
        view_83: "f32[8, 2048, 16, 192]" = torch.ops.aten.view.default(_unsafe_view_19, [8, 2048, -1, 192]);  _unsafe_view_19 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:221 in forward, code: q_nope, q_pe = torch.split(
        split_with_sizes_12 = torch.ops.aten.split_with_sizes.default(view_83, [128, 64], -1);  view_83 = None
        getitem_77: "f32[8, 2048, 16, 128]" = split_with_sizes_12[0]
        getitem_78: "f32[8, 2048, 16, 64]" = split_with_sizes_12[1];  split_with_sizes_12 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:141 in apply_rotary_emb, code: x = torch.view_as_complex(x.float().view(*x.shape[:-1], -1, 2))
        view_84: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.view.default(getitem_78, [8, 2048, 16, -1, 2]);  getitem_78 = None
        view_as_complex_8: "c64[8, 2048, 16, 32]" = torch.ops.aten.view_as_complex.default(view_84);  view_84 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:142 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(1, x.size(1), 1, x.size(-1))
        view_85: "c64[1, 2048, 1, 32]" = torch.ops.aten.view.default(primals_84, [1, 2048, 1, 32])
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:143 in apply_rotary_emb, code: y = torch.view_as_real(x * freqs_cis).flatten(3)
        mul_24: "c64[8, 2048, 16, 32]" = torch.ops.aten.mul.Tensor(view_as_complex_8, view_85);  view_as_complex_8 = None
        view_as_real_8: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.view_as_real.default(mul_24);  mul_24 = None
        view_86: "f32[8, 2048, 16, 64]" = torch.ops.aten.view.default(view_as_real_8, [8, 2048, 16, 64]);  view_as_real_8 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:225 in forward, code: q = torch.cat([q_nope, q_pe], dim=-1)  # (bsz, seqlen, n_heads, qk_head_dim)
        cat_11: "f32[8, 2048, 16, 192]" = torch.ops.aten.cat.default([getitem_77, view_86], -1);  getitem_77 = view_86 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:228 in forward, code: kv = self.wkv_a(x)  # (bsz, seqlen, kv_lora_rank + qk_rope_head_dim)
        t_32: "f32[256, 576]" = torch.ops.aten.t.default(primals_55);  primals_55 = None
        view_87: "f32[16384, 256]" = torch.ops.aten.view.default(getitem_75, [16384, 256]);  getitem_75 = None
        mm_32: "f32[16384, 576]" = torch.ops.aten.mm.default(view_87, t_32)
        _unsafe_view_20: "f32[8, 2048, 576]" = torch.ops.aten._unsafe_view.default(mm_32, [8, 2048, 576]);  mm_32 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:229 in forward, code: kv, k_pe = torch.split(kv, [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1)
        split_with_sizes_13 = torch.ops.aten.split_with_sizes.default(_unsafe_view_20, [512, 64], -1);  _unsafe_view_20 = None
        getitem_79: "f32[8, 2048, 512]" = split_with_sizes_13[0]
        getitem_80: "f32[8, 2048, 64]" = split_with_sizes_13[1];  split_with_sizes_13 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:232 in forward, code: k_pe.unsqueeze(2), freqs_cis
        unsqueeze_7: "f32[8, 2048, 1, 64]" = torch.ops.aten.unsqueeze.default(getitem_80, 2);  getitem_80 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:141 in apply_rotary_emb, code: x = torch.view_as_complex(x.float().view(*x.shape[:-1], -1, 2))
        view_88: "f32[8, 2048, 1, 32, 2]" = torch.ops.aten.view.default(unsqueeze_7, [8, 2048, 1, -1, 2]);  unsqueeze_7 = None
        view_as_complex_9: "c64[8, 2048, 1, 32]" = torch.ops.aten.view_as_complex.default(view_88);  view_88 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:142 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(1, x.size(1), 1, x.size(-1))
        view_89: "c64[1, 2048, 1, 32]" = torch.ops.aten.view.default(primals_84, [1, 2048, 1, 32])
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:143 in apply_rotary_emb, code: y = torch.view_as_real(x * freqs_cis).flatten(3)
        mul_25: "c64[8, 2048, 1, 32]" = torch.ops.aten.mul.Tensor(view_as_complex_9, view_89);  view_as_complex_9 = None
        view_as_real_9: "f32[8, 2048, 1, 32, 2]" = torch.ops.aten.view_as_real.default(mul_25);  mul_25 = None
        view_90: "f32[8, 2048, 1, 64]" = torch.ops.aten.view.default(view_as_real_9, [8, 2048, 1, 64]);  view_as_real_9 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        _fused_rms_norm_13 = torch.ops.aten._fused_rms_norm.default(getitem_79, [512], primals_56, 1e-05)
        getitem_81: "f32[8, 2048, 512]" = _fused_rms_norm_13[0]
        getitem_82: "f32[8, 2048, 1]" = _fused_rms_norm_13[1];  _fused_rms_norm_13 = None
        detach_24: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(getitem_82);  getitem_82 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:235 in forward, code: kv = self.wkv_b(
        t_33: "f32[512, 4096]" = torch.ops.aten.t.default(primals_57);  primals_57 = None
        view_91: "f32[16384, 512]" = torch.ops.aten.view.default(getitem_81, [16384, 512]);  getitem_81 = None
        mm_33: "f32[16384, 4096]" = torch.ops.aten.mm.default(view_91, t_33)
        _unsafe_view_21: "f32[8, 2048, 4096]" = torch.ops.aten._unsafe_view.default(mm_33, [8, 2048, 4096]);  mm_33 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:238 in forward, code: kv = kv.view(bsz, seqlen, -1, self.qk_nope_head_dim + self.v_head_dim)
        view_92: "f32[8, 2048, 16, 256]" = torch.ops.aten.view.default(_unsafe_view_21, [8, 2048, -1, 256]);  _unsafe_view_21 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:239 in forward, code: k_nope, v = torch.split(kv, [self.qk_nope_head_dim, self.v_head_dim], dim=-1)
        split_with_sizes_14 = torch.ops.aten.split_with_sizes.default(view_92, [128, 128], -1);  view_92 = None
        getitem_83: "f32[8, 2048, 16, 128]" = split_with_sizes_14[0]
        getitem_84: "f32[8, 2048, 16, 128]" = split_with_sizes_14[1];  split_with_sizes_14 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:241 in forward, code: [k_nope, k_pe.expand(-1, -1, self.n_heads, -1)], dim=-1
        expand_7: "f32[8, 2048, 16, 64]" = torch.ops.aten.expand.default(view_90, [-1, -1, 16, -1]);  view_90 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:240 in forward, code: k = torch.cat(
        cat_12: "f32[8, 2048, 16, 192]" = torch.ops.aten.cat.default([getitem_83, expand_7], -1);  getitem_83 = expand_7 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:244 in forward, code: q = q.transpose(1, 2)  # (bsz, n_heads, seqlen, qk_head_dim)
        transpose_25: "f32[8, 16, 2048, 192]" = torch.ops.aten.transpose.int(cat_11, 1, 2);  cat_11 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:245 in forward, code: k = k.transpose(1, 2)  # (bsz, n_heads, seqlen, qk_head_dim)
        transpose_26: "f32[8, 16, 2048, 192]" = torch.ops.aten.transpose.int(cat_12, 1, 2);  cat_12 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:246 in forward, code: v = v.transpose(1, 2)  # (bsz, n_heads, seqlen, v_head_dim)
        transpose_27: "f32[8, 16, 2048, 128]" = torch.ops.aten.transpose.int(getitem_84, 1, 2);  getitem_84 = None
        
        # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1585 in flex_attention, code: out, lse, max_scores = flex_attention_hop(
        sdpa_score4 = self.sdpa_score4
        sdpa_mask4 = self.sdpa_mask4
        _tensor_constant0_4: "i32[8, 2048]" = self._tensor_constant0
        flex_attention_4 = torch.ops.higher_order.flex_attention(transpose_25, transpose_26, transpose_27, sdpa_score4, (2048, 2048, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, 128, 128, sdpa_mask4), 0.07216878364870322, {'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (_tensor_constant0_4,));  sdpa_score4 = sdpa_mask4 = _tensor_constant0_4 = None
        getitem_85: "f32[8, 16, 2048, 128]" = flex_attention_4[0]
        getitem_86: "f32[8, 16, 2048]" = flex_attention_4[1];  flex_attention_4 = None
        detach_25: "f32[8, 16, 2048, 128]" = torch.ops.aten.detach.default(getitem_85)
        detach_26: "f32[8, 16, 2048]" = torch.ops.aten.detach.default(getitem_86);  getitem_86 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:258 in forward, code: output = output.transpose(
        transpose_28: "f32[8, 2048, 16, 128]" = torch.ops.aten.transpose.int(getitem_85, 1, 2);  getitem_85 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:261 in forward, code: output = output.view(bsz, seqlen, -1)  # (bsz, seqlen, n_heads * v_head_dim)
        view_93: "f32[8, 2048, 2048]" = torch.ops.aten.view.default(transpose_28, [8, 2048, -1]);  transpose_28 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:262 in forward, code: return self.wo(output)  # (bsz, seqlen, dim)
        t_34: "f32[2048, 256]" = torch.ops.aten.t.default(primals_58);  primals_58 = None
        view_94: "f32[16384, 2048]" = torch.ops.aten.view.default(view_93, [16384, 2048]);  view_93 = None
        mm_34: "f32[16384, 256]" = torch.ops.aten.mm.default(view_94, t_34)
        _unsafe_view_22: "f32[8, 2048, 256]" = torch.ops.aten._unsafe_view.default(mm_34, [8, 2048, 256]);  mm_34 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:324 in forward, code: x = x + self.attention(self.attention_norm(x), freqs_cis, attention_masks)
        add_17: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(add_16, _unsafe_view_22);  _unsafe_view_22 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        _fused_rms_norm_14 = torch.ops.aten._fused_rms_norm.default(add_17, [256], primals_60, 1e-05)
        getitem_88: "f32[8, 2048, 256]" = _fused_rms_norm_14[0]
        getitem_89: "f32[8, 2048, 1]" = _fused_rms_norm_14[1];  _fused_rms_norm_14 = None
        detach_27: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(getitem_89);  getitem_89 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:415 in forward, code: x = x.view(-1, dim)
        view_95: "f32[16384, 256]" = torch.ops.aten.view.default(getitem_88, [-1, 256]);  getitem_88 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:247 in forward, code: scores = self.gate(x)
        t_35: "f32[256, 8]" = torch.ops.aten.t.default(primals_64);  primals_64 = None
        mm_35: "f32[16384, 8]" = torch.ops.aten.mm.default(view_95, t_35)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:253 in forward, code: scores = F.softmax(scores.to(torch.float32), dim=1)
        _softmax_3: "f32[16384, 8]" = torch.ops.aten._softmax.default(mm_35, 1, False);  mm_35 = None
        detach_28: "f32[16384, 8]" = torch.ops.aten.detach.default(_softmax_3)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:262 in forward, code: scores + expert_bias, k=self.top_k, dim=1
        add_18: "f32[16384, 8]" = torch.ops.aten.add.Tensor(_softmax_3, primals_91);  primals_91 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:261 in forward, code: _, selected_experts_indices = torch.topk(
        topk_3 = torch.ops.aten.topk.default(add_18, 3, 1);  add_18 = None
        getitem_91: "i64[16384, 3]" = topk_3[1];  topk_3 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:264 in forward, code: top_scores = scores.gather(dim=1, index=selected_experts_indices)
        gather_6: "f32[16384, 3]" = torch.ops.aten.gather.default(_softmax_3, 1, getitem_91);  _softmax_3 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:280 in forward, code: top_scores = top_scores * self.route_scale
        mul_26: "f32[16384, 3]" = torch.ops.aten.mul.Tensor(gather_6, 1.0);  gather_6 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:284 in forward, code: selected_experts_indices.view(-1),
        view_96: "i64[49152]" = torch.ops.aten.view.default(getitem_91, [-1])
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:283 in forward, code: num_tokens_per_expert = torch.histc(
        histc_6: "i64[8]" = torch.ops.aten.histc.default(view_96, 8, 0, 8);  view_96 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:431 in forward, code: self.tokens_per_expert.add_(num_tokens_per_expert)
        add_19: "f32[8]" = torch.ops.aten.add.Tensor(primals_92, histc_6);  primals_92 = histc_6 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:335 in forward, code: selected_experts_indices.view(-1),
        view_97: "i64[49152]" = torch.ops.aten.view.default(getitem_91, [-1])
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:334 in forward, code: num_tokens_per_expert = torch.histc(
        histc_7: "i64[8]" = torch.ops.aten.histc.default(view_97, 8, 0, 8);  view_97 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:344 in forward, code: selected_experts_indices.view(-1), stable=True
        view_98: "i64[49152]" = torch.ops.aten.view.default(getitem_91, [-1])
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:343 in forward, code: token_indices_experts_sorted = torch.argsort(
        sort_3 = torch.ops.aten.sort.stable(view_98, stable = True);  view_98 = None
        getitem_93: "i64[49152]" = sort_3[1];  sort_3 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:347 in forward, code: top_scores_experts_sorted = top_scores.view(-1)[token_indices_experts_sorted]
        view_99: "f32[49152]" = torch.ops.aten.view.default(mul_26, [-1]);  mul_26 = None
        index_6: "f32[49152]" = torch.ops.aten.index.Tensor(view_99, [getitem_93]);  view_99 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:348 in forward, code: token_indices_experts_sorted = token_indices_experts_sorted // self.top_k
        floor_divide_6: "i64[49152]" = torch.ops.aten.floor_divide.default(getitem_93, 3)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:448 in forward, code: token_indices_experts_sorted = token_indices_experts_sorted.reshape(
        view_100: "i64[49152, 1]" = torch.ops.aten.view.default(floor_divide_6, [-1, 1]);  floor_divide_6 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:450 in forward, code: ).expand(-1, dim)
        expand_8: "i64[49152, 256]" = torch.ops.aten.expand.default(view_100, [-1, 256]);  view_100 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:453 in forward, code: routed_input = torch.gather(x, dim=0, index=token_indices_experts_sorted)
        gather_7: "f32[49152, 256]" = torch.ops.aten.gather.default(view_95, 0, expand_8)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:174 in generate_permute_indices, code: torch.cumsum(tokens_per_expert_group, 0) - tokens_per_expert_group
        cumsum_9: "i64[8]" = torch.ops.aten.cumsum.default(histc_7, 0)
        sub_9: "i64[8]" = torch.ops.aten.sub.Tensor(cumsum_9, histc_7);  cumsum_9 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:178 in generate_permute_indices, code: total_tokens_per_expert = tokens_per_expert_group.view(num_ranks, -1).sum(0)
        view_101: "i64[1, 8]" = torch.ops.aten.view.default(histc_7, [1, -1])
        sum_4: "i64[8]" = torch.ops.aten.sum.dim_IntList(view_101, [0]);  view_101 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:181 in generate_permute_indices, code: total_tokens_per_expert = torch.clamp_min(total_tokens_per_expert, alignment)
        clamp_min_3: "i64[8]" = torch.ops.aten.clamp_min.default(sum_4, 8);  sum_4 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:184 in generate_permute_indices, code: m_sizes = ((total_tokens_per_expert + alignment - 1) // alignment * alignment).to(
        add_20: "i64[8]" = torch.ops.aten.add.Tensor(clamp_min_3, 8);  clamp_min_3 = None
        sub_10: "i64[8]" = torch.ops.aten.sub.Tensor(add_20, 1);  add_20 = None
        floor_divide_7: "i64[8]" = torch.ops.aten.floor_divide.default(sub_10, 8);  sub_10 = None
        mul_27: "i64[8]" = torch.ops.aten.mul.Tensor(floor_divide_7, 8);  floor_divide_7 = None
        _to_copy_24: "i32[8]" = torch.ops.aten._to_copy.default(mul_27, dtype = torch.int32);  mul_27 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:190 in generate_permute_indices, code: m_offsets = torch.cumsum(m_sizes, 0)
        cumsum_10: "i64[8]" = torch.ops.aten.cumsum.default(_to_copy_24, 0)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:191 in generate_permute_indices, code: write_offsets = m_offsets - m_sizes
        sub_11: "i64[8]" = torch.ops.aten.sub.Tensor(cumsum_10, _to_copy_24);  cumsum_10 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:80 in fill_indices_wrapper, code: permuted_indices = torch.full(
        full_3: "i32[49216]" = torch.ops.aten.full.default([49216], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:90 in fill_indices_wrapper, code: _fill_indices_kernel[grid](
        triton_kernel_wrapper_functional_proxy_3 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 3, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': histc_7, 'start_index_values_ptr': sub_9, 'write_offsets_ptr': sub_11, 'output_ptr': full_3}, tensors_to_clone = ['output_ptr']);  histc_7 = sub_9 = sub_11 = full_3 = None
        getitem_94: "i32[49216]" = triton_kernel_wrapper_functional_proxy_3['output_ptr'];  triton_kernel_wrapper_functional_proxy_3 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:55 in _permute, code: x = torch.vstack((x, x.new_zeros((x.shape[-1]))))
        new_zeros_53: "f32[256]" = torch.ops.aten.new_zeros.default(gather_7, [256], pin_memory = False)
        unsqueeze_8: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(new_zeros_53, 0);  new_zeros_53 = None
        cat_13: "f32[49153, 256]" = torch.ops.aten.cat.default([gather_7, unsqueeze_8]);  gather_7 = unsqueeze_8 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:57 in _permute, code: x = x[permuted_indices, :]
        index_7: "f32[49216, 256]" = torch.ops.aten.index.Tensor(cat_13, [getitem_94]);  cat_13 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:114 in _run_experts_grouped_mm, code: offsets = torch.cumsum(num_tokens_per_expert, dim=0, dtype=torch.int32)
        cumsum_11: "i32[8]" = torch.ops.aten.cumsum.default(_to_copy_24, 0, dtype = torch.int32);  _to_copy_24 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:117 in _run_experts_grouped_mm, code: torch._grouped_mm(x.bfloat16(), w1.bfloat16().transpose(-2, -1), offs=offsets)
        _to_copy_26: "bf16[49216, 256]" = torch.ops.aten._to_copy.default(index_7, dtype = torch.bfloat16)
        _to_copy_27: "bf16[8, 256, 256]" = torch.ops.aten._to_copy.default(primals_61, dtype = torch.bfloat16);  primals_61 = None
        transpose_29: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_to_copy_27, -2, -1);  _to_copy_27 = None
        _grouped_mm_9: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(_to_copy_26, transpose_29, cumsum_11)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:116 in _run_experts_grouped_mm, code: h = F.silu(
        silu_7: "bf16[49216, 256]" = torch.ops.aten.silu.default(_grouped_mm_9)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:120 in _run_experts_grouped_mm, code: x.bfloat16(), w3.bfloat16().transpose(-2, -1), offs=offsets
        _to_copy_28: "bf16[49216, 256]" = torch.ops.aten._to_copy.default(index_7, dtype = torch.bfloat16);  index_7 = None
        _to_copy_29: "bf16[8, 256, 256]" = torch.ops.aten._to_copy.default(primals_63, dtype = torch.bfloat16);  primals_63 = None
        transpose_30: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_to_copy_29, -2, -1);  _to_copy_29 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:119 in _run_experts_grouped_mm, code: h = h * torch._grouped_mm(
        _grouped_mm_10: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(_to_copy_28, transpose_30, cumsum_11)
        mul_28: "bf16[49216, 256]" = torch.ops.aten.mul.Tensor(silu_7, _grouped_mm_10)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:122 in _run_experts_grouped_mm, code: out = torch._grouped_mm(h, w2.bfloat16().transpose(-2, -1), offs=offsets).type_as(x)
        _to_copy_30: "bf16[8, 256, 256]" = torch.ops.aten._to_copy.default(primals_62, dtype = torch.bfloat16);  primals_62 = None
        transpose_31: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_to_copy_30, -2, -1);  _to_copy_30 = None
        _grouped_mm_11: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(mul_28, transpose_31, cumsum_11)
        _to_copy_31: "f32[49216, 256]" = torch.ops.aten._to_copy.default(_grouped_mm_11, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  _grouped_mm_11 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:63 in _unpermute, code: out_unpermuted = out.new_empty(input_shape)
        new_empty_3: "f32[49153, 256]" = torch.ops.aten.new_empty.default(_to_copy_31, [49153, 256], pin_memory = False)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:64 in _unpermute, code: out_unpermuted[permuted_indices, :] = out
        index_put_3: "f32[49153, 256]" = torch.ops.aten.index_put.default(new_empty_3, [getitem_94], _to_copy_31);  new_empty_3 = _to_copy_31 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:62 in forward, code: return self.w2(F.silu(self.w1(x)) * self.w3(x))
        t_36: "f32[256, 512]" = torch.ops.aten.t.default(primals_65);  primals_65 = None
        mm_36: "f32[16384, 512]" = torch.ops.aten.mm.default(view_95, t_36)
        silu_8: "f32[16384, 512]" = torch.ops.aten.silu.default(mm_36)
        t_37: "f32[256, 512]" = torch.ops.aten.t.default(primals_67);  primals_67 = None
        mm_37: "f32[16384, 512]" = torch.ops.aten.mm.default(view_95, t_37)
        mul_29: "f32[16384, 512]" = torch.ops.aten.mul.Tensor(silu_8, mm_37)
        t_38: "f32[512, 256]" = torch.ops.aten.t.default(primals_66);  primals_66 = None
        mm_38: "f32[16384, 256]" = torch.ops.aten.mm.default(mul_29, t_38)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:475 in forward, code: * top_scores_experts_sorted.reshape(-1, 1)
        view_102: "f32[49152, 1]" = torch.ops.aten.view.default(index_6, [-1, 1]);  index_6 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:65 in _unpermute, code: out = out_unpermuted[:-1]
        slice_8: "f32[49152, 256]" = torch.ops.aten.slice.Tensor(index_put_3, 0, 0, -1);  index_put_3 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:474 in forward, code: routed_output.to(torch.float32)
        mul_30: "f32[49152, 256]" = torch.ops.aten.mul.Tensor(slice_8, view_102)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:478 in forward, code: out = out.scatter_add(
        scatter_add_3: "f32[16384, 256]" = torch.ops.aten.scatter_add.default(mm_38, 0, expand_8, mul_30);  mm_38 = mul_30 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:481 in forward, code: out = out.reshape(bs, slen, dim)
        view_103: "f32[8, 2048, 256]" = torch.ops.aten.view.default(scatter_add_3, [8, 2048, 256]);  scatter_add_3 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:326 in forward, code: x = x + self.moe(self.ffn_norm(x))
        add_21: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(add_17, view_103);  view_103 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        _fused_rms_norm_15 = torch.ops.aten._fused_rms_norm.default(add_21, [256], primals_73, 1e-05)
        getitem_95: "f32[8, 2048, 256]" = _fused_rms_norm_15[0]
        getitem_96: "f32[8, 2048, 1]" = _fused_rms_norm_15[1];  _fused_rms_norm_15 = None
        detach_29: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(getitem_96);  getitem_96 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:213 in forward, code: q = self.wq(x)  # (bsz, seqlen, n_heads * qk_head_dim)
        t_39: "f32[256, 3072]" = torch.ops.aten.t.default(primals_68);  primals_68 = None
        view_104: "f32[16384, 256]" = torch.ops.aten.view.default(getitem_95, [16384, 256])
        mm_39: "f32[16384, 3072]" = torch.ops.aten.mm.default(view_104, t_39)
        _unsafe_view_23: "f32[8, 2048, 3072]" = torch.ops.aten._unsafe_view.default(mm_39, [8, 2048, 3072]);  mm_39 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:220 in forward, code: q = q.view(bsz, seqlen, -1, self.qk_head_dim)
        view_105: "f32[8, 2048, 16, 192]" = torch.ops.aten.view.default(_unsafe_view_23, [8, 2048, -1, 192]);  _unsafe_view_23 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:221 in forward, code: q_nope, q_pe = torch.split(
        split_with_sizes_15 = torch.ops.aten.split_with_sizes.default(view_105, [128, 64], -1);  view_105 = None
        getitem_97: "f32[8, 2048, 16, 128]" = split_with_sizes_15[0]
        getitem_98: "f32[8, 2048, 16, 64]" = split_with_sizes_15[1];  split_with_sizes_15 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:141 in apply_rotary_emb, code: x = torch.view_as_complex(x.float().view(*x.shape[:-1], -1, 2))
        view_106: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.view.default(getitem_98, [8, 2048, 16, -1, 2]);  getitem_98 = None
        view_as_complex_10: "c64[8, 2048, 16, 32]" = torch.ops.aten.view_as_complex.default(view_106);  view_106 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:142 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(1, x.size(1), 1, x.size(-1))
        view_107: "c64[1, 2048, 1, 32]" = torch.ops.aten.view.default(primals_84, [1, 2048, 1, 32])
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:143 in apply_rotary_emb, code: y = torch.view_as_real(x * freqs_cis).flatten(3)
        mul_31: "c64[8, 2048, 16, 32]" = torch.ops.aten.mul.Tensor(view_as_complex_10, view_107);  view_as_complex_10 = None
        view_as_real_10: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.view_as_real.default(mul_31);  mul_31 = None
        view_108: "f32[8, 2048, 16, 64]" = torch.ops.aten.view.default(view_as_real_10, [8, 2048, 16, 64]);  view_as_real_10 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:225 in forward, code: q = torch.cat([q_nope, q_pe], dim=-1)  # (bsz, seqlen, n_heads, qk_head_dim)
        cat_14: "f32[8, 2048, 16, 192]" = torch.ops.aten.cat.default([getitem_97, view_108], -1);  getitem_97 = view_108 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:228 in forward, code: kv = self.wkv_a(x)  # (bsz, seqlen, kv_lora_rank + qk_rope_head_dim)
        t_40: "f32[256, 576]" = torch.ops.aten.t.default(primals_69);  primals_69 = None
        view_109: "f32[16384, 256]" = torch.ops.aten.view.default(getitem_95, [16384, 256]);  getitem_95 = None
        mm_40: "f32[16384, 576]" = torch.ops.aten.mm.default(view_109, t_40)
        _unsafe_view_24: "f32[8, 2048, 576]" = torch.ops.aten._unsafe_view.default(mm_40, [8, 2048, 576]);  mm_40 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:229 in forward, code: kv, k_pe = torch.split(kv, [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1)
        split_with_sizes_16 = torch.ops.aten.split_with_sizes.default(_unsafe_view_24, [512, 64], -1);  _unsafe_view_24 = None
        getitem_99: "f32[8, 2048, 512]" = split_with_sizes_16[0]
        getitem_100: "f32[8, 2048, 64]" = split_with_sizes_16[1];  split_with_sizes_16 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:232 in forward, code: k_pe.unsqueeze(2), freqs_cis
        unsqueeze_9: "f32[8, 2048, 1, 64]" = torch.ops.aten.unsqueeze.default(getitem_100, 2);  getitem_100 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:141 in apply_rotary_emb, code: x = torch.view_as_complex(x.float().view(*x.shape[:-1], -1, 2))
        view_110: "f32[8, 2048, 1, 32, 2]" = torch.ops.aten.view.default(unsqueeze_9, [8, 2048, 1, -1, 2]);  unsqueeze_9 = None
        view_as_complex_11: "c64[8, 2048, 1, 32]" = torch.ops.aten.view_as_complex.default(view_110);  view_110 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:142 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(1, x.size(1), 1, x.size(-1))
        view_111: "c64[1, 2048, 1, 32]" = torch.ops.aten.view.default(primals_84, [1, 2048, 1, 32]);  primals_84 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:143 in apply_rotary_emb, code: y = torch.view_as_real(x * freqs_cis).flatten(3)
        mul_32: "c64[8, 2048, 1, 32]" = torch.ops.aten.mul.Tensor(view_as_complex_11, view_111);  view_as_complex_11 = None
        view_as_real_11: "f32[8, 2048, 1, 32, 2]" = torch.ops.aten.view_as_real.default(mul_32);  mul_32 = None
        view_112: "f32[8, 2048, 1, 64]" = torch.ops.aten.view.default(view_as_real_11, [8, 2048, 1, 64]);  view_as_real_11 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        _fused_rms_norm_16 = torch.ops.aten._fused_rms_norm.default(getitem_99, [512], primals_70, 1e-05)
        getitem_101: "f32[8, 2048, 512]" = _fused_rms_norm_16[0]
        getitem_102: "f32[8, 2048, 1]" = _fused_rms_norm_16[1];  _fused_rms_norm_16 = None
        detach_30: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(getitem_102);  getitem_102 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:235 in forward, code: kv = self.wkv_b(
        t_41: "f32[512, 4096]" = torch.ops.aten.t.default(primals_71);  primals_71 = None
        view_113: "f32[16384, 512]" = torch.ops.aten.view.default(getitem_101, [16384, 512]);  getitem_101 = None
        mm_41: "f32[16384, 4096]" = torch.ops.aten.mm.default(view_113, t_41)
        _unsafe_view_25: "f32[8, 2048, 4096]" = torch.ops.aten._unsafe_view.default(mm_41, [8, 2048, 4096]);  mm_41 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:238 in forward, code: kv = kv.view(bsz, seqlen, -1, self.qk_nope_head_dim + self.v_head_dim)
        view_114: "f32[8, 2048, 16, 256]" = torch.ops.aten.view.default(_unsafe_view_25, [8, 2048, -1, 256]);  _unsafe_view_25 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:239 in forward, code: k_nope, v = torch.split(kv, [self.qk_nope_head_dim, self.v_head_dim], dim=-1)
        split_with_sizes_17 = torch.ops.aten.split_with_sizes.default(view_114, [128, 128], -1);  view_114 = None
        getitem_103: "f32[8, 2048, 16, 128]" = split_with_sizes_17[0]
        getitem_104: "f32[8, 2048, 16, 128]" = split_with_sizes_17[1];  split_with_sizes_17 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:241 in forward, code: [k_nope, k_pe.expand(-1, -1, self.n_heads, -1)], dim=-1
        expand_9: "f32[8, 2048, 16, 64]" = torch.ops.aten.expand.default(view_112, [-1, -1, 16, -1]);  view_112 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:240 in forward, code: k = torch.cat(
        cat_15: "f32[8, 2048, 16, 192]" = torch.ops.aten.cat.default([getitem_103, expand_9], -1);  getitem_103 = expand_9 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:244 in forward, code: q = q.transpose(1, 2)  # (bsz, n_heads, seqlen, qk_head_dim)
        transpose_32: "f32[8, 16, 2048, 192]" = torch.ops.aten.transpose.int(cat_14, 1, 2);  cat_14 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:245 in forward, code: k = k.transpose(1, 2)  # (bsz, n_heads, seqlen, qk_head_dim)
        transpose_33: "f32[8, 16, 2048, 192]" = torch.ops.aten.transpose.int(cat_15, 1, 2);  cat_15 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:246 in forward, code: v = v.transpose(1, 2)  # (bsz, n_heads, seqlen, v_head_dim)
        transpose_34: "f32[8, 16, 2048, 128]" = torch.ops.aten.transpose.int(getitem_104, 1, 2);  getitem_104 = None
        
        # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1585 in flex_attention, code: out, lse, max_scores = flex_attention_hop(
        sdpa_score5 = self.sdpa_score5
        sdpa_mask5 = self.sdpa_mask5
        _tensor_constant0_5: "i32[8, 2048]" = self._tensor_constant0
        flex_attention_5 = torch.ops.higher_order.flex_attention(transpose_32, transpose_33, transpose_34, sdpa_score5, (2048, 2048, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, 128, 128, sdpa_mask5), 0.07216878364870322, {'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (_tensor_constant0_5,));  sdpa_score5 = sdpa_mask5 = _tensor_constant0_5 = None
        getitem_105: "f32[8, 16, 2048, 128]" = flex_attention_5[0]
        getitem_106: "f32[8, 16, 2048]" = flex_attention_5[1];  flex_attention_5 = None
        detach_31: "f32[8, 16, 2048, 128]" = torch.ops.aten.detach.default(getitem_105)
        detach_32: "f32[8, 16, 2048]" = torch.ops.aten.detach.default(getitem_106);  getitem_106 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:258 in forward, code: output = output.transpose(
        transpose_35: "f32[8, 2048, 16, 128]" = torch.ops.aten.transpose.int(getitem_105, 1, 2);  getitem_105 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:261 in forward, code: output = output.view(bsz, seqlen, -1)  # (bsz, seqlen, n_heads * v_head_dim)
        view_115: "f32[8, 2048, 2048]" = torch.ops.aten.view.default(transpose_35, [8, 2048, -1]);  transpose_35 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:262 in forward, code: return self.wo(output)  # (bsz, seqlen, dim)
        t_42: "f32[2048, 256]" = torch.ops.aten.t.default(primals_72);  primals_72 = None
        view_116: "f32[16384, 2048]" = torch.ops.aten.view.default(view_115, [16384, 2048]);  view_115 = None
        mm_42: "f32[16384, 256]" = torch.ops.aten.mm.default(view_116, t_42)
        _unsafe_view_26: "f32[8, 2048, 256]" = torch.ops.aten._unsafe_view.default(mm_42, [8, 2048, 256]);  mm_42 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:324 in forward, code: x = x + self.attention(self.attention_norm(x), freqs_cis, attention_masks)
        add_22: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(add_21, _unsafe_view_26);  _unsafe_view_26 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        _fused_rms_norm_17 = torch.ops.aten._fused_rms_norm.default(add_22, [256], primals_74, 1e-05)
        getitem_108: "f32[8, 2048, 256]" = _fused_rms_norm_17[0]
        getitem_109: "f32[8, 2048, 1]" = _fused_rms_norm_17[1];  _fused_rms_norm_17 = None
        detach_33: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(getitem_109);  getitem_109 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:415 in forward, code: x = x.view(-1, dim)
        view_117: "f32[16384, 256]" = torch.ops.aten.view.default(getitem_108, [-1, 256]);  getitem_108 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:247 in forward, code: scores = self.gate(x)
        t_43: "f32[256, 8]" = torch.ops.aten.t.default(primals_78);  primals_78 = None
        mm_43: "f32[16384, 8]" = torch.ops.aten.mm.default(view_117, t_43)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:253 in forward, code: scores = F.softmax(scores.to(torch.float32), dim=1)
        _softmax_4: "f32[16384, 8]" = torch.ops.aten._softmax.default(mm_43, 1, False);  mm_43 = None
        detach_34: "f32[16384, 8]" = torch.ops.aten.detach.default(_softmax_4)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:262 in forward, code: scores + expert_bias, k=self.top_k, dim=1
        add_23: "f32[16384, 8]" = torch.ops.aten.add.Tensor(_softmax_4, primals_93);  primals_93 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:261 in forward, code: _, selected_experts_indices = torch.topk(
        topk_4 = torch.ops.aten.topk.default(add_23, 3, 1);  add_23 = None
        getitem_111: "i64[16384, 3]" = topk_4[1];  topk_4 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:264 in forward, code: top_scores = scores.gather(dim=1, index=selected_experts_indices)
        gather_8: "f32[16384, 3]" = torch.ops.aten.gather.default(_softmax_4, 1, getitem_111);  _softmax_4 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:280 in forward, code: top_scores = top_scores * self.route_scale
        mul_33: "f32[16384, 3]" = torch.ops.aten.mul.Tensor(gather_8, 1.0);  gather_8 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:284 in forward, code: selected_experts_indices.view(-1),
        view_118: "i64[49152]" = torch.ops.aten.view.default(getitem_111, [-1])
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:283 in forward, code: num_tokens_per_expert = torch.histc(
        histc_8: "i64[8]" = torch.ops.aten.histc.default(view_118, 8, 0, 8);  view_118 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:431 in forward, code: self.tokens_per_expert.add_(num_tokens_per_expert)
        add_24: "f32[8]" = torch.ops.aten.add.Tensor(primals_94, histc_8);  primals_94 = histc_8 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:335 in forward, code: selected_experts_indices.view(-1),
        view_119: "i64[49152]" = torch.ops.aten.view.default(getitem_111, [-1])
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:334 in forward, code: num_tokens_per_expert = torch.histc(
        histc_9: "i64[8]" = torch.ops.aten.histc.default(view_119, 8, 0, 8);  view_119 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:344 in forward, code: selected_experts_indices.view(-1), stable=True
        view_120: "i64[49152]" = torch.ops.aten.view.default(getitem_111, [-1])
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:343 in forward, code: token_indices_experts_sorted = torch.argsort(
        sort_4 = torch.ops.aten.sort.stable(view_120, stable = True);  view_120 = None
        getitem_113: "i64[49152]" = sort_4[1];  sort_4 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:347 in forward, code: top_scores_experts_sorted = top_scores.view(-1)[token_indices_experts_sorted]
        view_121: "f32[49152]" = torch.ops.aten.view.default(mul_33, [-1]);  mul_33 = None
        index_8: "f32[49152]" = torch.ops.aten.index.Tensor(view_121, [getitem_113]);  view_121 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:348 in forward, code: token_indices_experts_sorted = token_indices_experts_sorted // self.top_k
        floor_divide_8: "i64[49152]" = torch.ops.aten.floor_divide.default(getitem_113, 3)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:448 in forward, code: token_indices_experts_sorted = token_indices_experts_sorted.reshape(
        view_122: "i64[49152, 1]" = torch.ops.aten.view.default(floor_divide_8, [-1, 1]);  floor_divide_8 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:450 in forward, code: ).expand(-1, dim)
        expand_10: "i64[49152, 256]" = torch.ops.aten.expand.default(view_122, [-1, 256]);  view_122 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:453 in forward, code: routed_input = torch.gather(x, dim=0, index=token_indices_experts_sorted)
        gather_9: "f32[49152, 256]" = torch.ops.aten.gather.default(view_117, 0, expand_10)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:174 in generate_permute_indices, code: torch.cumsum(tokens_per_expert_group, 0) - tokens_per_expert_group
        cumsum_12: "i64[8]" = torch.ops.aten.cumsum.default(histc_9, 0)
        sub_12: "i64[8]" = torch.ops.aten.sub.Tensor(cumsum_12, histc_9);  cumsum_12 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:178 in generate_permute_indices, code: total_tokens_per_expert = tokens_per_expert_group.view(num_ranks, -1).sum(0)
        view_123: "i64[1, 8]" = torch.ops.aten.view.default(histc_9, [1, -1])
        sum_5: "i64[8]" = torch.ops.aten.sum.dim_IntList(view_123, [0]);  view_123 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:181 in generate_permute_indices, code: total_tokens_per_expert = torch.clamp_min(total_tokens_per_expert, alignment)
        clamp_min_4: "i64[8]" = torch.ops.aten.clamp_min.default(sum_5, 8);  sum_5 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:184 in generate_permute_indices, code: m_sizes = ((total_tokens_per_expert + alignment - 1) // alignment * alignment).to(
        add_25: "i64[8]" = torch.ops.aten.add.Tensor(clamp_min_4, 8);  clamp_min_4 = None
        sub_13: "i64[8]" = torch.ops.aten.sub.Tensor(add_25, 1);  add_25 = None
        floor_divide_9: "i64[8]" = torch.ops.aten.floor_divide.default(sub_13, 8);  sub_13 = None
        mul_34: "i64[8]" = torch.ops.aten.mul.Tensor(floor_divide_9, 8);  floor_divide_9 = None
        _to_copy_32: "i32[8]" = torch.ops.aten._to_copy.default(mul_34, dtype = torch.int32);  mul_34 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:190 in generate_permute_indices, code: m_offsets = torch.cumsum(m_sizes, 0)
        cumsum_13: "i64[8]" = torch.ops.aten.cumsum.default(_to_copy_32, 0)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:191 in generate_permute_indices, code: write_offsets = m_offsets - m_sizes
        sub_14: "i64[8]" = torch.ops.aten.sub.Tensor(cumsum_13, _to_copy_32);  cumsum_13 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:80 in fill_indices_wrapper, code: permuted_indices = torch.full(
        full_4: "i32[49216]" = torch.ops.aten.full.default([49216], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/kernels.py:90 in fill_indices_wrapper, code: _fill_indices_kernel[grid](
        triton_kernel_wrapper_functional_proxy_4 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 4, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': histc_9, 'start_index_values_ptr': sub_12, 'write_offsets_ptr': sub_14, 'output_ptr': full_4}, tensors_to_clone = ['output_ptr']);  histc_9 = sub_12 = sub_14 = full_4 = None
        getitem_114: "i32[49216]" = triton_kernel_wrapper_functional_proxy_4['output_ptr'];  triton_kernel_wrapper_functional_proxy_4 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:55 in _permute, code: x = torch.vstack((x, x.new_zeros((x.shape[-1]))))
        new_zeros_64: "f32[256]" = torch.ops.aten.new_zeros.default(gather_9, [256], pin_memory = False)
        unsqueeze_10: "f32[1, 256]" = torch.ops.aten.unsqueeze.default(new_zeros_64, 0);  new_zeros_64 = None
        cat_16: "f32[49153, 256]" = torch.ops.aten.cat.default([gather_9, unsqueeze_10]);  gather_9 = unsqueeze_10 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:57 in _permute, code: x = x[permuted_indices, :]
        index_9: "f32[49216, 256]" = torch.ops.aten.index.Tensor(cat_16, [getitem_114]);  cat_16 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:114 in _run_experts_grouped_mm, code: offsets = torch.cumsum(num_tokens_per_expert, dim=0, dtype=torch.int32)
        cumsum_14: "i32[8]" = torch.ops.aten.cumsum.default(_to_copy_32, 0, dtype = torch.int32);  _to_copy_32 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:117 in _run_experts_grouped_mm, code: torch._grouped_mm(x.bfloat16(), w1.bfloat16().transpose(-2, -1), offs=offsets)
        _to_copy_34: "bf16[49216, 256]" = torch.ops.aten._to_copy.default(index_9, dtype = torch.bfloat16)
        _to_copy_35: "bf16[8, 256, 256]" = torch.ops.aten._to_copy.default(primals_75, dtype = torch.bfloat16);  primals_75 = None
        transpose_36: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_to_copy_35, -2, -1);  _to_copy_35 = None
        _grouped_mm_12: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(_to_copy_34, transpose_36, cumsum_14)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:116 in _run_experts_grouped_mm, code: h = F.silu(
        silu_9: "bf16[49216, 256]" = torch.ops.aten.silu.default(_grouped_mm_12)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:120 in _run_experts_grouped_mm, code: x.bfloat16(), w3.bfloat16().transpose(-2, -1), offs=offsets
        _to_copy_36: "bf16[49216, 256]" = torch.ops.aten._to_copy.default(index_9, dtype = torch.bfloat16);  index_9 = None
        _to_copy_37: "bf16[8, 256, 256]" = torch.ops.aten._to_copy.default(primals_77, dtype = torch.bfloat16);  primals_77 = None
        transpose_37: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_to_copy_37, -2, -1);  _to_copy_37 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:119 in _run_experts_grouped_mm, code: h = h * torch._grouped_mm(
        _grouped_mm_13: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(_to_copy_36, transpose_37, cumsum_14)
        mul_35: "bf16[49216, 256]" = torch.ops.aten.mul.Tensor(silu_9, _grouped_mm_13)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:122 in _run_experts_grouped_mm, code: out = torch._grouped_mm(h, w2.bfloat16().transpose(-2, -1), offs=offsets).type_as(x)
        _to_copy_38: "bf16[8, 256, 256]" = torch.ops.aten._to_copy.default(primals_76, dtype = torch.bfloat16);  primals_76 = None
        transpose_38: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_to_copy_38, -2, -1);  _to_copy_38 = None
        _grouped_mm_14: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(mul_35, transpose_38, cumsum_14)
        _to_copy_39: "f32[49216, 256]" = torch.ops.aten._to_copy.default(_grouped_mm_14, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  _grouped_mm_14 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:63 in _unpermute, code: out_unpermuted = out.new_empty(input_shape)
        new_empty_4: "f32[49153, 256]" = torch.ops.aten.new_empty.default(_to_copy_39, [49153, 256], pin_memory = False)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:64 in _unpermute, code: out_unpermuted[permuted_indices, :] = out
        index_put_4: "f32[49153, 256]" = torch.ops.aten.index_put.default(new_empty_4, [getitem_114], _to_copy_39);  new_empty_4 = _to_copy_39 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:62 in forward, code: return self.w2(F.silu(self.w1(x)) * self.w3(x))
        t_44: "f32[256, 512]" = torch.ops.aten.t.default(primals_79);  primals_79 = None
        mm_44: "f32[16384, 512]" = torch.ops.aten.mm.default(view_117, t_44)
        silu_10: "f32[16384, 512]" = torch.ops.aten.silu.default(mm_44)
        t_45: "f32[256, 512]" = torch.ops.aten.t.default(primals_81);  primals_81 = None
        mm_45: "f32[16384, 512]" = torch.ops.aten.mm.default(view_117, t_45)
        mul_36: "f32[16384, 512]" = torch.ops.aten.mul.Tensor(silu_10, mm_45)
        t_46: "f32[512, 256]" = torch.ops.aten.t.default(primals_80);  primals_80 = None
        mm_46: "f32[16384, 256]" = torch.ops.aten.mm.default(mul_36, t_46)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:475 in forward, code: * top_scores_experts_sorted.reshape(-1, 1)
        view_124: "f32[49152, 1]" = torch.ops.aten.view.default(index_8, [-1, 1]);  index_8 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:65 in _unpermute, code: out = out_unpermuted[:-1]
        slice_10: "f32[49152, 256]" = torch.ops.aten.slice.Tensor(index_put_4, 0, 0, -1);  index_put_4 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:474 in forward, code: routed_output.to(torch.float32)
        mul_37: "f32[49152, 256]" = torch.ops.aten.mul.Tensor(slice_10, view_124)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:478 in forward, code: out = out.scatter_add(
        scatter_add_4: "f32[16384, 256]" = torch.ops.aten.scatter_add.default(mm_46, 0, expand_10, mul_37);  mm_46 = mul_37 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:481 in forward, code: out = out.reshape(bs, slen, dim)
        view_125: "f32[8, 2048, 256]" = torch.ops.aten.view.default(scatter_add_4, [8, 2048, 256]);  scatter_add_4 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:326 in forward, code: x = x + self.moe(self.ffn_norm(x))
        add_26: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(add_22, view_125);  view_125 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        _fused_rms_norm_18 = torch.ops.aten._fused_rms_norm.default(add_26, [256], primals_82, None)
        getitem_115: "f32[8, 2048, 256]" = _fused_rms_norm_18[0]
        getitem_116: "f32[8, 2048, 1]" = _fused_rms_norm_18[1];  _fused_rms_norm_18 = None
        detach_35: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(getitem_116);  getitem_116 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:433 in forward, code: output = self.output(h) if self.output is not None else h
        t_47: "f32[256, 2048]" = torch.ops.aten.t.default(primals_83);  primals_83 = None
        view_126: "f32[16384, 256]" = torch.ops.aten.view.default(getitem_115, [16384, 256]);  getitem_115 = None
        mm_47: "f32[16384, 2048]" = torch.ops.aten.mm.default(view_126, t_47)
        _unsafe_view_27: "f32[8, 2048, 2048]" = torch.ops.aten._unsafe_view.default(mm_47, [8, 2048, 2048]);  mm_47 = None
        view_127: "f32[16384, 2048]" = torch.ops.aten.view.default(tangents_1, [16384, 2048]);  tangents_1 = None
        t_48: "f32[2048, 16384]" = torch.ops.aten.t.default(view_127)
        mm_48: "f32[2048, 256]" = torch.ops.aten.mm.default(t_48, view_126);  t_48 = view_126 = None
        t_49: "f32[256, 2048]" = torch.ops.aten.t.default(mm_48);  mm_48 = None
        t_50: "f32[2048, 256]" = torch.ops.aten.t.default(t_47);  t_47 = None
        mm_49: "f32[16384, 256]" = torch.ops.aten.mm.default(view_127, t_50);  view_127 = t_50 = None
        view_128: "f32[8, 2048, 256]" = torch.ops.aten.view.default(mm_49, [8, 2048, 256]);  mm_49 = None
        t_51: "f32[2048, 256]" = torch.ops.aten.t.default(t_49);  t_49 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        detach_36: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(detach_35);  detach_35 = None
        _fused_rms_norm_backward = torch.ops.aten._fused_rms_norm_backward.default(view_128, add_26, [256], detach_36, primals_82, [True, True]);  view_128 = add_26 = detach_36 = primals_82 = None
        getitem_117: "f32[8, 2048, 256]" = _fused_rms_norm_backward[0]
        getitem_118: "f32[256]" = _fused_rms_norm_backward[1];  _fused_rms_norm_backward = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:481 in forward, code: out = out.reshape(bs, slen, dim)
        view_129: "f32[16384, 256]" = torch.ops.aten.view.default(getitem_117, [16384, 256])
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:478 in forward, code: out = out.scatter_add(
        gather_10: "f32[49152, 256]" = torch.ops.aten.gather.default(view_129, 0, expand_10)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:474 in forward, code: routed_output.to(torch.float32)
        mul_38: "f32[49152, 256]" = torch.ops.aten.mul.Tensor(gather_10, slice_10);  slice_10 = None
        mul_39: "f32[49152, 256]" = torch.ops.aten.mul.Tensor(gather_10, view_124);  gather_10 = view_124 = None
        sum_6: "f32[49152, 1]" = torch.ops.aten.sum.dim_IntList(mul_38, [1], True);  mul_38 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:475 in forward, code: * top_scores_experts_sorted.reshape(-1, 1)
        view_130: "f32[49152]" = torch.ops.aten.view.default(sum_6, [49152]);  sum_6 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:62 in forward, code: return self.w2(F.silu(self.w1(x)) * self.w3(x))
        t_52: "f32[256, 16384]" = torch.ops.aten.t.default(view_129)
        mm_50: "f32[256, 512]" = torch.ops.aten.mm.default(t_52, mul_36);  t_52 = mul_36 = None
        t_53: "f32[512, 256]" = torch.ops.aten.t.default(mm_50);  mm_50 = None
        t_54: "f32[256, 512]" = torch.ops.aten.t.default(t_46);  t_46 = None
        mm_51: "f32[16384, 512]" = torch.ops.aten.mm.default(view_129, t_54);  view_129 = t_54 = None
        t_55: "f32[256, 512]" = torch.ops.aten.t.default(t_53);  t_53 = None
        mul_40: "f32[16384, 512]" = torch.ops.aten.mul.Tensor(mm_51, silu_10);  silu_10 = None
        mul_41: "f32[16384, 512]" = torch.ops.aten.mul.Tensor(mm_51, mm_45);  mm_51 = mm_45 = None
        t_56: "f32[512, 16384]" = torch.ops.aten.t.default(mul_40)
        mm_52: "f32[512, 256]" = torch.ops.aten.mm.default(t_56, view_117);  t_56 = None
        t_57: "f32[256, 512]" = torch.ops.aten.t.default(mm_52);  mm_52 = None
        t_58: "f32[512, 256]" = torch.ops.aten.t.default(t_45);  t_45 = None
        mm_53: "f32[16384, 256]" = torch.ops.aten.mm.default(mul_40, t_58);  mul_40 = t_58 = None
        t_59: "f32[512, 256]" = torch.ops.aten.t.default(t_57);  t_57 = None
        silu_backward: "f32[16384, 512]" = torch.ops.aten.silu_backward.default(mul_41, mm_44);  mul_41 = mm_44 = None
        t_60: "f32[512, 16384]" = torch.ops.aten.t.default(silu_backward)
        mm_54: "f32[512, 256]" = torch.ops.aten.mm.default(t_60, view_117);  t_60 = None
        t_61: "f32[256, 512]" = torch.ops.aten.t.default(mm_54);  mm_54 = None
        t_62: "f32[512, 256]" = torch.ops.aten.t.default(t_44);  t_44 = None
        mm_55: "f32[16384, 256]" = torch.ops.aten.mm.default(silu_backward, t_62);  silu_backward = t_62 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:62 in forward, code: return self.w2(F.silu(self.w1(x)) * self.w3(x))
        add_27: "f32[16384, 256]" = torch.ops.aten.add.Tensor(mm_53, mm_55);  mm_53 = mm_55 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:62 in forward, code: return self.w2(F.silu(self.w1(x)) * self.w3(x))
        t_63: "f32[512, 256]" = torch.ops.aten.t.default(t_61);  t_61 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:65 in _unpermute, code: out = out_unpermuted[:-1]
        slice_backward: "f32[49153, 256]" = torch.ops.aten.slice_backward.default(mul_39, [49153, 256], 0, 0, -1, 1);  mul_39 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:64 in _unpermute, code: out_unpermuted[permuted_indices, :] = out
        index_10: "f32[49216, 256]" = torch.ops.aten.index.Tensor(slice_backward, [getitem_114]);  slice_backward = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:122 in _run_experts_grouped_mm, code: out = torch._grouped_mm(h, w2.bfloat16().transpose(-2, -1), offs=offsets).type_as(x)
        _to_copy_40: "bf16[49216, 256]" = torch.ops.aten._to_copy.default(index_10, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0));  index_10 = None
        transpose_39: "bf16[256, 49216]" = torch.ops.aten.transpose.int(_to_copy_40, -2, -1)
        _grouped_mm_15: "bf16[8, 256, 256]" = torch.ops.aten._grouped_mm.default(transpose_39, mul_35, cumsum_14);  transpose_39 = mul_35 = None
        transpose_40: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_grouped_mm_15, -2, -1);  _grouped_mm_15 = None
        transpose_41: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_38, -2, -1);  transpose_38 = None
        _grouped_mm_16: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(_to_copy_40, transpose_41, cumsum_14);  _to_copy_40 = transpose_41 = None
        transpose_42: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_40, -2, -1);  transpose_40 = None
        _to_copy_41: "f32[8, 256, 256]" = torch.ops.aten._to_copy.default(transpose_42, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  transpose_42 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:119 in _run_experts_grouped_mm, code: h = h * torch._grouped_mm(
        mul_42: "bf16[49216, 256]" = torch.ops.aten.mul.Tensor(_grouped_mm_16, silu_9);  silu_9 = None
        mul_43: "bf16[49216, 256]" = torch.ops.aten.mul.Tensor(_grouped_mm_16, _grouped_mm_13);  _grouped_mm_16 = _grouped_mm_13 = None
        transpose_43: "bf16[256, 49216]" = torch.ops.aten.transpose.int(mul_42, -2, -1)
        _grouped_mm_17: "bf16[8, 256, 256]" = torch.ops.aten._grouped_mm.default(transpose_43, _to_copy_36, cumsum_14);  transpose_43 = _to_copy_36 = None
        transpose_44: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_grouped_mm_17, -2, -1);  _grouped_mm_17 = None
        transpose_45: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_37, -2, -1);  transpose_37 = None
        _grouped_mm_18: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(mul_42, transpose_45, cumsum_14);  mul_42 = transpose_45 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:120 in _run_experts_grouped_mm, code: x.bfloat16(), w3.bfloat16().transpose(-2, -1), offs=offsets
        transpose_46: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_44, -2, -1);  transpose_44 = None
        _to_copy_42: "f32[8, 256, 256]" = torch.ops.aten._to_copy.default(transpose_46, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  transpose_46 = None
        _to_copy_43: "f32[49216, 256]" = torch.ops.aten._to_copy.default(_grouped_mm_18, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  _grouped_mm_18 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:116 in _run_experts_grouped_mm, code: h = F.silu(
        silu_backward_1: "bf16[49216, 256]" = torch.ops.aten.silu_backward.default(mul_43, _grouped_mm_12);  mul_43 = _grouped_mm_12 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:117 in _run_experts_grouped_mm, code: torch._grouped_mm(x.bfloat16(), w1.bfloat16().transpose(-2, -1), offs=offsets)
        transpose_47: "bf16[256, 49216]" = torch.ops.aten.transpose.int(silu_backward_1, -2, -1)
        _grouped_mm_19: "bf16[8, 256, 256]" = torch.ops.aten._grouped_mm.default(transpose_47, _to_copy_34, cumsum_14);  transpose_47 = _to_copy_34 = None
        transpose_48: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_grouped_mm_19, -2, -1);  _grouped_mm_19 = None
        transpose_49: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_36, -2, -1);  transpose_36 = None
        _grouped_mm_20: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(silu_backward_1, transpose_49, cumsum_14);  silu_backward_1 = transpose_49 = cumsum_14 = None
        transpose_50: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_48, -2, -1);  transpose_48 = None
        _to_copy_44: "f32[8, 256, 256]" = torch.ops.aten._to_copy.default(transpose_50, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  transpose_50 = None
        _to_copy_45: "f32[49216, 256]" = torch.ops.aten._to_copy.default(_grouped_mm_20, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  _grouped_mm_20 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:117 in _run_experts_grouped_mm, code: torch._grouped_mm(x.bfloat16(), w1.bfloat16().transpose(-2, -1), offs=offsets)
        add_28: "f32[49216, 256]" = torch.ops.aten.add.Tensor(_to_copy_43, _to_copy_45);  _to_copy_43 = _to_copy_45 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:57 in _permute, code: x = x[permuted_indices, :]
        new_zeros_65: "f32[49153, 256]" = torch.ops.aten.new_zeros.default(add_28, [49153, 256], dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        index_put_5: "f32[49153, 256]" = torch.ops.aten.index_put.default(new_zeros_65, [getitem_114], add_28, True);  new_zeros_65 = getitem_114 = add_28 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:55 in _permute, code: x = torch.vstack((x, x.new_zeros((x.shape[-1]))))
        slice_11: "f32[49152, 256]" = torch.ops.aten.slice.Tensor(index_put_5, 0, 0, 49152);  index_put_5 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:453 in forward, code: routed_input = torch.gather(x, dim=0, index=token_indices_experts_sorted)
        new_zeros_66: "f32[16384, 256]" = torch.ops.aten.new_zeros.default(slice_11, [16384, 256])
        scatter_add_5: "f32[16384, 256]" = torch.ops.aten.scatter_add.default(new_zeros_66, 0, expand_10, slice_11);  new_zeros_66 = expand_10 = slice_11 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:453 in forward, code: routed_input = torch.gather(x, dim=0, index=token_indices_experts_sorted)
        add_29: "f32[16384, 256]" = torch.ops.aten.add.Tensor(add_27, scatter_add_5);  add_27 = scatter_add_5 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:347 in forward, code: top_scores_experts_sorted = top_scores.view(-1)[token_indices_experts_sorted]
        new_zeros_67: "f32[49152]" = torch.ops.aten.new_zeros.default(view_130, [49152], dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        index_put_6: "f32[49152]" = torch.ops.aten.index_put.default(new_zeros_67, [getitem_113], view_130, True);  new_zeros_67 = getitem_113 = view_130 = None
        view_131: "f32[16384, 3]" = torch.ops.aten.view.default(index_put_6, [16384, 3]);  index_put_6 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:280 in forward, code: top_scores = top_scores * self.route_scale
        mul_44: "f32[16384, 3]" = torch.ops.aten.mul.Tensor(view_131, 1.0);  view_131 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:264 in forward, code: top_scores = scores.gather(dim=1, index=selected_experts_indices)
        new_zeros_68: "f32[16384, 8]" = torch.ops.aten.new_zeros.default(mul_44, [16384, 8])
        scatter_add_6: "f32[16384, 8]" = torch.ops.aten.scatter_add.default(new_zeros_68, 1, getitem_111, mul_44);  new_zeros_68 = getitem_111 = mul_44 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:253 in forward, code: scores = F.softmax(scores.to(torch.float32), dim=1)
        detach_37: "f32[16384, 8]" = torch.ops.aten.detach.default(detach_34);  detach_34 = None
        _softmax_backward_data: "f32[16384, 8]" = torch.ops.aten._softmax_backward_data.default(scatter_add_6, detach_37, 1, torch.float32);  scatter_add_6 = detach_37 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:247 in forward, code: scores = self.gate(x)
        t_64: "f32[8, 16384]" = torch.ops.aten.t.default(_softmax_backward_data)
        mm_56: "f32[8, 256]" = torch.ops.aten.mm.default(t_64, view_117);  t_64 = view_117 = None
        t_65: "f32[256, 8]" = torch.ops.aten.t.default(mm_56);  mm_56 = None
        t_66: "f32[8, 256]" = torch.ops.aten.t.default(t_43);  t_43 = None
        mm_57: "f32[16384, 256]" = torch.ops.aten.mm.default(_softmax_backward_data, t_66);  _softmax_backward_data = t_66 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:247 in forward, code: scores = self.gate(x)
        add_30: "f32[16384, 256]" = torch.ops.aten.add.Tensor(add_29, mm_57);  add_29 = mm_57 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:247 in forward, code: scores = self.gate(x)
        t_67: "f32[8, 256]" = torch.ops.aten.t.default(t_65);  t_65 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:415 in forward, code: x = x.view(-1, dim)
        view_132: "f32[8, 2048, 256]" = torch.ops.aten.view.default(add_30, [8, 2048, 256]);  add_30 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        detach_38: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(detach_33);  detach_33 = None
        _fused_rms_norm_backward_1 = torch.ops.aten._fused_rms_norm_backward.default(view_132, add_22, [256], detach_38, primals_74, [True, True]);  view_132 = add_22 = detach_38 = primals_74 = None
        getitem_119: "f32[8, 2048, 256]" = _fused_rms_norm_backward_1[0]
        getitem_120: "f32[256]" = _fused_rms_norm_backward_1[1];  _fused_rms_norm_backward_1 = None
        add_31: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(getitem_117, getitem_119);  getitem_117 = getitem_119 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:262 in forward, code: return self.wo(output)  # (bsz, seqlen, dim)
        view_133: "f32[16384, 256]" = torch.ops.aten.view.default(add_31, [16384, 256])
        t_68: "f32[256, 16384]" = torch.ops.aten.t.default(view_133)
        mm_58: "f32[256, 2048]" = torch.ops.aten.mm.default(t_68, view_116);  t_68 = view_116 = None
        t_69: "f32[2048, 256]" = torch.ops.aten.t.default(mm_58);  mm_58 = None
        t_70: "f32[256, 2048]" = torch.ops.aten.t.default(t_42);  t_42 = None
        mm_59: "f32[16384, 2048]" = torch.ops.aten.mm.default(view_133, t_70);  view_133 = t_70 = None
        view_134: "f32[8, 2048, 2048]" = torch.ops.aten.view.default(mm_59, [8, 2048, 2048]);  mm_59 = None
        t_71: "f32[256, 2048]" = torch.ops.aten.t.default(t_69);  t_69 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:261 in forward, code: output = output.view(bsz, seqlen, -1)  # (bsz, seqlen, n_heads * v_head_dim)
        view_135: "f32[8, 2048, 16, 128]" = torch.ops.aten.view.default(view_134, [8, 2048, 16, 128]);  view_134 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:258 in forward, code: output = output.transpose(
        transpose_51: "f32[8, 16, 2048, 128]" = torch.ops.aten.transpose.int(view_135, 1, 2);  view_135 = None
        
        # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1585 in flex_attention, code: out, lse, max_scores = flex_attention_hop(
        zeros: "f32[8, 16, 2048]" = torch.ops.aten.zeros.default([8, 16, 2048], dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        detach_39: "f32[8, 16, 2048, 128]" = torch.ops.aten.detach.default(detach_31);  detach_31 = None
        detach_40: "f32[8, 16, 2048]" = torch.ops.aten.detach.default(detach_32);  detach_32 = None
        fw_graph0 = self.fw_graph0
        joint_graph0 = self.joint_graph0
        mask_graph0 = self.mask_graph0
        _tensor_constant0_6: "i32[8, 2048]" = self._tensor_constant0
        flex_attention_backward = torch.ops.higher_order.flex_attention_backward(transpose_32, transpose_33, transpose_34, detach_39, detach_40, transpose_51, zeros, fw_graph0, joint_graph0, (2048, 2048, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, 128, 128, mask_graph0), 0.07216878364870322, {'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (_tensor_constant0_6,));  transpose_32 = transpose_33 = transpose_34 = detach_39 = detach_40 = transpose_51 = zeros = fw_graph0 = joint_graph0 = mask_graph0 = _tensor_constant0_6 = None
        getitem_121: "f32[8, 16, 2048, 192]" = flex_attention_backward[0]
        getitem_122: "f32[8, 16, 2048, 192]" = flex_attention_backward[1]
        getitem_123: "f32[8, 16, 2048, 128]" = flex_attention_backward[2];  flex_attention_backward = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:246 in forward, code: v = v.transpose(1, 2)  # (bsz, n_heads, seqlen, v_head_dim)
        transpose_52: "f32[8, 2048, 16, 128]" = torch.ops.aten.transpose.int(getitem_123, 1, 2);  getitem_123 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:245 in forward, code: k = k.transpose(1, 2)  # (bsz, n_heads, seqlen, qk_head_dim)
        transpose_53: "f32[8, 2048, 16, 192]" = torch.ops.aten.transpose.int(getitem_122, 1, 2);  getitem_122 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:244 in forward, code: q = q.transpose(1, 2)  # (bsz, n_heads, seqlen, qk_head_dim)
        transpose_54: "f32[8, 2048, 16, 192]" = torch.ops.aten.transpose.int(getitem_121, 1, 2);  getitem_121 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:240 in forward, code: k = torch.cat(
        slice_13: "f32[8, 2048, 16, 128]" = torch.ops.aten.slice.Tensor(transpose_53, 3, 0, 128)
        slice_14: "f32[8, 2048, 16, 64]" = torch.ops.aten.slice.Tensor(transpose_53, 3, 128, 192);  transpose_53 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:241 in forward, code: [k_nope, k_pe.expand(-1, -1, self.n_heads, -1)], dim=-1
        sum_7: "f32[8, 2048, 1, 64]" = torch.ops.aten.sum.dim_IntList(slice_14, [2], True);  slice_14 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:239 in forward, code: k_nope, v = torch.split(kv, [self.qk_nope_head_dim, self.v_head_dim], dim=-1)
        cat_17: "f32[8, 2048, 16, 256]" = torch.ops.aten.cat.default([slice_13, transpose_52], 3);  slice_13 = transpose_52 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:238 in forward, code: kv = kv.view(bsz, seqlen, -1, self.qk_nope_head_dim + self.v_head_dim)
        view_136: "f32[8, 2048, 4096]" = torch.ops.aten.view.default(cat_17, [8, 2048, 4096]);  cat_17 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:235 in forward, code: kv = self.wkv_b(
        view_137: "f32[16384, 4096]" = torch.ops.aten.view.default(view_136, [16384, 4096]);  view_136 = None
        t_72: "f32[4096, 16384]" = torch.ops.aten.t.default(view_137)
        mm_60: "f32[4096, 512]" = torch.ops.aten.mm.default(t_72, view_113);  t_72 = view_113 = None
        t_73: "f32[512, 4096]" = torch.ops.aten.t.default(mm_60);  mm_60 = None
        t_74: "f32[4096, 512]" = torch.ops.aten.t.default(t_41);  t_41 = None
        mm_61: "f32[16384, 512]" = torch.ops.aten.mm.default(view_137, t_74);  view_137 = t_74 = None
        view_138: "f32[8, 2048, 512]" = torch.ops.aten.view.default(mm_61, [8, 2048, 512]);  mm_61 = None
        t_75: "f32[4096, 512]" = torch.ops.aten.t.default(t_73);  t_73 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        detach_41: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(detach_30);  detach_30 = None
        _fused_rms_norm_backward_2 = torch.ops.aten._fused_rms_norm_backward.default(view_138, getitem_99, [512], detach_41, primals_70, [True, True]);  view_138 = getitem_99 = detach_41 = primals_70 = None
        getitem_125: "f32[8, 2048, 512]" = _fused_rms_norm_backward_2[0]
        getitem_126: "f32[512]" = _fused_rms_norm_backward_2[1];  _fused_rms_norm_backward_2 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:143 in apply_rotary_emb, code: y = torch.view_as_real(x * freqs_cis).flatten(3)
        view_139: "f32[8, 2048, 1, 32, 2]" = torch.ops.aten.view.default(sum_7, [8, 2048, 1, 32, 2]);  sum_7 = None
        view_as_complex_12: "c64[8, 2048, 1, 32]" = torch.ops.aten.view_as_complex.default(view_139);  view_139 = None
        _conj: "c64[1, 2048, 1, 32]" = torch.ops.aten._conj.default(view_111);  view_111 = None
        clone: "c64[1, 2048, 1, 32]" = torch.ops.aten.clone.default(_conj);  _conj = None
        mul_45: "c64[8, 2048, 1, 32]" = torch.ops.aten.mul.Tensor(view_as_complex_12, clone);  view_as_complex_12 = clone = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:141 in apply_rotary_emb, code: x = torch.view_as_complex(x.float().view(*x.shape[:-1], -1, 2))
        view_as_real_12: "f32[8, 2048, 1, 32, 2]" = torch.ops.aten.view_as_real.default(mul_45);  mul_45 = None
        view_140: "f32[8, 2048, 1, 64]" = torch.ops.aten.view.default(view_as_real_12, [8, 2048, 1, 64]);  view_as_real_12 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:232 in forward, code: k_pe.unsqueeze(2), freqs_cis
        squeeze: "f32[8, 2048, 64]" = torch.ops.aten.squeeze.dim(view_140, 2);  view_140 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:229 in forward, code: kv, k_pe = torch.split(kv, [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1)
        cat_18: "f32[8, 2048, 576]" = torch.ops.aten.cat.default([getitem_125, squeeze], 2);  getitem_125 = squeeze = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:228 in forward, code: kv = self.wkv_a(x)  # (bsz, seqlen, kv_lora_rank + qk_rope_head_dim)
        view_141: "f32[16384, 576]" = torch.ops.aten.view.default(cat_18, [16384, 576]);  cat_18 = None
        t_76: "f32[576, 16384]" = torch.ops.aten.t.default(view_141)
        mm_62: "f32[576, 256]" = torch.ops.aten.mm.default(t_76, view_109);  t_76 = view_109 = None
        t_77: "f32[256, 576]" = torch.ops.aten.t.default(mm_62);  mm_62 = None
        t_78: "f32[576, 256]" = torch.ops.aten.t.default(t_40);  t_40 = None
        mm_63: "f32[16384, 256]" = torch.ops.aten.mm.default(view_141, t_78);  view_141 = t_78 = None
        view_142: "f32[8, 2048, 256]" = torch.ops.aten.view.default(mm_63, [8, 2048, 256]);  mm_63 = None
        t_79: "f32[576, 256]" = torch.ops.aten.t.default(t_77);  t_77 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:225 in forward, code: q = torch.cat([q_nope, q_pe], dim=-1)  # (bsz, seqlen, n_heads, qk_head_dim)
        slice_15: "f32[8, 2048, 16, 128]" = torch.ops.aten.slice.Tensor(transpose_54, 3, 0, 128)
        slice_16: "f32[8, 2048, 16, 64]" = torch.ops.aten.slice.Tensor(transpose_54, 3, 128, 192);  transpose_54 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:143 in apply_rotary_emb, code: y = torch.view_as_real(x * freqs_cis).flatten(3)
        view_143: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.view.default(slice_16, [8, 2048, 16, 32, 2]);  slice_16 = None
        clone_1: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.clone.default(view_143, memory_format = torch.contiguous_format);  view_143 = None
        view_as_complex_13: "c64[8, 2048, 16, 32]" = torch.ops.aten.view_as_complex.default(clone_1);  clone_1 = None
        _conj_1: "c64[1, 2048, 1, 32]" = torch.ops.aten._conj.default(view_107);  view_107 = None
        clone_2: "c64[1, 2048, 1, 32]" = torch.ops.aten.clone.default(_conj_1);  _conj_1 = None
        mul_46: "c64[8, 2048, 16, 32]" = torch.ops.aten.mul.Tensor(view_as_complex_13, clone_2);  view_as_complex_13 = clone_2 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:141 in apply_rotary_emb, code: x = torch.view_as_complex(x.float().view(*x.shape[:-1], -1, 2))
        view_as_real_13: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.view_as_real.default(mul_46);  mul_46 = None
        view_144: "f32[8, 2048, 16, 64]" = torch.ops.aten.view.default(view_as_real_13, [8, 2048, 16, 64]);  view_as_real_13 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:221 in forward, code: q_nope, q_pe = torch.split(
        cat_19: "f32[8, 2048, 16, 192]" = torch.ops.aten.cat.default([slice_15, view_144], 3);  slice_15 = view_144 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:220 in forward, code: q = q.view(bsz, seqlen, -1, self.qk_head_dim)
        view_145: "f32[8, 2048, 3072]" = torch.ops.aten.view.default(cat_19, [8, 2048, 3072]);  cat_19 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:213 in forward, code: q = self.wq(x)  # (bsz, seqlen, n_heads * qk_head_dim)
        view_146: "f32[16384, 3072]" = torch.ops.aten.view.default(view_145, [16384, 3072]);  view_145 = None
        t_80: "f32[3072, 16384]" = torch.ops.aten.t.default(view_146)
        mm_64: "f32[3072, 256]" = torch.ops.aten.mm.default(t_80, view_104);  t_80 = view_104 = None
        t_81: "f32[256, 3072]" = torch.ops.aten.t.default(mm_64);  mm_64 = None
        t_82: "f32[3072, 256]" = torch.ops.aten.t.default(t_39);  t_39 = None
        mm_65: "f32[16384, 256]" = torch.ops.aten.mm.default(view_146, t_82);  view_146 = t_82 = None
        view_147: "f32[8, 2048, 256]" = torch.ops.aten.view.default(mm_65, [8, 2048, 256]);  mm_65 = None
        add_32: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(view_142, view_147);  view_142 = view_147 = None
        t_83: "f32[3072, 256]" = torch.ops.aten.t.default(t_81);  t_81 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        detach_42: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(detach_29);  detach_29 = None
        _fused_rms_norm_backward_3 = torch.ops.aten._fused_rms_norm_backward.default(add_32, add_21, [256], detach_42, primals_73, [True, True]);  add_32 = add_21 = detach_42 = primals_73 = None
        getitem_127: "f32[8, 2048, 256]" = _fused_rms_norm_backward_3[0]
        getitem_128: "f32[256]" = _fused_rms_norm_backward_3[1];  _fused_rms_norm_backward_3 = None
        add_33: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(add_31, getitem_127);  add_31 = getitem_127 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:481 in forward, code: out = out.reshape(bs, slen, dim)
        view_148: "f32[16384, 256]" = torch.ops.aten.view.default(add_33, [16384, 256])
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:478 in forward, code: out = out.scatter_add(
        gather_11: "f32[49152, 256]" = torch.ops.aten.gather.default(view_148, 0, expand_8)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:474 in forward, code: routed_output.to(torch.float32)
        mul_47: "f32[49152, 256]" = torch.ops.aten.mul.Tensor(gather_11, slice_8);  slice_8 = None
        mul_48: "f32[49152, 256]" = torch.ops.aten.mul.Tensor(gather_11, view_102);  gather_11 = view_102 = None
        sum_8: "f32[49152, 1]" = torch.ops.aten.sum.dim_IntList(mul_47, [1], True);  mul_47 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:475 in forward, code: * top_scores_experts_sorted.reshape(-1, 1)
        view_149: "f32[49152]" = torch.ops.aten.view.default(sum_8, [49152]);  sum_8 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:62 in forward, code: return self.w2(F.silu(self.w1(x)) * self.w3(x))
        t_84: "f32[256, 16384]" = torch.ops.aten.t.default(view_148)
        mm_66: "f32[256, 512]" = torch.ops.aten.mm.default(t_84, mul_29);  t_84 = mul_29 = None
        t_85: "f32[512, 256]" = torch.ops.aten.t.default(mm_66);  mm_66 = None
        t_86: "f32[256, 512]" = torch.ops.aten.t.default(t_38);  t_38 = None
        mm_67: "f32[16384, 512]" = torch.ops.aten.mm.default(view_148, t_86);  view_148 = t_86 = None
        t_87: "f32[256, 512]" = torch.ops.aten.t.default(t_85);  t_85 = None
        mul_49: "f32[16384, 512]" = torch.ops.aten.mul.Tensor(mm_67, silu_8);  silu_8 = None
        mul_50: "f32[16384, 512]" = torch.ops.aten.mul.Tensor(mm_67, mm_37);  mm_67 = mm_37 = None
        t_88: "f32[512, 16384]" = torch.ops.aten.t.default(mul_49)
        mm_68: "f32[512, 256]" = torch.ops.aten.mm.default(t_88, view_95);  t_88 = None
        t_89: "f32[256, 512]" = torch.ops.aten.t.default(mm_68);  mm_68 = None
        t_90: "f32[512, 256]" = torch.ops.aten.t.default(t_37);  t_37 = None
        mm_69: "f32[16384, 256]" = torch.ops.aten.mm.default(mul_49, t_90);  mul_49 = t_90 = None
        t_91: "f32[512, 256]" = torch.ops.aten.t.default(t_89);  t_89 = None
        silu_backward_2: "f32[16384, 512]" = torch.ops.aten.silu_backward.default(mul_50, mm_36);  mul_50 = mm_36 = None
        t_92: "f32[512, 16384]" = torch.ops.aten.t.default(silu_backward_2)
        mm_70: "f32[512, 256]" = torch.ops.aten.mm.default(t_92, view_95);  t_92 = None
        t_93: "f32[256, 512]" = torch.ops.aten.t.default(mm_70);  mm_70 = None
        t_94: "f32[512, 256]" = torch.ops.aten.t.default(t_36);  t_36 = None
        mm_71: "f32[16384, 256]" = torch.ops.aten.mm.default(silu_backward_2, t_94);  silu_backward_2 = t_94 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:62 in forward, code: return self.w2(F.silu(self.w1(x)) * self.w3(x))
        add_34: "f32[16384, 256]" = torch.ops.aten.add.Tensor(mm_69, mm_71);  mm_69 = mm_71 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:62 in forward, code: return self.w2(F.silu(self.w1(x)) * self.w3(x))
        t_95: "f32[512, 256]" = torch.ops.aten.t.default(t_93);  t_93 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:65 in _unpermute, code: out = out_unpermuted[:-1]
        slice_backward_1: "f32[49153, 256]" = torch.ops.aten.slice_backward.default(mul_48, [49153, 256], 0, 0, -1, 1);  mul_48 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:64 in _unpermute, code: out_unpermuted[permuted_indices, :] = out
        index_11: "f32[49216, 256]" = torch.ops.aten.index.Tensor(slice_backward_1, [getitem_94]);  slice_backward_1 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:122 in _run_experts_grouped_mm, code: out = torch._grouped_mm(h, w2.bfloat16().transpose(-2, -1), offs=offsets).type_as(x)
        _to_copy_46: "bf16[49216, 256]" = torch.ops.aten._to_copy.default(index_11, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0));  index_11 = None
        transpose_55: "bf16[256, 49216]" = torch.ops.aten.transpose.int(_to_copy_46, -2, -1)
        _grouped_mm_21: "bf16[8, 256, 256]" = torch.ops.aten._grouped_mm.default(transpose_55, mul_28, cumsum_11);  transpose_55 = mul_28 = None
        transpose_56: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_grouped_mm_21, -2, -1);  _grouped_mm_21 = None
        transpose_57: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_31, -2, -1);  transpose_31 = None
        _grouped_mm_22: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(_to_copy_46, transpose_57, cumsum_11);  _to_copy_46 = transpose_57 = None
        transpose_58: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_56, -2, -1);  transpose_56 = None
        _to_copy_47: "f32[8, 256, 256]" = torch.ops.aten._to_copy.default(transpose_58, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  transpose_58 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:119 in _run_experts_grouped_mm, code: h = h * torch._grouped_mm(
        mul_51: "bf16[49216, 256]" = torch.ops.aten.mul.Tensor(_grouped_mm_22, silu_7);  silu_7 = None
        mul_52: "bf16[49216, 256]" = torch.ops.aten.mul.Tensor(_grouped_mm_22, _grouped_mm_10);  _grouped_mm_22 = _grouped_mm_10 = None
        transpose_59: "bf16[256, 49216]" = torch.ops.aten.transpose.int(mul_51, -2, -1)
        _grouped_mm_23: "bf16[8, 256, 256]" = torch.ops.aten._grouped_mm.default(transpose_59, _to_copy_28, cumsum_11);  transpose_59 = _to_copy_28 = None
        transpose_60: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_grouped_mm_23, -2, -1);  _grouped_mm_23 = None
        transpose_61: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_30, -2, -1);  transpose_30 = None
        _grouped_mm_24: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(mul_51, transpose_61, cumsum_11);  mul_51 = transpose_61 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:120 in _run_experts_grouped_mm, code: x.bfloat16(), w3.bfloat16().transpose(-2, -1), offs=offsets
        transpose_62: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_60, -2, -1);  transpose_60 = None
        _to_copy_48: "f32[8, 256, 256]" = torch.ops.aten._to_copy.default(transpose_62, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  transpose_62 = None
        _to_copy_49: "f32[49216, 256]" = torch.ops.aten._to_copy.default(_grouped_mm_24, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  _grouped_mm_24 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:116 in _run_experts_grouped_mm, code: h = F.silu(
        silu_backward_3: "bf16[49216, 256]" = torch.ops.aten.silu_backward.default(mul_52, _grouped_mm_9);  mul_52 = _grouped_mm_9 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:117 in _run_experts_grouped_mm, code: torch._grouped_mm(x.bfloat16(), w1.bfloat16().transpose(-2, -1), offs=offsets)
        transpose_63: "bf16[256, 49216]" = torch.ops.aten.transpose.int(silu_backward_3, -2, -1)
        _grouped_mm_25: "bf16[8, 256, 256]" = torch.ops.aten._grouped_mm.default(transpose_63, _to_copy_26, cumsum_11);  transpose_63 = _to_copy_26 = None
        transpose_64: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_grouped_mm_25, -2, -1);  _grouped_mm_25 = None
        transpose_65: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_29, -2, -1);  transpose_29 = None
        _grouped_mm_26: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(silu_backward_3, transpose_65, cumsum_11);  silu_backward_3 = transpose_65 = cumsum_11 = None
        transpose_66: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_64, -2, -1);  transpose_64 = None
        _to_copy_50: "f32[8, 256, 256]" = torch.ops.aten._to_copy.default(transpose_66, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  transpose_66 = None
        _to_copy_51: "f32[49216, 256]" = torch.ops.aten._to_copy.default(_grouped_mm_26, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  _grouped_mm_26 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:117 in _run_experts_grouped_mm, code: torch._grouped_mm(x.bfloat16(), w1.bfloat16().transpose(-2, -1), offs=offsets)
        add_35: "f32[49216, 256]" = torch.ops.aten.add.Tensor(_to_copy_49, _to_copy_51);  _to_copy_49 = _to_copy_51 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:57 in _permute, code: x = x[permuted_indices, :]
        new_zeros_69: "f32[49153, 256]" = torch.ops.aten.new_zeros.default(add_35, [49153, 256], dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        index_put_7: "f32[49153, 256]" = torch.ops.aten.index_put.default(new_zeros_69, [getitem_94], add_35, True);  new_zeros_69 = getitem_94 = add_35 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:55 in _permute, code: x = torch.vstack((x, x.new_zeros((x.shape[-1]))))
        slice_17: "f32[49152, 256]" = torch.ops.aten.slice.Tensor(index_put_7, 0, 0, 49152);  index_put_7 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:453 in forward, code: routed_input = torch.gather(x, dim=0, index=token_indices_experts_sorted)
        new_zeros_70: "f32[16384, 256]" = torch.ops.aten.new_zeros.default(slice_17, [16384, 256])
        scatter_add_7: "f32[16384, 256]" = torch.ops.aten.scatter_add.default(new_zeros_70, 0, expand_8, slice_17);  new_zeros_70 = expand_8 = slice_17 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:453 in forward, code: routed_input = torch.gather(x, dim=0, index=token_indices_experts_sorted)
        add_36: "f32[16384, 256]" = torch.ops.aten.add.Tensor(add_34, scatter_add_7);  add_34 = scatter_add_7 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:347 in forward, code: top_scores_experts_sorted = top_scores.view(-1)[token_indices_experts_sorted]
        new_zeros_71: "f32[49152]" = torch.ops.aten.new_zeros.default(view_149, [49152], dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        index_put_8: "f32[49152]" = torch.ops.aten.index_put.default(new_zeros_71, [getitem_93], view_149, True);  new_zeros_71 = getitem_93 = view_149 = None
        view_150: "f32[16384, 3]" = torch.ops.aten.view.default(index_put_8, [16384, 3]);  index_put_8 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:280 in forward, code: top_scores = top_scores * self.route_scale
        mul_53: "f32[16384, 3]" = torch.ops.aten.mul.Tensor(view_150, 1.0);  view_150 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:264 in forward, code: top_scores = scores.gather(dim=1, index=selected_experts_indices)
        new_zeros_72: "f32[16384, 8]" = torch.ops.aten.new_zeros.default(mul_53, [16384, 8])
        scatter_add_8: "f32[16384, 8]" = torch.ops.aten.scatter_add.default(new_zeros_72, 1, getitem_91, mul_53);  new_zeros_72 = getitem_91 = mul_53 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:253 in forward, code: scores = F.softmax(scores.to(torch.float32), dim=1)
        detach_43: "f32[16384, 8]" = torch.ops.aten.detach.default(detach_28);  detach_28 = None
        _softmax_backward_data_1: "f32[16384, 8]" = torch.ops.aten._softmax_backward_data.default(scatter_add_8, detach_43, 1, torch.float32);  scatter_add_8 = detach_43 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:247 in forward, code: scores = self.gate(x)
        t_96: "f32[8, 16384]" = torch.ops.aten.t.default(_softmax_backward_data_1)
        mm_72: "f32[8, 256]" = torch.ops.aten.mm.default(t_96, view_95);  t_96 = view_95 = None
        t_97: "f32[256, 8]" = torch.ops.aten.t.default(mm_72);  mm_72 = None
        t_98: "f32[8, 256]" = torch.ops.aten.t.default(t_35);  t_35 = None
        mm_73: "f32[16384, 256]" = torch.ops.aten.mm.default(_softmax_backward_data_1, t_98);  _softmax_backward_data_1 = t_98 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:247 in forward, code: scores = self.gate(x)
        add_37: "f32[16384, 256]" = torch.ops.aten.add.Tensor(add_36, mm_73);  add_36 = mm_73 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:247 in forward, code: scores = self.gate(x)
        t_99: "f32[8, 256]" = torch.ops.aten.t.default(t_97);  t_97 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:415 in forward, code: x = x.view(-1, dim)
        view_151: "f32[8, 2048, 256]" = torch.ops.aten.view.default(add_37, [8, 2048, 256]);  add_37 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        detach_44: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(detach_27);  detach_27 = None
        _fused_rms_norm_backward_4 = torch.ops.aten._fused_rms_norm_backward.default(view_151, add_17, [256], detach_44, primals_60, [True, True]);  view_151 = add_17 = detach_44 = primals_60 = None
        getitem_129: "f32[8, 2048, 256]" = _fused_rms_norm_backward_4[0]
        getitem_130: "f32[256]" = _fused_rms_norm_backward_4[1];  _fused_rms_norm_backward_4 = None
        add_38: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(add_33, getitem_129);  add_33 = getitem_129 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:262 in forward, code: return self.wo(output)  # (bsz, seqlen, dim)
        view_152: "f32[16384, 256]" = torch.ops.aten.view.default(add_38, [16384, 256])
        t_100: "f32[256, 16384]" = torch.ops.aten.t.default(view_152)
        mm_74: "f32[256, 2048]" = torch.ops.aten.mm.default(t_100, view_94);  t_100 = view_94 = None
        t_101: "f32[2048, 256]" = torch.ops.aten.t.default(mm_74);  mm_74 = None
        t_102: "f32[256, 2048]" = torch.ops.aten.t.default(t_34);  t_34 = None
        mm_75: "f32[16384, 2048]" = torch.ops.aten.mm.default(view_152, t_102);  view_152 = t_102 = None
        view_153: "f32[8, 2048, 2048]" = torch.ops.aten.view.default(mm_75, [8, 2048, 2048]);  mm_75 = None
        t_103: "f32[256, 2048]" = torch.ops.aten.t.default(t_101);  t_101 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:261 in forward, code: output = output.view(bsz, seqlen, -1)  # (bsz, seqlen, n_heads * v_head_dim)
        view_154: "f32[8, 2048, 16, 128]" = torch.ops.aten.view.default(view_153, [8, 2048, 16, 128]);  view_153 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:258 in forward, code: output = output.transpose(
        transpose_67: "f32[8, 16, 2048, 128]" = torch.ops.aten.transpose.int(view_154, 1, 2);  view_154 = None
        
        # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1585 in flex_attention, code: out, lse, max_scores = flex_attention_hop(
        zeros_2: "f32[8, 16, 2048]" = torch.ops.aten.zeros.default([8, 16, 2048], dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        detach_45: "f32[8, 16, 2048, 128]" = torch.ops.aten.detach.default(detach_25);  detach_25 = None
        detach_46: "f32[8, 16, 2048]" = torch.ops.aten.detach.default(detach_26);  detach_26 = None
        fw_graph1 = self.fw_graph1
        joint_graph1 = self.joint_graph1
        mask_graph1 = self.mask_graph1
        _tensor_constant0_7: "i32[8, 2048]" = self._tensor_constant0
        flex_attention_backward_1 = torch.ops.higher_order.flex_attention_backward(transpose_25, transpose_26, transpose_27, detach_45, detach_46, transpose_67, zeros_2, fw_graph1, joint_graph1, (2048, 2048, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, 128, 128, mask_graph1), 0.07216878364870322, {'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (_tensor_constant0_7,));  transpose_25 = transpose_26 = transpose_27 = detach_45 = detach_46 = transpose_67 = zeros_2 = fw_graph1 = joint_graph1 = mask_graph1 = _tensor_constant0_7 = None
        getitem_131: "f32[8, 16, 2048, 192]" = flex_attention_backward_1[0]
        getitem_132: "f32[8, 16, 2048, 192]" = flex_attention_backward_1[1]
        getitem_133: "f32[8, 16, 2048, 128]" = flex_attention_backward_1[2];  flex_attention_backward_1 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:246 in forward, code: v = v.transpose(1, 2)  # (bsz, n_heads, seqlen, v_head_dim)
        transpose_68: "f32[8, 2048, 16, 128]" = torch.ops.aten.transpose.int(getitem_133, 1, 2);  getitem_133 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:245 in forward, code: k = k.transpose(1, 2)  # (bsz, n_heads, seqlen, qk_head_dim)
        transpose_69: "f32[8, 2048, 16, 192]" = torch.ops.aten.transpose.int(getitem_132, 1, 2);  getitem_132 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:244 in forward, code: q = q.transpose(1, 2)  # (bsz, n_heads, seqlen, qk_head_dim)
        transpose_70: "f32[8, 2048, 16, 192]" = torch.ops.aten.transpose.int(getitem_131, 1, 2);  getitem_131 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:240 in forward, code: k = torch.cat(
        slice_19: "f32[8, 2048, 16, 128]" = torch.ops.aten.slice.Tensor(transpose_69, 3, 0, 128)
        slice_20: "f32[8, 2048, 16, 64]" = torch.ops.aten.slice.Tensor(transpose_69, 3, 128, 192);  transpose_69 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:241 in forward, code: [k_nope, k_pe.expand(-1, -1, self.n_heads, -1)], dim=-1
        sum_9: "f32[8, 2048, 1, 64]" = torch.ops.aten.sum.dim_IntList(slice_20, [2], True);  slice_20 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:239 in forward, code: k_nope, v = torch.split(kv, [self.qk_nope_head_dim, self.v_head_dim], dim=-1)
        cat_20: "f32[8, 2048, 16, 256]" = torch.ops.aten.cat.default([slice_19, transpose_68], 3);  slice_19 = transpose_68 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:238 in forward, code: kv = kv.view(bsz, seqlen, -1, self.qk_nope_head_dim + self.v_head_dim)
        view_155: "f32[8, 2048, 4096]" = torch.ops.aten.view.default(cat_20, [8, 2048, 4096]);  cat_20 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:235 in forward, code: kv = self.wkv_b(
        view_156: "f32[16384, 4096]" = torch.ops.aten.view.default(view_155, [16384, 4096]);  view_155 = None
        t_104: "f32[4096, 16384]" = torch.ops.aten.t.default(view_156)
        mm_76: "f32[4096, 512]" = torch.ops.aten.mm.default(t_104, view_91);  t_104 = view_91 = None
        t_105: "f32[512, 4096]" = torch.ops.aten.t.default(mm_76);  mm_76 = None
        t_106: "f32[4096, 512]" = torch.ops.aten.t.default(t_33);  t_33 = None
        mm_77: "f32[16384, 512]" = torch.ops.aten.mm.default(view_156, t_106);  view_156 = t_106 = None
        view_157: "f32[8, 2048, 512]" = torch.ops.aten.view.default(mm_77, [8, 2048, 512]);  mm_77 = None
        t_107: "f32[4096, 512]" = torch.ops.aten.t.default(t_105);  t_105 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        detach_47: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(detach_24);  detach_24 = None
        _fused_rms_norm_backward_5 = torch.ops.aten._fused_rms_norm_backward.default(view_157, getitem_79, [512], detach_47, primals_56, [True, True]);  view_157 = getitem_79 = detach_47 = primals_56 = None
        getitem_135: "f32[8, 2048, 512]" = _fused_rms_norm_backward_5[0]
        getitem_136: "f32[512]" = _fused_rms_norm_backward_5[1];  _fused_rms_norm_backward_5 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:143 in apply_rotary_emb, code: y = torch.view_as_real(x * freqs_cis).flatten(3)
        view_158: "f32[8, 2048, 1, 32, 2]" = torch.ops.aten.view.default(sum_9, [8, 2048, 1, 32, 2]);  sum_9 = None
        view_as_complex_14: "c64[8, 2048, 1, 32]" = torch.ops.aten.view_as_complex.default(view_158);  view_158 = None
        _conj_2: "c64[1, 2048, 1, 32]" = torch.ops.aten._conj.default(view_89);  view_89 = None
        clone_3: "c64[1, 2048, 1, 32]" = torch.ops.aten.clone.default(_conj_2);  _conj_2 = None
        mul_54: "c64[8, 2048, 1, 32]" = torch.ops.aten.mul.Tensor(view_as_complex_14, clone_3);  view_as_complex_14 = clone_3 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:141 in apply_rotary_emb, code: x = torch.view_as_complex(x.float().view(*x.shape[:-1], -1, 2))
        view_as_real_14: "f32[8, 2048, 1, 32, 2]" = torch.ops.aten.view_as_real.default(mul_54);  mul_54 = None
        view_159: "f32[8, 2048, 1, 64]" = torch.ops.aten.view.default(view_as_real_14, [8, 2048, 1, 64]);  view_as_real_14 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:232 in forward, code: k_pe.unsqueeze(2), freqs_cis
        squeeze_1: "f32[8, 2048, 64]" = torch.ops.aten.squeeze.dim(view_159, 2);  view_159 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:229 in forward, code: kv, k_pe = torch.split(kv, [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1)
        cat_21: "f32[8, 2048, 576]" = torch.ops.aten.cat.default([getitem_135, squeeze_1], 2);  getitem_135 = squeeze_1 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:228 in forward, code: kv = self.wkv_a(x)  # (bsz, seqlen, kv_lora_rank + qk_rope_head_dim)
        view_160: "f32[16384, 576]" = torch.ops.aten.view.default(cat_21, [16384, 576]);  cat_21 = None
        t_108: "f32[576, 16384]" = torch.ops.aten.t.default(view_160)
        mm_78: "f32[576, 256]" = torch.ops.aten.mm.default(t_108, view_87);  t_108 = view_87 = None
        t_109: "f32[256, 576]" = torch.ops.aten.t.default(mm_78);  mm_78 = None
        t_110: "f32[576, 256]" = torch.ops.aten.t.default(t_32);  t_32 = None
        mm_79: "f32[16384, 256]" = torch.ops.aten.mm.default(view_160, t_110);  view_160 = t_110 = None
        view_161: "f32[8, 2048, 256]" = torch.ops.aten.view.default(mm_79, [8, 2048, 256]);  mm_79 = None
        t_111: "f32[576, 256]" = torch.ops.aten.t.default(t_109);  t_109 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:225 in forward, code: q = torch.cat([q_nope, q_pe], dim=-1)  # (bsz, seqlen, n_heads, qk_head_dim)
        slice_21: "f32[8, 2048, 16, 128]" = torch.ops.aten.slice.Tensor(transpose_70, 3, 0, 128)
        slice_22: "f32[8, 2048, 16, 64]" = torch.ops.aten.slice.Tensor(transpose_70, 3, 128, 192);  transpose_70 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:143 in apply_rotary_emb, code: y = torch.view_as_real(x * freqs_cis).flatten(3)
        view_162: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.view.default(slice_22, [8, 2048, 16, 32, 2]);  slice_22 = None
        clone_4: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.clone.default(view_162, memory_format = torch.contiguous_format);  view_162 = None
        view_as_complex_15: "c64[8, 2048, 16, 32]" = torch.ops.aten.view_as_complex.default(clone_4);  clone_4 = None
        _conj_3: "c64[1, 2048, 1, 32]" = torch.ops.aten._conj.default(view_85);  view_85 = None
        clone_5: "c64[1, 2048, 1, 32]" = torch.ops.aten.clone.default(_conj_3);  _conj_3 = None
        mul_55: "c64[8, 2048, 16, 32]" = torch.ops.aten.mul.Tensor(view_as_complex_15, clone_5);  view_as_complex_15 = clone_5 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:141 in apply_rotary_emb, code: x = torch.view_as_complex(x.float().view(*x.shape[:-1], -1, 2))
        view_as_real_15: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.view_as_real.default(mul_55);  mul_55 = None
        view_163: "f32[8, 2048, 16, 64]" = torch.ops.aten.view.default(view_as_real_15, [8, 2048, 16, 64]);  view_as_real_15 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:221 in forward, code: q_nope, q_pe = torch.split(
        cat_22: "f32[8, 2048, 16, 192]" = torch.ops.aten.cat.default([slice_21, view_163], 3);  slice_21 = view_163 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:220 in forward, code: q = q.view(bsz, seqlen, -1, self.qk_head_dim)
        view_164: "f32[8, 2048, 3072]" = torch.ops.aten.view.default(cat_22, [8, 2048, 3072]);  cat_22 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:213 in forward, code: q = self.wq(x)  # (bsz, seqlen, n_heads * qk_head_dim)
        view_165: "f32[16384, 3072]" = torch.ops.aten.view.default(view_164, [16384, 3072]);  view_164 = None
        t_112: "f32[3072, 16384]" = torch.ops.aten.t.default(view_165)
        mm_80: "f32[3072, 256]" = torch.ops.aten.mm.default(t_112, view_82);  t_112 = view_82 = None
        t_113: "f32[256, 3072]" = torch.ops.aten.t.default(mm_80);  mm_80 = None
        t_114: "f32[3072, 256]" = torch.ops.aten.t.default(t_31);  t_31 = None
        mm_81: "f32[16384, 256]" = torch.ops.aten.mm.default(view_165, t_114);  view_165 = t_114 = None
        view_166: "f32[8, 2048, 256]" = torch.ops.aten.view.default(mm_81, [8, 2048, 256]);  mm_81 = None
        add_39: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(view_161, view_166);  view_161 = view_166 = None
        t_115: "f32[3072, 256]" = torch.ops.aten.t.default(t_113);  t_113 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        detach_48: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(detach_23);  detach_23 = None
        _fused_rms_norm_backward_6 = torch.ops.aten._fused_rms_norm_backward.default(add_39, add_16, [256], detach_48, primals_59, [True, True]);  add_39 = add_16 = detach_48 = primals_59 = None
        getitem_137: "f32[8, 2048, 256]" = _fused_rms_norm_backward_6[0]
        getitem_138: "f32[256]" = _fused_rms_norm_backward_6[1];  _fused_rms_norm_backward_6 = None
        add_40: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(add_38, getitem_137);  add_38 = getitem_137 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:481 in forward, code: out = out.reshape(bs, slen, dim)
        view_167: "f32[16384, 256]" = torch.ops.aten.view.default(add_40, [16384, 256])
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:478 in forward, code: out = out.scatter_add(
        gather_12: "f32[49152, 256]" = torch.ops.aten.gather.default(view_167, 0, expand_6)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:474 in forward, code: routed_output.to(torch.float32)
        mul_56: "f32[49152, 256]" = torch.ops.aten.mul.Tensor(gather_12, slice_6);  slice_6 = None
        mul_57: "f32[49152, 256]" = torch.ops.aten.mul.Tensor(gather_12, view_80);  gather_12 = view_80 = None
        sum_10: "f32[49152, 1]" = torch.ops.aten.sum.dim_IntList(mul_56, [1], True);  mul_56 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:475 in forward, code: * top_scores_experts_sorted.reshape(-1, 1)
        view_168: "f32[49152]" = torch.ops.aten.view.default(sum_10, [49152]);  sum_10 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:62 in forward, code: return self.w2(F.silu(self.w1(x)) * self.w3(x))
        t_116: "f32[256, 16384]" = torch.ops.aten.t.default(view_167)
        mm_82: "f32[256, 512]" = torch.ops.aten.mm.default(t_116, mul_22);  t_116 = mul_22 = None
        t_117: "f32[512, 256]" = torch.ops.aten.t.default(mm_82);  mm_82 = None
        t_118: "f32[256, 512]" = torch.ops.aten.t.default(t_30);  t_30 = None
        mm_83: "f32[16384, 512]" = torch.ops.aten.mm.default(view_167, t_118);  view_167 = t_118 = None
        t_119: "f32[256, 512]" = torch.ops.aten.t.default(t_117);  t_117 = None
        mul_58: "f32[16384, 512]" = torch.ops.aten.mul.Tensor(mm_83, silu_6);  silu_6 = None
        mul_59: "f32[16384, 512]" = torch.ops.aten.mul.Tensor(mm_83, mm_29);  mm_83 = mm_29 = None
        t_120: "f32[512, 16384]" = torch.ops.aten.t.default(mul_58)
        mm_84: "f32[512, 256]" = torch.ops.aten.mm.default(t_120, view_73);  t_120 = None
        t_121: "f32[256, 512]" = torch.ops.aten.t.default(mm_84);  mm_84 = None
        t_122: "f32[512, 256]" = torch.ops.aten.t.default(t_29);  t_29 = None
        mm_85: "f32[16384, 256]" = torch.ops.aten.mm.default(mul_58, t_122);  mul_58 = t_122 = None
        t_123: "f32[512, 256]" = torch.ops.aten.t.default(t_121);  t_121 = None
        silu_backward_4: "f32[16384, 512]" = torch.ops.aten.silu_backward.default(mul_59, mm_28);  mul_59 = mm_28 = None
        t_124: "f32[512, 16384]" = torch.ops.aten.t.default(silu_backward_4)
        mm_86: "f32[512, 256]" = torch.ops.aten.mm.default(t_124, view_73);  t_124 = None
        t_125: "f32[256, 512]" = torch.ops.aten.t.default(mm_86);  mm_86 = None
        t_126: "f32[512, 256]" = torch.ops.aten.t.default(t_28);  t_28 = None
        mm_87: "f32[16384, 256]" = torch.ops.aten.mm.default(silu_backward_4, t_126);  silu_backward_4 = t_126 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:62 in forward, code: return self.w2(F.silu(self.w1(x)) * self.w3(x))
        add_41: "f32[16384, 256]" = torch.ops.aten.add.Tensor(mm_85, mm_87);  mm_85 = mm_87 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:62 in forward, code: return self.w2(F.silu(self.w1(x)) * self.w3(x))
        t_127: "f32[512, 256]" = torch.ops.aten.t.default(t_125);  t_125 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:65 in _unpermute, code: out = out_unpermuted[:-1]
        slice_backward_2: "f32[49153, 256]" = torch.ops.aten.slice_backward.default(mul_57, [49153, 256], 0, 0, -1, 1);  mul_57 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:64 in _unpermute, code: out_unpermuted[permuted_indices, :] = out
        index_12: "f32[49216, 256]" = torch.ops.aten.index.Tensor(slice_backward_2, [getitem_74]);  slice_backward_2 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:122 in _run_experts_grouped_mm, code: out = torch._grouped_mm(h, w2.bfloat16().transpose(-2, -1), offs=offsets).type_as(x)
        _to_copy_52: "bf16[49216, 256]" = torch.ops.aten._to_copy.default(index_12, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0));  index_12 = None
        transpose_71: "bf16[256, 49216]" = torch.ops.aten.transpose.int(_to_copy_52, -2, -1)
        _grouped_mm_27: "bf16[8, 256, 256]" = torch.ops.aten._grouped_mm.default(transpose_71, mul_21, cumsum_8);  transpose_71 = mul_21 = None
        transpose_72: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_grouped_mm_27, -2, -1);  _grouped_mm_27 = None
        transpose_73: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_24, -2, -1);  transpose_24 = None
        _grouped_mm_28: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(_to_copy_52, transpose_73, cumsum_8);  _to_copy_52 = transpose_73 = None
        transpose_74: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_72, -2, -1);  transpose_72 = None
        _to_copy_53: "f32[8, 256, 256]" = torch.ops.aten._to_copy.default(transpose_74, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  transpose_74 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:119 in _run_experts_grouped_mm, code: h = h * torch._grouped_mm(
        mul_60: "bf16[49216, 256]" = torch.ops.aten.mul.Tensor(_grouped_mm_28, silu_5);  silu_5 = None
        mul_61: "bf16[49216, 256]" = torch.ops.aten.mul.Tensor(_grouped_mm_28, _grouped_mm_7);  _grouped_mm_28 = _grouped_mm_7 = None
        transpose_75: "bf16[256, 49216]" = torch.ops.aten.transpose.int(mul_60, -2, -1)
        _grouped_mm_29: "bf16[8, 256, 256]" = torch.ops.aten._grouped_mm.default(transpose_75, _to_copy_20, cumsum_8);  transpose_75 = _to_copy_20 = None
        transpose_76: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_grouped_mm_29, -2, -1);  _grouped_mm_29 = None
        transpose_77: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_23, -2, -1);  transpose_23 = None
        _grouped_mm_30: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(mul_60, transpose_77, cumsum_8);  mul_60 = transpose_77 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:120 in _run_experts_grouped_mm, code: x.bfloat16(), w3.bfloat16().transpose(-2, -1), offs=offsets
        transpose_78: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_76, -2, -1);  transpose_76 = None
        _to_copy_54: "f32[8, 256, 256]" = torch.ops.aten._to_copy.default(transpose_78, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  transpose_78 = None
        _to_copy_55: "f32[49216, 256]" = torch.ops.aten._to_copy.default(_grouped_mm_30, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  _grouped_mm_30 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:116 in _run_experts_grouped_mm, code: h = F.silu(
        silu_backward_5: "bf16[49216, 256]" = torch.ops.aten.silu_backward.default(mul_61, _grouped_mm_6);  mul_61 = _grouped_mm_6 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:117 in _run_experts_grouped_mm, code: torch._grouped_mm(x.bfloat16(), w1.bfloat16().transpose(-2, -1), offs=offsets)
        transpose_79: "bf16[256, 49216]" = torch.ops.aten.transpose.int(silu_backward_5, -2, -1)
        _grouped_mm_31: "bf16[8, 256, 256]" = torch.ops.aten._grouped_mm.default(transpose_79, _to_copy_18, cumsum_8);  transpose_79 = _to_copy_18 = None
        transpose_80: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_grouped_mm_31, -2, -1);  _grouped_mm_31 = None
        transpose_81: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_22, -2, -1);  transpose_22 = None
        _grouped_mm_32: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(silu_backward_5, transpose_81, cumsum_8);  silu_backward_5 = transpose_81 = cumsum_8 = None
        transpose_82: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_80, -2, -1);  transpose_80 = None
        _to_copy_56: "f32[8, 256, 256]" = torch.ops.aten._to_copy.default(transpose_82, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  transpose_82 = None
        _to_copy_57: "f32[49216, 256]" = torch.ops.aten._to_copy.default(_grouped_mm_32, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  _grouped_mm_32 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:117 in _run_experts_grouped_mm, code: torch._grouped_mm(x.bfloat16(), w1.bfloat16().transpose(-2, -1), offs=offsets)
        add_42: "f32[49216, 256]" = torch.ops.aten.add.Tensor(_to_copy_55, _to_copy_57);  _to_copy_55 = _to_copy_57 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:57 in _permute, code: x = x[permuted_indices, :]
        new_zeros_73: "f32[49153, 256]" = torch.ops.aten.new_zeros.default(add_42, [49153, 256], dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        index_put_9: "f32[49153, 256]" = torch.ops.aten.index_put.default(new_zeros_73, [getitem_74], add_42, True);  new_zeros_73 = getitem_74 = add_42 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:55 in _permute, code: x = torch.vstack((x, x.new_zeros((x.shape[-1]))))
        slice_23: "f32[49152, 256]" = torch.ops.aten.slice.Tensor(index_put_9, 0, 0, 49152);  index_put_9 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:453 in forward, code: routed_input = torch.gather(x, dim=0, index=token_indices_experts_sorted)
        new_zeros_74: "f32[16384, 256]" = torch.ops.aten.new_zeros.default(slice_23, [16384, 256])
        scatter_add_9: "f32[16384, 256]" = torch.ops.aten.scatter_add.default(new_zeros_74, 0, expand_6, slice_23);  new_zeros_74 = expand_6 = slice_23 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:453 in forward, code: routed_input = torch.gather(x, dim=0, index=token_indices_experts_sorted)
        add_43: "f32[16384, 256]" = torch.ops.aten.add.Tensor(add_41, scatter_add_9);  add_41 = scatter_add_9 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:347 in forward, code: top_scores_experts_sorted = top_scores.view(-1)[token_indices_experts_sorted]
        new_zeros_75: "f32[49152]" = torch.ops.aten.new_zeros.default(view_168, [49152], dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        index_put_10: "f32[49152]" = torch.ops.aten.index_put.default(new_zeros_75, [getitem_73], view_168, True);  new_zeros_75 = getitem_73 = view_168 = None
        view_169: "f32[16384, 3]" = torch.ops.aten.view.default(index_put_10, [16384, 3]);  index_put_10 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:280 in forward, code: top_scores = top_scores * self.route_scale
        mul_62: "f32[16384, 3]" = torch.ops.aten.mul.Tensor(view_169, 1.0);  view_169 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:264 in forward, code: top_scores = scores.gather(dim=1, index=selected_experts_indices)
        new_zeros_76: "f32[16384, 8]" = torch.ops.aten.new_zeros.default(mul_62, [16384, 8])
        scatter_add_10: "f32[16384, 8]" = torch.ops.aten.scatter_add.default(new_zeros_76, 1, getitem_71, mul_62);  new_zeros_76 = getitem_71 = mul_62 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:253 in forward, code: scores = F.softmax(scores.to(torch.float32), dim=1)
        detach_49: "f32[16384, 8]" = torch.ops.aten.detach.default(detach_22);  detach_22 = None
        _softmax_backward_data_2: "f32[16384, 8]" = torch.ops.aten._softmax_backward_data.default(scatter_add_10, detach_49, 1, torch.float32);  scatter_add_10 = detach_49 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:247 in forward, code: scores = self.gate(x)
        t_128: "f32[8, 16384]" = torch.ops.aten.t.default(_softmax_backward_data_2)
        mm_88: "f32[8, 256]" = torch.ops.aten.mm.default(t_128, view_73);  t_128 = view_73 = None
        t_129: "f32[256, 8]" = torch.ops.aten.t.default(mm_88);  mm_88 = None
        t_130: "f32[8, 256]" = torch.ops.aten.t.default(t_27);  t_27 = None
        mm_89: "f32[16384, 256]" = torch.ops.aten.mm.default(_softmax_backward_data_2, t_130);  _softmax_backward_data_2 = t_130 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:247 in forward, code: scores = self.gate(x)
        add_44: "f32[16384, 256]" = torch.ops.aten.add.Tensor(add_43, mm_89);  add_43 = mm_89 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:247 in forward, code: scores = self.gate(x)
        t_131: "f32[8, 256]" = torch.ops.aten.t.default(t_129);  t_129 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:415 in forward, code: x = x.view(-1, dim)
        view_170: "f32[8, 2048, 256]" = torch.ops.aten.view.default(add_44, [8, 2048, 256]);  add_44 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        detach_50: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(detach_21);  detach_21 = None
        _fused_rms_norm_backward_7 = torch.ops.aten._fused_rms_norm_backward.default(view_170, add_12, [256], detach_50, primals_46, [True, True]);  view_170 = add_12 = detach_50 = primals_46 = None
        getitem_139: "f32[8, 2048, 256]" = _fused_rms_norm_backward_7[0]
        getitem_140: "f32[256]" = _fused_rms_norm_backward_7[1];  _fused_rms_norm_backward_7 = None
        add_45: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(add_40, getitem_139);  add_40 = getitem_139 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:262 in forward, code: return self.wo(output)  # (bsz, seqlen, dim)
        view_171: "f32[16384, 256]" = torch.ops.aten.view.default(add_45, [16384, 256])
        t_132: "f32[256, 16384]" = torch.ops.aten.t.default(view_171)
        mm_90: "f32[256, 2048]" = torch.ops.aten.mm.default(t_132, view_72);  t_132 = view_72 = None
        t_133: "f32[2048, 256]" = torch.ops.aten.t.default(mm_90);  mm_90 = None
        t_134: "f32[256, 2048]" = torch.ops.aten.t.default(t_26);  t_26 = None
        mm_91: "f32[16384, 2048]" = torch.ops.aten.mm.default(view_171, t_134);  view_171 = t_134 = None
        view_172: "f32[8, 2048, 2048]" = torch.ops.aten.view.default(mm_91, [8, 2048, 2048]);  mm_91 = None
        t_135: "f32[256, 2048]" = torch.ops.aten.t.default(t_133);  t_133 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:261 in forward, code: output = output.view(bsz, seqlen, -1)  # (bsz, seqlen, n_heads * v_head_dim)
        view_173: "f32[8, 2048, 16, 128]" = torch.ops.aten.view.default(view_172, [8, 2048, 16, 128]);  view_172 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:258 in forward, code: output = output.transpose(
        transpose_83: "f32[8, 16, 2048, 128]" = torch.ops.aten.transpose.int(view_173, 1, 2);  view_173 = None
        
        # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1585 in flex_attention, code: out, lse, max_scores = flex_attention_hop(
        zeros_4: "f32[8, 16, 2048]" = torch.ops.aten.zeros.default([8, 16, 2048], dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        detach_51: "f32[8, 16, 2048, 128]" = torch.ops.aten.detach.default(detach_19);  detach_19 = None
        detach_52: "f32[8, 16, 2048]" = torch.ops.aten.detach.default(detach_20);  detach_20 = None
        fw_graph2 = self.fw_graph2
        joint_graph2 = self.joint_graph2
        mask_graph2 = self.mask_graph2
        _tensor_constant0_8: "i32[8, 2048]" = self._tensor_constant0
        flex_attention_backward_2 = torch.ops.higher_order.flex_attention_backward(transpose_18, transpose_19, transpose_20, detach_51, detach_52, transpose_83, zeros_4, fw_graph2, joint_graph2, (2048, 2048, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, 128, 128, mask_graph2), 0.07216878364870322, {'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (_tensor_constant0_8,));  transpose_18 = transpose_19 = transpose_20 = detach_51 = detach_52 = transpose_83 = zeros_4 = fw_graph2 = joint_graph2 = mask_graph2 = _tensor_constant0_8 = None
        getitem_141: "f32[8, 16, 2048, 192]" = flex_attention_backward_2[0]
        getitem_142: "f32[8, 16, 2048, 192]" = flex_attention_backward_2[1]
        getitem_143: "f32[8, 16, 2048, 128]" = flex_attention_backward_2[2];  flex_attention_backward_2 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:246 in forward, code: v = v.transpose(1, 2)  # (bsz, n_heads, seqlen, v_head_dim)
        transpose_84: "f32[8, 2048, 16, 128]" = torch.ops.aten.transpose.int(getitem_143, 1, 2);  getitem_143 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:245 in forward, code: k = k.transpose(1, 2)  # (bsz, n_heads, seqlen, qk_head_dim)
        transpose_85: "f32[8, 2048, 16, 192]" = torch.ops.aten.transpose.int(getitem_142, 1, 2);  getitem_142 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:244 in forward, code: q = q.transpose(1, 2)  # (bsz, n_heads, seqlen, qk_head_dim)
        transpose_86: "f32[8, 2048, 16, 192]" = torch.ops.aten.transpose.int(getitem_141, 1, 2);  getitem_141 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:240 in forward, code: k = torch.cat(
        slice_25: "f32[8, 2048, 16, 128]" = torch.ops.aten.slice.Tensor(transpose_85, 3, 0, 128)
        slice_26: "f32[8, 2048, 16, 64]" = torch.ops.aten.slice.Tensor(transpose_85, 3, 128, 192);  transpose_85 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:241 in forward, code: [k_nope, k_pe.expand(-1, -1, self.n_heads, -1)], dim=-1
        sum_11: "f32[8, 2048, 1, 64]" = torch.ops.aten.sum.dim_IntList(slice_26, [2], True);  slice_26 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:239 in forward, code: k_nope, v = torch.split(kv, [self.qk_nope_head_dim, self.v_head_dim], dim=-1)
        cat_23: "f32[8, 2048, 16, 256]" = torch.ops.aten.cat.default([slice_25, transpose_84], 3);  slice_25 = transpose_84 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:238 in forward, code: kv = kv.view(bsz, seqlen, -1, self.qk_nope_head_dim + self.v_head_dim)
        view_174: "f32[8, 2048, 4096]" = torch.ops.aten.view.default(cat_23, [8, 2048, 4096]);  cat_23 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:235 in forward, code: kv = self.wkv_b(
        view_175: "f32[16384, 4096]" = torch.ops.aten.view.default(view_174, [16384, 4096]);  view_174 = None
        t_136: "f32[4096, 16384]" = torch.ops.aten.t.default(view_175)
        mm_92: "f32[4096, 512]" = torch.ops.aten.mm.default(t_136, view_69);  t_136 = view_69 = None
        t_137: "f32[512, 4096]" = torch.ops.aten.t.default(mm_92);  mm_92 = None
        t_138: "f32[4096, 512]" = torch.ops.aten.t.default(t_25);  t_25 = None
        mm_93: "f32[16384, 512]" = torch.ops.aten.mm.default(view_175, t_138);  view_175 = t_138 = None
        view_176: "f32[8, 2048, 512]" = torch.ops.aten.view.default(mm_93, [8, 2048, 512]);  mm_93 = None
        t_139: "f32[4096, 512]" = torch.ops.aten.t.default(t_137);  t_137 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        detach_53: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(detach_18);  detach_18 = None
        _fused_rms_norm_backward_8 = torch.ops.aten._fused_rms_norm_backward.default(view_176, getitem_59, [512], detach_53, primals_42, [True, True]);  view_176 = getitem_59 = detach_53 = primals_42 = None
        getitem_145: "f32[8, 2048, 512]" = _fused_rms_norm_backward_8[0]
        getitem_146: "f32[512]" = _fused_rms_norm_backward_8[1];  _fused_rms_norm_backward_8 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:143 in apply_rotary_emb, code: y = torch.view_as_real(x * freqs_cis).flatten(3)
        view_177: "f32[8, 2048, 1, 32, 2]" = torch.ops.aten.view.default(sum_11, [8, 2048, 1, 32, 2]);  sum_11 = None
        view_as_complex_16: "c64[8, 2048, 1, 32]" = torch.ops.aten.view_as_complex.default(view_177);  view_177 = None
        _conj_4: "c64[1, 2048, 1, 32]" = torch.ops.aten._conj.default(view_67);  view_67 = None
        clone_6: "c64[1, 2048, 1, 32]" = torch.ops.aten.clone.default(_conj_4);  _conj_4 = None
        mul_63: "c64[8, 2048, 1, 32]" = torch.ops.aten.mul.Tensor(view_as_complex_16, clone_6);  view_as_complex_16 = clone_6 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:141 in apply_rotary_emb, code: x = torch.view_as_complex(x.float().view(*x.shape[:-1], -1, 2))
        view_as_real_16: "f32[8, 2048, 1, 32, 2]" = torch.ops.aten.view_as_real.default(mul_63);  mul_63 = None
        view_178: "f32[8, 2048, 1, 64]" = torch.ops.aten.view.default(view_as_real_16, [8, 2048, 1, 64]);  view_as_real_16 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:232 in forward, code: k_pe.unsqueeze(2), freqs_cis
        squeeze_2: "f32[8, 2048, 64]" = torch.ops.aten.squeeze.dim(view_178, 2);  view_178 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:229 in forward, code: kv, k_pe = torch.split(kv, [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1)
        cat_24: "f32[8, 2048, 576]" = torch.ops.aten.cat.default([getitem_145, squeeze_2], 2);  getitem_145 = squeeze_2 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:228 in forward, code: kv = self.wkv_a(x)  # (bsz, seqlen, kv_lora_rank + qk_rope_head_dim)
        view_179: "f32[16384, 576]" = torch.ops.aten.view.default(cat_24, [16384, 576]);  cat_24 = None
        t_140: "f32[576, 16384]" = torch.ops.aten.t.default(view_179)
        mm_94: "f32[576, 256]" = torch.ops.aten.mm.default(t_140, view_65);  t_140 = view_65 = None
        t_141: "f32[256, 576]" = torch.ops.aten.t.default(mm_94);  mm_94 = None
        t_142: "f32[576, 256]" = torch.ops.aten.t.default(t_24);  t_24 = None
        mm_95: "f32[16384, 256]" = torch.ops.aten.mm.default(view_179, t_142);  view_179 = t_142 = None
        view_180: "f32[8, 2048, 256]" = torch.ops.aten.view.default(mm_95, [8, 2048, 256]);  mm_95 = None
        t_143: "f32[576, 256]" = torch.ops.aten.t.default(t_141);  t_141 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:225 in forward, code: q = torch.cat([q_nope, q_pe], dim=-1)  # (bsz, seqlen, n_heads, qk_head_dim)
        slice_27: "f32[8, 2048, 16, 128]" = torch.ops.aten.slice.Tensor(transpose_86, 3, 0, 128)
        slice_28: "f32[8, 2048, 16, 64]" = torch.ops.aten.slice.Tensor(transpose_86, 3, 128, 192);  transpose_86 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:143 in apply_rotary_emb, code: y = torch.view_as_real(x * freqs_cis).flatten(3)
        view_181: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.view.default(slice_28, [8, 2048, 16, 32, 2]);  slice_28 = None
        clone_7: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.clone.default(view_181, memory_format = torch.contiguous_format);  view_181 = None
        view_as_complex_17: "c64[8, 2048, 16, 32]" = torch.ops.aten.view_as_complex.default(clone_7);  clone_7 = None
        _conj_5: "c64[1, 2048, 1, 32]" = torch.ops.aten._conj.default(view_63);  view_63 = None
        clone_8: "c64[1, 2048, 1, 32]" = torch.ops.aten.clone.default(_conj_5);  _conj_5 = None
        mul_64: "c64[8, 2048, 16, 32]" = torch.ops.aten.mul.Tensor(view_as_complex_17, clone_8);  view_as_complex_17 = clone_8 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:141 in apply_rotary_emb, code: x = torch.view_as_complex(x.float().view(*x.shape[:-1], -1, 2))
        view_as_real_17: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.view_as_real.default(mul_64);  mul_64 = None
        view_182: "f32[8, 2048, 16, 64]" = torch.ops.aten.view.default(view_as_real_17, [8, 2048, 16, 64]);  view_as_real_17 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:221 in forward, code: q_nope, q_pe = torch.split(
        cat_25: "f32[8, 2048, 16, 192]" = torch.ops.aten.cat.default([slice_27, view_182], 3);  slice_27 = view_182 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:220 in forward, code: q = q.view(bsz, seqlen, -1, self.qk_head_dim)
        view_183: "f32[8, 2048, 3072]" = torch.ops.aten.view.default(cat_25, [8, 2048, 3072]);  cat_25 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:213 in forward, code: q = self.wq(x)  # (bsz, seqlen, n_heads * qk_head_dim)
        view_184: "f32[16384, 3072]" = torch.ops.aten.view.default(view_183, [16384, 3072]);  view_183 = None
        t_144: "f32[3072, 16384]" = torch.ops.aten.t.default(view_184)
        mm_96: "f32[3072, 256]" = torch.ops.aten.mm.default(t_144, view_60);  t_144 = view_60 = None
        t_145: "f32[256, 3072]" = torch.ops.aten.t.default(mm_96);  mm_96 = None
        t_146: "f32[3072, 256]" = torch.ops.aten.t.default(t_23);  t_23 = None
        mm_97: "f32[16384, 256]" = torch.ops.aten.mm.default(view_184, t_146);  view_184 = t_146 = None
        view_185: "f32[8, 2048, 256]" = torch.ops.aten.view.default(mm_97, [8, 2048, 256]);  mm_97 = None
        add_46: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(view_180, view_185);  view_180 = view_185 = None
        t_147: "f32[3072, 256]" = torch.ops.aten.t.default(t_145);  t_145 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        detach_54: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(detach_17);  detach_17 = None
        _fused_rms_norm_backward_9 = torch.ops.aten._fused_rms_norm_backward.default(add_46, add_11, [256], detach_54, primals_45, [True, True]);  add_46 = add_11 = detach_54 = primals_45 = None
        getitem_147: "f32[8, 2048, 256]" = _fused_rms_norm_backward_9[0]
        getitem_148: "f32[256]" = _fused_rms_norm_backward_9[1];  _fused_rms_norm_backward_9 = None
        add_47: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(add_45, getitem_147);  add_45 = getitem_147 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:481 in forward, code: out = out.reshape(bs, slen, dim)
        view_186: "f32[16384, 256]" = torch.ops.aten.view.default(add_47, [16384, 256])
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:478 in forward, code: out = out.scatter_add(
        gather_13: "f32[49152, 256]" = torch.ops.aten.gather.default(view_186, 0, expand_4)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:474 in forward, code: routed_output.to(torch.float32)
        mul_65: "f32[49152, 256]" = torch.ops.aten.mul.Tensor(gather_13, slice_4);  slice_4 = None
        mul_66: "f32[49152, 256]" = torch.ops.aten.mul.Tensor(gather_13, view_58);  gather_13 = view_58 = None
        sum_12: "f32[49152, 1]" = torch.ops.aten.sum.dim_IntList(mul_65, [1], True);  mul_65 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:475 in forward, code: * top_scores_experts_sorted.reshape(-1, 1)
        view_187: "f32[49152]" = torch.ops.aten.view.default(sum_12, [49152]);  sum_12 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:62 in forward, code: return self.w2(F.silu(self.w1(x)) * self.w3(x))
        t_148: "f32[256, 16384]" = torch.ops.aten.t.default(view_186)
        mm_98: "f32[256, 512]" = torch.ops.aten.mm.default(t_148, mul_15);  t_148 = mul_15 = None
        t_149: "f32[512, 256]" = torch.ops.aten.t.default(mm_98);  mm_98 = None
        t_150: "f32[256, 512]" = torch.ops.aten.t.default(t_22);  t_22 = None
        mm_99: "f32[16384, 512]" = torch.ops.aten.mm.default(view_186, t_150);  view_186 = t_150 = None
        t_151: "f32[256, 512]" = torch.ops.aten.t.default(t_149);  t_149 = None
        mul_67: "f32[16384, 512]" = torch.ops.aten.mul.Tensor(mm_99, silu_4);  silu_4 = None
        mul_68: "f32[16384, 512]" = torch.ops.aten.mul.Tensor(mm_99, mm_21);  mm_99 = mm_21 = None
        t_152: "f32[512, 16384]" = torch.ops.aten.t.default(mul_67)
        mm_100: "f32[512, 256]" = torch.ops.aten.mm.default(t_152, view_51);  t_152 = None
        t_153: "f32[256, 512]" = torch.ops.aten.t.default(mm_100);  mm_100 = None
        t_154: "f32[512, 256]" = torch.ops.aten.t.default(t_21);  t_21 = None
        mm_101: "f32[16384, 256]" = torch.ops.aten.mm.default(mul_67, t_154);  mul_67 = t_154 = None
        t_155: "f32[512, 256]" = torch.ops.aten.t.default(t_153);  t_153 = None
        silu_backward_6: "f32[16384, 512]" = torch.ops.aten.silu_backward.default(mul_68, mm_20);  mul_68 = mm_20 = None
        t_156: "f32[512, 16384]" = torch.ops.aten.t.default(silu_backward_6)
        mm_102: "f32[512, 256]" = torch.ops.aten.mm.default(t_156, view_51);  t_156 = None
        t_157: "f32[256, 512]" = torch.ops.aten.t.default(mm_102);  mm_102 = None
        t_158: "f32[512, 256]" = torch.ops.aten.t.default(t_20);  t_20 = None
        mm_103: "f32[16384, 256]" = torch.ops.aten.mm.default(silu_backward_6, t_158);  silu_backward_6 = t_158 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:62 in forward, code: return self.w2(F.silu(self.w1(x)) * self.w3(x))
        add_48: "f32[16384, 256]" = torch.ops.aten.add.Tensor(mm_101, mm_103);  mm_101 = mm_103 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:62 in forward, code: return self.w2(F.silu(self.w1(x)) * self.w3(x))
        t_159: "f32[512, 256]" = torch.ops.aten.t.default(t_157);  t_157 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:65 in _unpermute, code: out = out_unpermuted[:-1]
        slice_backward_3: "f32[49153, 256]" = torch.ops.aten.slice_backward.default(mul_66, [49153, 256], 0, 0, -1, 1);  mul_66 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:64 in _unpermute, code: out_unpermuted[permuted_indices, :] = out
        index_13: "f32[49216, 256]" = torch.ops.aten.index.Tensor(slice_backward_3, [getitem_54]);  slice_backward_3 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:122 in _run_experts_grouped_mm, code: out = torch._grouped_mm(h, w2.bfloat16().transpose(-2, -1), offs=offsets).type_as(x)
        _to_copy_58: "bf16[49216, 256]" = torch.ops.aten._to_copy.default(index_13, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0));  index_13 = None
        transpose_87: "bf16[256, 49216]" = torch.ops.aten.transpose.int(_to_copy_58, -2, -1)
        _grouped_mm_33: "bf16[8, 256, 256]" = torch.ops.aten._grouped_mm.default(transpose_87, mul_14, cumsum_5);  transpose_87 = mul_14 = None
        transpose_88: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_grouped_mm_33, -2, -1);  _grouped_mm_33 = None
        transpose_89: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_17, -2, -1);  transpose_17 = None
        _grouped_mm_34: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(_to_copy_58, transpose_89, cumsum_5);  _to_copy_58 = transpose_89 = None
        transpose_90: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_88, -2, -1);  transpose_88 = None
        _to_copy_59: "f32[8, 256, 256]" = torch.ops.aten._to_copy.default(transpose_90, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  transpose_90 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:119 in _run_experts_grouped_mm, code: h = h * torch._grouped_mm(
        mul_69: "bf16[49216, 256]" = torch.ops.aten.mul.Tensor(_grouped_mm_34, silu_3);  silu_3 = None
        mul_70: "bf16[49216, 256]" = torch.ops.aten.mul.Tensor(_grouped_mm_34, _grouped_mm_4);  _grouped_mm_34 = _grouped_mm_4 = None
        transpose_91: "bf16[256, 49216]" = torch.ops.aten.transpose.int(mul_69, -2, -1)
        _grouped_mm_35: "bf16[8, 256, 256]" = torch.ops.aten._grouped_mm.default(transpose_91, _to_copy_12, cumsum_5);  transpose_91 = _to_copy_12 = None
        transpose_92: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_grouped_mm_35, -2, -1);  _grouped_mm_35 = None
        transpose_93: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_16, -2, -1);  transpose_16 = None
        _grouped_mm_36: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(mul_69, transpose_93, cumsum_5);  mul_69 = transpose_93 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:120 in _run_experts_grouped_mm, code: x.bfloat16(), w3.bfloat16().transpose(-2, -1), offs=offsets
        transpose_94: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_92, -2, -1);  transpose_92 = None
        _to_copy_60: "f32[8, 256, 256]" = torch.ops.aten._to_copy.default(transpose_94, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  transpose_94 = None
        _to_copy_61: "f32[49216, 256]" = torch.ops.aten._to_copy.default(_grouped_mm_36, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  _grouped_mm_36 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:116 in _run_experts_grouped_mm, code: h = F.silu(
        silu_backward_7: "bf16[49216, 256]" = torch.ops.aten.silu_backward.default(mul_70, _grouped_mm_3);  mul_70 = _grouped_mm_3 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:117 in _run_experts_grouped_mm, code: torch._grouped_mm(x.bfloat16(), w1.bfloat16().transpose(-2, -1), offs=offsets)
        transpose_95: "bf16[256, 49216]" = torch.ops.aten.transpose.int(silu_backward_7, -2, -1)
        _grouped_mm_37: "bf16[8, 256, 256]" = torch.ops.aten._grouped_mm.default(transpose_95, _to_copy_10, cumsum_5);  transpose_95 = _to_copy_10 = None
        transpose_96: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_grouped_mm_37, -2, -1);  _grouped_mm_37 = None
        transpose_97: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_15, -2, -1);  transpose_15 = None
        _grouped_mm_38: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(silu_backward_7, transpose_97, cumsum_5);  silu_backward_7 = transpose_97 = cumsum_5 = None
        transpose_98: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_96, -2, -1);  transpose_96 = None
        _to_copy_62: "f32[8, 256, 256]" = torch.ops.aten._to_copy.default(transpose_98, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  transpose_98 = None
        _to_copy_63: "f32[49216, 256]" = torch.ops.aten._to_copy.default(_grouped_mm_38, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  _grouped_mm_38 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:117 in _run_experts_grouped_mm, code: torch._grouped_mm(x.bfloat16(), w1.bfloat16().transpose(-2, -1), offs=offsets)
        add_49: "f32[49216, 256]" = torch.ops.aten.add.Tensor(_to_copy_61, _to_copy_63);  _to_copy_61 = _to_copy_63 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:57 in _permute, code: x = x[permuted_indices, :]
        new_zeros_77: "f32[49153, 256]" = torch.ops.aten.new_zeros.default(add_49, [49153, 256], dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        index_put_11: "f32[49153, 256]" = torch.ops.aten.index_put.default(new_zeros_77, [getitem_54], add_49, True);  new_zeros_77 = getitem_54 = add_49 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:55 in _permute, code: x = torch.vstack((x, x.new_zeros((x.shape[-1]))))
        slice_29: "f32[49152, 256]" = torch.ops.aten.slice.Tensor(index_put_11, 0, 0, 49152);  index_put_11 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:453 in forward, code: routed_input = torch.gather(x, dim=0, index=token_indices_experts_sorted)
        new_zeros_78: "f32[16384, 256]" = torch.ops.aten.new_zeros.default(slice_29, [16384, 256])
        scatter_add_11: "f32[16384, 256]" = torch.ops.aten.scatter_add.default(new_zeros_78, 0, expand_4, slice_29);  new_zeros_78 = expand_4 = slice_29 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:453 in forward, code: routed_input = torch.gather(x, dim=0, index=token_indices_experts_sorted)
        add_50: "f32[16384, 256]" = torch.ops.aten.add.Tensor(add_48, scatter_add_11);  add_48 = scatter_add_11 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:347 in forward, code: top_scores_experts_sorted = top_scores.view(-1)[token_indices_experts_sorted]
        new_zeros_79: "f32[49152]" = torch.ops.aten.new_zeros.default(view_187, [49152], dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        index_put_12: "f32[49152]" = torch.ops.aten.index_put.default(new_zeros_79, [getitem_53], view_187, True);  new_zeros_79 = getitem_53 = view_187 = None
        view_188: "f32[16384, 3]" = torch.ops.aten.view.default(index_put_12, [16384, 3]);  index_put_12 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:280 in forward, code: top_scores = top_scores * self.route_scale
        mul_71: "f32[16384, 3]" = torch.ops.aten.mul.Tensor(view_188, 1.0);  view_188 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:264 in forward, code: top_scores = scores.gather(dim=1, index=selected_experts_indices)
        new_zeros_80: "f32[16384, 8]" = torch.ops.aten.new_zeros.default(mul_71, [16384, 8])
        scatter_add_12: "f32[16384, 8]" = torch.ops.aten.scatter_add.default(new_zeros_80, 1, getitem_51, mul_71);  new_zeros_80 = getitem_51 = mul_71 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:253 in forward, code: scores = F.softmax(scores.to(torch.float32), dim=1)
        detach_55: "f32[16384, 8]" = torch.ops.aten.detach.default(detach_16);  detach_16 = None
        _softmax_backward_data_3: "f32[16384, 8]" = torch.ops.aten._softmax_backward_data.default(scatter_add_12, detach_55, 1, torch.float32);  scatter_add_12 = detach_55 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:247 in forward, code: scores = self.gate(x)
        t_160: "f32[8, 16384]" = torch.ops.aten.t.default(_softmax_backward_data_3)
        mm_104: "f32[8, 256]" = torch.ops.aten.mm.default(t_160, view_51);  t_160 = view_51 = None
        t_161: "f32[256, 8]" = torch.ops.aten.t.default(mm_104);  mm_104 = None
        t_162: "f32[8, 256]" = torch.ops.aten.t.default(t_19);  t_19 = None
        mm_105: "f32[16384, 256]" = torch.ops.aten.mm.default(_softmax_backward_data_3, t_162);  _softmax_backward_data_3 = t_162 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:247 in forward, code: scores = self.gate(x)
        add_51: "f32[16384, 256]" = torch.ops.aten.add.Tensor(add_50, mm_105);  add_50 = mm_105 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:247 in forward, code: scores = self.gate(x)
        t_163: "f32[8, 256]" = torch.ops.aten.t.default(t_161);  t_161 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:415 in forward, code: x = x.view(-1, dim)
        view_189: "f32[8, 2048, 256]" = torch.ops.aten.view.default(add_51, [8, 2048, 256]);  add_51 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        detach_56: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(detach_15);  detach_15 = None
        _fused_rms_norm_backward_10 = torch.ops.aten._fused_rms_norm_backward.default(view_189, add_7, [256], detach_56, primals_32, [True, True]);  view_189 = add_7 = detach_56 = primals_32 = None
        getitem_149: "f32[8, 2048, 256]" = _fused_rms_norm_backward_10[0]
        getitem_150: "f32[256]" = _fused_rms_norm_backward_10[1];  _fused_rms_norm_backward_10 = None
        add_52: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(add_47, getitem_149);  add_47 = getitem_149 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:262 in forward, code: return self.wo(output)  # (bsz, seqlen, dim)
        view_190: "f32[16384, 256]" = torch.ops.aten.view.default(add_52, [16384, 256])
        t_164: "f32[256, 16384]" = torch.ops.aten.t.default(view_190)
        mm_106: "f32[256, 2048]" = torch.ops.aten.mm.default(t_164, view_50);  t_164 = view_50 = None
        t_165: "f32[2048, 256]" = torch.ops.aten.t.default(mm_106);  mm_106 = None
        t_166: "f32[256, 2048]" = torch.ops.aten.t.default(t_18);  t_18 = None
        mm_107: "f32[16384, 2048]" = torch.ops.aten.mm.default(view_190, t_166);  view_190 = t_166 = None
        view_191: "f32[8, 2048, 2048]" = torch.ops.aten.view.default(mm_107, [8, 2048, 2048]);  mm_107 = None
        t_167: "f32[256, 2048]" = torch.ops.aten.t.default(t_165);  t_165 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:261 in forward, code: output = output.view(bsz, seqlen, -1)  # (bsz, seqlen, n_heads * v_head_dim)
        view_192: "f32[8, 2048, 16, 128]" = torch.ops.aten.view.default(view_191, [8, 2048, 16, 128]);  view_191 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:258 in forward, code: output = output.transpose(
        transpose_99: "f32[8, 16, 2048, 128]" = torch.ops.aten.transpose.int(view_192, 1, 2);  view_192 = None
        
        # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1585 in flex_attention, code: out, lse, max_scores = flex_attention_hop(
        zeros_6: "f32[8, 16, 2048]" = torch.ops.aten.zeros.default([8, 16, 2048], dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        detach_57: "f32[8, 16, 2048, 128]" = torch.ops.aten.detach.default(detach_13);  detach_13 = None
        detach_58: "f32[8, 16, 2048]" = torch.ops.aten.detach.default(detach_14);  detach_14 = None
        fw_graph3 = self.fw_graph3
        joint_graph3 = self.joint_graph3
        mask_graph3 = self.mask_graph3
        _tensor_constant0_9: "i32[8, 2048]" = self._tensor_constant0
        flex_attention_backward_3 = torch.ops.higher_order.flex_attention_backward(transpose_11, transpose_12, transpose_13, detach_57, detach_58, transpose_99, zeros_6, fw_graph3, joint_graph3, (2048, 2048, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, 128, 128, mask_graph3), 0.07216878364870322, {'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (_tensor_constant0_9,));  transpose_11 = transpose_12 = transpose_13 = detach_57 = detach_58 = transpose_99 = zeros_6 = fw_graph3 = joint_graph3 = mask_graph3 = _tensor_constant0_9 = None
        getitem_151: "f32[8, 16, 2048, 192]" = flex_attention_backward_3[0]
        getitem_152: "f32[8, 16, 2048, 192]" = flex_attention_backward_3[1]
        getitem_153: "f32[8, 16, 2048, 128]" = flex_attention_backward_3[2];  flex_attention_backward_3 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:246 in forward, code: v = v.transpose(1, 2)  # (bsz, n_heads, seqlen, v_head_dim)
        transpose_100: "f32[8, 2048, 16, 128]" = torch.ops.aten.transpose.int(getitem_153, 1, 2);  getitem_153 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:245 in forward, code: k = k.transpose(1, 2)  # (bsz, n_heads, seqlen, qk_head_dim)
        transpose_101: "f32[8, 2048, 16, 192]" = torch.ops.aten.transpose.int(getitem_152, 1, 2);  getitem_152 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:244 in forward, code: q = q.transpose(1, 2)  # (bsz, n_heads, seqlen, qk_head_dim)
        transpose_102: "f32[8, 2048, 16, 192]" = torch.ops.aten.transpose.int(getitem_151, 1, 2);  getitem_151 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:240 in forward, code: k = torch.cat(
        slice_31: "f32[8, 2048, 16, 128]" = torch.ops.aten.slice.Tensor(transpose_101, 3, 0, 128)
        slice_32: "f32[8, 2048, 16, 64]" = torch.ops.aten.slice.Tensor(transpose_101, 3, 128, 192);  transpose_101 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:241 in forward, code: [k_nope, k_pe.expand(-1, -1, self.n_heads, -1)], dim=-1
        sum_13: "f32[8, 2048, 1, 64]" = torch.ops.aten.sum.dim_IntList(slice_32, [2], True);  slice_32 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:239 in forward, code: k_nope, v = torch.split(kv, [self.qk_nope_head_dim, self.v_head_dim], dim=-1)
        cat_26: "f32[8, 2048, 16, 256]" = torch.ops.aten.cat.default([slice_31, transpose_100], 3);  slice_31 = transpose_100 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:238 in forward, code: kv = kv.view(bsz, seqlen, -1, self.qk_nope_head_dim + self.v_head_dim)
        view_193: "f32[8, 2048, 4096]" = torch.ops.aten.view.default(cat_26, [8, 2048, 4096]);  cat_26 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:235 in forward, code: kv = self.wkv_b(
        view_194: "f32[16384, 4096]" = torch.ops.aten.view.default(view_193, [16384, 4096]);  view_193 = None
        t_168: "f32[4096, 16384]" = torch.ops.aten.t.default(view_194)
        mm_108: "f32[4096, 512]" = torch.ops.aten.mm.default(t_168, view_47);  t_168 = view_47 = None
        t_169: "f32[512, 4096]" = torch.ops.aten.t.default(mm_108);  mm_108 = None
        t_170: "f32[4096, 512]" = torch.ops.aten.t.default(t_17);  t_17 = None
        mm_109: "f32[16384, 512]" = torch.ops.aten.mm.default(view_194, t_170);  view_194 = t_170 = None
        view_195: "f32[8, 2048, 512]" = torch.ops.aten.view.default(mm_109, [8, 2048, 512]);  mm_109 = None
        t_171: "f32[4096, 512]" = torch.ops.aten.t.default(t_169);  t_169 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        detach_59: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(detach_12);  detach_12 = None
        _fused_rms_norm_backward_11 = torch.ops.aten._fused_rms_norm_backward.default(view_195, getitem_39, [512], detach_59, primals_28, [True, True]);  view_195 = getitem_39 = detach_59 = primals_28 = None
        getitem_155: "f32[8, 2048, 512]" = _fused_rms_norm_backward_11[0]
        getitem_156: "f32[512]" = _fused_rms_norm_backward_11[1];  _fused_rms_norm_backward_11 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:143 in apply_rotary_emb, code: y = torch.view_as_real(x * freqs_cis).flatten(3)
        view_196: "f32[8, 2048, 1, 32, 2]" = torch.ops.aten.view.default(sum_13, [8, 2048, 1, 32, 2]);  sum_13 = None
        view_as_complex_18: "c64[8, 2048, 1, 32]" = torch.ops.aten.view_as_complex.default(view_196);  view_196 = None
        _conj_6: "c64[1, 2048, 1, 32]" = torch.ops.aten._conj.default(view_45);  view_45 = None
        clone_9: "c64[1, 2048, 1, 32]" = torch.ops.aten.clone.default(_conj_6);  _conj_6 = None
        mul_72: "c64[8, 2048, 1, 32]" = torch.ops.aten.mul.Tensor(view_as_complex_18, clone_9);  view_as_complex_18 = clone_9 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:141 in apply_rotary_emb, code: x = torch.view_as_complex(x.float().view(*x.shape[:-1], -1, 2))
        view_as_real_18: "f32[8, 2048, 1, 32, 2]" = torch.ops.aten.view_as_real.default(mul_72);  mul_72 = None
        view_197: "f32[8, 2048, 1, 64]" = torch.ops.aten.view.default(view_as_real_18, [8, 2048, 1, 64]);  view_as_real_18 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:232 in forward, code: k_pe.unsqueeze(2), freqs_cis
        squeeze_3: "f32[8, 2048, 64]" = torch.ops.aten.squeeze.dim(view_197, 2);  view_197 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:229 in forward, code: kv, k_pe = torch.split(kv, [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1)
        cat_27: "f32[8, 2048, 576]" = torch.ops.aten.cat.default([getitem_155, squeeze_3], 2);  getitem_155 = squeeze_3 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:228 in forward, code: kv = self.wkv_a(x)  # (bsz, seqlen, kv_lora_rank + qk_rope_head_dim)
        view_198: "f32[16384, 576]" = torch.ops.aten.view.default(cat_27, [16384, 576]);  cat_27 = None
        t_172: "f32[576, 16384]" = torch.ops.aten.t.default(view_198)
        mm_110: "f32[576, 256]" = torch.ops.aten.mm.default(t_172, view_43);  t_172 = view_43 = None
        t_173: "f32[256, 576]" = torch.ops.aten.t.default(mm_110);  mm_110 = None
        t_174: "f32[576, 256]" = torch.ops.aten.t.default(t_16);  t_16 = None
        mm_111: "f32[16384, 256]" = torch.ops.aten.mm.default(view_198, t_174);  view_198 = t_174 = None
        view_199: "f32[8, 2048, 256]" = torch.ops.aten.view.default(mm_111, [8, 2048, 256]);  mm_111 = None
        t_175: "f32[576, 256]" = torch.ops.aten.t.default(t_173);  t_173 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:225 in forward, code: q = torch.cat([q_nope, q_pe], dim=-1)  # (bsz, seqlen, n_heads, qk_head_dim)
        slice_33: "f32[8, 2048, 16, 128]" = torch.ops.aten.slice.Tensor(transpose_102, 3, 0, 128)
        slice_34: "f32[8, 2048, 16, 64]" = torch.ops.aten.slice.Tensor(transpose_102, 3, 128, 192);  transpose_102 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:143 in apply_rotary_emb, code: y = torch.view_as_real(x * freqs_cis).flatten(3)
        view_200: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.view.default(slice_34, [8, 2048, 16, 32, 2]);  slice_34 = None
        clone_10: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.clone.default(view_200, memory_format = torch.contiguous_format);  view_200 = None
        view_as_complex_19: "c64[8, 2048, 16, 32]" = torch.ops.aten.view_as_complex.default(clone_10);  clone_10 = None
        _conj_7: "c64[1, 2048, 1, 32]" = torch.ops.aten._conj.default(view_41);  view_41 = None
        clone_11: "c64[1, 2048, 1, 32]" = torch.ops.aten.clone.default(_conj_7);  _conj_7 = None
        mul_73: "c64[8, 2048, 16, 32]" = torch.ops.aten.mul.Tensor(view_as_complex_19, clone_11);  view_as_complex_19 = clone_11 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:141 in apply_rotary_emb, code: x = torch.view_as_complex(x.float().view(*x.shape[:-1], -1, 2))
        view_as_real_19: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.view_as_real.default(mul_73);  mul_73 = None
        view_201: "f32[8, 2048, 16, 64]" = torch.ops.aten.view.default(view_as_real_19, [8, 2048, 16, 64]);  view_as_real_19 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:221 in forward, code: q_nope, q_pe = torch.split(
        cat_28: "f32[8, 2048, 16, 192]" = torch.ops.aten.cat.default([slice_33, view_201], 3);  slice_33 = view_201 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:220 in forward, code: q = q.view(bsz, seqlen, -1, self.qk_head_dim)
        view_202: "f32[8, 2048, 3072]" = torch.ops.aten.view.default(cat_28, [8, 2048, 3072]);  cat_28 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:213 in forward, code: q = self.wq(x)  # (bsz, seqlen, n_heads * qk_head_dim)
        view_203: "f32[16384, 3072]" = torch.ops.aten.view.default(view_202, [16384, 3072]);  view_202 = None
        t_176: "f32[3072, 16384]" = torch.ops.aten.t.default(view_203)
        mm_112: "f32[3072, 256]" = torch.ops.aten.mm.default(t_176, view_38);  t_176 = view_38 = None
        t_177: "f32[256, 3072]" = torch.ops.aten.t.default(mm_112);  mm_112 = None
        t_178: "f32[3072, 256]" = torch.ops.aten.t.default(t_15);  t_15 = None
        mm_113: "f32[16384, 256]" = torch.ops.aten.mm.default(view_203, t_178);  view_203 = t_178 = None
        view_204: "f32[8, 2048, 256]" = torch.ops.aten.view.default(mm_113, [8, 2048, 256]);  mm_113 = None
        add_53: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(view_199, view_204);  view_199 = view_204 = None
        t_179: "f32[3072, 256]" = torch.ops.aten.t.default(t_177);  t_177 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        detach_60: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(detach_11);  detach_11 = None
        _fused_rms_norm_backward_12 = torch.ops.aten._fused_rms_norm_backward.default(add_53, add_6, [256], detach_60, primals_31, [True, True]);  add_53 = add_6 = detach_60 = primals_31 = None
        getitem_157: "f32[8, 2048, 256]" = _fused_rms_norm_backward_12[0]
        getitem_158: "f32[256]" = _fused_rms_norm_backward_12[1];  _fused_rms_norm_backward_12 = None
        add_54: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(add_52, getitem_157);  add_52 = getitem_157 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:481 in forward, code: out = out.reshape(bs, slen, dim)
        view_205: "f32[16384, 256]" = torch.ops.aten.view.default(add_54, [16384, 256])
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:478 in forward, code: out = out.scatter_add(
        gather_14: "f32[49152, 256]" = torch.ops.aten.gather.default(view_205, 0, expand_2)
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:474 in forward, code: routed_output.to(torch.float32)
        mul_74: "f32[49152, 256]" = torch.ops.aten.mul.Tensor(gather_14, slice_2);  slice_2 = None
        mul_75: "f32[49152, 256]" = torch.ops.aten.mul.Tensor(gather_14, view_36);  gather_14 = view_36 = None
        sum_14: "f32[49152, 1]" = torch.ops.aten.sum.dim_IntList(mul_74, [1], True);  mul_74 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:475 in forward, code: * top_scores_experts_sorted.reshape(-1, 1)
        view_206: "f32[49152]" = torch.ops.aten.view.default(sum_14, [49152]);  sum_14 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:62 in forward, code: return self.w2(F.silu(self.w1(x)) * self.w3(x))
        t_180: "f32[256, 16384]" = torch.ops.aten.t.default(view_205)
        mm_114: "f32[256, 512]" = torch.ops.aten.mm.default(t_180, mul_8);  t_180 = mul_8 = None
        t_181: "f32[512, 256]" = torch.ops.aten.t.default(mm_114);  mm_114 = None
        t_182: "f32[256, 512]" = torch.ops.aten.t.default(t_14);  t_14 = None
        mm_115: "f32[16384, 512]" = torch.ops.aten.mm.default(view_205, t_182);  view_205 = t_182 = None
        t_183: "f32[256, 512]" = torch.ops.aten.t.default(t_181);  t_181 = None
        mul_76: "f32[16384, 512]" = torch.ops.aten.mul.Tensor(mm_115, silu_2);  silu_2 = None
        mul_77: "f32[16384, 512]" = torch.ops.aten.mul.Tensor(mm_115, mm_13);  mm_115 = mm_13 = None
        t_184: "f32[512, 16384]" = torch.ops.aten.t.default(mul_76)
        mm_116: "f32[512, 256]" = torch.ops.aten.mm.default(t_184, view_29);  t_184 = None
        t_185: "f32[256, 512]" = torch.ops.aten.t.default(mm_116);  mm_116 = None
        t_186: "f32[512, 256]" = torch.ops.aten.t.default(t_13);  t_13 = None
        mm_117: "f32[16384, 256]" = torch.ops.aten.mm.default(mul_76, t_186);  mul_76 = t_186 = None
        t_187: "f32[512, 256]" = torch.ops.aten.t.default(t_185);  t_185 = None
        silu_backward_8: "f32[16384, 512]" = torch.ops.aten.silu_backward.default(mul_77, mm_12);  mul_77 = mm_12 = None
        t_188: "f32[512, 16384]" = torch.ops.aten.t.default(silu_backward_8)
        mm_118: "f32[512, 256]" = torch.ops.aten.mm.default(t_188, view_29);  t_188 = None
        t_189: "f32[256, 512]" = torch.ops.aten.t.default(mm_118);  mm_118 = None
        t_190: "f32[512, 256]" = torch.ops.aten.t.default(t_12);  t_12 = None
        mm_119: "f32[16384, 256]" = torch.ops.aten.mm.default(silu_backward_8, t_190);  silu_backward_8 = t_190 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:62 in forward, code: return self.w2(F.silu(self.w1(x)) * self.w3(x))
        add_55: "f32[16384, 256]" = torch.ops.aten.add.Tensor(mm_117, mm_119);  mm_117 = mm_119 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:62 in forward, code: return self.w2(F.silu(self.w1(x)) * self.w3(x))
        t_191: "f32[512, 256]" = torch.ops.aten.t.default(t_189);  t_189 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:65 in _unpermute, code: out = out_unpermuted[:-1]
        slice_backward_4: "f32[49153, 256]" = torch.ops.aten.slice_backward.default(mul_75, [49153, 256], 0, 0, -1, 1);  mul_75 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:64 in _unpermute, code: out_unpermuted[permuted_indices, :] = out
        index_14: "f32[49216, 256]" = torch.ops.aten.index.Tensor(slice_backward_4, [getitem_34]);  slice_backward_4 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:122 in _run_experts_grouped_mm, code: out = torch._grouped_mm(h, w2.bfloat16().transpose(-2, -1), offs=offsets).type_as(x)
        _to_copy_64: "bf16[49216, 256]" = torch.ops.aten._to_copy.default(index_14, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0));  index_14 = None
        transpose_103: "bf16[256, 49216]" = torch.ops.aten.transpose.int(_to_copy_64, -2, -1)
        _grouped_mm_39: "bf16[8, 256, 256]" = torch.ops.aten._grouped_mm.default(transpose_103, mul_7, cumsum_2);  transpose_103 = mul_7 = None
        transpose_104: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_grouped_mm_39, -2, -1);  _grouped_mm_39 = None
        transpose_105: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_10, -2, -1);  transpose_10 = None
        _grouped_mm_40: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(_to_copy_64, transpose_105, cumsum_2);  _to_copy_64 = transpose_105 = None
        transpose_106: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_104, -2, -1);  transpose_104 = None
        _to_copy_65: "f32[8, 256, 256]" = torch.ops.aten._to_copy.default(transpose_106, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  transpose_106 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:119 in _run_experts_grouped_mm, code: h = h * torch._grouped_mm(
        mul_78: "bf16[49216, 256]" = torch.ops.aten.mul.Tensor(_grouped_mm_40, silu_1);  silu_1 = None
        mul_79: "bf16[49216, 256]" = torch.ops.aten.mul.Tensor(_grouped_mm_40, _grouped_mm_1);  _grouped_mm_40 = _grouped_mm_1 = None
        transpose_107: "bf16[256, 49216]" = torch.ops.aten.transpose.int(mul_78, -2, -1)
        _grouped_mm_41: "bf16[8, 256, 256]" = torch.ops.aten._grouped_mm.default(transpose_107, _to_copy_4, cumsum_2);  transpose_107 = _to_copy_4 = None
        transpose_108: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_grouped_mm_41, -2, -1);  _grouped_mm_41 = None
        transpose_109: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_9, -2, -1);  transpose_9 = None
        _grouped_mm_42: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(mul_78, transpose_109, cumsum_2);  mul_78 = transpose_109 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:120 in _run_experts_grouped_mm, code: x.bfloat16(), w3.bfloat16().transpose(-2, -1), offs=offsets
        transpose_110: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_108, -2, -1);  transpose_108 = None
        _to_copy_66: "f32[8, 256, 256]" = torch.ops.aten._to_copy.default(transpose_110, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  transpose_110 = None
        _to_copy_67: "f32[49216, 256]" = torch.ops.aten._to_copy.default(_grouped_mm_42, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  _grouped_mm_42 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:116 in _run_experts_grouped_mm, code: h = F.silu(
        silu_backward_9: "bf16[49216, 256]" = torch.ops.aten.silu_backward.default(mul_79, _grouped_mm);  mul_79 = _grouped_mm = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:117 in _run_experts_grouped_mm, code: torch._grouped_mm(x.bfloat16(), w1.bfloat16().transpose(-2, -1), offs=offsets)
        transpose_111: "bf16[256, 49216]" = torch.ops.aten.transpose.int(silu_backward_9, -2, -1)
        _grouped_mm_43: "bf16[8, 256, 256]" = torch.ops.aten._grouped_mm.default(transpose_111, _to_copy_2, cumsum_2);  transpose_111 = _to_copy_2 = None
        transpose_112: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(_grouped_mm_43, -2, -1);  _grouped_mm_43 = None
        transpose_113: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_8, -2, -1);  transpose_8 = None
        _grouped_mm_44: "bf16[49216, 256]" = torch.ops.aten._grouped_mm.default(silu_backward_9, transpose_113, cumsum_2);  silu_backward_9 = transpose_113 = cumsum_2 = None
        transpose_114: "bf16[8, 256, 256]" = torch.ops.aten.transpose.int(transpose_112, -2, -1);  transpose_112 = None
        _to_copy_68: "f32[8, 256, 256]" = torch.ops.aten._to_copy.default(transpose_114, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  transpose_114 = None
        _to_copy_69: "f32[49216, 256]" = torch.ops.aten._to_copy.default(_grouped_mm_44, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0));  _grouped_mm_44 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:117 in _run_experts_grouped_mm, code: torch._grouped_mm(x.bfloat16(), w1.bfloat16().transpose(-2, -1), offs=offsets)
        add_56: "f32[49216, 256]" = torch.ops.aten.add.Tensor(_to_copy_67, _to_copy_69);  _to_copy_67 = _to_copy_69 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:57 in _permute, code: x = x[permuted_indices, :]
        new_zeros_81: "f32[49153, 256]" = torch.ops.aten.new_zeros.default(add_56, [49153, 256], dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        index_put_13: "f32[49153, 256]" = torch.ops.aten.index_put.default(new_zeros_81, [getitem_34], add_56, True);  new_zeros_81 = getitem_34 = add_56 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/utils.py:55 in _permute, code: x = torch.vstack((x, x.new_zeros((x.shape[-1]))))
        slice_35: "f32[49152, 256]" = torch.ops.aten.slice.Tensor(index_put_13, 0, 0, 49152);  index_put_13 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:453 in forward, code: routed_input = torch.gather(x, dim=0, index=token_indices_experts_sorted)
        new_zeros_82: "f32[16384, 256]" = torch.ops.aten.new_zeros.default(slice_35, [16384, 256])
        scatter_add_13: "f32[16384, 256]" = torch.ops.aten.scatter_add.default(new_zeros_82, 0, expand_2, slice_35);  new_zeros_82 = expand_2 = slice_35 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:453 in forward, code: routed_input = torch.gather(x, dim=0, index=token_indices_experts_sorted)
        add_57: "f32[16384, 256]" = torch.ops.aten.add.Tensor(add_55, scatter_add_13);  add_55 = scatter_add_13 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:347 in forward, code: top_scores_experts_sorted = top_scores.view(-1)[token_indices_experts_sorted]
        new_zeros_83: "f32[49152]" = torch.ops.aten.new_zeros.default(view_206, [49152], dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        index_put_14: "f32[49152]" = torch.ops.aten.index_put.default(new_zeros_83, [getitem_33], view_206, True);  new_zeros_83 = getitem_33 = view_206 = None
        view_207: "f32[16384, 3]" = torch.ops.aten.view.default(index_put_14, [16384, 3]);  index_put_14 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:280 in forward, code: top_scores = top_scores * self.route_scale
        mul_80: "f32[16384, 3]" = torch.ops.aten.mul.Tensor(view_207, 1.0);  view_207 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:264 in forward, code: top_scores = scores.gather(dim=1, index=selected_experts_indices)
        new_zeros_84: "f32[16384, 8]" = torch.ops.aten.new_zeros.default(mul_80, [16384, 8])
        scatter_add_14: "f32[16384, 8]" = torch.ops.aten.scatter_add.default(new_zeros_84, 1, getitem_31, mul_80);  new_zeros_84 = getitem_31 = mul_80 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:253 in forward, code: scores = F.softmax(scores.to(torch.float32), dim=1)
        detach_61: "f32[16384, 8]" = torch.ops.aten.detach.default(detach_10);  detach_10 = None
        _softmax_backward_data_4: "f32[16384, 8]" = torch.ops.aten._softmax_backward_data.default(scatter_add_14, detach_61, 1, torch.float32);  scatter_add_14 = detach_61 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:247 in forward, code: scores = self.gate(x)
        t_192: "f32[8, 16384]" = torch.ops.aten.t.default(_softmax_backward_data_4)
        mm_120: "f32[8, 256]" = torch.ops.aten.mm.default(t_192, view_29);  t_192 = view_29 = None
        t_193: "f32[256, 8]" = torch.ops.aten.t.default(mm_120);  mm_120 = None
        t_194: "f32[8, 256]" = torch.ops.aten.t.default(t_11);  t_11 = None
        mm_121: "f32[16384, 256]" = torch.ops.aten.mm.default(_softmax_backward_data_4, t_194);  _softmax_backward_data_4 = t_194 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:247 in forward, code: scores = self.gate(x)
        add_58: "f32[16384, 256]" = torch.ops.aten.add.Tensor(add_57, mm_121);  add_57 = mm_121 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:247 in forward, code: scores = self.gate(x)
        t_195: "f32[8, 256]" = torch.ops.aten.t.default(t_193);  t_193 = None
        
        # Annotation: {'EP': 'compute'} File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:415 in forward, code: x = x.view(-1, dim)
        view_208: "f32[8, 2048, 256]" = torch.ops.aten.view.default(add_58, [8, 2048, 256]);  add_58 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        detach_62: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(detach_9);  detach_9 = None
        _fused_rms_norm_backward_13 = torch.ops.aten._fused_rms_norm_backward.default(view_208, add_2, [256], detach_62, primals_18, [True, True]);  view_208 = add_2 = detach_62 = primals_18 = None
        getitem_159: "f32[8, 2048, 256]" = _fused_rms_norm_backward_13[0]
        getitem_160: "f32[256]" = _fused_rms_norm_backward_13[1];  _fused_rms_norm_backward_13 = None
        add_59: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(add_54, getitem_159);  add_54 = getitem_159 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:262 in forward, code: return self.wo(output)  # (bsz, seqlen, dim)
        view_209: "f32[16384, 256]" = torch.ops.aten.view.default(add_59, [16384, 256])
        t_196: "f32[256, 16384]" = torch.ops.aten.t.default(view_209)
        mm_122: "f32[256, 2048]" = torch.ops.aten.mm.default(t_196, view_28);  t_196 = view_28 = None
        t_197: "f32[2048, 256]" = torch.ops.aten.t.default(mm_122);  mm_122 = None
        t_198: "f32[256, 2048]" = torch.ops.aten.t.default(t_10);  t_10 = None
        mm_123: "f32[16384, 2048]" = torch.ops.aten.mm.default(view_209, t_198);  view_209 = t_198 = None
        view_210: "f32[8, 2048, 2048]" = torch.ops.aten.view.default(mm_123, [8, 2048, 2048]);  mm_123 = None
        t_199: "f32[256, 2048]" = torch.ops.aten.t.default(t_197);  t_197 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:261 in forward, code: output = output.view(bsz, seqlen, -1)  # (bsz, seqlen, n_heads * v_head_dim)
        view_211: "f32[8, 2048, 16, 128]" = torch.ops.aten.view.default(view_210, [8, 2048, 16, 128]);  view_210 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:258 in forward, code: output = output.transpose(
        transpose_115: "f32[8, 16, 2048, 128]" = torch.ops.aten.transpose.int(view_211, 1, 2);  view_211 = None
        
        # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1585 in flex_attention, code: out, lse, max_scores = flex_attention_hop(
        zeros_8: "f32[8, 16, 2048]" = torch.ops.aten.zeros.default([8, 16, 2048], dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        detach_63: "f32[8, 16, 2048, 128]" = torch.ops.aten.detach.default(detach_7);  detach_7 = None
        detach_64: "f32[8, 16, 2048]" = torch.ops.aten.detach.default(detach_8);  detach_8 = None
        fw_graph4 = self.fw_graph4
        joint_graph4 = self.joint_graph4
        mask_graph4 = self.mask_graph4
        _tensor_constant0_10: "i32[8, 2048]" = self._tensor_constant0
        flex_attention_backward_4 = torch.ops.higher_order.flex_attention_backward(transpose_4, transpose_5, transpose_6, detach_63, detach_64, transpose_115, zeros_8, fw_graph4, joint_graph4, (2048, 2048, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, 128, 128, mask_graph4), 0.07216878364870322, {'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (_tensor_constant0_10,));  transpose_4 = transpose_5 = transpose_6 = detach_63 = detach_64 = transpose_115 = zeros_8 = fw_graph4 = joint_graph4 = mask_graph4 = _tensor_constant0_10 = None
        getitem_161: "f32[8, 16, 2048, 192]" = flex_attention_backward_4[0]
        getitem_162: "f32[8, 16, 2048, 192]" = flex_attention_backward_4[1]
        getitem_163: "f32[8, 16, 2048, 128]" = flex_attention_backward_4[2];  flex_attention_backward_4 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:246 in forward, code: v = v.transpose(1, 2)  # (bsz, n_heads, seqlen, v_head_dim)
        transpose_116: "f32[8, 2048, 16, 128]" = torch.ops.aten.transpose.int(getitem_163, 1, 2);  getitem_163 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:245 in forward, code: k = k.transpose(1, 2)  # (bsz, n_heads, seqlen, qk_head_dim)
        transpose_117: "f32[8, 2048, 16, 192]" = torch.ops.aten.transpose.int(getitem_162, 1, 2);  getitem_162 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:244 in forward, code: q = q.transpose(1, 2)  # (bsz, n_heads, seqlen, qk_head_dim)
        transpose_118: "f32[8, 2048, 16, 192]" = torch.ops.aten.transpose.int(getitem_161, 1, 2);  getitem_161 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:240 in forward, code: k = torch.cat(
        slice_37: "f32[8, 2048, 16, 128]" = torch.ops.aten.slice.Tensor(transpose_117, 3, 0, 128)
        slice_38: "f32[8, 2048, 16, 64]" = torch.ops.aten.slice.Tensor(transpose_117, 3, 128, 192);  transpose_117 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:241 in forward, code: [k_nope, k_pe.expand(-1, -1, self.n_heads, -1)], dim=-1
        sum_15: "f32[8, 2048, 1, 64]" = torch.ops.aten.sum.dim_IntList(slice_38, [2], True);  slice_38 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:239 in forward, code: k_nope, v = torch.split(kv, [self.qk_nope_head_dim, self.v_head_dim], dim=-1)
        cat_29: "f32[8, 2048, 16, 256]" = torch.ops.aten.cat.default([slice_37, transpose_116], 3);  slice_37 = transpose_116 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:238 in forward, code: kv = kv.view(bsz, seqlen, -1, self.qk_nope_head_dim + self.v_head_dim)
        view_212: "f32[8, 2048, 4096]" = torch.ops.aten.view.default(cat_29, [8, 2048, 4096]);  cat_29 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:235 in forward, code: kv = self.wkv_b(
        view_213: "f32[16384, 4096]" = torch.ops.aten.view.default(view_212, [16384, 4096]);  view_212 = None
        t_200: "f32[4096, 16384]" = torch.ops.aten.t.default(view_213)
        mm_124: "f32[4096, 512]" = torch.ops.aten.mm.default(t_200, view_25);  t_200 = view_25 = None
        t_201: "f32[512, 4096]" = torch.ops.aten.t.default(mm_124);  mm_124 = None
        t_202: "f32[4096, 512]" = torch.ops.aten.t.default(t_9);  t_9 = None
        mm_125: "f32[16384, 512]" = torch.ops.aten.mm.default(view_213, t_202);  view_213 = t_202 = None
        view_214: "f32[8, 2048, 512]" = torch.ops.aten.view.default(mm_125, [8, 2048, 512]);  mm_125 = None
        t_203: "f32[4096, 512]" = torch.ops.aten.t.default(t_201);  t_201 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        detach_65: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(detach_6);  detach_6 = None
        _fused_rms_norm_backward_14 = torch.ops.aten._fused_rms_norm_backward.default(view_214, getitem_19, [512], detach_65, primals_14, [True, True]);  view_214 = getitem_19 = detach_65 = primals_14 = None
        getitem_165: "f32[8, 2048, 512]" = _fused_rms_norm_backward_14[0]
        getitem_166: "f32[512]" = _fused_rms_norm_backward_14[1];  _fused_rms_norm_backward_14 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:143 in apply_rotary_emb, code: y = torch.view_as_real(x * freqs_cis).flatten(3)
        view_215: "f32[8, 2048, 1, 32, 2]" = torch.ops.aten.view.default(sum_15, [8, 2048, 1, 32, 2]);  sum_15 = None
        view_as_complex_20: "c64[8, 2048, 1, 32]" = torch.ops.aten.view_as_complex.default(view_215);  view_215 = None
        _conj_8: "c64[1, 2048, 1, 32]" = torch.ops.aten._conj.default(view_23);  view_23 = None
        clone_12: "c64[1, 2048, 1, 32]" = torch.ops.aten.clone.default(_conj_8);  _conj_8 = None
        mul_81: "c64[8, 2048, 1, 32]" = torch.ops.aten.mul.Tensor(view_as_complex_20, clone_12);  view_as_complex_20 = clone_12 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:141 in apply_rotary_emb, code: x = torch.view_as_complex(x.float().view(*x.shape[:-1], -1, 2))
        view_as_real_20: "f32[8, 2048, 1, 32, 2]" = torch.ops.aten.view_as_real.default(mul_81);  mul_81 = None
        view_216: "f32[8, 2048, 1, 64]" = torch.ops.aten.view.default(view_as_real_20, [8, 2048, 1, 64]);  view_as_real_20 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:232 in forward, code: k_pe.unsqueeze(2), freqs_cis
        squeeze_4: "f32[8, 2048, 64]" = torch.ops.aten.squeeze.dim(view_216, 2);  view_216 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:229 in forward, code: kv, k_pe = torch.split(kv, [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1)
        cat_30: "f32[8, 2048, 576]" = torch.ops.aten.cat.default([getitem_165, squeeze_4], 2);  getitem_165 = squeeze_4 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:228 in forward, code: kv = self.wkv_a(x)  # (bsz, seqlen, kv_lora_rank + qk_rope_head_dim)
        view_217: "f32[16384, 576]" = torch.ops.aten.view.default(cat_30, [16384, 576]);  cat_30 = None
        t_204: "f32[576, 16384]" = torch.ops.aten.t.default(view_217)
        mm_126: "f32[576, 256]" = torch.ops.aten.mm.default(t_204, view_21);  t_204 = view_21 = None
        t_205: "f32[256, 576]" = torch.ops.aten.t.default(mm_126);  mm_126 = None
        t_206: "f32[576, 256]" = torch.ops.aten.t.default(t_8);  t_8 = None
        mm_127: "f32[16384, 256]" = torch.ops.aten.mm.default(view_217, t_206);  view_217 = t_206 = None
        view_218: "f32[8, 2048, 256]" = torch.ops.aten.view.default(mm_127, [8, 2048, 256]);  mm_127 = None
        t_207: "f32[576, 256]" = torch.ops.aten.t.default(t_205);  t_205 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:225 in forward, code: q = torch.cat([q_nope, q_pe], dim=-1)  # (bsz, seqlen, n_heads, qk_head_dim)
        slice_39: "f32[8, 2048, 16, 128]" = torch.ops.aten.slice.Tensor(transpose_118, 3, 0, 128)
        slice_40: "f32[8, 2048, 16, 64]" = torch.ops.aten.slice.Tensor(transpose_118, 3, 128, 192);  transpose_118 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:143 in apply_rotary_emb, code: y = torch.view_as_real(x * freqs_cis).flatten(3)
        view_219: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.view.default(slice_40, [8, 2048, 16, 32, 2]);  slice_40 = None
        clone_13: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.clone.default(view_219, memory_format = torch.contiguous_format);  view_219 = None
        view_as_complex_21: "c64[8, 2048, 16, 32]" = torch.ops.aten.view_as_complex.default(clone_13);  clone_13 = None
        _conj_9: "c64[1, 2048, 1, 32]" = torch.ops.aten._conj.default(view_19);  view_19 = None
        clone_14: "c64[1, 2048, 1, 32]" = torch.ops.aten.clone.default(_conj_9);  _conj_9 = None
        mul_82: "c64[8, 2048, 16, 32]" = torch.ops.aten.mul.Tensor(view_as_complex_21, clone_14);  view_as_complex_21 = clone_14 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:141 in apply_rotary_emb, code: x = torch.view_as_complex(x.float().view(*x.shape[:-1], -1, 2))
        view_as_real_21: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.view_as_real.default(mul_82);  mul_82 = None
        view_220: "f32[8, 2048, 16, 64]" = torch.ops.aten.view.default(view_as_real_21, [8, 2048, 16, 64]);  view_as_real_21 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:221 in forward, code: q_nope, q_pe = torch.split(
        cat_31: "f32[8, 2048, 16, 192]" = torch.ops.aten.cat.default([slice_39, view_220], 3);  slice_39 = view_220 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:220 in forward, code: q = q.view(bsz, seqlen, -1, self.qk_head_dim)
        view_221: "f32[8, 2048, 3072]" = torch.ops.aten.view.default(cat_31, [8, 2048, 3072]);  cat_31 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:213 in forward, code: q = self.wq(x)  # (bsz, seqlen, n_heads * qk_head_dim)
        view_222: "f32[16384, 3072]" = torch.ops.aten.view.default(view_221, [16384, 3072]);  view_221 = None
        t_208: "f32[3072, 16384]" = torch.ops.aten.t.default(view_222)
        mm_128: "f32[3072, 256]" = torch.ops.aten.mm.default(t_208, view_16);  t_208 = view_16 = None
        t_209: "f32[256, 3072]" = torch.ops.aten.t.default(mm_128);  mm_128 = None
        t_210: "f32[3072, 256]" = torch.ops.aten.t.default(t_7);  t_7 = None
        mm_129: "f32[16384, 256]" = torch.ops.aten.mm.default(view_222, t_210);  view_222 = t_210 = None
        view_223: "f32[8, 2048, 256]" = torch.ops.aten.view.default(mm_129, [8, 2048, 256]);  mm_129 = None
        add_60: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(view_218, view_223);  view_218 = view_223 = None
        t_211: "f32[3072, 256]" = torch.ops.aten.t.default(t_209);  t_209 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        detach_66: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(detach_5);  detach_5 = None
        _fused_rms_norm_backward_15 = torch.ops.aten._fused_rms_norm_backward.default(add_60, add_1, [256], detach_66, primals_17, [True, True]);  add_60 = add_1 = detach_66 = primals_17 = None
        getitem_167: "f32[8, 2048, 256]" = _fused_rms_norm_backward_15[0]
        getitem_168: "f32[256]" = _fused_rms_norm_backward_15[1];  _fused_rms_norm_backward_15 = None
        add_61: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(add_59, getitem_167);  add_59 = getitem_167 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/moe/moe.py:62 in forward, code: return self.w2(F.silu(self.w1(x)) * self.w3(x))
        view_224: "f32[16384, 256]" = torch.ops.aten.view.default(add_61, [16384, 256])
        t_212: "f32[256, 16384]" = torch.ops.aten.t.default(view_224)
        mm_130: "f32[256, 1024]" = torch.ops.aten.mm.default(t_212, view_15);  t_212 = view_15 = None
        t_213: "f32[1024, 256]" = torch.ops.aten.t.default(mm_130);  mm_130 = None
        t_214: "f32[256, 1024]" = torch.ops.aten.t.default(t_6);  t_6 = None
        mm_131: "f32[16384, 1024]" = torch.ops.aten.mm.default(view_224, t_214);  view_224 = t_214 = None
        view_225: "f32[8, 2048, 1024]" = torch.ops.aten.view.default(mm_131, [8, 2048, 1024]);  mm_131 = None
        t_215: "f32[256, 1024]" = torch.ops.aten.t.default(t_213);  t_213 = None
        mul_83: "f32[8, 2048, 1024]" = torch.ops.aten.mul.Tensor(view_225, silu);  silu = None
        mul_84: "f32[8, 2048, 1024]" = torch.ops.aten.mul.Tensor(view_225, _unsafe_view_5);  view_225 = _unsafe_view_5 = None
        view_226: "f32[16384, 1024]" = torch.ops.aten.view.default(mul_83, [16384, 1024]);  mul_83 = None
        t_216: "f32[1024, 16384]" = torch.ops.aten.t.default(view_226)
        mm_132: "f32[1024, 256]" = torch.ops.aten.mm.default(t_216, view_14);  t_216 = view_14 = None
        t_217: "f32[256, 1024]" = torch.ops.aten.t.default(mm_132);  mm_132 = None
        t_218: "f32[1024, 256]" = torch.ops.aten.t.default(t_5);  t_5 = None
        mm_133: "f32[16384, 256]" = torch.ops.aten.mm.default(view_226, t_218);  view_226 = t_218 = None
        view_227: "f32[8, 2048, 256]" = torch.ops.aten.view.default(mm_133, [8, 2048, 256]);  mm_133 = None
        t_219: "f32[1024, 256]" = torch.ops.aten.t.default(t_217);  t_217 = None
        silu_backward_10: "f32[8, 2048, 1024]" = torch.ops.aten.silu_backward.default(mul_84, _unsafe_view_4);  mul_84 = _unsafe_view_4 = None
        view_228: "f32[16384, 1024]" = torch.ops.aten.view.default(silu_backward_10, [16384, 1024]);  silu_backward_10 = None
        t_220: "f32[1024, 16384]" = torch.ops.aten.t.default(view_228)
        mm_134: "f32[1024, 256]" = torch.ops.aten.mm.default(t_220, view_13);  t_220 = view_13 = None
        t_221: "f32[256, 1024]" = torch.ops.aten.t.default(mm_134);  mm_134 = None
        t_222: "f32[1024, 256]" = torch.ops.aten.t.default(t_4);  t_4 = None
        mm_135: "f32[16384, 256]" = torch.ops.aten.mm.default(view_228, t_222);  view_228 = t_222 = None
        view_229: "f32[8, 2048, 256]" = torch.ops.aten.view.default(mm_135, [8, 2048, 256]);  mm_135 = None
        add_62: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(view_227, view_229);  view_227 = view_229 = None
        t_223: "f32[1024, 256]" = torch.ops.aten.t.default(t_221);  t_221 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        detach_67: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(detach_4);  detach_4 = None
        _fused_rms_norm_backward_16 = torch.ops.aten._fused_rms_norm_backward.default(add_62, add, [256], detach_67, primals_8, [True, True]);  add_62 = add = detach_67 = primals_8 = None
        getitem_169: "f32[8, 2048, 256]" = _fused_rms_norm_backward_16[0]
        getitem_170: "f32[256]" = _fused_rms_norm_backward_16[1];  _fused_rms_norm_backward_16 = None
        add_63: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(add_61, getitem_169);  add_61 = getitem_169 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:262 in forward, code: return self.wo(output)  # (bsz, seqlen, dim)
        view_230: "f32[16384, 256]" = torch.ops.aten.view.default(add_63, [16384, 256])
        t_224: "f32[256, 16384]" = torch.ops.aten.t.default(view_230)
        mm_136: "f32[256, 2048]" = torch.ops.aten.mm.default(t_224, view_12);  t_224 = view_12 = None
        t_225: "f32[2048, 256]" = torch.ops.aten.t.default(mm_136);  mm_136 = None
        t_226: "f32[256, 2048]" = torch.ops.aten.t.default(t_3);  t_3 = None
        mm_137: "f32[16384, 2048]" = torch.ops.aten.mm.default(view_230, t_226);  view_230 = t_226 = None
        view_231: "f32[8, 2048, 2048]" = torch.ops.aten.view.default(mm_137, [8, 2048, 2048]);  mm_137 = None
        t_227: "f32[256, 2048]" = torch.ops.aten.t.default(t_225);  t_225 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:261 in forward, code: output = output.view(bsz, seqlen, -1)  # (bsz, seqlen, n_heads * v_head_dim)
        view_232: "f32[8, 2048, 16, 128]" = torch.ops.aten.view.default(view_231, [8, 2048, 16, 128]);  view_231 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:258 in forward, code: output = output.transpose(
        transpose_119: "f32[8, 16, 2048, 128]" = torch.ops.aten.transpose.int(view_232, 1, 2);  view_232 = None
        
        # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1585 in flex_attention, code: out, lse, max_scores = flex_attention_hop(
        zeros_10: "f32[8, 16, 2048]" = torch.ops.aten.zeros.default([8, 16, 2048], dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        detach_68: "f32[8, 16, 2048, 128]" = torch.ops.aten.detach.default(detach_2);  detach_2 = None
        detach_69: "f32[8, 16, 2048]" = torch.ops.aten.detach.default(detach_3);  detach_3 = None
        fw_graph5 = self.fw_graph5
        joint_graph5 = self.joint_graph5
        mask_graph5 = self.mask_graph5
        _tensor_constant0_11: "i32[8, 2048]" = self._tensor_constant0
        flex_attention_backward_5 = torch.ops.higher_order.flex_attention_backward(transpose, transpose_1, transpose_2, detach_68, detach_69, transpose_119, zeros_10, fw_graph5, joint_graph5, (2048, 2048, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, 128, 128, mask_graph5), 0.07216878364870322, {'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (_tensor_constant0_11,));  transpose = transpose_1 = transpose_2 = detach_68 = detach_69 = transpose_119 = zeros_10 = fw_graph5 = joint_graph5 = primals_96 = primals_97 = primals_98 = primals_99 = primals_100 = primals_101 = primals_102 = primals_103 = mask_graph5 = _tensor_constant0_11 = None
        getitem_171: "f32[8, 16, 2048, 192]" = flex_attention_backward_5[0]
        getitem_172: "f32[8, 16, 2048, 192]" = flex_attention_backward_5[1]
        getitem_173: "f32[8, 16, 2048, 128]" = flex_attention_backward_5[2];  flex_attention_backward_5 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:246 in forward, code: v = v.transpose(1, 2)  # (bsz, n_heads, seqlen, v_head_dim)
        transpose_120: "f32[8, 2048, 16, 128]" = torch.ops.aten.transpose.int(getitem_173, 1, 2);  getitem_173 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:245 in forward, code: k = k.transpose(1, 2)  # (bsz, n_heads, seqlen, qk_head_dim)
        transpose_121: "f32[8, 2048, 16, 192]" = torch.ops.aten.transpose.int(getitem_172, 1, 2);  getitem_172 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:244 in forward, code: q = q.transpose(1, 2)  # (bsz, n_heads, seqlen, qk_head_dim)
        transpose_122: "f32[8, 2048, 16, 192]" = torch.ops.aten.transpose.int(getitem_171, 1, 2);  getitem_171 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:240 in forward, code: k = torch.cat(
        slice_41: "f32[8, 2048, 16, 128]" = torch.ops.aten.slice.Tensor(transpose_121, 3, 0, 128)
        slice_42: "f32[8, 2048, 16, 64]" = torch.ops.aten.slice.Tensor(transpose_121, 3, 128, 192);  transpose_121 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:241 in forward, code: [k_nope, k_pe.expand(-1, -1, self.n_heads, -1)], dim=-1
        sum_16: "f32[8, 2048, 1, 64]" = torch.ops.aten.sum.dim_IntList(slice_42, [2], True);  slice_42 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:239 in forward, code: k_nope, v = torch.split(kv, [self.qk_nope_head_dim, self.v_head_dim], dim=-1)
        cat_32: "f32[8, 2048, 16, 256]" = torch.ops.aten.cat.default([slice_41, transpose_120], 3);  slice_41 = transpose_120 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:238 in forward, code: kv = kv.view(bsz, seqlen, -1, self.qk_nope_head_dim + self.v_head_dim)
        view_233: "f32[8, 2048, 4096]" = torch.ops.aten.view.default(cat_32, [8, 2048, 4096]);  cat_32 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:235 in forward, code: kv = self.wkv_b(
        view_234: "f32[16384, 4096]" = torch.ops.aten.view.default(view_233, [16384, 4096]);  view_233 = None
        t_228: "f32[4096, 16384]" = torch.ops.aten.t.default(view_234)
        mm_138: "f32[4096, 512]" = torch.ops.aten.mm.default(t_228, view_9);  t_228 = view_9 = None
        t_229: "f32[512, 4096]" = torch.ops.aten.t.default(mm_138);  mm_138 = None
        t_230: "f32[4096, 512]" = torch.ops.aten.t.default(t_2);  t_2 = None
        mm_139: "f32[16384, 512]" = torch.ops.aten.mm.default(view_234, t_230);  view_234 = t_230 = None
        view_235: "f32[8, 2048, 512]" = torch.ops.aten.view.default(mm_139, [8, 2048, 512]);  mm_139 = None
        t_231: "f32[4096, 512]" = torch.ops.aten.t.default(t_229);  t_229 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        detach_70: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(detach_1);  detach_1 = None
        _fused_rms_norm_backward_17 = torch.ops.aten._fused_rms_norm_backward.default(view_235, getitem_4, [512], detach_70, primals_4, [True, True]);  view_235 = getitem_4 = detach_70 = primals_4 = None
        getitem_175: "f32[8, 2048, 512]" = _fused_rms_norm_backward_17[0]
        getitem_176: "f32[512]" = _fused_rms_norm_backward_17[1];  _fused_rms_norm_backward_17 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:143 in apply_rotary_emb, code: y = torch.view_as_real(x * freqs_cis).flatten(3)
        view_236: "f32[8, 2048, 1, 32, 2]" = torch.ops.aten.view.default(sum_16, [8, 2048, 1, 32, 2]);  sum_16 = None
        view_as_complex_22: "c64[8, 2048, 1, 32]" = torch.ops.aten.view_as_complex.default(view_236);  view_236 = None
        _conj_10: "c64[1, 2048, 1, 32]" = torch.ops.aten._conj.default(view_7);  view_7 = None
        clone_15: "c64[1, 2048, 1, 32]" = torch.ops.aten.clone.default(_conj_10);  _conj_10 = None
        mul_85: "c64[8, 2048, 1, 32]" = torch.ops.aten.mul.Tensor(view_as_complex_22, clone_15);  view_as_complex_22 = clone_15 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:141 in apply_rotary_emb, code: x = torch.view_as_complex(x.float().view(*x.shape[:-1], -1, 2))
        view_as_real_22: "f32[8, 2048, 1, 32, 2]" = torch.ops.aten.view_as_real.default(mul_85);  mul_85 = None
        view_237: "f32[8, 2048, 1, 64]" = torch.ops.aten.view.default(view_as_real_22, [8, 2048, 1, 64]);  view_as_real_22 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:232 in forward, code: k_pe.unsqueeze(2), freqs_cis
        squeeze_5: "f32[8, 2048, 64]" = torch.ops.aten.squeeze.dim(view_237, 2);  view_237 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:229 in forward, code: kv, k_pe = torch.split(kv, [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1)
        cat_33: "f32[8, 2048, 576]" = torch.ops.aten.cat.default([getitem_175, squeeze_5], 2);  getitem_175 = squeeze_5 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:228 in forward, code: kv = self.wkv_a(x)  # (bsz, seqlen, kv_lora_rank + qk_rope_head_dim)
        view_238: "f32[16384, 576]" = torch.ops.aten.view.default(cat_33, [16384, 576]);  cat_33 = None
        t_232: "f32[576, 16384]" = torch.ops.aten.t.default(view_238)
        mm_140: "f32[576, 256]" = torch.ops.aten.mm.default(t_232, view_5);  t_232 = view_5 = None
        t_233: "f32[256, 576]" = torch.ops.aten.t.default(mm_140);  mm_140 = None
        t_234: "f32[576, 256]" = torch.ops.aten.t.default(t_1);  t_1 = None
        mm_141: "f32[16384, 256]" = torch.ops.aten.mm.default(view_238, t_234);  view_238 = t_234 = None
        view_239: "f32[8, 2048, 256]" = torch.ops.aten.view.default(mm_141, [8, 2048, 256]);  mm_141 = None
        t_235: "f32[576, 256]" = torch.ops.aten.t.default(t_233);  t_233 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:225 in forward, code: q = torch.cat([q_nope, q_pe], dim=-1)  # (bsz, seqlen, n_heads, qk_head_dim)
        slice_43: "f32[8, 2048, 16, 128]" = torch.ops.aten.slice.Tensor(transpose_122, 3, 0, 128)
        slice_44: "f32[8, 2048, 16, 64]" = torch.ops.aten.slice.Tensor(transpose_122, 3, 128, 192);  transpose_122 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:143 in apply_rotary_emb, code: y = torch.view_as_real(x * freqs_cis).flatten(3)
        view_240: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.view.default(slice_44, [8, 2048, 16, 32, 2]);  slice_44 = None
        clone_16: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.clone.default(view_240, memory_format = torch.contiguous_format);  view_240 = None
        view_as_complex_23: "c64[8, 2048, 16, 32]" = torch.ops.aten.view_as_complex.default(clone_16);  clone_16 = None
        _conj_11: "c64[1, 2048, 1, 32]" = torch.ops.aten._conj.default(view_3);  view_3 = None
        clone_17: "c64[1, 2048, 1, 32]" = torch.ops.aten.clone.default(_conj_11);  _conj_11 = None
        mul_86: "c64[8, 2048, 16, 32]" = torch.ops.aten.mul.Tensor(view_as_complex_23, clone_17);  view_as_complex_23 = clone_17 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:141 in apply_rotary_emb, code: x = torch.view_as_complex(x.float().view(*x.shape[:-1], -1, 2))
        view_as_real_23: "f32[8, 2048, 16, 32, 2]" = torch.ops.aten.view_as_real.default(mul_86);  mul_86 = None
        view_241: "f32[8, 2048, 16, 64]" = torch.ops.aten.view.default(view_as_real_23, [8, 2048, 16, 64]);  view_as_real_23 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:221 in forward, code: q_nope, q_pe = torch.split(
        cat_34: "f32[8, 2048, 16, 192]" = torch.ops.aten.cat.default([slice_43, view_241], 3);  slice_43 = view_241 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:220 in forward, code: q = q.view(bsz, seqlen, -1, self.qk_head_dim)
        view_242: "f32[8, 2048, 3072]" = torch.ops.aten.view.default(cat_34, [8, 2048, 3072]);  cat_34 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:213 in forward, code: q = self.wq(x)  # (bsz, seqlen, n_heads * qk_head_dim)
        view_243: "f32[16384, 3072]" = torch.ops.aten.view.default(view_242, [16384, 3072]);  view_242 = None
        t_236: "f32[3072, 16384]" = torch.ops.aten.t.default(view_243)
        mm_142: "f32[3072, 256]" = torch.ops.aten.mm.default(t_236, view);  t_236 = view = None
        t_237: "f32[256, 3072]" = torch.ops.aten.t.default(mm_142);  mm_142 = None
        t_238: "f32[3072, 256]" = torch.ops.aten.t.default(t);  t = None
        mm_143: "f32[16384, 256]" = torch.ops.aten.mm.default(view_243, t_238);  view_243 = t_238 = None
        view_244: "f32[8, 2048, 256]" = torch.ops.aten.view.default(mm_143, [8, 2048, 256]);  mm_143 = None
        add_64: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(view_239, view_244);  view_239 = view_244 = None
        t_239: "f32[3072, 256]" = torch.ops.aten.t.default(t_237);  t_237 = None
        
        # File: /data/users/shangdiy/pytorch/torch/nn/functional.py:2952 in rms_norm, code: return torch.rms_norm(input, normalized_shape, weight, eps)
        detach_71: "f32[8, 2048, 1]" = torch.ops.aten.detach.default(detach);  detach = None
        _fused_rms_norm_backward_18 = torch.ops.aten._fused_rms_norm_backward.default(add_64, embedding, [256], detach_71, primals_7, [True, True]);  add_64 = embedding = detach_71 = primals_7 = None
        getitem_177: "f32[8, 2048, 256]" = _fused_rms_norm_backward_18[0]
        getitem_178: "f32[256]" = _fused_rms_norm_backward_18[1];  _fused_rms_norm_backward_18 = None
        add_65: "f32[8, 2048, 256]" = torch.ops.aten.add.Tensor(add_63, getitem_177);  add_63 = getitem_177 = None
        
        # File: /data/users/shangdiy/torchtitan/torchtitan/models/deepseek_v3/model/model.py:428 in forward, code: h = self.tok_embeddings(tokens) if self.tok_embeddings is not None else tokens
        embedding_dense_backward: "f32[2048, 256]" = torch.ops.aten.embedding_dense_backward.default(add_65, primals_95, 2048, -1, False);  add_65 = primals_95 = None
        return pytree.tree_unflatten([add_4, add_9, add_14, add_19, add_24, _unsafe_view_27, embedding_dense_backward, t_239, t_235, getitem_176, t_231, t_227, getitem_178, getitem_170, t_223, t_215, t_219, t_211, t_207, getitem_166, t_203, t_199, getitem_168, getitem_160, _to_copy_68, _to_copy_65, _to_copy_66, t_195, t_191, t_183, t_187, t_179, t_175, getitem_156, t_171, t_167, getitem_158, getitem_150, _to_copy_62, _to_copy_59, _to_copy_60, t_163, t_159, t_151, t_155, t_147, t_143, getitem_146, t_139, t_135, getitem_148, getitem_140, _to_copy_56, _to_copy_53, _to_copy_54, t_131, t_127, t_119, t_123, t_115, t_111, getitem_136, t_107, t_103, getitem_138, getitem_130, _to_copy_50, _to_copy_47, _to_copy_48, t_99, t_95, t_87, t_91, t_83, t_79, getitem_126, t_75, t_71, getitem_128, getitem_120, _to_copy_44, _to_copy_41, _to_copy_42, t_67, t_63, t_55, t_59, getitem_118, t_51, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None], self._out_spec)
        
    class sdpa_score0(torch.nn.Module):
        def forward(self, arg0_1: "f32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[]"):
            return arg0_1
            
    class sdpa_mask0(torch.nn.Module):
        def forward(self, arg0_1: "i32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[8, 2048]"):
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1037 in and_mask, code: result = b.new_ones((), dtype=torch.bool)
            new_ones: "b8[]" = torch.ops.aten.new_ones.default(arg0_1, [], dtype = torch.bool, pin_memory = False)
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/torchtitan/torchtitan/models/attention.py:124 in _causal_mask, code: return q_idx >= kv_idx
            ge: "b8[]" = torch.ops.aten.ge.Tensor(arg2_1, arg3_1)
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1039 in and_mask, code: result = result & mask(b, h, q_idx, kv_idx)
            bitwise_and: "b8[]" = torch.ops.aten.bitwise_and.Tensor(new_ones, ge);  new_ones = ge = None
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/torchtitan/torchtitan/models/attention.py:156 in document_mask, code: return sequence_indices[b, q_idx] == sequence_indices[b, kv_idx]
            index: "i32[]" = torch.ops.aten.index.Tensor(arg4_1, [arg0_1, arg2_1]);  arg2_1 = None
            index_1: "i32[]" = torch.ops.aten.index.Tensor(arg4_1, [arg0_1, arg3_1]);  arg4_1 = arg0_1 = arg3_1 = None
            eq: "b8[]" = torch.ops.aten.eq.Tensor(index, index_1);  index = index_1 = None
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1039 in and_mask, code: result = result & mask(b, h, q_idx, kv_idx)
            bitwise_and_1: "b8[]" = torch.ops.aten.bitwise_and.Tensor(bitwise_and, eq);  bitwise_and = eq = None
            return bitwise_and_1
            
    class sdpa_score1(torch.nn.Module):
        def forward(self, arg0_1: "f32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[]"):
            return arg0_1
            
    class sdpa_mask1(torch.nn.Module):
        def forward(self, arg0_1: "i32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[8, 2048]"):
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1037 in and_mask, code: result = b.new_ones((), dtype=torch.bool)
            new_ones: "b8[]" = torch.ops.aten.new_ones.default(arg0_1, [], dtype = torch.bool, pin_memory = False)
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/torchtitan/torchtitan/models/attention.py:124 in _causal_mask, code: return q_idx >= kv_idx
            ge: "b8[]" = torch.ops.aten.ge.Tensor(arg2_1, arg3_1)
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1039 in and_mask, code: result = result & mask(b, h, q_idx, kv_idx)
            bitwise_and: "b8[]" = torch.ops.aten.bitwise_and.Tensor(new_ones, ge);  new_ones = ge = None
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/torchtitan/torchtitan/models/attention.py:156 in document_mask, code: return sequence_indices[b, q_idx] == sequence_indices[b, kv_idx]
            index: "i32[]" = torch.ops.aten.index.Tensor(arg4_1, [arg0_1, arg2_1]);  arg2_1 = None
            index_1: "i32[]" = torch.ops.aten.index.Tensor(arg4_1, [arg0_1, arg3_1]);  arg4_1 = arg0_1 = arg3_1 = None
            eq: "b8[]" = torch.ops.aten.eq.Tensor(index, index_1);  index = index_1 = None
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1039 in and_mask, code: result = result & mask(b, h, q_idx, kv_idx)
            bitwise_and_1: "b8[]" = torch.ops.aten.bitwise_and.Tensor(bitwise_and, eq);  bitwise_and = eq = None
            return bitwise_and_1
            
    class sdpa_score2(torch.nn.Module):
        def forward(self, arg0_1: "f32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[]"):
            return arg0_1
            
    class sdpa_mask2(torch.nn.Module):
        def forward(self, arg0_1: "i32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[8, 2048]"):
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1037 in and_mask, code: result = b.new_ones((), dtype=torch.bool)
            new_ones: "b8[]" = torch.ops.aten.new_ones.default(arg0_1, [], dtype = torch.bool, pin_memory = False)
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/torchtitan/torchtitan/models/attention.py:124 in _causal_mask, code: return q_idx >= kv_idx
            ge: "b8[]" = torch.ops.aten.ge.Tensor(arg2_1, arg3_1)
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1039 in and_mask, code: result = result & mask(b, h, q_idx, kv_idx)
            bitwise_and: "b8[]" = torch.ops.aten.bitwise_and.Tensor(new_ones, ge);  new_ones = ge = None
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/torchtitan/torchtitan/models/attention.py:156 in document_mask, code: return sequence_indices[b, q_idx] == sequence_indices[b, kv_idx]
            index: "i32[]" = torch.ops.aten.index.Tensor(arg4_1, [arg0_1, arg2_1]);  arg2_1 = None
            index_1: "i32[]" = torch.ops.aten.index.Tensor(arg4_1, [arg0_1, arg3_1]);  arg4_1 = arg0_1 = arg3_1 = None
            eq: "b8[]" = torch.ops.aten.eq.Tensor(index, index_1);  index = index_1 = None
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1039 in and_mask, code: result = result & mask(b, h, q_idx, kv_idx)
            bitwise_and_1: "b8[]" = torch.ops.aten.bitwise_and.Tensor(bitwise_and, eq);  bitwise_and = eq = None
            return bitwise_and_1
            
    class sdpa_score3(torch.nn.Module):
        def forward(self, arg0_1: "f32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[]"):
            return arg0_1
            
    class sdpa_mask3(torch.nn.Module):
        def forward(self, arg0_1: "i32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[8, 2048]"):
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1037 in and_mask, code: result = b.new_ones((), dtype=torch.bool)
            new_ones: "b8[]" = torch.ops.aten.new_ones.default(arg0_1, [], dtype = torch.bool, pin_memory = False)
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/torchtitan/torchtitan/models/attention.py:124 in _causal_mask, code: return q_idx >= kv_idx
            ge: "b8[]" = torch.ops.aten.ge.Tensor(arg2_1, arg3_1)
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1039 in and_mask, code: result = result & mask(b, h, q_idx, kv_idx)
            bitwise_and: "b8[]" = torch.ops.aten.bitwise_and.Tensor(new_ones, ge);  new_ones = ge = None
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/torchtitan/torchtitan/models/attention.py:156 in document_mask, code: return sequence_indices[b, q_idx] == sequence_indices[b, kv_idx]
            index: "i32[]" = torch.ops.aten.index.Tensor(arg4_1, [arg0_1, arg2_1]);  arg2_1 = None
            index_1: "i32[]" = torch.ops.aten.index.Tensor(arg4_1, [arg0_1, arg3_1]);  arg4_1 = arg0_1 = arg3_1 = None
            eq: "b8[]" = torch.ops.aten.eq.Tensor(index, index_1);  index = index_1 = None
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1039 in and_mask, code: result = result & mask(b, h, q_idx, kv_idx)
            bitwise_and_1: "b8[]" = torch.ops.aten.bitwise_and.Tensor(bitwise_and, eq);  bitwise_and = eq = None
            return bitwise_and_1
            
    class sdpa_score4(torch.nn.Module):
        def forward(self, arg0_1: "f32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[]"):
            return arg0_1
            
    class sdpa_mask4(torch.nn.Module):
        def forward(self, arg0_1: "i32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[8, 2048]"):
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1037 in and_mask, code: result = b.new_ones((), dtype=torch.bool)
            new_ones: "b8[]" = torch.ops.aten.new_ones.default(arg0_1, [], dtype = torch.bool, pin_memory = False)
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/torchtitan/torchtitan/models/attention.py:124 in _causal_mask, code: return q_idx >= kv_idx
            ge: "b8[]" = torch.ops.aten.ge.Tensor(arg2_1, arg3_1)
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1039 in and_mask, code: result = result & mask(b, h, q_idx, kv_idx)
            bitwise_and: "b8[]" = torch.ops.aten.bitwise_and.Tensor(new_ones, ge);  new_ones = ge = None
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/torchtitan/torchtitan/models/attention.py:156 in document_mask, code: return sequence_indices[b, q_idx] == sequence_indices[b, kv_idx]
            index: "i32[]" = torch.ops.aten.index.Tensor(arg4_1, [arg0_1, arg2_1]);  arg2_1 = None
            index_1: "i32[]" = torch.ops.aten.index.Tensor(arg4_1, [arg0_1, arg3_1]);  arg4_1 = arg0_1 = arg3_1 = None
            eq: "b8[]" = torch.ops.aten.eq.Tensor(index, index_1);  index = index_1 = None
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1039 in and_mask, code: result = result & mask(b, h, q_idx, kv_idx)
            bitwise_and_1: "b8[]" = torch.ops.aten.bitwise_and.Tensor(bitwise_and, eq);  bitwise_and = eq = None
            return bitwise_and_1
            
    class sdpa_score5(torch.nn.Module):
        def forward(self, arg0_1: "f32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[]"):
            return arg0_1
            
    class sdpa_mask5(torch.nn.Module):
        def forward(self, arg0_1: "i32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[8, 2048]"):
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1037 in and_mask, code: result = b.new_ones((), dtype=torch.bool)
            new_ones: "b8[]" = torch.ops.aten.new_ones.default(arg0_1, [], dtype = torch.bool, pin_memory = False)
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/torchtitan/torchtitan/models/attention.py:124 in _causal_mask, code: return q_idx >= kv_idx
            ge: "b8[]" = torch.ops.aten.ge.Tensor(arg2_1, arg3_1)
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1039 in and_mask, code: result = result & mask(b, h, q_idx, kv_idx)
            bitwise_and: "b8[]" = torch.ops.aten.bitwise_and.Tensor(new_ones, ge);  new_ones = ge = None
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/torchtitan/torchtitan/models/attention.py:156 in document_mask, code: return sequence_indices[b, q_idx] == sequence_indices[b, kv_idx]
            index: "i32[]" = torch.ops.aten.index.Tensor(arg4_1, [arg0_1, arg2_1]);  arg2_1 = None
            index_1: "i32[]" = torch.ops.aten.index.Tensor(arg4_1, [arg0_1, arg3_1]);  arg4_1 = arg0_1 = arg3_1 = None
            eq: "b8[]" = torch.ops.aten.eq.Tensor(index, index_1);  index = index_1 = None
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1039 in and_mask, code: result = result & mask(b, h, q_idx, kv_idx)
            bitwise_and_1: "b8[]" = torch.ops.aten.bitwise_and.Tensor(bitwise_and, eq);  bitwise_and = eq = None
            return bitwise_and_1
            
    class fw_graph0(torch.nn.Module):
        def forward(self, arg0_1: "f32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[]"):
            return arg0_1
            
    class joint_graph0(torch.nn.Module):
        def forward(self, arg0_1: "f32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[]", arg5_1: "f32[]"):
            return [arg5_1, None, None, None, None]
            
    class mask_graph0(torch.nn.Module):
        def forward(self, arg0_1: "i32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[8, 2048]"):
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1037 in and_mask, code: result = b.new_ones((), dtype=torch.bool)
            new_ones: "b8[]" = torch.ops.aten.new_ones.default(arg0_1, [], dtype = torch.bool, pin_memory = False)
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/torchtitan/torchtitan/models/attention.py:124 in _causal_mask, code: return q_idx >= kv_idx
            ge: "b8[]" = torch.ops.aten.ge.Tensor(arg2_1, arg3_1)
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1039 in and_mask, code: result = result & mask(b, h, q_idx, kv_idx)
            bitwise_and: "b8[]" = torch.ops.aten.bitwise_and.Tensor(new_ones, ge);  new_ones = ge = None
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/torchtitan/torchtitan/models/attention.py:156 in document_mask, code: return sequence_indices[b, q_idx] == sequence_indices[b, kv_idx]
            index: "i32[]" = torch.ops.aten.index.Tensor(arg4_1, [arg0_1, arg2_1]);  arg2_1 = None
            index_1: "i32[]" = torch.ops.aten.index.Tensor(arg4_1, [arg0_1, arg3_1]);  arg4_1 = arg0_1 = arg3_1 = None
            eq: "b8[]" = torch.ops.aten.eq.Tensor(index, index_1);  index = index_1 = None
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1039 in and_mask, code: result = result & mask(b, h, q_idx, kv_idx)
            bitwise_and_1: "b8[]" = torch.ops.aten.bitwise_and.Tensor(bitwise_and, eq);  bitwise_and = eq = None
            return bitwise_and_1
            
    class fw_graph1(torch.nn.Module):
        def forward(self, arg0_1: "f32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[]"):
            return arg0_1
            
    class joint_graph1(torch.nn.Module):
        def forward(self, arg0_1: "f32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[]", arg5_1: "f32[]"):
            return [arg5_1, None, None, None, None]
            
    class mask_graph1(torch.nn.Module):
        def forward(self, arg0_1: "i32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[8, 2048]"):
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1037 in and_mask, code: result = b.new_ones((), dtype=torch.bool)
            new_ones: "b8[]" = torch.ops.aten.new_ones.default(arg0_1, [], dtype = torch.bool, pin_memory = False)
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/torchtitan/torchtitan/models/attention.py:124 in _causal_mask, code: return q_idx >= kv_idx
            ge: "b8[]" = torch.ops.aten.ge.Tensor(arg2_1, arg3_1)
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1039 in and_mask, code: result = result & mask(b, h, q_idx, kv_idx)
            bitwise_and: "b8[]" = torch.ops.aten.bitwise_and.Tensor(new_ones, ge);  new_ones = ge = None
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/torchtitan/torchtitan/models/attention.py:156 in document_mask, code: return sequence_indices[b, q_idx] == sequence_indices[b, kv_idx]
            index: "i32[]" = torch.ops.aten.index.Tensor(arg4_1, [arg0_1, arg2_1]);  arg2_1 = None
            index_1: "i32[]" = torch.ops.aten.index.Tensor(arg4_1, [arg0_1, arg3_1]);  arg4_1 = arg0_1 = arg3_1 = None
            eq: "b8[]" = torch.ops.aten.eq.Tensor(index, index_1);  index = index_1 = None
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1039 in and_mask, code: result = result & mask(b, h, q_idx, kv_idx)
            bitwise_and_1: "b8[]" = torch.ops.aten.bitwise_and.Tensor(bitwise_and, eq);  bitwise_and = eq = None
            return bitwise_and_1
            
    class fw_graph2(torch.nn.Module):
        def forward(self, arg0_1: "f32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[]"):
            return arg0_1
            
    class joint_graph2(torch.nn.Module):
        def forward(self, arg0_1: "f32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[]", arg5_1: "f32[]"):
            return [arg5_1, None, None, None, None]
            
    class mask_graph2(torch.nn.Module):
        def forward(self, arg0_1: "i32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[8, 2048]"):
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1037 in and_mask, code: result = b.new_ones((), dtype=torch.bool)
            new_ones: "b8[]" = torch.ops.aten.new_ones.default(arg0_1, [], dtype = torch.bool, pin_memory = False)
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/torchtitan/torchtitan/models/attention.py:124 in _causal_mask, code: return q_idx >= kv_idx
            ge: "b8[]" = torch.ops.aten.ge.Tensor(arg2_1, arg3_1)
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1039 in and_mask, code: result = result & mask(b, h, q_idx, kv_idx)
            bitwise_and: "b8[]" = torch.ops.aten.bitwise_and.Tensor(new_ones, ge);  new_ones = ge = None
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/torchtitan/torchtitan/models/attention.py:156 in document_mask, code: return sequence_indices[b, q_idx] == sequence_indices[b, kv_idx]
            index: "i32[]" = torch.ops.aten.index.Tensor(arg4_1, [arg0_1, arg2_1]);  arg2_1 = None
            index_1: "i32[]" = torch.ops.aten.index.Tensor(arg4_1, [arg0_1, arg3_1]);  arg4_1 = arg0_1 = arg3_1 = None
            eq: "b8[]" = torch.ops.aten.eq.Tensor(index, index_1);  index = index_1 = None
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1039 in and_mask, code: result = result & mask(b, h, q_idx, kv_idx)
            bitwise_and_1: "b8[]" = torch.ops.aten.bitwise_and.Tensor(bitwise_and, eq);  bitwise_and = eq = None
            return bitwise_and_1
            
    class fw_graph3(torch.nn.Module):
        def forward(self, arg0_1: "f32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[]"):
            return arg0_1
            
    class joint_graph3(torch.nn.Module):
        def forward(self, arg0_1: "f32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[]", arg5_1: "f32[]"):
            return [arg5_1, None, None, None, None]
            
    class mask_graph3(torch.nn.Module):
        def forward(self, arg0_1: "i32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[8, 2048]"):
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1037 in and_mask, code: result = b.new_ones((), dtype=torch.bool)
            new_ones: "b8[]" = torch.ops.aten.new_ones.default(arg0_1, [], dtype = torch.bool, pin_memory = False)
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/torchtitan/torchtitan/models/attention.py:124 in _causal_mask, code: return q_idx >= kv_idx
            ge: "b8[]" = torch.ops.aten.ge.Tensor(arg2_1, arg3_1)
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1039 in and_mask, code: result = result & mask(b, h, q_idx, kv_idx)
            bitwise_and: "b8[]" = torch.ops.aten.bitwise_and.Tensor(new_ones, ge);  new_ones = ge = None
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/torchtitan/torchtitan/models/attention.py:156 in document_mask, code: return sequence_indices[b, q_idx] == sequence_indices[b, kv_idx]
            index: "i32[]" = torch.ops.aten.index.Tensor(arg4_1, [arg0_1, arg2_1]);  arg2_1 = None
            index_1: "i32[]" = torch.ops.aten.index.Tensor(arg4_1, [arg0_1, arg3_1]);  arg4_1 = arg0_1 = arg3_1 = None
            eq: "b8[]" = torch.ops.aten.eq.Tensor(index, index_1);  index = index_1 = None
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1039 in and_mask, code: result = result & mask(b, h, q_idx, kv_idx)
            bitwise_and_1: "b8[]" = torch.ops.aten.bitwise_and.Tensor(bitwise_and, eq);  bitwise_and = eq = None
            return bitwise_and_1
            
    class fw_graph4(torch.nn.Module):
        def forward(self, arg0_1: "f32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[]"):
            return arg0_1
            
    class joint_graph4(torch.nn.Module):
        def forward(self, arg0_1: "f32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[]", arg5_1: "f32[]"):
            return [arg5_1, None, None, None, None]
            
    class mask_graph4(torch.nn.Module):
        def forward(self, arg0_1: "i32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[8, 2048]"):
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1037 in and_mask, code: result = b.new_ones((), dtype=torch.bool)
            new_ones: "b8[]" = torch.ops.aten.new_ones.default(arg0_1, [], dtype = torch.bool, pin_memory = False)
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/torchtitan/torchtitan/models/attention.py:124 in _causal_mask, code: return q_idx >= kv_idx
            ge: "b8[]" = torch.ops.aten.ge.Tensor(arg2_1, arg3_1)
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1039 in and_mask, code: result = result & mask(b, h, q_idx, kv_idx)
            bitwise_and: "b8[]" = torch.ops.aten.bitwise_and.Tensor(new_ones, ge);  new_ones = ge = None
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/torchtitan/torchtitan/models/attention.py:156 in document_mask, code: return sequence_indices[b, q_idx] == sequence_indices[b, kv_idx]
            index: "i32[]" = torch.ops.aten.index.Tensor(arg4_1, [arg0_1, arg2_1]);  arg2_1 = None
            index_1: "i32[]" = torch.ops.aten.index.Tensor(arg4_1, [arg0_1, arg3_1]);  arg4_1 = arg0_1 = arg3_1 = None
            eq: "b8[]" = torch.ops.aten.eq.Tensor(index, index_1);  index = index_1 = None
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1039 in and_mask, code: result = result & mask(b, h, q_idx, kv_idx)
            bitwise_and_1: "b8[]" = torch.ops.aten.bitwise_and.Tensor(bitwise_and, eq);  bitwise_and = eq = None
            return bitwise_and_1
            
    class fw_graph5(torch.nn.Module):
        def forward(self, arg0_1: "f32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[]"):
            return arg0_1
            
    class joint_graph5(torch.nn.Module):
        def forward(self, arg0_1: "f32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[]", arg5_1: "f32[]"):
            return [arg5_1, None, None, None, None]
            
    class mask_graph5(torch.nn.Module):
        def forward(self, arg0_1: "i32[]", arg1_1: "i32[]", arg2_1: "i32[]", arg3_1: "i32[]", arg4_1: "i32[8, 2048]"):
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1037 in and_mask, code: result = b.new_ones((), dtype=torch.bool)
            new_ones: "b8[]" = torch.ops.aten.new_ones.default(arg0_1, [], dtype = torch.bool, pin_memory = False)
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/torchtitan/torchtitan/models/attention.py:124 in _causal_mask, code: return q_idx >= kv_idx
            ge: "b8[]" = torch.ops.aten.ge.Tensor(arg2_1, arg3_1)
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1039 in and_mask, code: result = result & mask(b, h, q_idx, kv_idx)
            bitwise_and: "b8[]" = torch.ops.aten.bitwise_and.Tensor(new_ones, ge);  new_ones = ge = None
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/torchtitan/torchtitan/models/attention.py:156 in document_mask, code: return sequence_indices[b, q_idx] == sequence_indices[b, kv_idx]
            index: "i32[]" = torch.ops.aten.index.Tensor(arg4_1, [arg0_1, arg2_1]);  arg2_1 = None
            index_1: "i32[]" = torch.ops.aten.index.Tensor(arg4_1, [arg0_1, arg3_1]);  arg4_1 = arg0_1 = arg3_1 = None
            eq: "b8[]" = torch.ops.aten.eq.Tensor(index, index_1);  index = index_1 = None
            
            # Annotation: {'compile_with_inductor': 'flex_attention'} File: /data/users/shangdiy/pytorch/torch/nn/attention/flex_attention.py:1039 in and_mask, code: result = result & mask(b, h, q_idx, kv_idx)
            bitwise_and_1: "b8[]" = torch.ops.aten.bitwise_and.Tensor(bitwise_and, eq);  bitwise_and = eq = None
            return bitwise_and_1
            
