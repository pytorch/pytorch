{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e71cb75c",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import header_code\n",
    "import logging\n",
    "torch._logging.set_logs(dynamo=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79ab969",
   "metadata": {},
   "source": [
    "# Skipped Functions\n",
    "\n",
    "**Summary:**\n",
    "- Sometimes, `torch.compile` completely gives up compiling a function and runs it eagerly instead,\n",
    "  resulting in potentially lost optimization opportunities.\n",
    "- There are ways to work around skipped functions in order to re-enable tracing around the problematic code.\n",
    "\n",
    "Sometimes, `torch.compile` with `fullgraph=False` is unable to resume tracing when encountering a graph break\n",
    "or other compiler error. In many of these cases, `torch.compile` will skip compiling the function entirely and run it eagerly.\n",
    "\n",
    "Note that the skip is only applied to the current function and NOT any nested function calls.\n",
    "`torch.compile` will still attempt to compile nested calls.\n",
    "\n",
    "<!-- TODO: fix logging for skipped functions. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "880e200f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ChromiumEventLogger initialized with id 806b0fe4-f6a5-4574-9ab4-6bd1d0733e1c\n",
      "torchdynamo start compiling fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:5, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py\", line 10, in <module>\n",
      "    fn(torch.randn(3))\n",
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:5\n",
      "create_env\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:5 in fn\n",
      "    @torch.compile\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:7 in fn\n",
      "        x = inner1(x)\n",
      "TRACE LOAD_GLOBAL inner1 []\n",
      "TRACE LOAD_FAST x [LazyVariableTracker(), NullVariable]\n",
      "TRACE CALL 1 [LazyVariableTracker(), NullVariable, LazyVariableTracker()]\n",
      "TRACE inlined call inner1 from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:7 in fn\n",
      "    x = inner1(x)\n",
      "INLINING <code object inner1 at 0x000001ADDC2811B0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py\", line 1>, inlined according trace_rules.lookup inlined by default\n",
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n",
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:1 in inner1 (inline depth: 1)\n",
      "    def inner1(x):\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:2 in inner1 (inline depth: 1)\n",
      "        return x + 1\n",
      "TRACE LOAD_FAST x []\n",
      "TRACE LOAD_CONST 1 [TensorVariable()]\n",
      "TRACE BINARY_OP 0 [TensorVariable(), ConstantVariable(int: 1)]\n",
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:2 in inner1 (inline depth: 1)\n",
      "    return x + 1\n",
      "           ~~^~~\n",
      "TRACE RETURN_VALUE None [TensorVariable()]\n",
      "DONE INLINING <code object inner1 at 0x000001ADDC2811B0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py\", line 1>\n",
      "TRACE STORE_FAST x [TensorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:8 in fn\n",
      "        torch._dynamo.skip_frame()\n",
      "TRACE LOAD_GLOBAL torch []\n",
      "TRACE LOAD_ATTR _dynamo [LazyVariableTracker()]\n",
      "TRACE LOAD_ATTR skip_frame [LazyVariableTracker()]\n",
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n",
      "Skipping frame Skip frame due to `torch._dynamo.skip_frame()`. Message: None fn                 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py 5\n",
      "put_code_state: no cache key, skipping\n",
      "run_gc_after_compile: running gc\n",
      "torchdynamo start compiling inner1 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:1, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py\", line 10, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 832, in compile_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "Step 1: torchdynamo start tracing inner1 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:1\n",
      "create_env\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:1 in inner1\n",
      "    def inner1(x):\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:2 in inner1\n",
      "        return x + 1\n",
      "TRACE LOAD_FAST x []\n",
      "TRACE LOAD_CONST 1 [LazyVariableTracker()]\n",
      "TRACE BINARY_OP 0 [LazyVariableTracker(), ConstantVariable(int: 1)]\n",
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n",
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n",
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:2 in inner1\n",
      "    return x + 1\n",
      "           ~~^~~\n",
      "TRACE RETURN_VALUE None [TensorVariable()]\n",
      "Step 1: torchdynamo done tracing inner1 (RETURN_VALUE)\n",
      "RETURN_VALUE triggered compile\n",
      "COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py, line 2 in inner1>], graph_break=False)\n",
      "TRACED GRAPH\n",
      " ===== __compiled_fn_2_5105e9b5_5ae2_46e1_a07e_07afa24d41f6 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:2 in inner1, code: return x + 1\n",
      "        add: \"f32[3][1]cpu\" = l_x_ + 1;  l_x_ = None\n",
      "        return (add,)\n",
      "Step 2: calling compiler function eager\n",
      "Step 2: done compiler function eager\n",
      "produce_guards\n",
      "track_symint L['x'].size()[0] 3 None\n",
      "track_symint L['x'].stride()[0] 1 None\n",
      "track_symint L['x'].storage_offset() 0 None\n",
      "Skipping guard L['x'].size()[0] == 3\n",
      "Skipping guard L['x'].stride()[0] == 1\n",
      "Skipping guard L['x'].storage_offset() == 0\n",
      "GUARDS:\n",
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=0), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # return x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:2 in inner1\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # return x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:2 in inner1\n",
      "Guard eval latency = 223.80 us\n",
      "put_code_state: no cache key, skipping\n",
      "run_gc_after_compile: running gc\n",
      "skipping: inner (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_compile.py)\n",
      "skipping: disable (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\decorators.py)\n",
      "skipping: innermost_fn (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py)\n",
      "skipping: __init__ (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py)\n",
      "skipping: __init__ (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py)\n",
      "skipping: nothing (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py)\n",
      "skipping: __call__ (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py)\n",
      "skipping: _fn (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py)\n",
      "skipping: skip_frame (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\decorators.py)\n",
      "torchdynamo start compiling inner2 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:3, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py\", line 10, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 832, in compile_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "Step 1: torchdynamo start tracing inner2 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:3\n",
      "create_env\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:3 in inner2\n",
      "    def inner2(x):\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:4 in inner2\n",
      "        return x + 2\n",
      "TRACE LOAD_FAST x []\n",
      "TRACE LOAD_CONST 2 [LazyVariableTracker()]\n",
      "TRACE BINARY_OP 0 [LazyVariableTracker(), ConstantVariable(int: 2)]\n",
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n",
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n",
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:4 in inner2\n",
      "    return x + 2\n",
      "           ~~^~~\n",
      "TRACE RETURN_VALUE None [TensorVariable()]\n",
      "Step 1: torchdynamo done tracing inner2 (RETURN_VALUE)\n",
      "RETURN_VALUE triggered compile\n",
      "COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py, line 4 in inner2>], graph_break=False)\n",
      "TRACED GRAPH\n",
      " ===== __compiled_fn_4_81c2fed2_1c39_4397_87ba_29a342263e15 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:4 in inner2, code: return x + 2\n",
      "        add: \"f32[3][1]cpu\" = l_x_ + 2;  l_x_ = None\n",
      "        return (add,)\n",
      "Step 2: calling compiler function eager\n",
      "Step 2: done compiler function eager\n",
      "produce_guards\n",
      "track_symint L['x'].size()[0] 3 None\n",
      "track_symint L['x'].stride()[0] 1 None\n",
      "track_symint L['x'].storage_offset() 0 None\n",
      "Skipping guard L['x'].size()[0] == 3\n",
      "Skipping guard L['x'].stride()[0] == 1\n",
      "Skipping guard L['x'].storage_offset() == 0\n",
      "GUARDS:\n",
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=0), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # return x + 2  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:4 in inner2\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # return x + 2  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:4 in inner2\n",
      "Guard eval latency = 216.10 us\n",
      "put_code_state: no cache key, skipping\n",
      "run_gc_after_compile: running gc\n",
      "skipping: remove (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\utils\\weak.py)\n",
      "skipping: __hash__ (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\utils\\weak.py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchdynamo start compiling fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:5, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py\", line 10, in <module>\n",
      "    fn(torch.randn(3))\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:5 in fn\n",
      "    @torch.compile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:7 in fn\n",
      "        x = inner1(x)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL inner1 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x [LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 1 [LazyVariableTracker(), NullVariable, LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE inlined call inner1 from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:7 in fn\n",
      "    x = inner1(x)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INLINING <code object inner1 at 0x000001ADDC2811B0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py\", line 1>, inlined according trace_rules.lookup inlined by default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:1 in inner1 (inline depth: 1)\n",
      "    def inner1(x):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:2 in inner1 (inline depth: 1)\n",
      "        return x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [TensorVariable(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:2 in inner1 (inline depth: 1)\n",
      "    return x + 1\n",
      "           ~~^~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_VALUE None [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DONE INLINING <code object inner1 at 0x000001ADDC2811B0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py\", line 1>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST x [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:8 in fn\n",
      "        torch._dynamo.skip_frame()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL torch []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR _dynamo [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR skip_frame [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping frame Skip frame due to `torch._dynamo.skip_frame()`. Message: None fn                 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "put_code_state: no cache key, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_gc_after_compile: running gc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchdynamo start compiling inner1 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:1, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py\", line 10, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 832, in compile_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo start tracing inner1 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:1 in inner1\n",
      "    def inner1(x):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:2 in inner1\n",
      "        return x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [LazyVariableTracker(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:2 in inner1\n",
      "    return x + 1\n",
      "           ~~^~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_VALUE None [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo done tracing inner1 (RETURN_VALUE)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RETURN_VALUE triggered compile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py, line 2 in inner1>], graph_break=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACED GRAPH\n",
      " ===== __compiled_fn_2_5105e9b5_5ae2_46e1_a07e_07afa24d41f6 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:2 in inner1, code: return x + 1\n",
      "        add: \"f32[3][1]cpu\" = l_x_ + 1;  l_x_ = None\n",
      "        return (add,)\n",
      "        \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: calling compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: done compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "produce_guards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].size()[0] 3 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].stride()[0] 1 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].storage_offset() 0 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].size()[0] == 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].stride()[0] == 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].storage_offset() == 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GUARDS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=0), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # return x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:2 in inner1\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # return x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:2 in inner1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Guard eval latency = 223.80 us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "put_code_state: no cache key, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_gc_after_compile: running gc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping: inner (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_compile.py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping: disable (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\decorators.py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping: innermost_fn (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping: __init__ (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping: __init__ (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping: nothing (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping: __call__ (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping: _fn (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping: skip_frame (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\decorators.py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchdynamo start compiling inner2 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:3, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py\", line 10, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 832, in compile_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo start tracing inner2 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:3 in inner2\n",
      "    def inner2(x):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:4 in inner2\n",
      "        return x + 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 2 [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [LazyVariableTracker(), ConstantVariable(int: 2)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:4 in inner2\n",
      "    return x + 2\n",
      "           ~~^~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_VALUE None [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo done tracing inner2 (RETURN_VALUE)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RETURN_VALUE triggered compile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py, line 4 in inner2>], graph_break=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACED GRAPH\n",
      " ===== __compiled_fn_4_81c2fed2_1c39_4397_87ba_29a342263e15 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:4 in inner2, code: return x + 2\n",
      "        add: \"f32[3][1]cpu\" = l_x_ + 2;  l_x_ = None\n",
      "        return (add,)\n",
      "        \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: calling compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: done compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "produce_guards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].size()[0] 3 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].stride()[0] 1 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].storage_offset() 0 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].size()[0] == 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].stride()[0] == 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].storage_offset() == 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GUARDS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=0), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # return x + 2  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:4 in inner2\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # return x + 2  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2126697152.py:4 in inner2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Guard eval latency = 216.10 us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "put_code_state: no cache key, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_gc_after_compile: running gc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping: remove (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\utils\\weak.py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping: __hash__ (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\utils\\weak.py)\n"
     ]
    }
   ],
   "source": [
    "def inner1(x):\n",
    "    return x + 1\n",
    "def inner2(x):\n",
    "    return x + 2\n",
    "@torch.compile\n",
    "def fn(x):\n",
    "    x = inner1(x)\n",
    "    torch._dynamo.skip_frame()\n",
    "    x = inner2(x)\n",
    "fn(torch.randn(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3b15cc",
   "metadata": {},
   "source": [
    "In the above example, `torch.compile` will trace `fn` (including `inner1`) up until the `skip_frame`.\n",
    "Then `fn` is skipped and run eagerly - `inner1` and `inner2` are compiled when they are called.\n",
    "\n",
    "Skipping functions may result in lost optimization opportunities,\n",
    "so it is important to check if code you want compiled is being skipped, and if so, to work around the skip.\n",
    "\n",
    "## Graph Break in a Loop\n",
    "\n",
    "`torch.compile` cannot resume tracing if a graph break occurs in a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e1a38a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchdynamo start compiling fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:1, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py\", line 8, in <module>\n",
      "    fn(torch.randn(3))\n",
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:1\n",
      "create_env\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:1 in fn\n",
      "    @torch.compile\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:3 in fn\n",
      "        for i in range(5):\n",
      "TRACE LOAD_GLOBAL range []\n",
      "TRACE LOAD_CONST 5 [LazyVariableTracker(), NullVariable]\n",
      "TRACE CALL 1 [LazyVariableTracker(), NullVariable, ConstantVariable(int: 5)]\n",
      "TRACE GET_ITER None [RangeVariable()]\n",
      "TRACE FOR_ITER 120 [RangeIteratorVariable()]\n",
      "TRACE STORE_FAST i [RangeIteratorVariable(), ConstantVariable(int: 0)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:4 in fn\n",
      "            x = x + 1\n",
      "TRACE LOAD_FAST x [RangeIteratorVariable()]\n",
      "TRACE LOAD_CONST 1 [RangeIteratorVariable(), LazyVariableTracker()]\n",
      "TRACE BINARY_OP 0 [RangeIteratorVariable(), LazyVariableTracker(), ConstantVariable(int: 1)]\n",
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n",
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n",
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:4 in fn\n",
      "        x = x + 1\n",
      "            ~~^~~\n",
      "TRACE STORE_FAST x [RangeIteratorVariable(), TensorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:5 in fn\n",
      "            if i == 3:\n",
      "TRACE LOAD_FAST i [RangeIteratorVariable()]\n",
      "TRACE LOAD_CONST 3 [RangeIteratorVariable(), ConstantVariable(int: 0)]\n",
      "TRACE COMPARE_OP == [RangeIteratorVariable(), ConstantVariable(int: 0), ConstantVariable(int: 3)]\n",
      "TRACE POP_JUMP_IF_TRUE 56 [RangeIteratorVariable(), ConstantVariable(bool: False)]\n",
      "TRACE JUMP_BACKWARD 24 [RangeIteratorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:3 in fn\n",
      "        for i in range(5):\n",
      "TRACE FOR_ITER 120 [RangeIteratorVariable()]\n",
      "TRACE STORE_FAST i [RangeIteratorVariable(), ConstantVariable(int: 1)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:4 in fn\n",
      "            x = x + 1\n",
      "TRACE LOAD_FAST x [RangeIteratorVariable()]\n",
      "TRACE LOAD_CONST 1 [RangeIteratorVariable(), TensorVariable()]\n",
      "TRACE BINARY_OP 0 [RangeIteratorVariable(), TensorVariable(), ConstantVariable(int: 1)]\n",
      "TRACE STORE_FAST x [RangeIteratorVariable(), TensorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:5 in fn\n",
      "            if i == 3:\n",
      "TRACE LOAD_FAST i [RangeIteratorVariable()]\n",
      "TRACE LOAD_CONST 3 [RangeIteratorVariable(), ConstantVariable(int: 1)]\n",
      "TRACE COMPARE_OP == [RangeIteratorVariable(), ConstantVariable(int: 1), ConstantVariable(int: 3)]\n",
      "TRACE POP_JUMP_IF_TRUE 56 [RangeIteratorVariable(), ConstantVariable(bool: False)]\n",
      "TRACE JUMP_BACKWARD 24 [RangeIteratorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:3 in fn\n",
      "        for i in range(5):\n",
      "TRACE FOR_ITER 120 [RangeIteratorVariable()]\n",
      "TRACE STORE_FAST i [RangeIteratorVariable(), ConstantVariable(int: 2)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:4 in fn\n",
      "            x = x + 1\n",
      "TRACE LOAD_FAST x [RangeIteratorVariable()]\n",
      "TRACE LOAD_CONST 1 [RangeIteratorVariable(), TensorVariable()]\n",
      "TRACE BINARY_OP 0 [RangeIteratorVariable(), TensorVariable(), ConstantVariable(int: 1)]\n",
      "TRACE STORE_FAST x [RangeIteratorVariable(), TensorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:5 in fn\n",
      "            if i == 3:\n",
      "TRACE LOAD_FAST i [RangeIteratorVariable()]\n",
      "TRACE LOAD_CONST 3 [RangeIteratorVariable(), ConstantVariable(int: 2)]\n",
      "TRACE COMPARE_OP == [RangeIteratorVariable(), ConstantVariable(int: 2), ConstantVariable(int: 3)]\n",
      "TRACE POP_JUMP_IF_TRUE 56 [RangeIteratorVariable(), ConstantVariable(bool: False)]\n",
      "TRACE JUMP_BACKWARD 24 [RangeIteratorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:3 in fn\n",
      "        for i in range(5):\n",
      "TRACE FOR_ITER 120 [RangeIteratorVariable()]\n",
      "TRACE STORE_FAST i [RangeIteratorVariable(), ConstantVariable(int: 3)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:4 in fn\n",
      "            x = x + 1\n",
      "TRACE LOAD_FAST x [RangeIteratorVariable()]\n",
      "TRACE LOAD_CONST 1 [RangeIteratorVariable(), TensorVariable()]\n",
      "TRACE BINARY_OP 0 [RangeIteratorVariable(), TensorVariable(), ConstantVariable(int: 1)]\n",
      "TRACE STORE_FAST x [RangeIteratorVariable(), TensorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:5 in fn\n",
      "            if i == 3:\n",
      "TRACE LOAD_FAST i [RangeIteratorVariable()]\n",
      "TRACE LOAD_CONST 3 [RangeIteratorVariable(), ConstantVariable(int: 3)]\n",
      "TRACE COMPARE_OP == [RangeIteratorVariable(), ConstantVariable(int: 3), ConstantVariable(int: 3)]\n",
      "TRACE POP_JUMP_IF_TRUE 56 [RangeIteratorVariable(), ConstantVariable(bool: True)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:6 in fn\n",
      "                torch._dynamo.graph_break()\n",
      "TRACE LOAD_GLOBAL torch [RangeIteratorVariable()]\n",
      "TRACE LOAD_ATTR _dynamo [RangeIteratorVariable(), LazyVariableTracker()]\n",
      "TRACE LOAD_ATTR graph_break [RangeIteratorVariable(), LazyVariableTracker()]\n",
      "TRACE CALL 0 [RangeIteratorVariable(), LazyVariableTracker(), NullVariable]\n",
      "Graph break in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:6\n",
      "Graph Break Reason: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "User code traceback:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py\", line 8, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py\", line 6, in fn\n",
      "    torch._dynamo.graph_break()\n",
      "Skipping frame because there is a graph break in a for/while loop\n",
      "<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py, line 6 in fn>\n",
      "Skipping frame Skipping frame because there is a graph break in a for/while loop\n",
      "<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py, line 6 in fn> fn                 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py 1\n",
      "put_code_state: no cache key, skipping\n",
      "run_gc_after_compile: running gc\n",
      "skipping: graph_break (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\decorators.py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:1 in fn\n",
      "    @torch.compile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:3 in fn\n",
      "        for i in range(5):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL range []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 5 [LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 1 [LazyVariableTracker(), NullVariable, ConstantVariable(int: 5)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE GET_ITER None [RangeVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FOR_ITER 120 [RangeIteratorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST i [RangeIteratorVariable(), ConstantVariable(int: 0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:4 in fn\n",
      "            x = x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x [RangeIteratorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [RangeIteratorVariable(), LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [RangeIteratorVariable(), LazyVariableTracker(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:4 in fn\n",
      "        x = x + 1\n",
      "            ~~^~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST x [RangeIteratorVariable(), TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:5 in fn\n",
      "            if i == 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST i [RangeIteratorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 3 [RangeIteratorVariable(), ConstantVariable(int: 0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COMPARE_OP == [RangeIteratorVariable(), ConstantVariable(int: 0), ConstantVariable(int: 3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_JUMP_IF_TRUE 56 [RangeIteratorVariable(), ConstantVariable(bool: False)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE JUMP_BACKWARD 24 [RangeIteratorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:3 in fn\n",
      "        for i in range(5):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FOR_ITER 120 [RangeIteratorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST i [RangeIteratorVariable(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:4 in fn\n",
      "            x = x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x [RangeIteratorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [RangeIteratorVariable(), TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [RangeIteratorVariable(), TensorVariable(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST x [RangeIteratorVariable(), TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:5 in fn\n",
      "            if i == 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST i [RangeIteratorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 3 [RangeIteratorVariable(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COMPARE_OP == [RangeIteratorVariable(), ConstantVariable(int: 1), ConstantVariable(int: 3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_JUMP_IF_TRUE 56 [RangeIteratorVariable(), ConstantVariable(bool: False)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE JUMP_BACKWARD 24 [RangeIteratorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:3 in fn\n",
      "        for i in range(5):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FOR_ITER 120 [RangeIteratorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST i [RangeIteratorVariable(), ConstantVariable(int: 2)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:4 in fn\n",
      "            x = x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x [RangeIteratorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [RangeIteratorVariable(), TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [RangeIteratorVariable(), TensorVariable(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST x [RangeIteratorVariable(), TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:5 in fn\n",
      "            if i == 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST i [RangeIteratorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 3 [RangeIteratorVariable(), ConstantVariable(int: 2)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COMPARE_OP == [RangeIteratorVariable(), ConstantVariable(int: 2), ConstantVariable(int: 3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_JUMP_IF_TRUE 56 [RangeIteratorVariable(), ConstantVariable(bool: False)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE JUMP_BACKWARD 24 [RangeIteratorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:3 in fn\n",
      "        for i in range(5):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FOR_ITER 120 [RangeIteratorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST i [RangeIteratorVariable(), ConstantVariable(int: 3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:4 in fn\n",
      "            x = x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x [RangeIteratorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [RangeIteratorVariable(), TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [RangeIteratorVariable(), TensorVariable(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST x [RangeIteratorVariable(), TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:5 in fn\n",
      "            if i == 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST i [RangeIteratorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 3 [RangeIteratorVariable(), ConstantVariable(int: 3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COMPARE_OP == [RangeIteratorVariable(), ConstantVariable(int: 3), ConstantVariable(int: 3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_JUMP_IF_TRUE 56 [RangeIteratorVariable(), ConstantVariable(bool: True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:6 in fn\n",
      "                torch._dynamo.graph_break()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL torch [RangeIteratorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR _dynamo [RangeIteratorVariable(), LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR graph_break [RangeIteratorVariable(), LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [RangeIteratorVariable(), LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph break in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py:6\n",
      "Graph Break Reason: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "User code traceback:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py\", line 8, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py\", line 6, in fn\n",
      "    torch._dynamo.graph_break()\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping frame because there is a graph break in a for/while loop\n",
      "<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py, line 6 in fn>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping frame Skipping frame because there is a graph break in a for/while loop\n",
      "<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py, line 6 in fn> fn                 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2044822433.py 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "put_code_state: no cache key, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_gc_after_compile: running gc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping: graph_break (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\decorators.py)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([6.8604, 4.9334, 3.3658])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.compile\n",
    "def fn(x):\n",
    "    for i in range(5):\n",
    "        x = x + 1\n",
    "        if i == 3:\n",
    "            torch._dynamo.graph_break()\n",
    "    return x\n",
    "fn(torch.randn(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1604d21",
   "metadata": {},
   "source": [
    "In this example, we can avoid skipping by unrolling the loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a74581ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchdynamo start compiling fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:1, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 14, in <module>\n",
      "    fn(torch.randn(3))\n",
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:1\n",
      "create_env\n",
      "TRACE MAKE_CELL x []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:1 in fn\n",
      "    @torch.compile\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3 in fn\n",
      "        def inner(i):\n",
      "TRACE LOAD_FAST x []\n",
      "TRACE BUILD_TUPLE 1 [CellVariable()]\n",
      "TRACE LOAD_CONST <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3> [TupleVariable(length=1)]\n",
      "TRACE MAKE_FUNCTION None [TupleVariable(length=1), ConstantVariable(code: <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>)]\n",
      "TRACE SET_FUNCTION_ATTRIBUTE 8 [TupleVariable(length=1), NestedUserFunctionVariable()]\n",
      "TRACE STORE_FAST inner [NestedUserFunctionVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:8 in fn\n",
      "        inner(0)\n",
      "TRACE LOAD_FAST inner []\n",
      "TRACE PUSH_NULL None [NestedUserFunctionVariable()]\n",
      "TRACE LOAD_CONST 0 [NestedUserFunctionVariable(), NullVariable]\n",
      "TRACE CALL 1 [NestedUserFunctionVariable(), NullVariable, ConstantVariable(int: 0)]\n",
      "TRACE inlined call inner from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:8 in fn\n",
      "    inner(0)\n",
      "    ~~~~~^^^\n",
      "INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>, inlined according trace_rules.lookup inlined by default\n",
      "TRACE COPY_FREE_VARS 1 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3 in inner (inline depth: 1)\n",
      "        def inner(i):\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner (inline depth: 1)\n",
      "            x = x + 1\n",
      "TRACE LOAD_DEREF x []\n",
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=True), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n",
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n",
      "TRACE LOAD_CONST 1 [TensorVariable()]\n",
      "TRACE BINARY_OP 0 [TensorVariable(), ConstantVariable(int: 1)]\n",
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner (inline depth: 1)\n",
      "        x = x + 1\n",
      "            ~~^~~\n",
      "TRACE STORE_DEREF x [TensorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:6 in inner (inline depth: 1)\n",
      "            if i == 3:\n",
      "TRACE LOAD_FAST i []\n",
      "TRACE LOAD_CONST 3 [ConstantVariable(int: 0)]\n",
      "TRACE COMPARE_OP == [ConstantVariable(int: 0), ConstantVariable(int: 3)]\n",
      "TRACE POP_JUMP_IF_FALSE 88 [ConstantVariable(bool: False)]\n",
      "TRACE RETURN_CONST None []\n",
      "DONE INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>\n",
      "TRACE POP_TOP None [ConstantVariable(NoneType: None)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:9 in fn\n",
      "        inner(1)\n",
      "TRACE LOAD_FAST inner []\n",
      "TRACE PUSH_NULL None [NestedUserFunctionVariable()]\n",
      "TRACE LOAD_CONST 1 [NestedUserFunctionVariable(), NullVariable]\n",
      "TRACE CALL 1 [NestedUserFunctionVariable(), NullVariable, ConstantVariable(int: 1)]\n",
      "TRACE inlined call inner from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:9 in fn\n",
      "    inner(1)\n",
      "    ~~~~~^^^\n",
      "INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>, inlined according trace_rules.lookup inlined by default\n",
      "TRACE COPY_FREE_VARS 1 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3 in inner (inline depth: 1)\n",
      "        def inner(i):\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner (inline depth: 1)\n",
      "            x = x + 1\n",
      "TRACE LOAD_DEREF x []\n",
      "TRACE LOAD_CONST 1 [TensorVariable()]\n",
      "TRACE BINARY_OP 0 [TensorVariable(), ConstantVariable(int: 1)]\n",
      "TRACE STORE_DEREF x [TensorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:6 in inner (inline depth: 1)\n",
      "            if i == 3:\n",
      "TRACE LOAD_FAST i []\n",
      "TRACE LOAD_CONST 3 [ConstantVariable(int: 1)]\n",
      "TRACE COMPARE_OP == [ConstantVariable(int: 1), ConstantVariable(int: 3)]\n",
      "TRACE POP_JUMP_IF_FALSE 88 [ConstantVariable(bool: False)]\n",
      "TRACE RETURN_CONST None []\n",
      "DONE INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>\n",
      "TRACE POP_TOP None [ConstantVariable(NoneType: None)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:10 in fn\n",
      "        inner(2)\n",
      "TRACE LOAD_FAST inner []\n",
      "TRACE PUSH_NULL None [NestedUserFunctionVariable()]\n",
      "TRACE LOAD_CONST 2 [NestedUserFunctionVariable(), NullVariable]\n",
      "TRACE CALL 1 [NestedUserFunctionVariable(), NullVariable, ConstantVariable(int: 2)]\n",
      "TRACE inlined call inner from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:10 in fn\n",
      "    inner(2)\n",
      "    ~~~~~^^^\n",
      "INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>, inlined according trace_rules.lookup inlined by default\n",
      "TRACE COPY_FREE_VARS 1 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3 in inner (inline depth: 1)\n",
      "        def inner(i):\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner (inline depth: 1)\n",
      "            x = x + 1\n",
      "TRACE LOAD_DEREF x []\n",
      "TRACE LOAD_CONST 1 [TensorVariable()]\n",
      "TRACE BINARY_OP 0 [TensorVariable(), ConstantVariable(int: 1)]\n",
      "TRACE STORE_DEREF x [TensorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:6 in inner (inline depth: 1)\n",
      "            if i == 3:\n",
      "TRACE LOAD_FAST i []\n",
      "TRACE LOAD_CONST 3 [ConstantVariable(int: 2)]\n",
      "TRACE COMPARE_OP == [ConstantVariable(int: 2), ConstantVariable(int: 3)]\n",
      "TRACE POP_JUMP_IF_FALSE 88 [ConstantVariable(bool: False)]\n",
      "TRACE RETURN_CONST None []\n",
      "DONE INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>\n",
      "TRACE POP_TOP None [ConstantVariable(NoneType: None)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:11 in fn\n",
      "        inner(3)\n",
      "TRACE LOAD_FAST inner []\n",
      "TRACE PUSH_NULL None [NestedUserFunctionVariable()]\n",
      "TRACE LOAD_CONST 3 [NestedUserFunctionVariable(), NullVariable]\n",
      "TRACE CALL 1 [NestedUserFunctionVariable(), NullVariable, ConstantVariable(int: 3)]\n",
      "TRACE inlined call inner from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:11 in fn\n",
      "    inner(3)\n",
      "    ~~~~~^^^\n",
      "INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>, inlined according trace_rules.lookup inlined by default\n",
      "TRACE COPY_FREE_VARS 1 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3 in inner (inline depth: 1)\n",
      "        def inner(i):\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner (inline depth: 1)\n",
      "            x = x + 1\n",
      "TRACE LOAD_DEREF x []\n",
      "TRACE LOAD_CONST 1 [TensorVariable()]\n",
      "TRACE BINARY_OP 0 [TensorVariable(), ConstantVariable(int: 1)]\n",
      "TRACE STORE_DEREF x [TensorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:6 in inner (inline depth: 1)\n",
      "            if i == 3:\n",
      "TRACE LOAD_FAST i []\n",
      "TRACE LOAD_CONST 3 [ConstantVariable(int: 3)]\n",
      "TRACE COMPARE_OP == [ConstantVariable(int: 3), ConstantVariable(int: 3)]\n",
      "TRACE POP_JUMP_IF_FALSE 88 [ConstantVariable(bool: True)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:7 in inner (inline depth: 1)\n",
      "                torch._dynamo.graph_break()\n",
      "TRACE LOAD_GLOBAL torch []\n",
      "TRACE LOAD_ATTR _dynamo [LazyVariableTracker()]\n",
      "TRACE LOAD_ATTR graph_break [LazyVariableTracker()]\n",
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n",
      "empty checkpoint\n",
      "FAILED INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>\n",
      "Graph break in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:7\n",
      "Graph Break Reason: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "User code traceback:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 14, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 11, in fn\n",
      "    inner(3)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 7, in inner\n",
      "    torch._dynamo.graph_break()\n",
      "Restarting analysis due to _dynamo\\symbolic_convert.py:249 in fail_and_restart_analysis\n",
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:1\n",
      "create_env\n",
      "TRACE MAKE_CELL x []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:1 in fn\n",
      "    @torch.compile\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3 in fn\n",
      "        def inner(i):\n",
      "TRACE LOAD_FAST x []\n",
      "TRACE BUILD_TUPLE 1 [CellVariable()]\n",
      "TRACE LOAD_CONST <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3> [TupleVariable(length=1)]\n",
      "TRACE MAKE_FUNCTION None [TupleVariable(length=1), ConstantVariable(code: <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>)]\n",
      "TRACE SET_FUNCTION_ATTRIBUTE 8 [TupleVariable(length=1), NestedUserFunctionVariable()]\n",
      "TRACE STORE_FAST inner [NestedUserFunctionVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:8 in fn\n",
      "        inner(0)\n",
      "TRACE LOAD_FAST inner []\n",
      "TRACE PUSH_NULL None [NestedUserFunctionVariable()]\n",
      "TRACE LOAD_CONST 0 [NestedUserFunctionVariable(), NullVariable]\n",
      "TRACE CALL 1 [NestedUserFunctionVariable(), NullVariable, ConstantVariable(int: 0)]\n",
      "TRACE inlined call inner from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:8 in fn\n",
      "    inner(0)\n",
      "    ~~~~~^^^\n",
      "INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>, inlined according trace_rules.lookup inlined by default\n",
      "TRACE COPY_FREE_VARS 1 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3 in inner (inline depth: 1)\n",
      "        def inner(i):\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner (inline depth: 1)\n",
      "            x = x + 1\n",
      "TRACE LOAD_DEREF x []\n",
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=True), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n",
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n",
      "TRACE LOAD_CONST 1 [TensorVariable()]\n",
      "TRACE BINARY_OP 0 [TensorVariable(), ConstantVariable(int: 1)]\n",
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner (inline depth: 1)\n",
      "        x = x + 1\n",
      "            ~~^~~\n",
      "TRACE STORE_DEREF x [TensorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:6 in inner (inline depth: 1)\n",
      "            if i == 3:\n",
      "TRACE LOAD_FAST i []\n",
      "TRACE LOAD_CONST 3 [ConstantVariable(int: 0)]\n",
      "TRACE COMPARE_OP == [ConstantVariable(int: 0), ConstantVariable(int: 3)]\n",
      "TRACE POP_JUMP_IF_FALSE 88 [ConstantVariable(bool: False)]\n",
      "TRACE RETURN_CONST None []\n",
      "DONE INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>\n",
      "TRACE POP_TOP None [ConstantVariable(NoneType: None)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:9 in fn\n",
      "        inner(1)\n",
      "TRACE LOAD_FAST inner []\n",
      "TRACE PUSH_NULL None [NestedUserFunctionVariable()]\n",
      "TRACE LOAD_CONST 1 [NestedUserFunctionVariable(), NullVariable]\n",
      "TRACE CALL 1 [NestedUserFunctionVariable(), NullVariable, ConstantVariable(int: 1)]\n",
      "TRACE inlined call inner from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:9 in fn\n",
      "    inner(1)\n",
      "    ~~~~~^^^\n",
      "INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>, inlined according trace_rules.lookup inlined by default\n",
      "TRACE COPY_FREE_VARS 1 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3 in inner (inline depth: 1)\n",
      "        def inner(i):\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner (inline depth: 1)\n",
      "            x = x + 1\n",
      "TRACE LOAD_DEREF x []\n",
      "TRACE LOAD_CONST 1 [TensorVariable()]\n",
      "TRACE BINARY_OP 0 [TensorVariable(), ConstantVariable(int: 1)]\n",
      "TRACE STORE_DEREF x [TensorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:6 in inner (inline depth: 1)\n",
      "            if i == 3:\n",
      "TRACE LOAD_FAST i []\n",
      "TRACE LOAD_CONST 3 [ConstantVariable(int: 1)]\n",
      "TRACE COMPARE_OP == [ConstantVariable(int: 1), ConstantVariable(int: 3)]\n",
      "TRACE POP_JUMP_IF_FALSE 88 [ConstantVariable(bool: False)]\n",
      "TRACE RETURN_CONST None []\n",
      "DONE INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>\n",
      "TRACE POP_TOP None [ConstantVariable(NoneType: None)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:10 in fn\n",
      "        inner(2)\n",
      "TRACE LOAD_FAST inner []\n",
      "TRACE PUSH_NULL None [NestedUserFunctionVariable()]\n",
      "TRACE LOAD_CONST 2 [NestedUserFunctionVariable(), NullVariable]\n",
      "TRACE CALL 1 [NestedUserFunctionVariable(), NullVariable, ConstantVariable(int: 2)]\n",
      "TRACE inlined call inner from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:10 in fn\n",
      "    inner(2)\n",
      "    ~~~~~^^^\n",
      "INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>, inlined according trace_rules.lookup inlined by default\n",
      "TRACE COPY_FREE_VARS 1 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3 in inner (inline depth: 1)\n",
      "        def inner(i):\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner (inline depth: 1)\n",
      "            x = x + 1\n",
      "TRACE LOAD_DEREF x []\n",
      "TRACE LOAD_CONST 1 [TensorVariable()]\n",
      "TRACE BINARY_OP 0 [TensorVariable(), ConstantVariable(int: 1)]\n",
      "TRACE STORE_DEREF x [TensorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:6 in inner (inline depth: 1)\n",
      "            if i == 3:\n",
      "TRACE LOAD_FAST i []\n",
      "TRACE LOAD_CONST 3 [ConstantVariable(int: 2)]\n",
      "TRACE COMPARE_OP == [ConstantVariable(int: 2), ConstantVariable(int: 3)]\n",
      "TRACE POP_JUMP_IF_FALSE 88 [ConstantVariable(bool: False)]\n",
      "TRACE RETURN_CONST None []\n",
      "DONE INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>\n",
      "TRACE POP_TOP None [ConstantVariable(NoneType: None)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:11 in fn\n",
      "        inner(3)\n",
      "TRACE LOAD_FAST inner []\n",
      "TRACE PUSH_NULL None [NestedUserFunctionVariable()]\n",
      "TRACE LOAD_CONST 3 [NestedUserFunctionVariable(), NullVariable]\n",
      "TRACE CALL 1 [NestedUserFunctionVariable(), NullVariable, ConstantVariable(int: 3)]\n",
      "COMPILING GRAPH due to GraphCompileReason(reason='Call to `torch._dynamo.graph_break()`\\n  Explanation: User-inserted graph break. Message: None\\n  Hint: Remove the `torch._dynamo.graph_break()` call.\\n\\n  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\\n\\n For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py, line 11 in fn>, <FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py, line 7 in inner>], graph_break=True)\n",
      "TRACED GRAPH\n",
      " ===== __compiled_fn_8_83210245_99e4_443c_8ade_65bebe71394c =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner, code: x = x + 1\n",
      "        x: \"f32[3][1]cpu\" = l_x_ + 1;  l_x_ = None\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner, code: x = x + 1\n",
      "        x_1: \"f32[3][1]cpu\" = x + 1;  x = None\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner, code: x = x + 1\n",
      "        x_2: \"f32[3][1]cpu\" = x_1 + 1;  x_1 = None\n",
      "        return (x_2,)\n",
      "Step 2: calling compiler function eager\n",
      "Step 2: done compiler function eager\n",
      "produce_guards\n",
      "track_symint L['x'].size()[0] 3 None\n",
      "track_symint L['x'].stride()[0] 1 None\n",
      "track_symint L['x'].storage_offset() 0 None\n",
      "Skipping guard L['x'].size()[0] == 3\n",
      "Skipping guard L['x'].stride()[0] == 1\n",
      "Skipping guard L['x'].storage_offset() == 0\n",
      "GUARDS:\n",
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=0), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # x = x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # x = x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner\n",
      "Guard eval latency = 89.50 us\n",
      "put_code_state: no cache key, skipping\n",
      "run_gc_after_compile: running gc\n",
      "skipping: _create_nested_fn (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\functions.py)\n",
      "skipping: __getattr__ (reason: in skipfiles, file: C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\types.py)\n",
      "torchdynamo start compiling inner C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 14, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 832, in compile_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "Step 1: torchdynamo start tracing inner C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3\n",
      "create_env\n",
      "TRACE COPY_FREE_VARS 1 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3 in inner\n",
      "        def inner(i):\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner\n",
      "            x = x + 1\n",
      "TRACE LOAD_DEREF x []\n",
      "TRACE LOAD_CONST 1 [LazyVariableTracker()]\n",
      "TRACE BINARY_OP 0 [LazyVariableTracker(), ConstantVariable(int: 1)]\n",
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=False, dynamism=None, is_derefed_cell_contents=True), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n",
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n",
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner\n",
      "        x = x + 1\n",
      "            ~~^~~\n",
      "TRACE STORE_DEREF x [TensorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:6 in inner\n",
      "            if i == 3:\n",
      "TRACE LOAD_FAST i []\n",
      "TRACE LOAD_CONST 3 [LazyVariableTracker()]\n",
      "TRACE COMPARE_OP == [LazyVariableTracker(), ConstantVariable(int: 3)]\n",
      "TRACE POP_JUMP_IF_FALSE 88 [ConstantVariable(bool: True)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:7 in inner\n",
      "                torch._dynamo.graph_break()\n",
      "TRACE LOAD_GLOBAL torch []\n",
      "TRACE LOAD_ATTR _dynamo [LazyVariableTracker()]\n",
      "TRACE LOAD_ATTR graph_break [LazyVariableTracker()]\n",
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n",
      "Graph break (user stack suppressed due to duplicate graph break) in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:7\n",
      "Graph Break Reason: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "Restarting analysis due to _dynamo\\symbolic_convert.py:249 in fail_and_restart_analysis\n",
      "Step 1: torchdynamo start tracing inner C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3\n",
      "create_env\n",
      "TRACE COPY_FREE_VARS 1 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3 in inner\n",
      "        def inner(i):\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner\n",
      "            x = x + 1\n",
      "TRACE LOAD_DEREF x []\n",
      "TRACE LOAD_CONST 1 [LazyVariableTracker()]\n",
      "TRACE BINARY_OP 0 [LazyVariableTracker(), ConstantVariable(int: 1)]\n",
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=False, dynamism=None, is_derefed_cell_contents=True), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n",
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n",
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner\n",
      "        x = x + 1\n",
      "            ~~^~~\n",
      "TRACE STORE_DEREF x [TensorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:6 in inner\n",
      "            if i == 3:\n",
      "TRACE LOAD_FAST i []\n",
      "TRACE LOAD_CONST 3 [LazyVariableTracker()]\n",
      "TRACE COMPARE_OP == [LazyVariableTracker(), ConstantVariable(int: 3)]\n",
      "TRACE POP_JUMP_IF_FALSE 88 [ConstantVariable(bool: True)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:7 in inner\n",
      "                torch._dynamo.graph_break()\n",
      "TRACE LOAD_GLOBAL torch []\n",
      "TRACE LOAD_ATTR _dynamo [LazyVariableTracker()]\n",
      "TRACE LOAD_ATTR graph_break [LazyVariableTracker()]\n",
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n",
      "COMPILING GRAPH due to GraphCompileReason(reason='Call to `torch._dynamo.graph_break()`\\n  Explanation: User-inserted graph break. Message: None\\n  Hint: Remove the `torch._dynamo.graph_break()` call.\\n\\n  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\\n\\n For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py, line 7 in inner>], graph_break=True)\n",
      "TRACED GRAPH\n",
      " ===== __compiled_fn_12_bf6b642b_3d45_4c5a_92b2_db8e0d19a346 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner, code: x = x + 1\n",
      "        x: \"f32[3][1]cpu\" = l_x_ + 1;  l_x_ = None\n",
      "        return (x,)\n",
      "Step 2: calling compiler function eager\n",
      "Step 2: done compiler function eager\n",
      "produce_guards\n",
      "track_symint L['x'].size()[0] 3 None\n",
      "track_symint L['x'].stride()[0] 1 None\n",
      "track_symint L['x'].storage_offset() 0 None\n",
      "Skipping guard L['x'].size()[0] == 3\n",
      "Skipping guard L['x'].stride()[0] == 1\n",
      "Skipping guard L['x'].storage_offset() == 0\n",
      "GUARDS:\n",
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['i'], accessed_by=FrameLocalsGuardAccessor(key='i', framelocals_idx=0), type=<class 'int'>, tag_safe=(True, False)\n",
      "| | +- EQUALS_MATCH: L['i'] == 3                                                   # if i == 3:  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:6 in inner\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=1), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # x = x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # x = x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner\n",
      "| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor, type=<class 'dict'>, tag_safe=(False, False)\n",
      "| | +- GuardManager: source=G['torch'], accessed_by=DictGetItemGuardAccessor('torch'), type=<class 'module'>, tag_safe=(False, False)\n",
      "| | | +- ID_MATCH: ___check_obj_id(G['torch'], 1846212640448)                    # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:7 in inner\n",
      "| | | +- GuardManager: source=G['torch']._dynamo, accessed_by=GetAttrGuardAccessor(_dynamo), type=<class 'module'>, tag_safe=(False, False)\n",
      "| | | | +- ID_MATCH: ___check_obj_id(G['torch']._dynamo, 1846752934096)            # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:7 in inner\n",
      "| | | | +- GuardManager: source=G['torch']._dynamo.graph_break, accessed_by=GetAttrGuardAccessor(graph_break), type=<class 'function'>, tag_safe=(True, False)\n",
      "| | | | | +- GuardManager: source=G['torch']._dynamo.graph_break.__code__, accessed_by=CodeGuardAccessor, type=<class 'code'>, tag_safe=(True, False)\n",
      "| | | | | | +- ID_MATCH: ___check_obj_id(G['torch']._dynamo.graph_break.__code__, 1846802753744)  # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:7 in inner\n",
      "Guard eval latency = 137.50 us\n",
      "put_code_state: no cache key, skipping\n",
      "run_gc_after_compile: running gc\n",
      "torchdynamo start compiling torch_dynamo_resume_in_inner_at_7 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:7, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 14, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 832, in compile_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 11, in fn\n",
      "    inner(3)\n",
      "Step 1: torchdynamo start tracing torch_dynamo_resume_in_inner_at_7 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:7\n",
      "create_env\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:7 in torch_dynamo_resume_in_inner_at_7\n",
      "                torch._dynamo.graph_break()\n",
      "TRACE COPY_FREE_VARS 1 []\n",
      "TRACE RESUME 0 []\n",
      "TRACE LOAD_CONST True []\n",
      "TRACE STORE_FAST __is_tracing_resume_prologue [ConstantVariable(bool: True)]\n",
      "TRACE LOAD_FAST ___stack0 []\n",
      "TRACE LOAD_CONST False [LazyVariableTracker()]\n",
      "TRACE STORE_FAST __is_tracing_resume_prologue [LazyVariableTracker(), ConstantVariable(bool: False)]\n",
      "TRACE JUMP_FORWARD 100 [LazyVariableTracker()]\n",
      "TRACE POP_TOP None [LazyVariableTracker()]\n",
      "TRACE RETURN_CONST None []\n",
      "Skipping frame because no content in function call torch_dynamo_resume_in_inner_at_7                 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py 7\n",
      "put_code_state: no cache key, skipping\n",
      "run_gc_after_compile: running gc\n",
      "torchdynamo start compiling torch_dynamo_resume_in_fn_at_11 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:11, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 14, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 832, in compile_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "Step 1: torchdynamo start tracing torch_dynamo_resume_in_fn_at_11 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:11\n",
      "create_env\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:11 in torch_dynamo_resume_in_fn_at_11\n",
      "        inner(3)\n",
      "TRACE COPY_FREE_VARS 1 []\n",
      "TRACE RESUME 0 []\n",
      "TRACE LOAD_CONST True []\n",
      "TRACE STORE_FAST __is_tracing_resume_prologue [ConstantVariable(bool: True)]\n",
      "TRACE LOAD_FAST ___stack0 []\n",
      "TRACE LOAD_CONST False [LazyVariableTracker()]\n",
      "TRACE STORE_FAST __is_tracing_resume_prologue [LazyVariableTracker(), ConstantVariable(bool: False)]\n",
      "TRACE JUMP_FORWARD 94 [LazyVariableTracker()]\n",
      "TRACE POP_TOP None [LazyVariableTracker()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:12 in torch_dynamo_resume_in_fn_at_11\n",
      "        inner(4)\n",
      "TRACE LOAD_FAST inner []\n",
      "TRACE PUSH_NULL None [LazyVariableTracker()]\n",
      "TRACE LOAD_CONST 4 [LazyVariableTracker(), NullVariable]\n",
      "TRACE CALL 1 [LazyVariableTracker(), NullVariable, ConstantVariable(int: 4)]\n",
      "TRACE inlined call inner from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:12 in torch_dynamo_resume_in_fn_at_11\n",
      "    inner(4)\n",
      "    ~~~~~^^^\n",
      "INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>, inlined according trace_rules.lookup inlined by default\n",
      "TRACE COPY_FREE_VARS 1 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3 in inner (inline depth: 1)\n",
      "        def inner(i):\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner (inline depth: 1)\n",
      "            x = x + 1\n",
      "TRACE LOAD_DEREF x []\n",
      "TRACE LOAD_CONST 1 [LazyVariableTracker()]\n",
      "TRACE BINARY_OP 0 [LazyVariableTracker(), ConstantVariable(int: 1)]\n",
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=False, dynamism=None, is_derefed_cell_contents=True), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n",
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n",
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner (inline depth: 1)\n",
      "        x = x + 1\n",
      "            ~~^~~\n",
      "TRACE STORE_DEREF x [TensorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:6 in inner (inline depth: 1)\n",
      "            if i == 3:\n",
      "TRACE LOAD_FAST i []\n",
      "TRACE LOAD_CONST 3 [ConstantVariable(int: 4)]\n",
      "TRACE COMPARE_OP == [ConstantVariable(int: 4), ConstantVariable(int: 3)]\n",
      "TRACE POP_JUMP_IF_FALSE 88 [ConstantVariable(bool: False)]\n",
      "TRACE RETURN_CONST None []\n",
      "DONE INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>\n",
      "TRACE POP_TOP None [ConstantVariable(NoneType: None)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:13 in torch_dynamo_resume_in_fn_at_11\n",
      "        return x\n",
      "TRACE LOAD_DEREF x []\n",
      "TRACE RETURN_VALUE None [TensorVariable()]\n",
      "Step 1: torchdynamo done tracing torch_dynamo_resume_in_fn_at_11 (RETURN_VALUE)\n",
      "RETURN_VALUE triggered compile\n",
      "COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py, line 13 in torch_dynamo_resume_in_fn_at_11>], graph_break=False)\n",
      "TRACED GRAPH\n",
      " ===== __compiled_fn_16_da2145d3_17a0_4609_aff3_c1a17bb11d96 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner, code: x = x + 1\n",
      "        x: \"f32[3][1]cpu\" = l_x_ + 1;  l_x_ = None\n",
      "        return (x,)\n",
      "Step 2: calling compiler function eager\n",
      "Step 2: done compiler function eager\n",
      "produce_guards\n",
      "track_symint L['x'].size()[0] 3 None\n",
      "track_symint L['x'].stride()[0] 1 None\n",
      "track_symint L['x'].storage_offset() 0 None\n",
      "Skipping guard L['x'].size()[0] == 3\n",
      "Skipping guard L['x'].stride()[0] == 1\n",
      "Skipping guard L['x'].storage_offset() == 0\n",
      "GUARDS:\n",
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=6), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # x = x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # x = x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner\n",
      "| +- GuardManager: source=L['inner'], accessed_by=FrameLocalsGuardAccessor(key='inner', framelocals_idx=3), type=<class 'function'>, tag_safe=(True, False)\n",
      "| | +- GuardManager: source=L['inner'].__code__, accessed_by=CodeGuardAccessor, type=<class 'code'>, tag_safe=(True, False)\n",
      "| | | +- ID_MATCH: ___check_obj_id(L['inner'].__code__, 1846817738656)           # inner(4)  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:12 in torch_dynamo_resume_in_fn_at_11\n",
      "Guard eval latency = 264.50 us\n",
      "put_code_state: no cache key, skipping\n",
      "run_gc_after_compile: running gc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE MAKE_CELL x []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:1 in fn\n",
      "    @torch.compile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3 in fn\n",
      "        def inner(i):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BUILD_TUPLE 1 [CellVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3> [TupleVariable(length=1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE MAKE_FUNCTION None [TupleVariable(length=1), ConstantVariable(code: <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE SET_FUNCTION_ATTRIBUTE 8 [TupleVariable(length=1), NestedUserFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST inner [NestedUserFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:8 in fn\n",
      "        inner(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST inner []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE PUSH_NULL None [NestedUserFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 0 [NestedUserFunctionVariable(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 1 [NestedUserFunctionVariable(), NullVariable, ConstantVariable(int: 0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE inlined call inner from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:8 in fn\n",
      "    inner(0)\n",
      "    ~~~~~^^^\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>, inlined according trace_rules.lookup inlined by default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COPY_FREE_VARS 1 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3 in inner (inline depth: 1)\n",
      "        def inner(i):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner (inline depth: 1)\n",
      "            x = x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_DEREF x []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=True), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [TensorVariable(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner (inline depth: 1)\n",
      "        x = x + 1\n",
      "            ~~^~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_DEREF x [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:6 in inner (inline depth: 1)\n",
      "            if i == 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST i []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 3 [ConstantVariable(int: 0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COMPARE_OP == [ConstantVariable(int: 0), ConstantVariable(int: 3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_JUMP_IF_FALSE 88 [ConstantVariable(bool: False)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_CONST None []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DONE INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:9 in fn\n",
      "        inner(1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST inner []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE PUSH_NULL None [NestedUserFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [NestedUserFunctionVariable(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 1 [NestedUserFunctionVariable(), NullVariable, ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE inlined call inner from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:9 in fn\n",
      "    inner(1)\n",
      "    ~~~~~^^^\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>, inlined according trace_rules.lookup inlined by default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COPY_FREE_VARS 1 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3 in inner (inline depth: 1)\n",
      "        def inner(i):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner (inline depth: 1)\n",
      "            x = x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_DEREF x []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [TensorVariable(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_DEREF x [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:6 in inner (inline depth: 1)\n",
      "            if i == 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST i []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 3 [ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COMPARE_OP == [ConstantVariable(int: 1), ConstantVariable(int: 3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_JUMP_IF_FALSE 88 [ConstantVariable(bool: False)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_CONST None []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DONE INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:10 in fn\n",
      "        inner(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST inner []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE PUSH_NULL None [NestedUserFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 2 [NestedUserFunctionVariable(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 1 [NestedUserFunctionVariable(), NullVariable, ConstantVariable(int: 2)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE inlined call inner from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:10 in fn\n",
      "    inner(2)\n",
      "    ~~~~~^^^\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>, inlined according trace_rules.lookup inlined by default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COPY_FREE_VARS 1 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3 in inner (inline depth: 1)\n",
      "        def inner(i):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner (inline depth: 1)\n",
      "            x = x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_DEREF x []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [TensorVariable(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_DEREF x [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:6 in inner (inline depth: 1)\n",
      "            if i == 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST i []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 3 [ConstantVariable(int: 2)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COMPARE_OP == [ConstantVariable(int: 2), ConstantVariable(int: 3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_JUMP_IF_FALSE 88 [ConstantVariable(bool: False)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_CONST None []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DONE INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:11 in fn\n",
      "        inner(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST inner []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE PUSH_NULL None [NestedUserFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 3 [NestedUserFunctionVariable(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 1 [NestedUserFunctionVariable(), NullVariable, ConstantVariable(int: 3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE inlined call inner from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:11 in fn\n",
      "    inner(3)\n",
      "    ~~~~~^^^\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>, inlined according trace_rules.lookup inlined by default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COPY_FREE_VARS 1 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3 in inner (inline depth: 1)\n",
      "        def inner(i):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner (inline depth: 1)\n",
      "            x = x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_DEREF x []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [TensorVariable(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_DEREF x [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:6 in inner (inline depth: 1)\n",
      "            if i == 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST i []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 3 [ConstantVariable(int: 3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COMPARE_OP == [ConstantVariable(int: 3), ConstantVariable(int: 3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_JUMP_IF_FALSE 88 [ConstantVariable(bool: True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:7 in inner (inline depth: 1)\n",
      "                torch._dynamo.graph_break()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL torch []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR _dynamo [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR graph_break [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "empty checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FAILED INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph break in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:7\n",
      "Graph Break Reason: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "User code traceback:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 14, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 11, in fn\n",
      "    inner(3)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 7, in inner\n",
      "    torch._dynamo.graph_break()\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restarting analysis due to _dynamo\\symbolic_convert.py:249 in fail_and_restart_analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE MAKE_CELL x []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:1 in fn\n",
      "    @torch.compile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3 in fn\n",
      "        def inner(i):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BUILD_TUPLE 1 [CellVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3> [TupleVariable(length=1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE MAKE_FUNCTION None [TupleVariable(length=1), ConstantVariable(code: <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE SET_FUNCTION_ATTRIBUTE 8 [TupleVariable(length=1), NestedUserFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST inner [NestedUserFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:8 in fn\n",
      "        inner(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST inner []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE PUSH_NULL None [NestedUserFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 0 [NestedUserFunctionVariable(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 1 [NestedUserFunctionVariable(), NullVariable, ConstantVariable(int: 0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE inlined call inner from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:8 in fn\n",
      "    inner(0)\n",
      "    ~~~~~^^^\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>, inlined according trace_rules.lookup inlined by default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COPY_FREE_VARS 1 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3 in inner (inline depth: 1)\n",
      "        def inner(i):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner (inline depth: 1)\n",
      "            x = x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_DEREF x []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=True), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [TensorVariable(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner (inline depth: 1)\n",
      "        x = x + 1\n",
      "            ~~^~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_DEREF x [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:6 in inner (inline depth: 1)\n",
      "            if i == 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST i []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 3 [ConstantVariable(int: 0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COMPARE_OP == [ConstantVariable(int: 0), ConstantVariable(int: 3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_JUMP_IF_FALSE 88 [ConstantVariable(bool: False)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_CONST None []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DONE INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:9 in fn\n",
      "        inner(1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST inner []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE PUSH_NULL None [NestedUserFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [NestedUserFunctionVariable(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 1 [NestedUserFunctionVariable(), NullVariable, ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE inlined call inner from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:9 in fn\n",
      "    inner(1)\n",
      "    ~~~~~^^^\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>, inlined according trace_rules.lookup inlined by default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COPY_FREE_VARS 1 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3 in inner (inline depth: 1)\n",
      "        def inner(i):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner (inline depth: 1)\n",
      "            x = x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_DEREF x []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [TensorVariable(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_DEREF x [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:6 in inner (inline depth: 1)\n",
      "            if i == 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST i []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 3 [ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COMPARE_OP == [ConstantVariable(int: 1), ConstantVariable(int: 3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_JUMP_IF_FALSE 88 [ConstantVariable(bool: False)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_CONST None []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DONE INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:10 in fn\n",
      "        inner(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST inner []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE PUSH_NULL None [NestedUserFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 2 [NestedUserFunctionVariable(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 1 [NestedUserFunctionVariable(), NullVariable, ConstantVariable(int: 2)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE inlined call inner from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:10 in fn\n",
      "    inner(2)\n",
      "    ~~~~~^^^\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>, inlined according trace_rules.lookup inlined by default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COPY_FREE_VARS 1 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3 in inner (inline depth: 1)\n",
      "        def inner(i):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner (inline depth: 1)\n",
      "            x = x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_DEREF x []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [TensorVariable(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_DEREF x [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:6 in inner (inline depth: 1)\n",
      "            if i == 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST i []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 3 [ConstantVariable(int: 2)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COMPARE_OP == [ConstantVariable(int: 2), ConstantVariable(int: 3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_JUMP_IF_FALSE 88 [ConstantVariable(bool: False)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_CONST None []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DONE INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:11 in fn\n",
      "        inner(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST inner []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE PUSH_NULL None [NestedUserFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 3 [NestedUserFunctionVariable(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 1 [NestedUserFunctionVariable(), NullVariable, ConstantVariable(int: 3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMPILING GRAPH due to GraphCompileReason(reason='Call to `torch._dynamo.graph_break()`\\n  Explanation: User-inserted graph break. Message: None\\n  Hint: Remove the `torch._dynamo.graph_break()` call.\\n\\n  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\\n\\n For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py, line 11 in fn>, <FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py, line 7 in inner>], graph_break=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACED GRAPH\n",
      " ===== __compiled_fn_8_83210245_99e4_443c_8ade_65bebe71394c =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner, code: x = x + 1\n",
      "        x: \"f32[3][1]cpu\" = l_x_ + 1;  l_x_ = None\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner, code: x = x + 1\n",
      "        x_1: \"f32[3][1]cpu\" = x + 1;  x = None\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner, code: x = x + 1\n",
      "        x_2: \"f32[3][1]cpu\" = x_1 + 1;  x_1 = None\n",
      "        return (x_2,)\n",
      "        \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: calling compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: done compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "produce_guards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].size()[0] 3 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].stride()[0] 1 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].storage_offset() 0 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].size()[0] == 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].stride()[0] == 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].storage_offset() == 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GUARDS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=0), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # x = x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # x = x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Guard eval latency = 89.50 us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "put_code_state: no cache key, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_gc_after_compile: running gc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping: _create_nested_fn (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\functions.py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping: __getattr__ (reason: in skipfiles, file: C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\types.py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchdynamo start compiling inner C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 14, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 832, in compile_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo start tracing inner C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COPY_FREE_VARS 1 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3 in inner\n",
      "        def inner(i):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner\n",
      "            x = x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_DEREF x []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [LazyVariableTracker(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=False, dynamism=None, is_derefed_cell_contents=True), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner\n",
      "        x = x + 1\n",
      "            ~~^~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_DEREF x [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:6 in inner\n",
      "            if i == 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST i []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 3 [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COMPARE_OP == [LazyVariableTracker(), ConstantVariable(int: 3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_JUMP_IF_FALSE 88 [ConstantVariable(bool: True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:7 in inner\n",
      "                torch._dynamo.graph_break()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL torch []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR _dynamo [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR graph_break [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph break (user stack suppressed due to duplicate graph break) in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:7\n",
      "Graph Break Reason: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restarting analysis due to _dynamo\\symbolic_convert.py:249 in fail_and_restart_analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo start tracing inner C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COPY_FREE_VARS 1 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3 in inner\n",
      "        def inner(i):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner\n",
      "            x = x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_DEREF x []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [LazyVariableTracker(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=False, dynamism=None, is_derefed_cell_contents=True), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner\n",
      "        x = x + 1\n",
      "            ~~^~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_DEREF x [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:6 in inner\n",
      "            if i == 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST i []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 3 [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COMPARE_OP == [LazyVariableTracker(), ConstantVariable(int: 3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_JUMP_IF_FALSE 88 [ConstantVariable(bool: True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:7 in inner\n",
      "                torch._dynamo.graph_break()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL torch []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR _dynamo [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR graph_break [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMPILING GRAPH due to GraphCompileReason(reason='Call to `torch._dynamo.graph_break()`\\n  Explanation: User-inserted graph break. Message: None\\n  Hint: Remove the `torch._dynamo.graph_break()` call.\\n\\n  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\\n\\n For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py, line 7 in inner>], graph_break=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACED GRAPH\n",
      " ===== __compiled_fn_12_bf6b642b_3d45_4c5a_92b2_db8e0d19a346 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner, code: x = x + 1\n",
      "        x: \"f32[3][1]cpu\" = l_x_ + 1;  l_x_ = None\n",
      "        return (x,)\n",
      "        \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: calling compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: done compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "produce_guards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].size()[0] 3 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].stride()[0] 1 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].storage_offset() 0 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].size()[0] == 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].stride()[0] == 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].storage_offset() == 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GUARDS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['i'], accessed_by=FrameLocalsGuardAccessor(key='i', framelocals_idx=0), type=<class 'int'>, tag_safe=(True, False)\n",
      "| | +- EQUALS_MATCH: L['i'] == 3                                                   # if i == 3:  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:6 in inner\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=1), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # x = x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # x = x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner\n",
      "| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor, type=<class 'dict'>, tag_safe=(False, False)\n",
      "| | +- GuardManager: source=G['torch'], accessed_by=DictGetItemGuardAccessor('torch'), type=<class 'module'>, tag_safe=(False, False)\n",
      "| | | +- ID_MATCH: ___check_obj_id(G['torch'], 1846212640448)                    # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:7 in inner\n",
      "| | | +- GuardManager: source=G['torch']._dynamo, accessed_by=GetAttrGuardAccessor(_dynamo), type=<class 'module'>, tag_safe=(False, False)\n",
      "| | | | +- ID_MATCH: ___check_obj_id(G['torch']._dynamo, 1846752934096)            # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:7 in inner\n",
      "| | | | +- GuardManager: source=G['torch']._dynamo.graph_break, accessed_by=GetAttrGuardAccessor(graph_break), type=<class 'function'>, tag_safe=(True, False)\n",
      "| | | | | +- GuardManager: source=G['torch']._dynamo.graph_break.__code__, accessed_by=CodeGuardAccessor, type=<class 'code'>, tag_safe=(True, False)\n",
      "| | | | | | +- ID_MATCH: ___check_obj_id(G['torch']._dynamo.graph_break.__code__, 1846802753744)  # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:7 in inner\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Guard eval latency = 137.50 us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "put_code_state: no cache key, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_gc_after_compile: running gc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchdynamo start compiling torch_dynamo_resume_in_inner_at_7 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:7, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 14, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 832, in compile_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 11, in fn\n",
      "    inner(3)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo start tracing torch_dynamo_resume_in_inner_at_7 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:7 in torch_dynamo_resume_in_inner_at_7\n",
      "                torch._dynamo.graph_break()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COPY_FREE_VARS 1 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST True []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST __is_tracing_resume_prologue [ConstantVariable(bool: True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST ___stack0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST False [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST __is_tracing_resume_prologue [LazyVariableTracker(), ConstantVariable(bool: False)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE JUMP_FORWARD 100 [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_CONST None []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping frame because no content in function call torch_dynamo_resume_in_inner_at_7                 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "put_code_state: no cache key, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_gc_after_compile: running gc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchdynamo start compiling torch_dynamo_resume_in_fn_at_11 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:11, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 14, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 832, in compile_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo start tracing torch_dynamo_resume_in_fn_at_11 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:11 in torch_dynamo_resume_in_fn_at_11\n",
      "        inner(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COPY_FREE_VARS 1 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST True []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST __is_tracing_resume_prologue [ConstantVariable(bool: True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST ___stack0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST False [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST __is_tracing_resume_prologue [LazyVariableTracker(), ConstantVariable(bool: False)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE JUMP_FORWARD 94 [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:12 in torch_dynamo_resume_in_fn_at_11\n",
      "        inner(4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST inner []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE PUSH_NULL None [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 4 [LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 1 [LazyVariableTracker(), NullVariable, ConstantVariable(int: 4)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE inlined call inner from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:12 in torch_dynamo_resume_in_fn_at_11\n",
      "    inner(4)\n",
      "    ~~~~~^^^\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>, inlined according trace_rules.lookup inlined by default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COPY_FREE_VARS 1 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:3 in inner (inline depth: 1)\n",
      "        def inner(i):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner (inline depth: 1)\n",
      "            x = x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_DEREF x []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [LazyVariableTracker(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=False, dynamism=None, is_derefed_cell_contents=True), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner (inline depth: 1)\n",
      "        x = x + 1\n",
      "            ~~^~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_DEREF x [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:6 in inner (inline depth: 1)\n",
      "            if i == 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST i []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 3 [ConstantVariable(int: 4)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE COMPARE_OP == [ConstantVariable(int: 4), ConstantVariable(int: 3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_JUMP_IF_FALSE 88 [ConstantVariable(bool: False)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_CONST None []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DONE INLINING <code object inner at 0x000001ADFEEA4FA0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py\", line 3>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:13 in torch_dynamo_resume_in_fn_at_11\n",
      "        return x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_DEREF x []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_VALUE None [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo done tracing torch_dynamo_resume_in_fn_at_11 (RETURN_VALUE)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RETURN_VALUE triggered compile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py, line 13 in torch_dynamo_resume_in_fn_at_11>], graph_break=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACED GRAPH\n",
      " ===== __compiled_fn_16_da2145d3_17a0_4609_aff3_c1a17bb11d96 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner, code: x = x + 1\n",
      "        x: \"f32[3][1]cpu\" = l_x_ + 1;  l_x_ = None\n",
      "        return (x,)\n",
      "        \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: calling compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: done compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "produce_guards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].size()[0] 3 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].stride()[0] 1 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].storage_offset() 0 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].size()[0] == 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].stride()[0] == 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].storage_offset() == 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GUARDS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=6), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # x = x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # x = x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:5 in inner\n",
      "| +- GuardManager: source=L['inner'], accessed_by=FrameLocalsGuardAccessor(key='inner', framelocals_idx=3), type=<class 'function'>, tag_safe=(True, False)\n",
      "| | +- GuardManager: source=L['inner'].__code__, accessed_by=CodeGuardAccessor, type=<class 'code'>, tag_safe=(True, False)\n",
      "| | | +- ID_MATCH: ___check_obj_id(L['inner'].__code__, 1846817738656)           # inner(4)  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\617960493.py:12 in torch_dynamo_resume_in_fn_at_11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Guard eval latency = 264.50 us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "put_code_state: no cache key, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_gc_after_compile: running gc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([4.5721, 3.7991, 4.9834])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.compile\n",
    "def fn(x):\n",
    "    def inner(i):\n",
    "        nonlocal x\n",
    "        x = x + 1\n",
    "        if i == 3:\n",
    "            torch._dynamo.graph_break()\n",
    "    inner(0)\n",
    "    inner(1)\n",
    "    inner(2)\n",
    "    inner(3)\n",
    "    inner(4)\n",
    "    return x\n",
    "fn(torch.randn(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b60388",
   "metadata": {},
   "source": [
    "In general, resolving the graph break causing the skip will also resolve the skip.\n",
    "\n",
    "## Graph Break in a Context Manager\n",
    "\n",
    "Another common example of an unresumable graph break is a graph break in most context managers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "849e0699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchdynamo start compiling fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:6, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 12, in <module>\n",
      "    fn(torch.randn(3))\n",
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:6\n",
      "create_env\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:6 in fn\n",
      "    @torch.compile\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:8 in fn\n",
      "        with CustomCtxManager():\n",
      "TRACE LOAD_GLOBAL CustomCtxManager []\n",
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n",
      "TRACE BEFORE_WITH None [GenericContextWrappingVariable(CustomCtxManager)]\n",
      "TRACE inlined call __enter__ from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:8 in fn\n",
      "    with CustomCtxManager():\n",
      "         ~~~~~~~~~~~~~~~~^^\n",
      "INLINING <code object __enter__ at 0x000001ADFEEBD890, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 2>, inlined according trace_rules.lookup inlined by default\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:2 in __enter__ (inline depth: 1)\n",
      "        def __enter__(self):\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:3 in __enter__ (inline depth: 1)\n",
      "            pass\n",
      "TRACE RETURN_CONST None []\n",
      "DONE INLINING <code object __enter__ at 0x000001ADFEEBD890, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 2>\n",
      "TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:9 in fn\n",
      "            x = x + 1\n",
      "TRACE LOAD_FAST x [WithExitFunctionVariable()]\n",
      "TRACE LOAD_CONST 1 [WithExitFunctionVariable(), LazyVariableTracker()]\n",
      "TRACE BINARY_OP 0 [WithExitFunctionVariable(), LazyVariableTracker(), ConstantVariable(int: 1)]\n",
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n",
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n",
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:9 in fn\n",
      "        x = x + 1\n",
      "            ~~^~~\n",
      "TRACE STORE_FAST x [WithExitFunctionVariable(), TensorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:10 in fn\n",
      "            torch._dynamo.graph_break()\n",
      "TRACE LOAD_GLOBAL torch [WithExitFunctionVariable()]\n",
      "TRACE LOAD_ATTR _dynamo [WithExitFunctionVariable(), LazyVariableTracker()]\n",
      "TRACE LOAD_ATTR graph_break [WithExitFunctionVariable(), LazyVariableTracker()]\n",
      "TRACE CALL 0 [WithExitFunctionVariable(), LazyVariableTracker(), NullVariable]\n",
      "empty checkpoint\n",
      "run_gc_after_compile: running gc\n",
      "Graph break: skip: from user code at:\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 10, in fn\n",
      "    torch._dynamo.graph_break()\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 904, in wrapper\n",
      "    return inner_fn(self, inst)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3411, in CALL\n",
      "    self._call(inst)\n",
      "    ~~~~~~~~~~^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3405, in _call\n",
      "    self.call_function(fn, args, kwargs)\n",
      "    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1266, in call_function\n",
      "    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n",
      "              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\lazy.py\", line 212, in realize_and_forward\n",
      "    return getattr(self.realize(), name)(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\functions.py\", line 1515, in call_function\n",
      "    unimplemented_v2(\n",
      "    ~~~~~~~~~~~~~~~~^\n",
      "        gb_type=\"Call to `torch._dynamo.graph_break()`\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        ],\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\exc.py\", line 596, in unimplemented_v2\n",
      "    raise Unsupported(msg)\n",
      "torch._dynamo.exc.Unsupported: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1624, in __call__\n",
      "    result = self._inner_convert(\n",
      "        frame, cache_entry, hooks, frame_state, skip=skip + 1\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 688, in __call__\n",
      "    result = _compile(\n",
      "        frame.f_code,\n",
      "    ...<16 lines>...\n",
      "        convert_frame_box=self._box,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1433, in _compile\n",
      "    guarded_code, tracer_output = compile_inner(code, one_graph, hooks)\n",
      "                                  ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_utils_internal.py\", line 92, in wrapper_function\n",
      "    return function(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1117, in compile_inner\n",
      "    return _compile_inner(code, one_graph, hooks)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1151, in _compile_inner\n",
      "    dynamo_output = compile_frame(\n",
      "        code,\n",
      "    ...<11 lines>...\n",
      "        package=package,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1032, in compile_frame\n",
      "    bytecode, tracer_output = transform_code_object(code, transform)\n",
      "                              ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1592, in transform_code_object\n",
      "    tracer_output = transformations(instructions, code_options)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1004, in transform\n",
      "    tracer_output = trace_frame(\n",
      "        code,\n",
      "    ...<14 lines>...\n",
      "        package=package,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 312, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 815, in trace_frame\n",
      "    run_tracer()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in run_tracer\n",
      "    tracer.run()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1487, in run\n",
      "    while self.step():\n",
      "          ~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1348, in step\n",
      "    self.dispatch_table[inst.opcode](self, inst)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 910, in wrapper\n",
      "    unimplemented_v2(\n",
      "    ~~~~~~~~~~~~~~~~^\n",
      "        gb_type=\"Graph break under GenericContextWrappingVariable\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "        from_exc=excp,\n",
      "        ^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\exc.py\", line 595, in unimplemented_v2\n",
      "    raise Unsupported(msg) from from_exc\n",
      "torch._dynamo.exc.Unsupported: Graph break under GenericContextWrappingVariable\n",
      "  Explanation: Attempted to graph break in an active context manager(s) that doesn't support graph breaking.\n",
      "  Hint: Move the offending context manager(s) to outside the compiled region.\n",
      "  Hint: This graph break may have been caused by an earlier graph break. Resolving the earlier graph break may resolve this one.\n",
      "\n",
      "  Developer debug context: Active generic context managers: [GenericContextWrappingVariable(CustomCtxManager)]\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0066.html\n",
      "\n",
      "from user code:\n",
      "   File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 10, in fn\n",
      "    torch._dynamo.graph_break()\n",
      "\n",
      "Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "WON'T CONVERT fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py line 6 \n",
      "due to: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 904, in wrapper\n",
      "    return inner_fn(self, inst)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3411, in CALL\n",
      "    self._call(inst)\n",
      "    ~~~~~~~~~~^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3405, in _call\n",
      "    self.call_function(fn, args, kwargs)\n",
      "    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1266, in call_function\n",
      "    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n",
      "              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\lazy.py\", line 212, in realize_and_forward\n",
      "    return getattr(self.realize(), name)(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\functions.py\", line 1515, in call_function\n",
      "    unimplemented_v2(\n",
      "    ~~~~~~~~~~~~~~~~^\n",
      "        gb_type=\"Call to `torch._dynamo.graph_break()`\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        ],\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\exc.py\", line 596, in unimplemented_v2\n",
      "    raise Unsupported(msg)\n",
      "torch._dynamo.exc.Unsupported: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1624, in __call__\n",
      "    result = self._inner_convert(\n",
      "        frame, cache_entry, hooks, frame_state, skip=skip + 1\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 688, in __call__\n",
      "    result = _compile(\n",
      "        frame.f_code,\n",
      "    ...<16 lines>...\n",
      "        convert_frame_box=self._box,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1433, in _compile\n",
      "    guarded_code, tracer_output = compile_inner(code, one_graph, hooks)\n",
      "                                  ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_utils_internal.py\", line 92, in wrapper_function\n",
      "    return function(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1117, in compile_inner\n",
      "    return _compile_inner(code, one_graph, hooks)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1151, in _compile_inner\n",
      "    dynamo_output = compile_frame(\n",
      "        code,\n",
      "    ...<11 lines>...\n",
      "        package=package,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1032, in compile_frame\n",
      "    bytecode, tracer_output = transform_code_object(code, transform)\n",
      "                              ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1592, in transform_code_object\n",
      "    tracer_output = transformations(instructions, code_options)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1004, in transform\n",
      "    tracer_output = trace_frame(\n",
      "        code,\n",
      "    ...<14 lines>...\n",
      "        package=package,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 312, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 815, in trace_frame\n",
      "    run_tracer()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in run_tracer\n",
      "    tracer.run()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1487, in run\n",
      "    while self.step():\n",
      "          ~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1348, in step\n",
      "    self.dispatch_table[inst.opcode](self, inst)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 910, in wrapper\n",
      "    unimplemented_v2(\n",
      "    ~~~~~~~~~~~~~~~~^\n",
      "        gb_type=\"Graph break under GenericContextWrappingVariable\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "        from_exc=excp,\n",
      "        ^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\exc.py\", line 595, in unimplemented_v2\n",
      "    raise Unsupported(msg) from from_exc\n",
      "torch._dynamo.exc.Unsupported: Graph break under GenericContextWrappingVariable\n",
      "  Explanation: Attempted to graph break in an active context manager(s) that doesn't support graph breaking.\n",
      "  Hint: Move the offending context manager(s) to outside the compiled region.\n",
      "  Hint: This graph break may have been caused by an earlier graph break. Resolving the earlier graph break may resolve this one.\n",
      "\n",
      "  Developer debug context: Active generic context managers: [GenericContextWrappingVariable(CustomCtxManager)]\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0066.html\n",
      "\n",
      "from user code:\n",
      "   File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 10, in fn\n",
      "    torch._dynamo.graph_break()\n",
      "\n",
      "Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 904, in wrapper\n",
      "    return inner_fn(self, inst)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3411, in CALL\n",
      "    self._call(inst)\n",
      "    ~~~~~~~~~~^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3405, in _call\n",
      "    self.call_function(fn, args, kwargs)\n",
      "    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1266, in call_function\n",
      "    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n",
      "              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\lazy.py\", line 212, in realize_and_forward\n",
      "    return getattr(self.realize(), name)(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\functions.py\", line 1515, in call_function\n",
      "    unimplemented_v2(\n",
      "    ~~~~~~~~~~~~~~~~^\n",
      "        gb_type=\"Call to `torch._dynamo.graph_break()`\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        ],\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\exc.py\", line 596, in unimplemented_v2\n",
      "    raise Unsupported(msg)\n",
      "torch._dynamo.exc.Unsupported: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1624, in __call__\n",
      "    result = self._inner_convert(\n",
      "        frame, cache_entry, hooks, frame_state, skip=skip + 1\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 688, in __call__\n",
      "    result = _compile(\n",
      "        frame.f_code,\n",
      "    ...<16 lines>...\n",
      "        convert_frame_box=self._box,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1433, in _compile\n",
      "    guarded_code, tracer_output = compile_inner(code, one_graph, hooks)\n",
      "                                  ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_utils_internal.py\", line 92, in wrapper_function\n",
      "    return function(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1117, in compile_inner\n",
      "    return _compile_inner(code, one_graph, hooks)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1151, in _compile_inner\n",
      "    dynamo_output = compile_frame(\n",
      "        code,\n",
      "    ...<11 lines>...\n",
      "        package=package,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1032, in compile_frame\n",
      "    bytecode, tracer_output = transform_code_object(code, transform)\n",
      "                              ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1592, in transform_code_object\n",
      "    tracer_output = transformations(instructions, code_options)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1004, in transform\n",
      "    tracer_output = trace_frame(\n",
      "        code,\n",
      "    ...<14 lines>...\n",
      "        package=package,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 312, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 815, in trace_frame\n",
      "    run_tracer()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in run_tracer\n",
      "    tracer.run()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1487, in run\n",
      "    while self.step():\n",
      "          ~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1348, in step\n",
      "    self.dispatch_table[inst.opcode](self, inst)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 910, in wrapper\n",
      "    unimplemented_v2(\n",
      "    ~~~~~~~~~~~~~~~~^\n",
      "        gb_type=\"Graph break under GenericContextWrappingVariable\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "        from_exc=excp,\n",
      "        ^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\exc.py\", line 595, in unimplemented_v2\n",
      "    raise Unsupported(msg) from from_exc\n",
      "torch._dynamo.exc.Unsupported: Graph break under GenericContextWrappingVariable\n",
      "  Explanation: Attempted to graph break in an active context manager(s) that doesn't support graph breaking.\n",
      "  Hint: Move the offending context manager(s) to outside the compiled region.\n",
      "  Hint: This graph break may have been caused by an earlier graph break. Resolving the earlier graph break may resolve this one.\n",
      "\n",
      "  Developer debug context: Active generic context managers: [GenericContextWrappingVariable(CustomCtxManager)]\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0066.html\n",
      "\n",
      "from user code:\n",
      "   File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 10, in fn\n",
      "    torch._dynamo.graph_break()\n",
      "\n",
      "Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "skipping because no torch.* __enter__             C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py 2\n",
      "skipping because no torch.* __exit__             C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:6 in fn\n",
      "    @torch.compile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:8 in fn\n",
      "        with CustomCtxManager():\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL CustomCtxManager []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BEFORE_WITH None [GenericContextWrappingVariable(CustomCtxManager)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE inlined call __enter__ from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:8 in fn\n",
      "    with CustomCtxManager():\n",
      "         ~~~~~~~~~~~~~~~~^^\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INLINING <code object __enter__ at 0x000001ADFEEBD890, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 2>, inlined according trace_rules.lookup inlined by default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:2 in __enter__ (inline depth: 1)\n",
      "        def __enter__(self):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:3 in __enter__ (inline depth: 1)\n",
      "            pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_CONST None []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DONE INLINING <code object __enter__ at 0x000001ADFEEBD890, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 2>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:9 in fn\n",
      "            x = x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x [WithExitFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [WithExitFunctionVariable(), LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [WithExitFunctionVariable(), LazyVariableTracker(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:9 in fn\n",
      "        x = x + 1\n",
      "            ~~^~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST x [WithExitFunctionVariable(), TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:10 in fn\n",
      "            torch._dynamo.graph_break()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL torch [WithExitFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR _dynamo [WithExitFunctionVariable(), LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR graph_break [WithExitFunctionVariable(), LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [WithExitFunctionVariable(), LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "empty checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_gc_after_compile: running gc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph break: skip: from user code at:\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 10, in fn\n",
      "    torch._dynamo.graph_break()\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 904, in wrapper\n",
      "    return inner_fn(self, inst)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3411, in CALL\n",
      "    self._call(inst)\n",
      "    ~~~~~~~~~~^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3405, in _call\n",
      "    self.call_function(fn, args, kwargs)\n",
      "    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1266, in call_function\n",
      "    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n",
      "              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\lazy.py\", line 212, in realize_and_forward\n",
      "    return getattr(self.realize(), name)(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\functions.py\", line 1515, in call_function\n",
      "    unimplemented_v2(\n",
      "    ~~~~~~~~~~~~~~~~^\n",
      "        gb_type=\"Call to `torch._dynamo.graph_break()`\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        ],\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\exc.py\", line 596, in unimplemented_v2\n",
      "    raise Unsupported(msg)\n",
      "torch._dynamo.exc.Unsupported: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1624, in __call__\n",
      "    result = self._inner_convert(\n",
      "        frame, cache_entry, hooks, frame_state, skip=skip + 1\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 688, in __call__\n",
      "    result = _compile(\n",
      "        frame.f_code,\n",
      "    ...<16 lines>...\n",
      "        convert_frame_box=self._box,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1433, in _compile\n",
      "    guarded_code, tracer_output = compile_inner(code, one_graph, hooks)\n",
      "                                  ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_utils_internal.py\", line 92, in wrapper_function\n",
      "    return function(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1117, in compile_inner\n",
      "    return _compile_inner(code, one_graph, hooks)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1151, in _compile_inner\n",
      "    dynamo_output = compile_frame(\n",
      "        code,\n",
      "    ...<11 lines>...\n",
      "        package=package,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1032, in compile_frame\n",
      "    bytecode, tracer_output = transform_code_object(code, transform)\n",
      "                              ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1592, in transform_code_object\n",
      "    tracer_output = transformations(instructions, code_options)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1004, in transform\n",
      "    tracer_output = trace_frame(\n",
      "        code,\n",
      "    ...<14 lines>...\n",
      "        package=package,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 312, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 815, in trace_frame\n",
      "    run_tracer()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in run_tracer\n",
      "    tracer.run()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1487, in run\n",
      "    while self.step():\n",
      "          ~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1348, in step\n",
      "    self.dispatch_table[inst.opcode](self, inst)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 910, in wrapper\n",
      "    unimplemented_v2(\n",
      "    ~~~~~~~~~~~~~~~~^\n",
      "        gb_type=\"Graph break under GenericContextWrappingVariable\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "        from_exc=excp,\n",
      "        ^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\exc.py\", line 595, in unimplemented_v2\n",
      "    raise Unsupported(msg) from from_exc\n",
      "torch._dynamo.exc.Unsupported: Graph break under GenericContextWrappingVariable\n",
      "  Explanation: Attempted to graph break in an active context manager(s) that doesn't support graph breaking.\n",
      "  Hint: Move the offending context manager(s) to outside the compiled region.\n",
      "  Hint: This graph break may have been caused by an earlier graph break. Resolving the earlier graph break may resolve this one.\n",
      "\n",
      "  Developer debug context: Active generic context managers: [GenericContextWrappingVariable(CustomCtxManager)]\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0066.html\n",
      "\n",
      "from user code:\n",
      "   File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 10, in fn\n",
      "    torch._dynamo.graph_break()\n",
      "\n",
      "Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WON'T CONVERT fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py line 6 \n",
      "due to: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 904, in wrapper\n",
      "    return inner_fn(self, inst)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3411, in CALL\n",
      "    self._call(inst)\n",
      "    ~~~~~~~~~~^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3405, in _call\n",
      "    self.call_function(fn, args, kwargs)\n",
      "    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1266, in call_function\n",
      "    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n",
      "              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\lazy.py\", line 212, in realize_and_forward\n",
      "    return getattr(self.realize(), name)(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\functions.py\", line 1515, in call_function\n",
      "    unimplemented_v2(\n",
      "    ~~~~~~~~~~~~~~~~^\n",
      "        gb_type=\"Call to `torch._dynamo.graph_break()`\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        ],\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\exc.py\", line 596, in unimplemented_v2\n",
      "    raise Unsupported(msg)\n",
      "torch._dynamo.exc.Unsupported: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1624, in __call__\n",
      "    result = self._inner_convert(\n",
      "        frame, cache_entry, hooks, frame_state, skip=skip + 1\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 688, in __call__\n",
      "    result = _compile(\n",
      "        frame.f_code,\n",
      "    ...<16 lines>...\n",
      "        convert_frame_box=self._box,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1433, in _compile\n",
      "    guarded_code, tracer_output = compile_inner(code, one_graph, hooks)\n",
      "                                  ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_utils_internal.py\", line 92, in wrapper_function\n",
      "    return function(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1117, in compile_inner\n",
      "    return _compile_inner(code, one_graph, hooks)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1151, in _compile_inner\n",
      "    dynamo_output = compile_frame(\n",
      "        code,\n",
      "    ...<11 lines>...\n",
      "        package=package,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1032, in compile_frame\n",
      "    bytecode, tracer_output = transform_code_object(code, transform)\n",
      "                              ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1592, in transform_code_object\n",
      "    tracer_output = transformations(instructions, code_options)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1004, in transform\n",
      "    tracer_output = trace_frame(\n",
      "        code,\n",
      "    ...<14 lines>...\n",
      "        package=package,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 312, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 815, in trace_frame\n",
      "    run_tracer()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in run_tracer\n",
      "    tracer.run()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1487, in run\n",
      "    while self.step():\n",
      "          ~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1348, in step\n",
      "    self.dispatch_table[inst.opcode](self, inst)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 910, in wrapper\n",
      "    unimplemented_v2(\n",
      "    ~~~~~~~~~~~~~~~~^\n",
      "        gb_type=\"Graph break under GenericContextWrappingVariable\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "        from_exc=excp,\n",
      "        ^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\exc.py\", line 595, in unimplemented_v2\n",
      "    raise Unsupported(msg) from from_exc\n",
      "torch._dynamo.exc.Unsupported: Graph break under GenericContextWrappingVariable\n",
      "  Explanation: Attempted to graph break in an active context manager(s) that doesn't support graph breaking.\n",
      "  Hint: Move the offending context manager(s) to outside the compiled region.\n",
      "  Hint: This graph break may have been caused by an earlier graph break. Resolving the earlier graph break may resolve this one.\n",
      "\n",
      "  Developer debug context: Active generic context managers: [GenericContextWrappingVariable(CustomCtxManager)]\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0066.html\n",
      "\n",
      "from user code:\n",
      "   File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 10, in fn\n",
      "    torch._dynamo.graph_break()\n",
      "\n",
      "Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 904, in wrapper\n",
      "    return inner_fn(self, inst)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3411, in CALL\n",
      "    self._call(inst)\n",
      "    ~~~~~~~~~~^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3405, in _call\n",
      "    self.call_function(fn, args, kwargs)\n",
      "    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1266, in call_function\n",
      "    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n",
      "              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\lazy.py\", line 212, in realize_and_forward\n",
      "    return getattr(self.realize(), name)(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\functions.py\", line 1515, in call_function\n",
      "    unimplemented_v2(\n",
      "    ~~~~~~~~~~~~~~~~^\n",
      "        gb_type=\"Call to `torch._dynamo.graph_break()`\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        ],\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\exc.py\", line 596, in unimplemented_v2\n",
      "    raise Unsupported(msg)\n",
      "torch._dynamo.exc.Unsupported: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1624, in __call__\n",
      "    result = self._inner_convert(\n",
      "        frame, cache_entry, hooks, frame_state, skip=skip + 1\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 688, in __call__\n",
      "    result = _compile(\n",
      "        frame.f_code,\n",
      "    ...<16 lines>...\n",
      "        convert_frame_box=self._box,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1433, in _compile\n",
      "    guarded_code, tracer_output = compile_inner(code, one_graph, hooks)\n",
      "                                  ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_utils_internal.py\", line 92, in wrapper_function\n",
      "    return function(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1117, in compile_inner\n",
      "    return _compile_inner(code, one_graph, hooks)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1151, in _compile_inner\n",
      "    dynamo_output = compile_frame(\n",
      "        code,\n",
      "    ...<11 lines>...\n",
      "        package=package,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1032, in compile_frame\n",
      "    bytecode, tracer_output = transform_code_object(code, transform)\n",
      "                              ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1592, in transform_code_object\n",
      "    tracer_output = transformations(instructions, code_options)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1004, in transform\n",
      "    tracer_output = trace_frame(\n",
      "        code,\n",
      "    ...<14 lines>...\n",
      "        package=package,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 312, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 815, in trace_frame\n",
      "    run_tracer()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in run_tracer\n",
      "    tracer.run()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1487, in run\n",
      "    while self.step():\n",
      "          ~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1348, in step\n",
      "    self.dispatch_table[inst.opcode](self, inst)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 910, in wrapper\n",
      "    unimplemented_v2(\n",
      "    ~~~~~~~~~~~~~~~~^\n",
      "        gb_type=\"Graph break under GenericContextWrappingVariable\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "        from_exc=excp,\n",
      "        ^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\exc.py\", line 595, in unimplemented_v2\n",
      "    raise Unsupported(msg) from from_exc\n",
      "torch._dynamo.exc.Unsupported: Graph break under GenericContextWrappingVariable\n",
      "  Explanation: Attempted to graph break in an active context manager(s) that doesn't support graph breaking.\n",
      "  Hint: Move the offending context manager(s) to outside the compiled region.\n",
      "  Hint: This graph break may have been caused by an earlier graph break. Resolving the earlier graph break may resolve this one.\n",
      "\n",
      "  Developer debug context: Active generic context managers: [GenericContextWrappingVariable(CustomCtxManager)]\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0066.html\n",
      "\n",
      "from user code:\n",
      "   File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 10, in fn\n",
      "    torch._dynamo.graph_break()\n",
      "\n",
      "Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping because no torch.* __enter__             C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping because no torch.* __exit__             C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2.8117, 2.0776, 1.7796])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomCtxManager:\n",
    "    def __enter__(self):\n",
    "        pass\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        pass\n",
    "@torch.compile\n",
    "def fn(x):\n",
    "    with CustomCtxManager():\n",
    "        x = x + 1\n",
    "        torch._dynamo.graph_break()\n",
    "        return x + 1\n",
    "fn(torch.randn(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968082bb",
   "metadata": {},
   "source": [
    "We can avoid skipping by moving the graph break outside of the context manager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d72e6147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchdynamo start compiling fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:1, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py\", line 8, in <module>\n",
      "    fn(torch.randn(3))\n",
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:1\n",
      "create_env\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:1 in fn\n",
      "    @torch.compile\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:3 in fn\n",
      "        with CustomCtxManager():\n",
      "TRACE LOAD_GLOBAL CustomCtxManager []\n",
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n",
      "TRACE BEFORE_WITH None [GenericContextWrappingVariable(CustomCtxManager)]\n",
      "TRACE inlined call __enter__ from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:3 in fn\n",
      "    with CustomCtxManager():\n",
      "         ~~~~~~~~~~~~~~~~^^\n",
      "INLINING <code object __enter__ at 0x000001ADFEEBD890, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 2>, inlined according trace_rules.lookup inlined by default\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:2 in __enter__ (inline depth: 1)\n",
      "        def __enter__(self):\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:3 in __enter__ (inline depth: 1)\n",
      "            pass\n",
      "TRACE RETURN_CONST None []\n",
      "DONE INLINING <code object __enter__ at 0x000001ADFEEBD890, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 2>\n",
      "TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:4 in fn\n",
      "            x = x + 1\n",
      "TRACE LOAD_FAST x [WithExitFunctionVariable()]\n",
      "TRACE LOAD_CONST 1 [WithExitFunctionVariable(), LazyVariableTracker()]\n",
      "TRACE BINARY_OP 0 [WithExitFunctionVariable(), LazyVariableTracker(), ConstantVariable(int: 1)]\n",
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n",
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n",
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:4 in fn\n",
      "        x = x + 1\n",
      "            ~~^~~\n",
      "TRACE STORE_FAST x [WithExitFunctionVariable(), TensorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:3 in fn\n",
      "        with CustomCtxManager():\n",
      "TRACE LOAD_CONST None [WithExitFunctionVariable()]\n",
      "TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n",
      "TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None)]\n",
      "TRACE CALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None)]\n",
      "TRACE inlined call __exit__ from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:3 in fn\n",
      "    with CustomCtxManager():\n",
      "         ~~~~~~~~~~~~~~~~^^\n",
      "INLINING <code object __exit__ at 0x000001ADFEEBF500, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 4>, inlined according trace_rules.lookup inlined by default\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:4 in __exit__ (inline depth: 1)\n",
      "        def __exit__(self, exc_type, exc_value, traceback):\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:5 in __exit__ (inline depth: 1)\n",
      "            pass\n",
      "TRACE RETURN_CONST None []\n",
      "DONE INLINING <code object __exit__ at 0x000001ADFEEBF500, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 4>\n",
      "TRACE POP_TOP None [ConstantVariable(NoneType: None)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:5 in fn\n",
      "        torch._dynamo.graph_break()\n",
      "TRACE LOAD_GLOBAL torch []\n",
      "TRACE LOAD_ATTR _dynamo [LazyVariableTracker()]\n",
      "TRACE LOAD_ATTR graph_break [LazyVariableTracker()]\n",
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n",
      "Graph break in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:5\n",
      "Graph Break Reason: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "User code traceback:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py\", line 8, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py\", line 5, in fn\n",
      "    torch._dynamo.graph_break()\n",
      "Restarting analysis due to _dynamo\\symbolic_convert.py:249 in fail_and_restart_analysis\n",
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:1\n",
      "create_env\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:1 in fn\n",
      "    @torch.compile\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:3 in fn\n",
      "        with CustomCtxManager():\n",
      "TRACE LOAD_GLOBAL CustomCtxManager []\n",
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n",
      "TRACE BEFORE_WITH None [GenericContextWrappingVariable(CustomCtxManager)]\n",
      "TRACE inlined call __enter__ from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:3 in fn\n",
      "    with CustomCtxManager():\n",
      "         ~~~~~~~~~~~~~~~~^^\n",
      "INLINING <code object __enter__ at 0x000001ADFEEBD890, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 2>, inlined according trace_rules.lookup inlined by default\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:2 in __enter__ (inline depth: 1)\n",
      "        def __enter__(self):\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:3 in __enter__ (inline depth: 1)\n",
      "            pass\n",
      "TRACE RETURN_CONST None []\n",
      "DONE INLINING <code object __enter__ at 0x000001ADFEEBD890, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 2>\n",
      "TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:4 in fn\n",
      "            x = x + 1\n",
      "TRACE LOAD_FAST x [WithExitFunctionVariable()]\n",
      "TRACE LOAD_CONST 1 [WithExitFunctionVariable(), LazyVariableTracker()]\n",
      "TRACE BINARY_OP 0 [WithExitFunctionVariable(), LazyVariableTracker(), ConstantVariable(int: 1)]\n",
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n",
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n",
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:4 in fn\n",
      "        x = x + 1\n",
      "            ~~^~~\n",
      "TRACE STORE_FAST x [WithExitFunctionVariable(), TensorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:3 in fn\n",
      "        with CustomCtxManager():\n",
      "TRACE LOAD_CONST None [WithExitFunctionVariable()]\n",
      "TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n",
      "TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None)]\n",
      "TRACE CALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None)]\n",
      "TRACE inlined call __exit__ from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:3 in fn\n",
      "    with CustomCtxManager():\n",
      "         ~~~~~~~~~~~~~~~~^^\n",
      "INLINING <code object __exit__ at 0x000001ADFEEBF500, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 4>, inlined according trace_rules.lookup inlined by default\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:4 in __exit__ (inline depth: 1)\n",
      "        def __exit__(self, exc_type, exc_value, traceback):\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:5 in __exit__ (inline depth: 1)\n",
      "            pass\n",
      "TRACE RETURN_CONST None []\n",
      "DONE INLINING <code object __exit__ at 0x000001ADFEEBF500, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 4>\n",
      "TRACE POP_TOP None [ConstantVariable(NoneType: None)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:5 in fn\n",
      "        torch._dynamo.graph_break()\n",
      "TRACE LOAD_GLOBAL torch []\n",
      "TRACE LOAD_ATTR _dynamo [LazyVariableTracker()]\n",
      "TRACE LOAD_ATTR graph_break [LazyVariableTracker()]\n",
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n",
      "COMPILING GRAPH due to GraphCompileReason(reason='Call to `torch._dynamo.graph_break()`\\n  Explanation: User-inserted graph break. Message: None\\n  Hint: Remove the `torch._dynamo.graph_break()` call.\\n\\n  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\\n\\n For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py, line 5 in fn>], graph_break=True)\n",
      "TRACED GRAPH\n",
      " ===== __compiled_fn_20_1be1b229_5d99_4297_95b2_8a43621125bb =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:4 in fn, code: x = x + 1\n",
      "        x: \"f32[3][1]cpu\" = l_x_ + 1;  l_x_ = None\n",
      "        return (x,)\n",
      "Step 2: calling compiler function eager\n",
      "Step 2: done compiler function eager\n",
      "produce_guards\n",
      "track_symint L['x'].size()[0] 3 None\n",
      "track_symint L['x'].stride()[0] 1 None\n",
      "track_symint L['x'].storage_offset() 0 None\n",
      "Skipping guard L['x'].size()[0] == 3\n",
      "Skipping guard L['x'].stride()[0] == 1\n",
      "Skipping guard L['x'].storage_offset() == 0\n",
      "GUARDS:\n",
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=0), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # x = x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:4 in fn\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # x = x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:4 in fn\n",
      "| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor, type=<class 'dict'>, tag_safe=(False, False)\n",
      "| | +- GuardManager: source=G['torch'], accessed_by=DictGetItemGuardAccessor('torch'), type=<class 'module'>, tag_safe=(False, False)\n",
      "| | | +- ID_MATCH: ___check_obj_id(G['torch'], 1846212640448)                    # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:5 in fn\n",
      "| | | +- GuardManager: source=G['torch']._dynamo, accessed_by=GetAttrGuardAccessor(_dynamo), type=<class 'module'>, tag_safe=(False, False)\n",
      "| | | | +- ID_MATCH: ___check_obj_id(G['torch']._dynamo, 1846752934096)            # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:5 in fn\n",
      "| | | | +- GuardManager: source=G['torch']._dynamo.graph_break, accessed_by=GetAttrGuardAccessor(graph_break), type=<class 'function'>, tag_safe=(True, False)\n",
      "| | | | | +- GuardManager: source=G['torch']._dynamo.graph_break.__code__, accessed_by=CodeGuardAccessor, type=<class 'code'>, tag_safe=(True, False)\n",
      "| | | | | | +- ID_MATCH: ___check_obj_id(G['torch']._dynamo.graph_break.__code__, 1846802753744)  # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:5 in fn\n",
      "| | +- GuardManager: source=G['CustomCtxManager'], accessed_by=DictGetItemGuardAccessor('CustomCtxManager'), type=<class 'type'>, tag_safe=(True, False)\n",
      "| | | +- ID_MATCH: ___check_obj_id(G['CustomCtxManager'], 1846784432848)         # with CustomCtxManager():  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:3 in fn\n",
      "Guard eval latency = 55.30 us\n",
      "put_code_state: no cache key, skipping\n",
      "run_gc_after_compile: running gc\n",
      "torchdynamo start compiling torch_dynamo_resume_in_fn_at_5 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:5, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py\", line 8, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 832, in compile_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "Step 1: torchdynamo start tracing torch_dynamo_resume_in_fn_at_5 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:5\n",
      "create_env\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:5 in torch_dynamo_resume_in_fn_at_5\n",
      "        torch._dynamo.graph_break()\n",
      "TRACE RESUME 0 []\n",
      "TRACE LOAD_CONST True []\n",
      "TRACE STORE_FAST __is_tracing_resume_prologue [ConstantVariable(bool: True)]\n",
      "TRACE LOAD_FAST ___stack0 []\n",
      "TRACE LOAD_CONST False [LazyVariableTracker()]\n",
      "TRACE STORE_FAST __is_tracing_resume_prologue [LazyVariableTracker(), ConstantVariable(bool: False)]\n",
      "TRACE JUMP_FORWARD 122 [LazyVariableTracker()]\n",
      "TRACE POP_TOP None [LazyVariableTracker()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:6 in torch_dynamo_resume_in_fn_at_5\n",
      "        with CustomCtxManager():\n",
      "TRACE LOAD_GLOBAL CustomCtxManager []\n",
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n",
      "TRACE BEFORE_WITH None [GenericContextWrappingVariable(CustomCtxManager)]\n",
      "TRACE inlined call __enter__ from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:6 in torch_dynamo_resume_in_fn_at_5\n",
      "    with CustomCtxManager():\n",
      "         ~~~~~~~~~~~~~~~~^^\n",
      "INLINING <code object __enter__ at 0x000001ADFEEBD890, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 2>, inlined according trace_rules.lookup inlined by default\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:2 in __enter__ (inline depth: 1)\n",
      "        def __enter__(self):\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:3 in __enter__ (inline depth: 1)\n",
      "            pass\n",
      "TRACE RETURN_CONST None []\n",
      "DONE INLINING <code object __enter__ at 0x000001ADFEEBD890, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 2>\n",
      "TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:7 in torch_dynamo_resume_in_fn_at_5\n",
      "            return x + 1\n",
      "TRACE LOAD_FAST x [WithExitFunctionVariable()]\n",
      "TRACE LOAD_CONST 1 [WithExitFunctionVariable(), LazyVariableTracker()]\n",
      "TRACE BINARY_OP 0 [WithExitFunctionVariable(), LazyVariableTracker(), ConstantVariable(int: 1)]\n",
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n",
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n",
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:7 in torch_dynamo_resume_in_fn_at_5\n",
      "        return x + 1\n",
      "               ~~^~~\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:6 in torch_dynamo_resume_in_fn_at_5\n",
      "        with CustomCtxManager():\n",
      "TRACE SWAP 2 [WithExitFunctionVariable(), TensorVariable()]\n",
      "TRACE LOAD_CONST None [TensorVariable(), WithExitFunctionVariable()]\n",
      "TRACE LOAD_CONST None [TensorVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n",
      "TRACE LOAD_CONST None [TensorVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None)]\n",
      "TRACE CALL 2 [TensorVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None)]\n",
      "TRACE inlined call __exit__ from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:6 in torch_dynamo_resume_in_fn_at_5\n",
      "    with CustomCtxManager():\n",
      "         ~~~~~~~~~~~~~~~~^^\n",
      "INLINING <code object __exit__ at 0x000001ADFEEBF500, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 4>, inlined according trace_rules.lookup inlined by default\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:4 in __exit__ (inline depth: 1)\n",
      "        def __exit__(self, exc_type, exc_value, traceback):\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:5 in __exit__ (inline depth: 1)\n",
      "            pass\n",
      "TRACE RETURN_CONST None []\n",
      "DONE INLINING <code object __exit__ at 0x000001ADFEEBF500, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 4>\n",
      "TRACE POP_TOP None [TensorVariable(), ConstantVariable(NoneType: None)]\n",
      "TRACE RETURN_VALUE None [TensorVariable()]\n",
      "Step 1: torchdynamo done tracing torch_dynamo_resume_in_fn_at_5 (RETURN_VALUE)\n",
      "RETURN_VALUE triggered compile\n",
      "COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py, line 6 in torch_dynamo_resume_in_fn_at_5>], graph_break=False)\n",
      "TRACED GRAPH\n",
      " ===== __compiled_fn_23_ac2c6f99_209b_491a_8869_88e1952f79f5 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:7 in torch_dynamo_resume_in_fn_at_5, code: return x + 1\n",
      "        add: \"f32[3][1]cpu\" = l_x_ + 1;  l_x_ = None\n",
      "        return (add,)\n",
      "Step 2: calling compiler function eager\n",
      "Step 2: done compiler function eager\n",
      "produce_guards\n",
      "track_symint L['x'].size()[0] 3 None\n",
      "track_symint L['x'].stride()[0] 1 None\n",
      "track_symint L['x'].storage_offset() 0 None\n",
      "Skipping guard L['x'].size()[0] == 3\n",
      "Skipping guard L['x'].stride()[0] == 1\n",
      "Skipping guard L['x'].storage_offset() == 0\n",
      "GUARDS:\n",
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=3), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # return x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:7 in torch_dynamo_resume_in_fn_at_5\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # return x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:7 in torch_dynamo_resume_in_fn_at_5\n",
      "| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor, type=<class 'dict'>, tag_safe=(True, False)\n",
      "| | +- GuardManager: source=G['CustomCtxManager'], accessed_by=DictGetItemGuardAccessor('CustomCtxManager'), type=<class 'type'>, tag_safe=(True, False)\n",
      "| | | +- ID_MATCH: ___check_obj_id(G['CustomCtxManager'], 1846784432848)         # with CustomCtxManager():  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:6 in torch_dynamo_resume_in_fn_at_5\n",
      "Guard eval latency = 77.20 us\n",
      "put_code_state: no cache key, skipping\n",
      "run_gc_after_compile: running gc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:1 in fn\n",
      "    @torch.compile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:3 in fn\n",
      "        with CustomCtxManager():\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL CustomCtxManager []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BEFORE_WITH None [GenericContextWrappingVariable(CustomCtxManager)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE inlined call __enter__ from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:3 in fn\n",
      "    with CustomCtxManager():\n",
      "         ~~~~~~~~~~~~~~~~^^\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INLINING <code object __enter__ at 0x000001ADFEEBD890, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 2>, inlined according trace_rules.lookup inlined by default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:2 in __enter__ (inline depth: 1)\n",
      "        def __enter__(self):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:3 in __enter__ (inline depth: 1)\n",
      "            pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_CONST None []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DONE INLINING <code object __enter__ at 0x000001ADFEEBD890, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 2>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:4 in fn\n",
      "            x = x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x [WithExitFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [WithExitFunctionVariable(), LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [WithExitFunctionVariable(), LazyVariableTracker(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:4 in fn\n",
      "        x = x + 1\n",
      "            ~~^~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST x [WithExitFunctionVariable(), TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:3 in fn\n",
      "        with CustomCtxManager():\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST None [WithExitFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE inlined call __exit__ from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:3 in fn\n",
      "    with CustomCtxManager():\n",
      "         ~~~~~~~~~~~~~~~~^^\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INLINING <code object __exit__ at 0x000001ADFEEBF500, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 4>, inlined according trace_rules.lookup inlined by default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:4 in __exit__ (inline depth: 1)\n",
      "        def __exit__(self, exc_type, exc_value, traceback):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:5 in __exit__ (inline depth: 1)\n",
      "            pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_CONST None []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DONE INLINING <code object __exit__ at 0x000001ADFEEBF500, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 4>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:5 in fn\n",
      "        torch._dynamo.graph_break()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL torch []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR _dynamo [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR graph_break [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph break in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:5\n",
      "Graph Break Reason: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "User code traceback:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py\", line 8, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py\", line 5, in fn\n",
      "    torch._dynamo.graph_break()\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restarting analysis due to _dynamo\\symbolic_convert.py:249 in fail_and_restart_analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:1 in fn\n",
      "    @torch.compile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:3 in fn\n",
      "        with CustomCtxManager():\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL CustomCtxManager []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BEFORE_WITH None [GenericContextWrappingVariable(CustomCtxManager)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE inlined call __enter__ from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:3 in fn\n",
      "    with CustomCtxManager():\n",
      "         ~~~~~~~~~~~~~~~~^^\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INLINING <code object __enter__ at 0x000001ADFEEBD890, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 2>, inlined according trace_rules.lookup inlined by default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:2 in __enter__ (inline depth: 1)\n",
      "        def __enter__(self):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:3 in __enter__ (inline depth: 1)\n",
      "            pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_CONST None []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DONE INLINING <code object __enter__ at 0x000001ADFEEBD890, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 2>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:4 in fn\n",
      "            x = x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x [WithExitFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [WithExitFunctionVariable(), LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [WithExitFunctionVariable(), LazyVariableTracker(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:4 in fn\n",
      "        x = x + 1\n",
      "            ~~^~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST x [WithExitFunctionVariable(), TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:3 in fn\n",
      "        with CustomCtxManager():\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST None [WithExitFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE inlined call __exit__ from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:3 in fn\n",
      "    with CustomCtxManager():\n",
      "         ~~~~~~~~~~~~~~~~^^\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INLINING <code object __exit__ at 0x000001ADFEEBF500, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 4>, inlined according trace_rules.lookup inlined by default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:4 in __exit__ (inline depth: 1)\n",
      "        def __exit__(self, exc_type, exc_value, traceback):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:5 in __exit__ (inline depth: 1)\n",
      "            pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_CONST None []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DONE INLINING <code object __exit__ at 0x000001ADFEEBF500, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 4>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:5 in fn\n",
      "        torch._dynamo.graph_break()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL torch []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR _dynamo [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR graph_break [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMPILING GRAPH due to GraphCompileReason(reason='Call to `torch._dynamo.graph_break()`\\n  Explanation: User-inserted graph break. Message: None\\n  Hint: Remove the `torch._dynamo.graph_break()` call.\\n\\n  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\\n\\n For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py, line 5 in fn>], graph_break=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACED GRAPH\n",
      " ===== __compiled_fn_20_1be1b229_5d99_4297_95b2_8a43621125bb =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:4 in fn, code: x = x + 1\n",
      "        x: \"f32[3][1]cpu\" = l_x_ + 1;  l_x_ = None\n",
      "        return (x,)\n",
      "        \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: calling compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: done compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "produce_guards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].size()[0] 3 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].stride()[0] 1 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].storage_offset() 0 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].size()[0] == 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].stride()[0] == 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].storage_offset() == 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GUARDS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=0), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # x = x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:4 in fn\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # x = x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:4 in fn\n",
      "| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor, type=<class 'dict'>, tag_safe=(False, False)\n",
      "| | +- GuardManager: source=G['torch'], accessed_by=DictGetItemGuardAccessor('torch'), type=<class 'module'>, tag_safe=(False, False)\n",
      "| | | +- ID_MATCH: ___check_obj_id(G['torch'], 1846212640448)                    # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:5 in fn\n",
      "| | | +- GuardManager: source=G['torch']._dynamo, accessed_by=GetAttrGuardAccessor(_dynamo), type=<class 'module'>, tag_safe=(False, False)\n",
      "| | | | +- ID_MATCH: ___check_obj_id(G['torch']._dynamo, 1846752934096)            # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:5 in fn\n",
      "| | | | +- GuardManager: source=G['torch']._dynamo.graph_break, accessed_by=GetAttrGuardAccessor(graph_break), type=<class 'function'>, tag_safe=(True, False)\n",
      "| | | | | +- GuardManager: source=G['torch']._dynamo.graph_break.__code__, accessed_by=CodeGuardAccessor, type=<class 'code'>, tag_safe=(True, False)\n",
      "| | | | | | +- ID_MATCH: ___check_obj_id(G['torch']._dynamo.graph_break.__code__, 1846802753744)  # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:5 in fn\n",
      "| | +- GuardManager: source=G['CustomCtxManager'], accessed_by=DictGetItemGuardAccessor('CustomCtxManager'), type=<class 'type'>, tag_safe=(True, False)\n",
      "| | | +- ID_MATCH: ___check_obj_id(G['CustomCtxManager'], 1846784432848)         # with CustomCtxManager():  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:3 in fn\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Guard eval latency = 55.30 us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "put_code_state: no cache key, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_gc_after_compile: running gc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchdynamo start compiling torch_dynamo_resume_in_fn_at_5 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:5, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py\", line 8, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 832, in compile_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo start tracing torch_dynamo_resume_in_fn_at_5 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:5 in torch_dynamo_resume_in_fn_at_5\n",
      "        torch._dynamo.graph_break()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST True []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST __is_tracing_resume_prologue [ConstantVariable(bool: True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST ___stack0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST False [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST __is_tracing_resume_prologue [LazyVariableTracker(), ConstantVariable(bool: False)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE JUMP_FORWARD 122 [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:6 in torch_dynamo_resume_in_fn_at_5\n",
      "        with CustomCtxManager():\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL CustomCtxManager []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BEFORE_WITH None [GenericContextWrappingVariable(CustomCtxManager)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE inlined call __enter__ from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:6 in torch_dynamo_resume_in_fn_at_5\n",
      "    with CustomCtxManager():\n",
      "         ~~~~~~~~~~~~~~~~^^\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INLINING <code object __enter__ at 0x000001ADFEEBD890, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 2>, inlined according trace_rules.lookup inlined by default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:2 in __enter__ (inline depth: 1)\n",
      "        def __enter__(self):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:3 in __enter__ (inline depth: 1)\n",
      "            pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_CONST None []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DONE INLINING <code object __enter__ at 0x000001ADFEEBD890, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 2>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:7 in torch_dynamo_resume_in_fn_at_5\n",
      "            return x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x [WithExitFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [WithExitFunctionVariable(), LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [WithExitFunctionVariable(), LazyVariableTracker(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:7 in torch_dynamo_resume_in_fn_at_5\n",
      "        return x + 1\n",
      "               ~~^~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:6 in torch_dynamo_resume_in_fn_at_5\n",
      "        with CustomCtxManager():\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE SWAP 2 [WithExitFunctionVariable(), TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST None [TensorVariable(), WithExitFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST None [TensorVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST None [TensorVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 2 [TensorVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE inlined call __exit__ from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:6 in torch_dynamo_resume_in_fn_at_5\n",
      "    with CustomCtxManager():\n",
      "         ~~~~~~~~~~~~~~~~^^\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INLINING <code object __exit__ at 0x000001ADFEEBF500, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 4>, inlined according trace_rules.lookup inlined by default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:4 in __exit__ (inline depth: 1)\n",
      "        def __exit__(self, exc_type, exc_value, traceback):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py:5 in __exit__ (inline depth: 1)\n",
      "            pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_CONST None []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DONE INLINING <code object __exit__ at 0x000001ADFEEBF500, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\4148913404.py\", line 4>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [TensorVariable(), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_VALUE None [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo done tracing torch_dynamo_resume_in_fn_at_5 (RETURN_VALUE)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RETURN_VALUE triggered compile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py, line 6 in torch_dynamo_resume_in_fn_at_5>], graph_break=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACED GRAPH\n",
      " ===== __compiled_fn_23_ac2c6f99_209b_491a_8869_88e1952f79f5 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:7 in torch_dynamo_resume_in_fn_at_5, code: return x + 1\n",
      "        add: \"f32[3][1]cpu\" = l_x_ + 1;  l_x_ = None\n",
      "        return (add,)\n",
      "        \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: calling compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: done compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "produce_guards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].size()[0] 3 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].stride()[0] 1 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].storage_offset() 0 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].size()[0] == 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].stride()[0] == 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].storage_offset() == 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GUARDS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=3), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # return x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:7 in torch_dynamo_resume_in_fn_at_5\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # return x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:7 in torch_dynamo_resume_in_fn_at_5\n",
      "| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor, type=<class 'dict'>, tag_safe=(True, False)\n",
      "| | +- GuardManager: source=G['CustomCtxManager'], accessed_by=DictGetItemGuardAccessor('CustomCtxManager'), type=<class 'type'>, tag_safe=(True, False)\n",
      "| | | +- ID_MATCH: ___check_obj_id(G['CustomCtxManager'], 1846784432848)         # with CustomCtxManager():  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2124425154.py:6 in torch_dynamo_resume_in_fn_at_5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Guard eval latency = 77.20 us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "put_code_state: no cache key, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_gc_after_compile: running gc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2.5893, 2.2229, 3.2566])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.compile\n",
    "def fn(x):\n",
    "    with CustomCtxManager():\n",
    "        x = x + 1\n",
    "    torch._dynamo.graph_break()\n",
    "    with CustomCtxManager():\n",
    "        return x + 1\n",
    "fn(torch.randn(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a4bd9c",
   "metadata": {},
   "source": [
    "There are some context managers where Dynamo can resume after a graph break.\n",
    "Some of these can be found in `supported_ctx_manager_classes` in `torch/_dynamo/variables/torch.py`.\n",
    "In general, any context manager represented by a `ContextWrappingVariable` subclass in\n",
    "`torch/_dynamo/variables/ctx_manager.py` support resuming after a graph break. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bd8e64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchdynamo start compiling fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:2, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py\", line 9, in <module>\n",
      "    fn(torch.randn(3))\n",
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:2\n",
      "create_env\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:2 in fn\n",
      "    @torch.compile\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:4 in fn\n",
      "        with contextlib.nullcontext():\n",
      "TRACE LOAD_GLOBAL contextlib []\n",
      "TRACE LOAD_ATTR nullcontext [LazyVariableTracker()]\n",
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n",
      "TRACE BEFORE_WITH None [NullContextVariable()]\n",
      "TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:5 in fn\n",
      "            with torch.no_grad():\n",
      "TRACE LOAD_GLOBAL torch [WithExitFunctionVariable()]\n",
      "TRACE LOAD_ATTR no_grad [WithExitFunctionVariable(), LazyVariableTracker()]\n",
      "TRACE CALL 0 [WithExitFunctionVariable(), LazyVariableTracker(), NullVariable]\n",
      "TRACE BEFORE_WITH None [WithExitFunctionVariable(), GradModeVariable()]\n",
      "TRACE POP_TOP None [WithExitFunctionVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:6 in fn\n",
      "                x = x + 1\n",
      "TRACE LOAD_FAST x [WithExitFunctionVariable(), WithExitFunctionVariable()]\n",
      "TRACE LOAD_CONST 1 [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker()]\n",
      "TRACE BINARY_OP 0 [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker(), ConstantVariable(int: 1)]\n",
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n",
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n",
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:6 in fn\n",
      "            x = x + 1\n",
      "                ~~^~~\n",
      "TRACE STORE_FAST x [WithExitFunctionVariable(), WithExitFunctionVariable(), TensorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:7 in fn\n",
      "                torch._dynamo.graph_break()\n",
      "TRACE LOAD_GLOBAL torch [WithExitFunctionVariable(), WithExitFunctionVariable()]\n",
      "TRACE LOAD_ATTR _dynamo [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker()]\n",
      "TRACE LOAD_ATTR graph_break [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker()]\n",
      "TRACE CALL 0 [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker(), NullVariable]\n",
      "Graph break in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:7\n",
      "Graph Break Reason: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "User code traceback:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py\", line 9, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py\", line 7, in fn\n",
      "    torch._dynamo.graph_break()\n",
      "Restarting analysis due to _dynamo\\symbolic_convert.py:249 in fail_and_restart_analysis\n",
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:2\n",
      "create_env\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:2 in fn\n",
      "    @torch.compile\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:4 in fn\n",
      "        with contextlib.nullcontext():\n",
      "TRACE LOAD_GLOBAL contextlib []\n",
      "TRACE LOAD_ATTR nullcontext [LazyVariableTracker()]\n",
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n",
      "TRACE BEFORE_WITH None [NullContextVariable()]\n",
      "TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:5 in fn\n",
      "            with torch.no_grad():\n",
      "TRACE LOAD_GLOBAL torch [WithExitFunctionVariable()]\n",
      "TRACE LOAD_ATTR no_grad [WithExitFunctionVariable(), LazyVariableTracker()]\n",
      "TRACE CALL 0 [WithExitFunctionVariable(), LazyVariableTracker(), NullVariable]\n",
      "TRACE BEFORE_WITH None [WithExitFunctionVariable(), GradModeVariable()]\n",
      "TRACE POP_TOP None [WithExitFunctionVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:6 in fn\n",
      "                x = x + 1\n",
      "TRACE LOAD_FAST x [WithExitFunctionVariable(), WithExitFunctionVariable()]\n",
      "TRACE LOAD_CONST 1 [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker()]\n",
      "TRACE BINARY_OP 0 [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker(), ConstantVariable(int: 1)]\n",
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n",
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n",
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:6 in fn\n",
      "            x = x + 1\n",
      "                ~~^~~\n",
      "TRACE STORE_FAST x [WithExitFunctionVariable(), WithExitFunctionVariable(), TensorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:7 in fn\n",
      "                torch._dynamo.graph_break()\n",
      "TRACE LOAD_GLOBAL torch [WithExitFunctionVariable(), WithExitFunctionVariable()]\n",
      "TRACE LOAD_ATTR _dynamo [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker()]\n",
      "TRACE LOAD_ATTR graph_break [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker()]\n",
      "TRACE CALL 0 [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker(), NullVariable]\n",
      "COMPILING GRAPH due to GraphCompileReason(reason='Call to `torch._dynamo.graph_break()`\\n  Explanation: User-inserted graph break. Message: None\\n  Hint: Remove the `torch._dynamo.graph_break()` call.\\n\\n  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\\n\\n For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py, line 7 in fn>], graph_break=True)\n",
      "TRACED GRAPH\n",
      " ===== __compiled_fn_26_fb042f3a_7254_45c6_9239_5f7bca5adcaa =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "        # No stacktrace found for following nodes\n",
      "        _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:6 in fn, code: x = x + 1\n",
      "        x: \"f32[3][1]cpu\" = l_x_ + 1;  l_x_ = None\n",
      "        \n",
      "        # No stacktrace found for following nodes\n",
      "        _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None\n",
      "        return (x,)\n",
      "Step 2: calling compiler function eager\n",
      "Step 2: done compiler function eager\n",
      "produce_guards\n",
      "track_symint L['x'].size()[0] 3 None\n",
      "track_symint L['x'].stride()[0] 1 None\n",
      "track_symint L['x'].storage_offset() 0 None\n",
      "Skipping guard L['x'].size()[0] == 3\n",
      "Skipping guard L['x'].stride()[0] == 1\n",
      "Skipping guard L['x'].storage_offset() == 0\n",
      "GUARDS:\n",
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=0), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # x = x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:6 in fn\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # x = x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:6 in fn\n",
      "| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor, type=<class 'dict'>, tag_safe=(False, False)\n",
      "| | +- GuardManager: source=G['torch'], accessed_by=DictGetItemGuardAccessor('torch'), type=<class 'module'>, tag_safe=(False, False)\n",
      "| | | +- ID_MATCH: ___check_obj_id(G['torch'], 1846212640448)                    # with torch.no_grad():  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:5 in fn\n",
      "| | | +- GuardManager: source=G['torch']._dynamo, accessed_by=GetAttrGuardAccessor(_dynamo), type=<class 'module'>, tag_safe=(False, False)\n",
      "| | | | +- ID_MATCH: ___check_obj_id(G['torch']._dynamo, 1846752934096)            # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:7 in fn\n",
      "| | | | +- GuardManager: source=G['torch']._dynamo.graph_break, accessed_by=GetAttrGuardAccessor(graph_break), type=<class 'function'>, tag_safe=(True, False)\n",
      "| | | | | +- GuardManager: source=G['torch']._dynamo.graph_break.__code__, accessed_by=CodeGuardAccessor, type=<class 'code'>, tag_safe=(True, False)\n",
      "| | | | | | +- ID_MATCH: ___check_obj_id(G['torch']._dynamo.graph_break.__code__, 1846802753744)  # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:7 in fn\n",
      "| | | +- GuardManager: source=G['torch'].no_grad, accessed_by=GetAttrGuardAccessor(no_grad), type=<class 'type'>, tag_safe=(True, False)\n",
      "| | | | +- ID_MATCH: ___check_obj_id(G['torch'].no_grad, 1846300076112)            # with torch.no_grad():  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:5 in fn\n",
      "| | +- GuardManager: source=G['contextlib'], accessed_by=DictGetItemGuardAccessor('contextlib'), type=<class 'module'>, tag_safe=(False, False)\n",
      "| | | +- ID_MATCH: ___check_obj_id(G['contextlib'], 1846140161616)               # with contextlib.nullcontext():  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:4 in fn\n",
      "| | | +- GuardManager: source=G['contextlib'].nullcontext, accessed_by=GetAttrGuardAccessor(nullcontext), type=<class 'abc.ABCMeta'>, tag_safe=(True, False)\n",
      "| | | | +- ID_MATCH: ___check_obj_id(G['contextlib'].nullcontext, 1846139731936)   # with contextlib.nullcontext():  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:4 in fn\n",
      "Guard eval latency = 55.50 us\n",
      "put_code_state: no cache key, skipping\n",
      "run_gc_after_compile: running gc\n",
      "skipping because no torch.* __init__             C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py 786\n",
      "skipping because no torch.* __enter__             C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py 789\n",
      "skipping: __init__ (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py)\n",
      "skipping: __enter__ (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py)\n",
      "skipping: __exit__ (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py)\n",
      "skipping because no torch.* __exit__             C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py 792\n",
      "torchdynamo start compiling torch_dynamo_resume_in_fn_at_7 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:7, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py\", line 9, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 832, in compile_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "Step 1: torchdynamo start tracing torch_dynamo_resume_in_fn_at_7 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:7\n",
      "create_env\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:7 in torch_dynamo_resume_in_fn_at_7\n",
      "                torch._dynamo.graph_break()\n",
      "TRACE RESUME 0 []\n",
      "TRACE LOAD_CONST True []\n",
      "TRACE STORE_FAST __is_tracing_resume_prologue [ConstantVariable(bool: True)]\n",
      "TRACE LOAD_FAST ___stack0 []\n",
      "TRACE PUSH_NULL None [LazyVariableTracker()]\n",
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n",
      "TRACE NOP None [NullContextVariable()]\n",
      "TRACE BEFORE_WITH None [NullContextVariable()]\n",
      "TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n",
      "TRACE NOP None [WithExitFunctionVariable()]\n",
      "TRACE LOAD_FAST ___stack1 [WithExitFunctionVariable()]\n",
      "TRACE PUSH_NULL None [WithExitFunctionVariable(), LazyVariableTracker()]\n",
      "TRACE LOAD_CONST False [WithExitFunctionVariable(), LazyVariableTracker(), NullVariable]\n",
      "TRACE CALL 1 [WithExitFunctionVariable(), LazyVariableTracker(), NullVariable, ConstantVariable(bool: False)]\n",
      "TRACE NOP None [WithExitFunctionVariable(), GradModeVariable()]\n",
      "TRACE BEFORE_WITH None [WithExitFunctionVariable(), GradModeVariable()]\n",
      "TRACE POP_TOP None [WithExitFunctionVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n",
      "TRACE NOP None [WithExitFunctionVariable(), WithExitFunctionVariable()]\n",
      "TRACE LOAD_FAST ___stack2 [WithExitFunctionVariable(), WithExitFunctionVariable()]\n",
      "TRACE LOAD_CONST False [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker()]\n",
      "TRACE STORE_FAST __is_tracing_resume_prologue [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker(), ConstantVariable(bool: False)]\n",
      "TRACE JUMP_FORWARD 338 [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker()]\n",
      "TRACE POP_TOP None [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:8 in torch_dynamo_resume_in_fn_at_7\n",
      "                return x + 1\n",
      "TRACE LOAD_FAST x [WithExitFunctionVariable(), WithExitFunctionVariable()]\n",
      "TRACE LOAD_CONST 1 [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker()]\n",
      "TRACE BINARY_OP 0 [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker(), ConstantVariable(int: 1)]\n",
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n",
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n",
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:8 in torch_dynamo_resume_in_fn_at_7\n",
      "            return x + 1\n",
      "                   ~~^~~\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:5 in torch_dynamo_resume_in_fn_at_7\n",
      "            with torch.no_grad():\n",
      "TRACE SWAP 2 [WithExitFunctionVariable(), WithExitFunctionVariable(), TensorVariable()]\n",
      "TRACE LOAD_CONST None [WithExitFunctionVariable(), TensorVariable(), WithExitFunctionVariable()]\n",
      "TRACE LOAD_CONST None [WithExitFunctionVariable(), TensorVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n",
      "TRACE LOAD_CONST None [WithExitFunctionVariable(), TensorVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None)]\n",
      "TRACE CALL 2 [WithExitFunctionVariable(), TensorVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None)]\n",
      "TRACE POP_TOP None [WithExitFunctionVariable(), TensorVariable(), ConstantVariable(NoneType: None)]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:4 in torch_dynamo_resume_in_fn_at_7\n",
      "        with contextlib.nullcontext():\n",
      "TRACE SWAP 2 [WithExitFunctionVariable(), TensorVariable()]\n",
      "TRACE LOAD_CONST None [TensorVariable(), WithExitFunctionVariable()]\n",
      "TRACE LOAD_CONST None [TensorVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n",
      "TRACE LOAD_CONST None [TensorVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None)]\n",
      "TRACE CALL 2 [TensorVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None)]\n",
      "TRACE POP_TOP None [TensorVariable(), ConstantVariable(NoneType: None)]\n",
      "TRACE RETURN_VALUE None [TensorVariable()]\n",
      "Step 1: torchdynamo done tracing torch_dynamo_resume_in_fn_at_7 (RETURN_VALUE)\n",
      "RETURN_VALUE triggered compile\n",
      "COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py, line 4 in torch_dynamo_resume_in_fn_at_7>], graph_break=False)\n",
      "TRACED GRAPH\n",
      " ===== __compiled_fn_31_1825b007_3530_4dcc_8cc6_dfcca71939d2 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "        # No stacktrace found for following nodes\n",
      "        _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:8 in torch_dynamo_resume_in_fn_at_7, code: return x + 1\n",
      "        add: \"f32[3][1]cpu\" = l_x_ + 1;  l_x_ = None\n",
      "        \n",
      "        # No stacktrace found for following nodes\n",
      "        _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None\n",
      "        return (add,)\n",
      "Step 2: calling compiler function eager\n",
      "Step 2: done compiler function eager\n",
      "produce_guards\n",
      "track_symint L['x'].size()[0] 3 None\n",
      "track_symint L['x'].stride()[0] 1 None\n",
      "track_symint L['x'].storage_offset() 0 None\n",
      "Skipping guard L['x'].size()[0] == 3\n",
      "Skipping guard L['x'].stride()[0] == 1\n",
      "Skipping guard L['x'].storage_offset() == 0\n",
      "GUARDS:\n",
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=5), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # return x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:8 in torch_dynamo_resume_in_fn_at_7\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # return x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:8 in torch_dynamo_resume_in_fn_at_7\n",
      "| +- GuardManager: source=L['___stack0'], accessed_by=FrameLocalsGuardAccessor(key='___stack0', framelocals_idx=2), type=<class 'abc.ABCMeta'>, tag_safe=(True, False)\n",
      "| | +- ID_MATCH: ___check_obj_id(L['___stack0'], 1846139731936)                # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:7 in torch_dynamo_resume_in_fn_at_7\n",
      "| +- GuardManager: source=L['___stack1'], accessed_by=FrameLocalsGuardAccessor(key='___stack1', framelocals_idx=3), type=<class 'type'>, tag_safe=(True, False)\n",
      "| | +- ID_MATCH: ___check_obj_id(L['___stack1'], 1846300078096)                # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:7 in torch_dynamo_resume_in_fn_at_7\n",
      "Guard eval latency = 51.50 us\n",
      "put_code_state: no cache key, skipping\n",
      "run_gc_after_compile: running gc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:2 in fn\n",
      "    @torch.compile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:4 in fn\n",
      "        with contextlib.nullcontext():\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL contextlib []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR nullcontext [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BEFORE_WITH None [NullContextVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:5 in fn\n",
      "            with torch.no_grad():\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL torch [WithExitFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR no_grad [WithExitFunctionVariable(), LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [WithExitFunctionVariable(), LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BEFORE_WITH None [WithExitFunctionVariable(), GradModeVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [WithExitFunctionVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:6 in fn\n",
      "                x = x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x [WithExitFunctionVariable(), WithExitFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:6 in fn\n",
      "            x = x + 1\n",
      "                ~~^~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST x [WithExitFunctionVariable(), WithExitFunctionVariable(), TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:7 in fn\n",
      "                torch._dynamo.graph_break()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL torch [WithExitFunctionVariable(), WithExitFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR _dynamo [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR graph_break [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph break in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:7\n",
      "Graph Break Reason: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "User code traceback:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py\", line 9, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py\", line 7, in fn\n",
      "    torch._dynamo.graph_break()\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restarting analysis due to _dynamo\\symbolic_convert.py:249 in fail_and_restart_analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:2 in fn\n",
      "    @torch.compile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:4 in fn\n",
      "        with contextlib.nullcontext():\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL contextlib []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR nullcontext [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BEFORE_WITH None [NullContextVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:5 in fn\n",
      "            with torch.no_grad():\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL torch [WithExitFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR no_grad [WithExitFunctionVariable(), LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [WithExitFunctionVariable(), LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BEFORE_WITH None [WithExitFunctionVariable(), GradModeVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [WithExitFunctionVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:6 in fn\n",
      "                x = x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x [WithExitFunctionVariable(), WithExitFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:6 in fn\n",
      "            x = x + 1\n",
      "                ~~^~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST x [WithExitFunctionVariable(), WithExitFunctionVariable(), TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:7 in fn\n",
      "                torch._dynamo.graph_break()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL torch [WithExitFunctionVariable(), WithExitFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR _dynamo [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR graph_break [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMPILING GRAPH due to GraphCompileReason(reason='Call to `torch._dynamo.graph_break()`\\n  Explanation: User-inserted graph break. Message: None\\n  Hint: Remove the `torch._dynamo.graph_break()` call.\\n\\n  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\\n\\n For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py, line 7 in fn>], graph_break=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACED GRAPH\n",
      " ===== __compiled_fn_26_fb042f3a_7254_45c6_9239_5f7bca5adcaa =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "        # No stacktrace found for following nodes\n",
      "        _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:6 in fn, code: x = x + 1\n",
      "        x: \"f32[3][1]cpu\" = l_x_ + 1;  l_x_ = None\n",
      "        \n",
      "        # No stacktrace found for following nodes\n",
      "        _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None\n",
      "        return (x,)\n",
      "        \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: calling compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: done compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "produce_guards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].size()[0] 3 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].stride()[0] 1 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].storage_offset() 0 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].size()[0] == 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].stride()[0] == 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].storage_offset() == 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GUARDS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=0), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # x = x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:6 in fn\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # x = x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:6 in fn\n",
      "| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor, type=<class 'dict'>, tag_safe=(False, False)\n",
      "| | +- GuardManager: source=G['torch'], accessed_by=DictGetItemGuardAccessor('torch'), type=<class 'module'>, tag_safe=(False, False)\n",
      "| | | +- ID_MATCH: ___check_obj_id(G['torch'], 1846212640448)                    # with torch.no_grad():  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:5 in fn\n",
      "| | | +- GuardManager: source=G['torch']._dynamo, accessed_by=GetAttrGuardAccessor(_dynamo), type=<class 'module'>, tag_safe=(False, False)\n",
      "| | | | +- ID_MATCH: ___check_obj_id(G['torch']._dynamo, 1846752934096)            # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:7 in fn\n",
      "| | | | +- GuardManager: source=G['torch']._dynamo.graph_break, accessed_by=GetAttrGuardAccessor(graph_break), type=<class 'function'>, tag_safe=(True, False)\n",
      "| | | | | +- GuardManager: source=G['torch']._dynamo.graph_break.__code__, accessed_by=CodeGuardAccessor, type=<class 'code'>, tag_safe=(True, False)\n",
      "| | | | | | +- ID_MATCH: ___check_obj_id(G['torch']._dynamo.graph_break.__code__, 1846802753744)  # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:7 in fn\n",
      "| | | +- GuardManager: source=G['torch'].no_grad, accessed_by=GetAttrGuardAccessor(no_grad), type=<class 'type'>, tag_safe=(True, False)\n",
      "| | | | +- ID_MATCH: ___check_obj_id(G['torch'].no_grad, 1846300076112)            # with torch.no_grad():  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:5 in fn\n",
      "| | +- GuardManager: source=G['contextlib'], accessed_by=DictGetItemGuardAccessor('contextlib'), type=<class 'module'>, tag_safe=(False, False)\n",
      "| | | +- ID_MATCH: ___check_obj_id(G['contextlib'], 1846140161616)               # with contextlib.nullcontext():  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:4 in fn\n",
      "| | | +- GuardManager: source=G['contextlib'].nullcontext, accessed_by=GetAttrGuardAccessor(nullcontext), type=<class 'abc.ABCMeta'>, tag_safe=(True, False)\n",
      "| | | | +- ID_MATCH: ___check_obj_id(G['contextlib'].nullcontext, 1846139731936)   # with contextlib.nullcontext():  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:4 in fn\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Guard eval latency = 55.50 us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "put_code_state: no cache key, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_gc_after_compile: running gc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping because no torch.* __init__             C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py 786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping because no torch.* __enter__             C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py 789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping: __init__ (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping: __enter__ (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping: __exit__ (reason: in skipfiles, file: C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping because no torch.* __exit__             C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py 792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchdynamo start compiling torch_dynamo_resume_in_fn_at_7 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:7, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py\", line 9, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 832, in compile_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo start tracing torch_dynamo_resume_in_fn_at_7 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:7 in torch_dynamo_resume_in_fn_at_7\n",
      "                torch._dynamo.graph_break()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST True []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST __is_tracing_resume_prologue [ConstantVariable(bool: True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST ___stack0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE PUSH_NULL None [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE NOP None [NullContextVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BEFORE_WITH None [NullContextVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE NOP None [WithExitFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST ___stack1 [WithExitFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE PUSH_NULL None [WithExitFunctionVariable(), LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST False [WithExitFunctionVariable(), LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 1 [WithExitFunctionVariable(), LazyVariableTracker(), NullVariable, ConstantVariable(bool: False)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE NOP None [WithExitFunctionVariable(), GradModeVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BEFORE_WITH None [WithExitFunctionVariable(), GradModeVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [WithExitFunctionVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE NOP None [WithExitFunctionVariable(), WithExitFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST ___stack2 [WithExitFunctionVariable(), WithExitFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST False [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST __is_tracing_resume_prologue [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker(), ConstantVariable(bool: False)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE JUMP_FORWARD 338 [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:8 in torch_dynamo_resume_in_fn_at_7\n",
      "                return x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x [WithExitFunctionVariable(), WithExitFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [WithExitFunctionVariable(), WithExitFunctionVariable(), LazyVariableTracker(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:8 in torch_dynamo_resume_in_fn_at_7\n",
      "            return x + 1\n",
      "                   ~~^~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:5 in torch_dynamo_resume_in_fn_at_7\n",
      "            with torch.no_grad():\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE SWAP 2 [WithExitFunctionVariable(), WithExitFunctionVariable(), TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST None [WithExitFunctionVariable(), TensorVariable(), WithExitFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST None [WithExitFunctionVariable(), TensorVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST None [WithExitFunctionVariable(), TensorVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 2 [WithExitFunctionVariable(), TensorVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [WithExitFunctionVariable(), TensorVariable(), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:4 in torch_dynamo_resume_in_fn_at_7\n",
      "        with contextlib.nullcontext():\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE SWAP 2 [WithExitFunctionVariable(), TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST None [TensorVariable(), WithExitFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST None [TensorVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST None [TensorVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 2 [TensorVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [TensorVariable(), ConstantVariable(NoneType: None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_VALUE None [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo done tracing torch_dynamo_resume_in_fn_at_7 (RETURN_VALUE)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RETURN_VALUE triggered compile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py, line 4 in torch_dynamo_resume_in_fn_at_7>], graph_break=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACED GRAPH\n",
      " ===== __compiled_fn_31_1825b007_3530_4dcc_8cc6_dfcca71939d2 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "        # No stacktrace found for following nodes\n",
      "        _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:8 in torch_dynamo_resume_in_fn_at_7, code: return x + 1\n",
      "        add: \"f32[3][1]cpu\" = l_x_ + 1;  l_x_ = None\n",
      "        \n",
      "        # No stacktrace found for following nodes\n",
      "        _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None\n",
      "        return (add,)\n",
      "        \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: calling compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: done compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "produce_guards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].size()[0] 3 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].stride()[0] 1 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].storage_offset() 0 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].size()[0] == 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].stride()[0] == 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].storage_offset() == 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GUARDS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=5), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # return x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:8 in torch_dynamo_resume_in_fn_at_7\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # return x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:8 in torch_dynamo_resume_in_fn_at_7\n",
      "| +- GuardManager: source=L['___stack0'], accessed_by=FrameLocalsGuardAccessor(key='___stack0', framelocals_idx=2), type=<class 'abc.ABCMeta'>, tag_safe=(True, False)\n",
      "| | +- ID_MATCH: ___check_obj_id(L['___stack0'], 1846139731936)                # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:7 in torch_dynamo_resume_in_fn_at_7\n",
      "| +- GuardManager: source=L['___stack1'], accessed_by=FrameLocalsGuardAccessor(key='___stack1', framelocals_idx=3), type=<class 'type'>, tag_safe=(True, False)\n",
      "| | +- ID_MATCH: ___check_obj_id(L['___stack1'], 1846300078096)                # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3152636365.py:7 in torch_dynamo_resume_in_fn_at_7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Guard eval latency = 51.50 us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "put_code_state: no cache key, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_gc_after_compile: running gc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.1801, 2.4112, 0.2910])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import contextlib\n",
    "@torch.compile\n",
    "def fn(x):\n",
    "    with contextlib.nullcontext():\n",
    "        with torch.no_grad():\n",
    "            x = x + 1\n",
    "            torch._dynamo.graph_break()\n",
    "            return x + 1\n",
    "fn(torch.randn(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11d60af",
   "metadata": {},
   "source": [
    "## Graph Break in a Try Block\n",
    "\n",
    "A graph break in a try block cannot be resumed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2265a2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchdynamo start compiling fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2546874632.py:1, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2546874632.py\", line 9, in <module>\n",
      "    fn(torch.randn(3))\n",
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2546874632.py:1\n",
      "create_env\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2546874632.py:1 in fn\n",
      "    @torch.compile\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2546874632.py:3 in fn\n",
      "        try:\n",
      "TRACE NOP None []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2546874632.py:4 in fn\n",
      "            x = x + 1\n",
      "TRACE LOAD_FAST x []\n",
      "TRACE LOAD_CONST 1 [LazyVariableTracker()]\n",
      "TRACE BINARY_OP 0 [LazyVariableTracker(), ConstantVariable(int: 1)]\n",
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n",
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n",
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2546874632.py:4 in fn\n",
      "        x = x + 1\n",
      "            ~~^~~\n",
      "TRACE STORE_FAST x [TensorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2546874632.py:5 in fn\n",
      "            torch._dynamo.graph_break()\n",
      "TRACE LOAD_GLOBAL torch []\n",
      "TRACE LOAD_ATTR _dynamo [LazyVariableTracker()]\n",
      "TRACE LOAD_ATTR graph_break [LazyVariableTracker()]\n",
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n",
      "empty checkpoint\n",
      "run_gc_after_compile: running gc\n",
      "Graph break: skip: from user code at:\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2546874632.py\", line 5, in fn\n",
      "    torch._dynamo.graph_break()\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1624, in __call__\n",
      "    result = self._inner_convert(\n",
      "        frame, cache_entry, hooks, frame_state, skip=skip + 1\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 688, in __call__\n",
      "    result = _compile(\n",
      "        frame.f_code,\n",
      "    ...<16 lines>...\n",
      "        convert_frame_box=self._box,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1433, in _compile\n",
      "    guarded_code, tracer_output = compile_inner(code, one_graph, hooks)\n",
      "                                  ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_utils_internal.py\", line 92, in wrapper_function\n",
      "    return function(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1117, in compile_inner\n",
      "    return _compile_inner(code, one_graph, hooks)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1151, in _compile_inner\n",
      "    dynamo_output = compile_frame(\n",
      "        code,\n",
      "    ...<11 lines>...\n",
      "        package=package,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1032, in compile_frame\n",
      "    bytecode, tracer_output = transform_code_object(code, transform)\n",
      "                              ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1592, in transform_code_object\n",
      "    tracer_output = transformations(instructions, code_options)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1004, in transform\n",
      "    tracer_output = trace_frame(\n",
      "        code,\n",
      "    ...<14 lines>...\n",
      "        package=package,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 312, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 815, in trace_frame\n",
      "    run_tracer()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in run_tracer\n",
      "    tracer.run()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1487, in run\n",
      "    while self.step():\n",
      "          ~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1348, in step\n",
      "    self.dispatch_table[inst.opcode](self, inst)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 904, in wrapper\n",
      "    return inner_fn(self, inst)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3411, in CALL\n",
      "    self._call(inst)\n",
      "    ~~~~~~~~~~^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3405, in _call\n",
      "    self.call_function(fn, args, kwargs)\n",
      "    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1266, in call_function\n",
      "    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n",
      "              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\lazy.py\", line 212, in realize_and_forward\n",
      "    return getattr(self.realize(), name)(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\functions.py\", line 1515, in call_function\n",
      "    unimplemented_v2(\n",
      "    ~~~~~~~~~~~~~~~~^\n",
      "        gb_type=\"Call to `torch._dynamo.graph_break()`\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        ],\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\exc.py\", line 596, in unimplemented_v2\n",
      "    raise Unsupported(msg)\n",
      "torch._dynamo.exc.Unsupported: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "\n",
      "from user code:\n",
      "   File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2546874632.py\", line 5, in fn\n",
      "    torch._dynamo.graph_break()\n",
      "\n",
      "Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "WON'T CONVERT fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2546874632.py line 1 \n",
      "due to: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1624, in __call__\n",
      "    result = self._inner_convert(\n",
      "        frame, cache_entry, hooks, frame_state, skip=skip + 1\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 688, in __call__\n",
      "    result = _compile(\n",
      "        frame.f_code,\n",
      "    ...<16 lines>...\n",
      "        convert_frame_box=self._box,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1433, in _compile\n",
      "    guarded_code, tracer_output = compile_inner(code, one_graph, hooks)\n",
      "                                  ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_utils_internal.py\", line 92, in wrapper_function\n",
      "    return function(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1117, in compile_inner\n",
      "    return _compile_inner(code, one_graph, hooks)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1151, in _compile_inner\n",
      "    dynamo_output = compile_frame(\n",
      "        code,\n",
      "    ...<11 lines>...\n",
      "        package=package,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1032, in compile_frame\n",
      "    bytecode, tracer_output = transform_code_object(code, transform)\n",
      "                              ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1592, in transform_code_object\n",
      "    tracer_output = transformations(instructions, code_options)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1004, in transform\n",
      "    tracer_output = trace_frame(\n",
      "        code,\n",
      "    ...<14 lines>...\n",
      "        package=package,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 312, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 815, in trace_frame\n",
      "    run_tracer()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in run_tracer\n",
      "    tracer.run()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1487, in run\n",
      "    while self.step():\n",
      "          ~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1348, in step\n",
      "    self.dispatch_table[inst.opcode](self, inst)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 904, in wrapper\n",
      "    return inner_fn(self, inst)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3411, in CALL\n",
      "    self._call(inst)\n",
      "    ~~~~~~~~~~^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3405, in _call\n",
      "    self.call_function(fn, args, kwargs)\n",
      "    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1266, in call_function\n",
      "    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n",
      "              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\lazy.py\", line 212, in realize_and_forward\n",
      "    return getattr(self.realize(), name)(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\functions.py\", line 1515, in call_function\n",
      "    unimplemented_v2(\n",
      "    ~~~~~~~~~~~~~~~~^\n",
      "        gb_type=\"Call to `torch._dynamo.graph_break()`\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        ],\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\exc.py\", line 596, in unimplemented_v2\n",
      "    raise Unsupported(msg)\n",
      "torch._dynamo.exc.Unsupported: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "\n",
      "from user code:\n",
      "   File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2546874632.py\", line 5, in fn\n",
      "    torch._dynamo.graph_break()\n",
      "\n",
      "Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1624, in __call__\n",
      "    result = self._inner_convert(\n",
      "        frame, cache_entry, hooks, frame_state, skip=skip + 1\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 688, in __call__\n",
      "    result = _compile(\n",
      "        frame.f_code,\n",
      "    ...<16 lines>...\n",
      "        convert_frame_box=self._box,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1433, in _compile\n",
      "    guarded_code, tracer_output = compile_inner(code, one_graph, hooks)\n",
      "                                  ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_utils_internal.py\", line 92, in wrapper_function\n",
      "    return function(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1117, in compile_inner\n",
      "    return _compile_inner(code, one_graph, hooks)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1151, in _compile_inner\n",
      "    dynamo_output = compile_frame(\n",
      "        code,\n",
      "    ...<11 lines>...\n",
      "        package=package,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1032, in compile_frame\n",
      "    bytecode, tracer_output = transform_code_object(code, transform)\n",
      "                              ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1592, in transform_code_object\n",
      "    tracer_output = transformations(instructions, code_options)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1004, in transform\n",
      "    tracer_output = trace_frame(\n",
      "        code,\n",
      "    ...<14 lines>...\n",
      "        package=package,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 312, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 815, in trace_frame\n",
      "    run_tracer()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in run_tracer\n",
      "    tracer.run()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1487, in run\n",
      "    while self.step():\n",
      "          ~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1348, in step\n",
      "    self.dispatch_table[inst.opcode](self, inst)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 904, in wrapper\n",
      "    return inner_fn(self, inst)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3411, in CALL\n",
      "    self._call(inst)\n",
      "    ~~~~~~~~~~^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3405, in _call\n",
      "    self.call_function(fn, args, kwargs)\n",
      "    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1266, in call_function\n",
      "    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n",
      "              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\lazy.py\", line 212, in realize_and_forward\n",
      "    return getattr(self.realize(), name)(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\functions.py\", line 1515, in call_function\n",
      "    unimplemented_v2(\n",
      "    ~~~~~~~~~~~~~~~~^\n",
      "        gb_type=\"Call to `torch._dynamo.graph_break()`\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        ],\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\exc.py\", line 596, in unimplemented_v2\n",
      "    raise Unsupported(msg)\n",
      "torch._dynamo.exc.Unsupported: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "\n",
      "from user code:\n",
      "   File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2546874632.py\", line 5, in fn\n",
      "    torch._dynamo.graph_break()\n",
      "\n",
      "Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2546874632.py:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2546874632.py:1 in fn\n",
      "    @torch.compile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2546874632.py:3 in fn\n",
      "        try:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE NOP None []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2546874632.py:4 in fn\n",
      "            x = x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [LazyVariableTracker(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2546874632.py:4 in fn\n",
      "        x = x + 1\n",
      "            ~~^~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST x [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2546874632.py:5 in fn\n",
      "            torch._dynamo.graph_break()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL torch []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR _dynamo [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR graph_break [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "empty checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_gc_after_compile: running gc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph break: skip: from user code at:\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2546874632.py\", line 5, in fn\n",
      "    torch._dynamo.graph_break()\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1624, in __call__\n",
      "    result = self._inner_convert(\n",
      "        frame, cache_entry, hooks, frame_state, skip=skip + 1\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 688, in __call__\n",
      "    result = _compile(\n",
      "        frame.f_code,\n",
      "    ...<16 lines>...\n",
      "        convert_frame_box=self._box,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1433, in _compile\n",
      "    guarded_code, tracer_output = compile_inner(code, one_graph, hooks)\n",
      "                                  ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_utils_internal.py\", line 92, in wrapper_function\n",
      "    return function(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1117, in compile_inner\n",
      "    return _compile_inner(code, one_graph, hooks)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1151, in _compile_inner\n",
      "    dynamo_output = compile_frame(\n",
      "        code,\n",
      "    ...<11 lines>...\n",
      "        package=package,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1032, in compile_frame\n",
      "    bytecode, tracer_output = transform_code_object(code, transform)\n",
      "                              ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1592, in transform_code_object\n",
      "    tracer_output = transformations(instructions, code_options)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1004, in transform\n",
      "    tracer_output = trace_frame(\n",
      "        code,\n",
      "    ...<14 lines>...\n",
      "        package=package,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 312, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 815, in trace_frame\n",
      "    run_tracer()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in run_tracer\n",
      "    tracer.run()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1487, in run\n",
      "    while self.step():\n",
      "          ~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1348, in step\n",
      "    self.dispatch_table[inst.opcode](self, inst)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 904, in wrapper\n",
      "    return inner_fn(self, inst)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3411, in CALL\n",
      "    self._call(inst)\n",
      "    ~~~~~~~~~~^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3405, in _call\n",
      "    self.call_function(fn, args, kwargs)\n",
      "    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1266, in call_function\n",
      "    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n",
      "              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\lazy.py\", line 212, in realize_and_forward\n",
      "    return getattr(self.realize(), name)(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\functions.py\", line 1515, in call_function\n",
      "    unimplemented_v2(\n",
      "    ~~~~~~~~~~~~~~~~^\n",
      "        gb_type=\"Call to `torch._dynamo.graph_break()`\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        ],\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\exc.py\", line 596, in unimplemented_v2\n",
      "    raise Unsupported(msg)\n",
      "torch._dynamo.exc.Unsupported: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "\n",
      "from user code:\n",
      "   File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2546874632.py\", line 5, in fn\n",
      "    torch._dynamo.graph_break()\n",
      "\n",
      "Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WON'T CONVERT fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2546874632.py line 1 \n",
      "due to: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1624, in __call__\n",
      "    result = self._inner_convert(\n",
      "        frame, cache_entry, hooks, frame_state, skip=skip + 1\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 688, in __call__\n",
      "    result = _compile(\n",
      "        frame.f_code,\n",
      "    ...<16 lines>...\n",
      "        convert_frame_box=self._box,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1433, in _compile\n",
      "    guarded_code, tracer_output = compile_inner(code, one_graph, hooks)\n",
      "                                  ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_utils_internal.py\", line 92, in wrapper_function\n",
      "    return function(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1117, in compile_inner\n",
      "    return _compile_inner(code, one_graph, hooks)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1151, in _compile_inner\n",
      "    dynamo_output = compile_frame(\n",
      "        code,\n",
      "    ...<11 lines>...\n",
      "        package=package,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1032, in compile_frame\n",
      "    bytecode, tracer_output = transform_code_object(code, transform)\n",
      "                              ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1592, in transform_code_object\n",
      "    tracer_output = transformations(instructions, code_options)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1004, in transform\n",
      "    tracer_output = trace_frame(\n",
      "        code,\n",
      "    ...<14 lines>...\n",
      "        package=package,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 312, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 815, in trace_frame\n",
      "    run_tracer()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in run_tracer\n",
      "    tracer.run()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1487, in run\n",
      "    while self.step():\n",
      "          ~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1348, in step\n",
      "    self.dispatch_table[inst.opcode](self, inst)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 904, in wrapper\n",
      "    return inner_fn(self, inst)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3411, in CALL\n",
      "    self._call(inst)\n",
      "    ~~~~~~~~~~^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3405, in _call\n",
      "    self.call_function(fn, args, kwargs)\n",
      "    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1266, in call_function\n",
      "    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n",
      "              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\lazy.py\", line 212, in realize_and_forward\n",
      "    return getattr(self.realize(), name)(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\functions.py\", line 1515, in call_function\n",
      "    unimplemented_v2(\n",
      "    ~~~~~~~~~~~~~~~~^\n",
      "        gb_type=\"Call to `torch._dynamo.graph_break()`\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        ],\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\exc.py\", line 596, in unimplemented_v2\n",
      "    raise Unsupported(msg)\n",
      "torch._dynamo.exc.Unsupported: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "\n",
      "from user code:\n",
      "   File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2546874632.py\", line 5, in fn\n",
      "    torch._dynamo.graph_break()\n",
      "\n",
      "Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1624, in __call__\n",
      "    result = self._inner_convert(\n",
      "        frame, cache_entry, hooks, frame_state, skip=skip + 1\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 688, in __call__\n",
      "    result = _compile(\n",
      "        frame.f_code,\n",
      "    ...<16 lines>...\n",
      "        convert_frame_box=self._box,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1433, in _compile\n",
      "    guarded_code, tracer_output = compile_inner(code, one_graph, hooks)\n",
      "                                  ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_utils_internal.py\", line 92, in wrapper_function\n",
      "    return function(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1117, in compile_inner\n",
      "    return _compile_inner(code, one_graph, hooks)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1151, in _compile_inner\n",
      "    dynamo_output = compile_frame(\n",
      "        code,\n",
      "    ...<11 lines>...\n",
      "        package=package,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1032, in compile_frame\n",
      "    bytecode, tracer_output = transform_code_object(code, transform)\n",
      "                              ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1592, in transform_code_object\n",
      "    tracer_output = transformations(instructions, code_options)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1004, in transform\n",
      "    tracer_output = trace_frame(\n",
      "        code,\n",
      "    ...<14 lines>...\n",
      "        package=package,\n",
      "    )\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 312, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 815, in trace_frame\n",
      "    run_tracer()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in run_tracer\n",
      "    tracer.run()\n",
      "    ~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1487, in run\n",
      "    while self.step():\n",
      "          ~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1348, in step\n",
      "    self.dispatch_table[inst.opcode](self, inst)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 904, in wrapper\n",
      "    return inner_fn(self, inst)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3411, in CALL\n",
      "    self._call(inst)\n",
      "    ~~~~~~~~~~^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3405, in _call\n",
      "    self.call_function(fn, args, kwargs)\n",
      "    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1266, in call_function\n",
      "    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n",
      "              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\lazy.py\", line 212, in realize_and_forward\n",
      "    return getattr(self.realize(), name)(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\variables\\functions.py\", line 1515, in call_function\n",
      "    unimplemented_v2(\n",
      "    ~~~~~~~~~~~~~~~~^\n",
      "        gb_type=\"Call to `torch._dynamo.graph_break()`\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        ],\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\exc.py\", line 596, in unimplemented_v2\n",
      "    raise Unsupported(msg)\n",
      "torch._dynamo.exc.Unsupported: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "\n",
      "from user code:\n",
      "   File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\2546874632.py\", line 5, in fn\n",
      "    torch._dynamo.graph_break()\n",
      "\n",
      "Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2.1518, 3.1957, 0.6976])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.compile\n",
    "def fn(x):\n",
    "    try:\n",
    "        x = x + 1\n",
    "        torch._dynamo.graph_break()\n",
    "        return x + 1\n",
    "    except Exception as e:\n",
    "        pass\n",
    "fn(torch.randn(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c78f963",
   "metadata": {},
   "source": [
    "We can avoid skipping by moving the graph break outside of the try block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad38eb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchdynamo start compiling fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:1, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py\", line 12, in <module>\n",
      "    fn(torch.randn(3))\n",
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:1\n",
      "create_env\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:1 in fn\n",
      "    @torch.compile\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:3 in fn\n",
      "        try:\n",
      "TRACE NOP None []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:4 in fn\n",
      "            x = x + 1\n",
      "TRACE LOAD_FAST x []\n",
      "TRACE LOAD_CONST 1 [LazyVariableTracker()]\n",
      "TRACE BINARY_OP 0 [LazyVariableTracker(), ConstantVariable(int: 1)]\n",
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n",
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n",
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:4 in fn\n",
      "        x = x + 1\n",
      "            ~~^~~\n",
      "TRACE STORE_FAST x [TensorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:7 in fn\n",
      "        torch._dynamo.graph_break()\n",
      "TRACE LOAD_GLOBAL torch []\n",
      "TRACE LOAD_ATTR _dynamo [LazyVariableTracker()]\n",
      "TRACE LOAD_ATTR graph_break [LazyVariableTracker()]\n",
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n",
      "Graph break in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:7\n",
      "Graph Break Reason: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "User code traceback:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py\", line 12, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py\", line 7, in fn\n",
      "    torch._dynamo.graph_break()\n",
      "Restarting analysis due to _dynamo\\symbolic_convert.py:249 in fail_and_restart_analysis\n",
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:1\n",
      "create_env\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:1 in fn\n",
      "    @torch.compile\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:3 in fn\n",
      "        try:\n",
      "TRACE NOP None []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:4 in fn\n",
      "            x = x + 1\n",
      "TRACE LOAD_FAST x []\n",
      "TRACE LOAD_CONST 1 [LazyVariableTracker()]\n",
      "TRACE BINARY_OP 0 [LazyVariableTracker(), ConstantVariable(int: 1)]\n",
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n",
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n",
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:4 in fn\n",
      "        x = x + 1\n",
      "            ~~^~~\n",
      "TRACE STORE_FAST x [TensorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:7 in fn\n",
      "        torch._dynamo.graph_break()\n",
      "TRACE LOAD_GLOBAL torch []\n",
      "TRACE LOAD_ATTR _dynamo [LazyVariableTracker()]\n",
      "TRACE LOAD_ATTR graph_break [LazyVariableTracker()]\n",
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n",
      "COMPILING GRAPH due to GraphCompileReason(reason='Call to `torch._dynamo.graph_break()`\\n  Explanation: User-inserted graph break. Message: None\\n  Hint: Remove the `torch._dynamo.graph_break()` call.\\n\\n  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\\n\\n For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py, line 7 in fn>], graph_break=True)\n",
      "TRACED GRAPH\n",
      " ===== __compiled_fn_35_40d9f249_36ed_4c70_b9f9_7995e537d632 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:4 in fn, code: x = x + 1\n",
      "        x: \"f32[3][1]cpu\" = l_x_ + 1;  l_x_ = None\n",
      "        return (x,)\n",
      "Step 2: calling compiler function eager\n",
      "Step 2: done compiler function eager\n",
      "produce_guards\n",
      "track_symint L['x'].size()[0] 3 None\n",
      "track_symint L['x'].stride()[0] 1 None\n",
      "track_symint L['x'].storage_offset() 0 None\n",
      "Skipping guard L['x'].size()[0] == 3\n",
      "Skipping guard L['x'].stride()[0] == 1\n",
      "Skipping guard L['x'].storage_offset() == 0\n",
      "GUARDS:\n",
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=0), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # x = x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:4 in fn\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # x = x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:4 in fn\n",
      "| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor, type=<class 'dict'>, tag_safe=(False, False)\n",
      "| | +- GuardManager: source=G['torch'], accessed_by=DictGetItemGuardAccessor('torch'), type=<class 'module'>, tag_safe=(False, False)\n",
      "| | | +- ID_MATCH: ___check_obj_id(G['torch'], 1846212640448)                    # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:7 in fn\n",
      "| | | +- GuardManager: source=G['torch']._dynamo, accessed_by=GetAttrGuardAccessor(_dynamo), type=<class 'module'>, tag_safe=(False, False)\n",
      "| | | | +- ID_MATCH: ___check_obj_id(G['torch']._dynamo, 1846752934096)            # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:7 in fn\n",
      "| | | | +- GuardManager: source=G['torch']._dynamo.graph_break, accessed_by=GetAttrGuardAccessor(graph_break), type=<class 'function'>, tag_safe=(True, False)\n",
      "| | | | | +- GuardManager: source=G['torch']._dynamo.graph_break.__code__, accessed_by=CodeGuardAccessor, type=<class 'code'>, tag_safe=(True, False)\n",
      "| | | | | | +- ID_MATCH: ___check_obj_id(G['torch']._dynamo.graph_break.__code__, 1846802753744)  # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:7 in fn\n",
      "Guard eval latency = 75.10 us\n",
      "put_code_state: no cache key, skipping\n",
      "run_gc_after_compile: running gc\n",
      "torchdynamo start compiling torch_dynamo_resume_in_fn_at_7 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:7, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py\", line 12, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 832, in compile_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "Step 1: torchdynamo start tracing torch_dynamo_resume_in_fn_at_7 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:7\n",
      "create_env\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:7 in torch_dynamo_resume_in_fn_at_7\n",
      "        torch._dynamo.graph_break()\n",
      "TRACE RESUME 0 []\n",
      "TRACE LOAD_CONST True []\n",
      "TRACE STORE_FAST __is_tracing_resume_prologue [ConstantVariable(bool: True)]\n",
      "TRACE LOAD_FAST ___stack0 []\n",
      "TRACE LOAD_CONST False [LazyVariableTracker()]\n",
      "TRACE STORE_FAST __is_tracing_resume_prologue [LazyVariableTracker(), ConstantVariable(bool: False)]\n",
      "TRACE JUMP_FORWARD 86 [LazyVariableTracker()]\n",
      "TRACE POP_TOP None [LazyVariableTracker()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:8 in torch_dynamo_resume_in_fn_at_7\n",
      "        try:\n",
      "TRACE NOP None []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:9 in torch_dynamo_resume_in_fn_at_7\n",
      "            return x + 1\n",
      "TRACE LOAD_FAST x []\n",
      "TRACE LOAD_CONST 1 [LazyVariableTracker()]\n",
      "TRACE BINARY_OP 0 [LazyVariableTracker(), ConstantVariable(int: 1)]\n",
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n",
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n",
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:9 in torch_dynamo_resume_in_fn_at_7\n",
      "        return x + 1\n",
      "               ~~^~~\n",
      "TRACE RETURN_VALUE None [TensorVariable()]\n",
      "Step 1: torchdynamo done tracing torch_dynamo_resume_in_fn_at_7 (RETURN_VALUE)\n",
      "RETURN_VALUE triggered compile\n",
      "COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py, line 9 in torch_dynamo_resume_in_fn_at_7>], graph_break=False)\n",
      "TRACED GRAPH\n",
      " ===== __compiled_fn_38_5483752e_d611_468e_8d0a_36a70020e233 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:9 in torch_dynamo_resume_in_fn_at_7, code: return x + 1\n",
      "        add: \"f32[3][1]cpu\" = l_x_ + 1;  l_x_ = None\n",
      "        return (add,)\n",
      "Step 2: calling compiler function eager\n",
      "Step 2: done compiler function eager\n",
      "produce_guards\n",
      "track_symint L['x'].size()[0] 3 None\n",
      "track_symint L['x'].stride()[0] 1 None\n",
      "track_symint L['x'].storage_offset() 0 None\n",
      "Skipping guard L['x'].size()[0] == 3\n",
      "Skipping guard L['x'].stride()[0] == 1\n",
      "Skipping guard L['x'].storage_offset() == 0\n",
      "GUARDS:\n",
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=3), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # return x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:9 in torch_dynamo_resume_in_fn_at_7\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # return x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:9 in torch_dynamo_resume_in_fn_at_7\n",
      "Guard eval latency = 45.40 us\n",
      "put_code_state: no cache key, skipping\n",
      "run_gc_after_compile: running gc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:1 in fn\n",
      "    @torch.compile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:3 in fn\n",
      "        try:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE NOP None []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:4 in fn\n",
      "            x = x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [LazyVariableTracker(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:4 in fn\n",
      "        x = x + 1\n",
      "            ~~^~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST x [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:7 in fn\n",
      "        torch._dynamo.graph_break()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL torch []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR _dynamo [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR graph_break [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph break in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:7\n",
      "Graph Break Reason: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "User code traceback:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py\", line 12, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py\", line 7, in fn\n",
      "    torch._dynamo.graph_break()\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restarting analysis due to _dynamo\\symbolic_convert.py:249 in fail_and_restart_analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:1 in fn\n",
      "    @torch.compile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:3 in fn\n",
      "        try:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE NOP None []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:4 in fn\n",
      "            x = x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [LazyVariableTracker(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:4 in fn\n",
      "        x = x + 1\n",
      "            ~~^~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST x [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:7 in fn\n",
      "        torch._dynamo.graph_break()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL torch []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR _dynamo [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR graph_break [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMPILING GRAPH due to GraphCompileReason(reason='Call to `torch._dynamo.graph_break()`\\n  Explanation: User-inserted graph break. Message: None\\n  Hint: Remove the `torch._dynamo.graph_break()` call.\\n\\n  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\\n\\n For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py, line 7 in fn>], graph_break=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACED GRAPH\n",
      " ===== __compiled_fn_35_40d9f249_36ed_4c70_b9f9_7995e537d632 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:4 in fn, code: x = x + 1\n",
      "        x: \"f32[3][1]cpu\" = l_x_ + 1;  l_x_ = None\n",
      "        return (x,)\n",
      "        \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: calling compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: done compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "produce_guards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].size()[0] 3 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].stride()[0] 1 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].storage_offset() 0 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].size()[0] == 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].stride()[0] == 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].storage_offset() == 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GUARDS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=0), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # x = x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:4 in fn\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # x = x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:4 in fn\n",
      "| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor, type=<class 'dict'>, tag_safe=(False, False)\n",
      "| | +- GuardManager: source=G['torch'], accessed_by=DictGetItemGuardAccessor('torch'), type=<class 'module'>, tag_safe=(False, False)\n",
      "| | | +- ID_MATCH: ___check_obj_id(G['torch'], 1846212640448)                    # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:7 in fn\n",
      "| | | +- GuardManager: source=G['torch']._dynamo, accessed_by=GetAttrGuardAccessor(_dynamo), type=<class 'module'>, tag_safe=(False, False)\n",
      "| | | | +- ID_MATCH: ___check_obj_id(G['torch']._dynamo, 1846752934096)            # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:7 in fn\n",
      "| | | | +- GuardManager: source=G['torch']._dynamo.graph_break, accessed_by=GetAttrGuardAccessor(graph_break), type=<class 'function'>, tag_safe=(True, False)\n",
      "| | | | | +- GuardManager: source=G['torch']._dynamo.graph_break.__code__, accessed_by=CodeGuardAccessor, type=<class 'code'>, tag_safe=(True, False)\n",
      "| | | | | | +- ID_MATCH: ___check_obj_id(G['torch']._dynamo.graph_break.__code__, 1846802753744)  # torch._dynamo.graph_break()  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:7 in fn\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Guard eval latency = 75.10 us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "put_code_state: no cache key, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_gc_after_compile: running gc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchdynamo start compiling torch_dynamo_resume_in_fn_at_7 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:7, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py\", line 12, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 832, in compile_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo start tracing torch_dynamo_resume_in_fn_at_7 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:7 in torch_dynamo_resume_in_fn_at_7\n",
      "        torch._dynamo.graph_break()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST True []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST __is_tracing_resume_prologue [ConstantVariable(bool: True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST ___stack0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST False [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST __is_tracing_resume_prologue [LazyVariableTracker(), ConstantVariable(bool: False)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE JUMP_FORWARD 86 [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:8 in torch_dynamo_resume_in_fn_at_7\n",
      "        try:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE NOP None []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:9 in torch_dynamo_resume_in_fn_at_7\n",
      "            return x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [LazyVariableTracker(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:9 in torch_dynamo_resume_in_fn_at_7\n",
      "        return x + 1\n",
      "               ~~^~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_VALUE None [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo done tracing torch_dynamo_resume_in_fn_at_7 (RETURN_VALUE)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RETURN_VALUE triggered compile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py, line 9 in torch_dynamo_resume_in_fn_at_7>], graph_break=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACED GRAPH\n",
      " ===== __compiled_fn_38_5483752e_d611_468e_8d0a_36a70020e233 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:9 in torch_dynamo_resume_in_fn_at_7, code: return x + 1\n",
      "        add: \"f32[3][1]cpu\" = l_x_ + 1;  l_x_ = None\n",
      "        return (add,)\n",
      "        \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: calling compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: done compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "produce_guards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].size()[0] 3 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].stride()[0] 1 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].storage_offset() 0 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].size()[0] == 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].stride()[0] == 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].storage_offset() == 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GUARDS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=3), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # return x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:9 in torch_dynamo_resume_in_fn_at_7\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # return x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\3015389759.py:9 in torch_dynamo_resume_in_fn_at_7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Guard eval latency = 45.40 us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "put_code_state: no cache key, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_gc_after_compile: running gc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.7803, 1.7455, 0.9772])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.compile\n",
    "def fn(x):\n",
    "    try:\n",
    "        x = x + 1\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    torch._dynamo.graph_break()\n",
    "    try:\n",
    "        return x + 1\n",
    "    except Exception as e:\n",
    "        pass\n",
    "fn(torch.randn(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5728f740",
   "metadata": {},
   "source": [
    "## Hitting a Recompilation Limit\n",
    "See [Changing the Cache Size Limit.](programming_model.recompilation.changing_cache_size_limit)\n",
    "\n",
    "## Compiler Errors\n",
    "Some compiler errors will result in skipped functions.\n",
    "Other compiler errors will result in a hard error rather than a skipped function.\n",
    "\n",
    "## Dealing with Skipped Functions\n",
    "In general, you can resolve a skipped function by fixing the underlying graph break or error that\n",
    "is causing the function to be skipped.\n",
    "\n",
    "If the graph break/error causing the skipped function is difficult to fix,\n",
    "then consider isolating the graph break/error in its own function so that minimal things are skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e061b8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchdynamo start compiling fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:5, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 12, in <module>\n",
      "    fn(torch.randn(3))\n",
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:5\n",
      "create_env\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:5 in fn\n",
      "    @torch.compile\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:7 in fn\n",
      "        x = inner1(x)\n",
      "TRACE LOAD_GLOBAL inner1 []\n",
      "TRACE LOAD_FAST x [LazyVariableTracker(), NullVariable]\n",
      "TRACE CALL 1 [LazyVariableTracker(), NullVariable, LazyVariableTracker()]\n",
      "TRACE inlined call inner1 from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:7 in fn\n",
      "    x = inner1(x)\n",
      "INLINING <code object inner1 at 0x000001AD8003A090, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 1>, inlined according trace_rules.lookup inlined by default\n",
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n",
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:1 in inner1 (inline depth: 1)\n",
      "    def inner1(x):\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:2 in inner1 (inline depth: 1)\n",
      "        return x + 1\n",
      "TRACE LOAD_FAST x []\n",
      "TRACE LOAD_CONST 1 [TensorVariable()]\n",
      "TRACE BINARY_OP 0 [TensorVariable(), ConstantVariable(int: 1)]\n",
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:2 in inner1 (inline depth: 1)\n",
      "    return x + 1\n",
      "           ~~^~~\n",
      "TRACE RETURN_VALUE None [TensorVariable()]\n",
      "DONE INLINING <code object inner1 at 0x000001AD8003A090, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 1>\n",
      "TRACE STORE_FAST x [TensorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:8 in fn\n",
      "        def problematic_code():\n",
      "TRACE LOAD_CONST <code object problematic_code at 0x000001ADFEC5FDD0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 8> []\n",
      "TRACE MAKE_FUNCTION None [ConstantVariable(code: <code object problematic_code at 0x000001ADFEC5FDD0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 8>)]\n",
      "TRACE STORE_FAST problematic_code [NestedUserFunctionVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:10 in fn\n",
      "        problematic_code()\n",
      "TRACE LOAD_FAST problematic_code []\n",
      "TRACE PUSH_NULL None [NestedUserFunctionVariable()]\n",
      "TRACE CALL 0 [NestedUserFunctionVariable(), NullVariable]\n",
      "TRACE inlined call problematic_code from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:10 in fn\n",
      "    problematic_code()\n",
      "    ~~~~~~~~~~~~~~~~^^\n",
      "INLINING <code object problematic_code at 0x000001ADFEC5FDD0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 8>, inlined according trace_rules.lookup inlined by default\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:8 in problematic_code (inline depth: 1)\n",
      "        def problematic_code():\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:9 in problematic_code (inline depth: 1)\n",
      "            torch._dynamo.skip_frame()\n",
      "TRACE LOAD_GLOBAL torch []\n",
      "TRACE LOAD_ATTR _dynamo [LazyVariableTracker()]\n",
      "TRACE LOAD_ATTR skip_frame [LazyVariableTracker()]\n",
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n",
      "SKIPPED INLINING <code object problematic_code at 0x000001ADFEC5FDD0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 8>: Skip frame due to `torch._dynamo.skip_frame()`. Message: None\n",
      "Graph break in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:10\n",
      "Graph Break Reason: SKIPPED INLINING <code object problematic_code at 0x000001ADFEC5FDD0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 8>: Skip frame due to `torch._dynamo.skip_frame()`. Message: None\n",
      "User code traceback:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 12, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 10, in fn\n",
      "    problematic_code()\n",
      "Restarting analysis due to _dynamo\\symbolic_convert.py:249 in fail_and_restart_analysis\n",
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:5\n",
      "create_env\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:5 in fn\n",
      "    @torch.compile\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:7 in fn\n",
      "        x = inner1(x)\n",
      "TRACE LOAD_GLOBAL inner1 []\n",
      "TRACE LOAD_FAST x [LazyVariableTracker(), NullVariable]\n",
      "TRACE CALL 1 [LazyVariableTracker(), NullVariable, LazyVariableTracker()]\n",
      "TRACE inlined call inner1 from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:7 in fn\n",
      "    x = inner1(x)\n",
      "INLINING <code object inner1 at 0x000001AD8003A090, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 1>, inlined according trace_rules.lookup inlined by default\n",
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n",
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:1 in inner1 (inline depth: 1)\n",
      "    def inner1(x):\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:2 in inner1 (inline depth: 1)\n",
      "        return x + 1\n",
      "TRACE LOAD_FAST x []\n",
      "TRACE LOAD_CONST 1 [TensorVariable()]\n",
      "TRACE BINARY_OP 0 [TensorVariable(), ConstantVariable(int: 1)]\n",
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:2 in inner1 (inline depth: 1)\n",
      "    return x + 1\n",
      "           ~~^~~\n",
      "TRACE RETURN_VALUE None [TensorVariable()]\n",
      "DONE INLINING <code object inner1 at 0x000001AD8003A090, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 1>\n",
      "TRACE STORE_FAST x [TensorVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:8 in fn\n",
      "        def problematic_code():\n",
      "TRACE LOAD_CONST <code object problematic_code at 0x000001ADFEC5FDD0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 8> []\n",
      "TRACE MAKE_FUNCTION None [ConstantVariable(code: <code object problematic_code at 0x000001ADFEC5FDD0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 8>)]\n",
      "TRACE STORE_FAST problematic_code [NestedUserFunctionVariable()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:10 in fn\n",
      "        problematic_code()\n",
      "TRACE LOAD_FAST problematic_code []\n",
      "TRACE PUSH_NULL None [NestedUserFunctionVariable()]\n",
      "TRACE CALL 0 [NestedUserFunctionVariable(), NullVariable]\n",
      "COMPILING GRAPH due to GraphCompileReason(reason='SKIPPED INLINING <code object problematic_code at 0x000001ADFEC5FDD0, file \"C:\\\\Users\\\\Aditya\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_4800\\\\273153676.py\", line 8>: Skip frame due to `torch._dynamo.skip_frame()`. Message: None', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py, line 10 in fn>], graph_break=True)\n",
      "TRACED GRAPH\n",
      " ===== __compiled_fn_41_ba03c2fe_9a0e_4307_a2e7_7a0df305860b =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:2 in inner1, code: return x + 1\n",
      "        x: \"f32[3][1]cpu\" = l_x_ + 1;  l_x_ = None\n",
      "        return (x,)\n",
      "Step 2: calling compiler function eager\n",
      "Step 2: done compiler function eager\n",
      "produce_guards\n",
      "track_symint L['x'].size()[0] 3 None\n",
      "track_symint L['x'].stride()[0] 1 None\n",
      "track_symint L['x'].storage_offset() 0 None\n",
      "Skipping guard L['x'].size()[0] == 3\n",
      "Skipping guard L['x'].stride()[0] == 1\n",
      "Skipping guard L['x'].storage_offset() == 0\n",
      "GUARDS:\n",
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=0), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # x = inner1(x)  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:7 in fn\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # x = inner1(x)  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:7 in fn\n",
      "| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor, type=<class 'dict'>, tag_safe=(True, False)\n",
      "| | +- GuardManager: source=G['inner1'], accessed_by=DictGetItemGuardAccessor('inner1'), type=<class 'function'>, tag_safe=(True, False)\n",
      "| | | +- GuardManager: source=G['inner1'].__code__, accessed_by=CodeGuardAccessor, type=<class 'code'>, tag_safe=(True, False)\n",
      "| | | | +- ID_MATCH: ___check_obj_id(G['inner1'].__code__, 1844688691344)          # x = inner1(x)  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:7 in fn\n",
      "Guard eval latency = 46.50 us\n",
      "put_code_state: no cache key, skipping\n",
      "run_gc_after_compile: running gc\n",
      "torchdynamo start compiling problematic_code C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:8, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 12, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 832, in compile_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "Step 1: torchdynamo start tracing problematic_code C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:8\n",
      "create_env\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:8 in problematic_code\n",
      "        def problematic_code():\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:9 in problematic_code\n",
      "            torch._dynamo.skip_frame()\n",
      "TRACE LOAD_GLOBAL torch []\n",
      "TRACE LOAD_ATTR _dynamo [LazyVariableTracker()]\n",
      "TRACE LOAD_ATTR skip_frame [LazyVariableTracker()]\n",
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n",
      "Skipping frame Skip frame due to `torch._dynamo.skip_frame()`. Message: None problematic_code                 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py 8\n",
      "put_code_state: no cache key, skipping\n",
      "run_gc_after_compile: running gc\n",
      "torchdynamo start compiling torch_dynamo_resume_in_fn_at_10 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:10, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 12, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 832, in compile_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "Step 1: torchdynamo start tracing torch_dynamo_resume_in_fn_at_10 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:10\n",
      "create_env\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:10 in torch_dynamo_resume_in_fn_at_10\n",
      "        problematic_code()\n",
      "TRACE RESUME 0 []\n",
      "TRACE LOAD_CONST True []\n",
      "TRACE STORE_FAST __is_tracing_resume_prologue [ConstantVariable(bool: True)]\n",
      "TRACE LOAD_FAST ___stack0 []\n",
      "TRACE LOAD_CONST False [LazyVariableTracker()]\n",
      "TRACE STORE_FAST __is_tracing_resume_prologue [LazyVariableTracker(), ConstantVariable(bool: False)]\n",
      "TRACE JUMP_FORWARD 56 [LazyVariableTracker()]\n",
      "TRACE POP_TOP None [LazyVariableTracker()]\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:11 in torch_dynamo_resume_in_fn_at_10\n",
      "        x = inner2(x)\n",
      "TRACE LOAD_GLOBAL inner2 []\n",
      "TRACE LOAD_FAST x [LazyVariableTracker(), NullVariable]\n",
      "TRACE CALL 1 [LazyVariableTracker(), NullVariable, LazyVariableTracker()]\n",
      "TRACE inlined call inner2 from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:11 in torch_dynamo_resume_in_fn_at_10\n",
      "    x = inner2(x)\n",
      "INLINING <code object inner2 at 0x000001AD80005C30, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 3>, inlined according trace_rules.lookup inlined by default\n",
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n",
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:3 in inner2 (inline depth: 1)\n",
      "    def inner2(x):\n",
      "TRACE RESUME 0 []\n",
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:4 in inner2 (inline depth: 1)\n",
      "        return x + 2\n",
      "TRACE LOAD_FAST x []\n",
      "TRACE LOAD_CONST 2 [TensorVariable()]\n",
      "TRACE BINARY_OP 0 [TensorVariable(), ConstantVariable(int: 2)]\n",
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:4 in inner2 (inline depth: 1)\n",
      "    return x + 2\n",
      "           ~~^~~\n",
      "TRACE RETURN_VALUE None [TensorVariable()]\n",
      "DONE INLINING <code object inner2 at 0x000001AD80005C30, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 3>\n",
      "TRACE STORE_FAST x [TensorVariable()]\n",
      "TRACE RETURN_CONST None []\n",
      "Step 1: torchdynamo done tracing torch_dynamo_resume_in_fn_at_10 (RETURN_CONST)\n",
      "RETURN_CONST triggered compile\n",
      "COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py, line 11 in torch_dynamo_resume_in_fn_at_10>], graph_break=False)\n",
      "TRACED GRAPH\n",
      " ===== __compiled_fn_45_b6a96751_4df3_4b1b_9b8d_d576f4b4afb3 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:4 in inner2, code: return x + 2\n",
      "        x: \"f32[3][1]cpu\" = l_x_ + 2;  l_x_ = x = None\n",
      "        return ()\n",
      "Step 2: calling compiler function eager\n",
      "Step 2: done compiler function eager\n",
      "produce_guards\n",
      "track_symint L['x'].size()[0] 3 None\n",
      "track_symint L['x'].stride()[0] 1 None\n",
      "track_symint L['x'].storage_offset() 0 None\n",
      "Skipping guard L['x'].size()[0] == 3\n",
      "Skipping guard L['x'].stride()[0] == 1\n",
      "Skipping guard L['x'].storage_offset() == 0\n",
      "GUARDS:\n",
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=3), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # x = inner2(x)  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:11 in torch_dynamo_resume_in_fn_at_10\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # x = inner2(x)  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:11 in torch_dynamo_resume_in_fn_at_10\n",
      "| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor, type=<class 'dict'>, tag_safe=(True, False)\n",
      "| | +- GuardManager: source=G['inner2'], accessed_by=DictGetItemGuardAccessor('inner2'), type=<class 'function'>, tag_safe=(True, False)\n",
      "| | | +- GuardManager: source=G['inner2'].__code__, accessed_by=CodeGuardAccessor, type=<class 'code'>, tag_safe=(True, False)\n",
      "| | | | +- ID_MATCH: ___check_obj_id(G['inner2'].__code__, 1844688477232)          # x = inner2(x)  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:11 in torch_dynamo_resume_in_fn_at_10\n",
      "Guard eval latency = 52.00 us\n",
      "put_code_state: no cache key, skipping\n",
      "run_gc_after_compile: running gc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:5 in fn\n",
      "    @torch.compile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:7 in fn\n",
      "        x = inner1(x)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL inner1 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x [LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 1 [LazyVariableTracker(), NullVariable, LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE inlined call inner1 from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:7 in fn\n",
      "    x = inner1(x)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INLINING <code object inner1 at 0x000001AD8003A090, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 1>, inlined according trace_rules.lookup inlined by default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:1 in inner1 (inline depth: 1)\n",
      "    def inner1(x):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:2 in inner1 (inline depth: 1)\n",
      "        return x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [TensorVariable(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:2 in inner1 (inline depth: 1)\n",
      "    return x + 1\n",
      "           ~~^~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_VALUE None [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DONE INLINING <code object inner1 at 0x000001AD8003A090, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 1>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST x [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:8 in fn\n",
      "        def problematic_code():\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST <code object problematic_code at 0x000001ADFEC5FDD0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 8> []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE MAKE_FUNCTION None [ConstantVariable(code: <code object problematic_code at 0x000001ADFEC5FDD0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 8>)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST problematic_code [NestedUserFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:10 in fn\n",
      "        problematic_code()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST problematic_code []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE PUSH_NULL None [NestedUserFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [NestedUserFunctionVariable(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE inlined call problematic_code from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:10 in fn\n",
      "    problematic_code()\n",
      "    ~~~~~~~~~~~~~~~~^^\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INLINING <code object problematic_code at 0x000001ADFEC5FDD0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 8>, inlined according trace_rules.lookup inlined by default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:8 in problematic_code (inline depth: 1)\n",
      "        def problematic_code():\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:9 in problematic_code (inline depth: 1)\n",
      "            torch._dynamo.skip_frame()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL torch []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR _dynamo [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR skip_frame [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SKIPPED INLINING <code object problematic_code at 0x000001ADFEC5FDD0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 8>: Skip frame due to `torch._dynamo.skip_frame()`. Message: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph break in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:10\n",
      "Graph Break Reason: SKIPPED INLINING <code object problematic_code at 0x000001ADFEC5FDD0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 8>: Skip frame due to `torch._dynamo.skip_frame()`. Message: None\n",
      "User code traceback:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 12, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 10, in fn\n",
      "    problematic_code()\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restarting analysis due to _dynamo\\symbolic_convert.py:249 in fail_and_restart_analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo start tracing fn C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:5 in fn\n",
      "    @torch.compile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:7 in fn\n",
      "        x = inner1(x)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL inner1 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x [LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 1 [LazyVariableTracker(), NullVariable, LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE inlined call inner1 from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:7 in fn\n",
      "    x = inner1(x)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INLINING <code object inner1 at 0x000001AD8003A090, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 1>, inlined according trace_rules.lookup inlined by default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:1 in inner1 (inline depth: 1)\n",
      "    def inner1(x):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:2 in inner1 (inline depth: 1)\n",
      "        return x + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 1 [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [TensorVariable(), ConstantVariable(int: 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:2 in inner1 (inline depth: 1)\n",
      "    return x + 1\n",
      "           ~~^~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_VALUE None [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DONE INLINING <code object inner1 at 0x000001AD8003A090, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 1>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST x [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:8 in fn\n",
      "        def problematic_code():\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST <code object problematic_code at 0x000001ADFEC5FDD0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 8> []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE MAKE_FUNCTION None [ConstantVariable(code: <code object problematic_code at 0x000001ADFEC5FDD0, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 8>)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST problematic_code [NestedUserFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:10 in fn\n",
      "        problematic_code()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST problematic_code []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE PUSH_NULL None [NestedUserFunctionVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [NestedUserFunctionVariable(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMPILING GRAPH due to GraphCompileReason(reason='SKIPPED INLINING <code object problematic_code at 0x000001ADFEC5FDD0, file \"C:\\\\Users\\\\Aditya\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_4800\\\\273153676.py\", line 8>: Skip frame due to `torch._dynamo.skip_frame()`. Message: None', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py, line 10 in fn>], graph_break=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACED GRAPH\n",
      " ===== __compiled_fn_41_ba03c2fe_9a0e_4307_a2e7_7a0df305860b =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:2 in inner1, code: return x + 1\n",
      "        x: \"f32[3][1]cpu\" = l_x_ + 1;  l_x_ = None\n",
      "        return (x,)\n",
      "        \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: calling compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: done compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "produce_guards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].size()[0] 3 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].stride()[0] 1 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].storage_offset() 0 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].size()[0] == 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].stride()[0] == 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].storage_offset() == 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GUARDS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=0), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # x = inner1(x)  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:7 in fn\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # x = inner1(x)  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:7 in fn\n",
      "| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor, type=<class 'dict'>, tag_safe=(True, False)\n",
      "| | +- GuardManager: source=G['inner1'], accessed_by=DictGetItemGuardAccessor('inner1'), type=<class 'function'>, tag_safe=(True, False)\n",
      "| | | +- GuardManager: source=G['inner1'].__code__, accessed_by=CodeGuardAccessor, type=<class 'code'>, tag_safe=(True, False)\n",
      "| | | | +- ID_MATCH: ___check_obj_id(G['inner1'].__code__, 1844688691344)          # x = inner1(x)  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:7 in fn\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Guard eval latency = 46.50 us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "put_code_state: no cache key, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_gc_after_compile: running gc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchdynamo start compiling problematic_code C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:8, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 12, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 832, in compile_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo start tracing problematic_code C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:8 in problematic_code\n",
      "        def problematic_code():\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:9 in problematic_code\n",
      "            torch._dynamo.skip_frame()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL torch []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR _dynamo [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_ATTR skip_frame [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 0 [LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping frame Skip frame due to `torch._dynamo.skip_frame()`. Message: None problematic_code                 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "put_code_state: no cache key, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_gc_after_compile: running gc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchdynamo start compiling torch_dynamo_resume_in_fn_at_10 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:10, stack (elided 5 frames):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 12, in <module>\n",
      "    fn(torch.randn(3))\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 832, in compile_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo start tracing torch_dynamo_resume_in_fn_at_10 C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:10 in torch_dynamo_resume_in_fn_at_10\n",
      "        problematic_code()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST True []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST __is_tracing_resume_prologue [ConstantVariable(bool: True)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST ___stack0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST False [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST __is_tracing_resume_prologue [LazyVariableTracker(), ConstantVariable(bool: False)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE JUMP_FORWARD 56 [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE POP_TOP None [LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:11 in torch_dynamo_resume_in_fn_at_10\n",
      "        x = inner2(x)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_GLOBAL inner2 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x [LazyVariableTracker(), NullVariable]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE CALL 1 [LazyVariableTracker(), NullVariable, LazyVariableTracker()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE inlined call inner2 from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:11 in torch_dynamo_resume_in_fn_at_10\n",
      "    x = inner2(x)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INLINING <code object inner2 at 0x000001AD80005C30, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 3>, inlined according trace_rules.lookup inlined by default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wrap_to_fake L['x'] (3,) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None], constraint_strides=[None], specialize_on=[[]], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_graph_input L_x_ L['x'] FakeTensor(..., size=(3,)) at debug_level 0 before=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:3 in inner2 (inline depth: 1)\n",
      "    def inner2(x):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE starts_line C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:4 in inner2 (inline depth: 1)\n",
      "        return x + 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_FAST x []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE LOAD_CONST 2 [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE BINARY_OP 0 [TensorVariable(), ConstantVariable(int: 2)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE FX call add from C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:4 in inner2 (inline depth: 1)\n",
      "    return x + 2\n",
      "           ~~^~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_VALUE None [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DONE INLINING <code object inner2 at 0x000001AD80005C30, file \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py\", line 3>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE STORE_FAST x [TensorVariable()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACE RETURN_CONST None []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: torchdynamo done tracing torch_dynamo_resume_in_fn_at_10 (RETURN_CONST)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RETURN_CONST triggered compile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py, line 11 in torch_dynamo_resume_in_fn_at_10>], graph_break=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACED GRAPH\n",
      " ===== __compiled_fn_45_b6a96751_4df3_4b1b_9b8d_d576f4b4afb3 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:4 in inner2, code: return x + 2\n",
      "        x: \"f32[3][1]cpu\" = l_x_ + 2;  l_x_ = x = None\n",
      "        return ()\n",
      "        \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: calling compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 2: done compiler function eager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "produce_guards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].size()[0] 3 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].stride()[0] 1 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "track_symint L['x'].storage_offset() 0 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].size()[0] == 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].stride()[0] == 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping guard L['x'].storage_offset() == 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GUARDS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=3), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3], stride=[1])  # x = inner2(x)  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:11 in torch_dynamo_resume_in_fn_at_10\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # x = inner2(x)  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:11 in torch_dynamo_resume_in_fn_at_10\n",
      "| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor, type=<class 'dict'>, tag_safe=(True, False)\n",
      "| | +- GuardManager: source=G['inner2'], accessed_by=DictGetItemGuardAccessor('inner2'), type=<class 'function'>, tag_safe=(True, False)\n",
      "| | | +- GuardManager: source=G['inner2'].__code__, accessed_by=CodeGuardAccessor, type=<class 'code'>, tag_safe=(True, False)\n",
      "| | | | +- ID_MATCH: ___check_obj_id(G['inner2'].__code__, 1844688477232)          # x = inner2(x)  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_4800\\273153676.py:11 in torch_dynamo_resume_in_fn_at_10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Guard eval latency = 52.00 us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "put_code_state: no cache key, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "run_gc_after_compile: running gc\n"
     ]
    }
   ],
   "source": [
    "def inner1(x):\n",
    "    return x + 1\n",
    "def inner2(x):\n",
    "    return x + 2\n",
    "@torch.compile\n",
    "def fn(x):\n",
    "    x = inner1(x)\n",
    "    def problematic_code():\n",
    "        torch._dynamo.skip_frame()\n",
    "    problematic_code()\n",
    "    x = inner2(x)\n",
    "fn(torch.randn(3))"
   ]
  }
 ],
 "metadata": {
  "file_format": "mystnb",
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "mystnb": {
   "execution_show_tb": true,
   "execution_timeout": 30,
   "merge_streams": true
  },
  "source_map": [
   11,
   18,
   35,
   46,
   58,
   67,
   71,
   86,
   94,
   107,
   111,
   120,
   127,
   137,
   143,
   153,
   157,
   170,
   186
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}