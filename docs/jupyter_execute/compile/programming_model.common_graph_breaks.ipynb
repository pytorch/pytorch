{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9703776",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import header_code\n",
    "\n",
    "torch._logging.set_logs(graph_breaks=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a1e740",
   "metadata": {},
   "source": [
    "# Common Graph Breaks\n",
    "\n",
    "Below are some common graph breaks and some workarounds.\n",
    "\n",
    "## Incorrect Code\n",
    "Your code might contain errors (meaning it doesn't execute even without `torch.compile`). In the example below, there's a typo in the `torch.sin` call due to an extra argument. **Always disable `torch.compile` to check if the code runs correctly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "450a5227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph break in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_13088\\343837593.py:3\n",
      "Graph Break Reason: TypeError when making fake tensor call\n",
      "  Explanation: \n",
      "\n",
      "\n",
      "  Developer debug context: TypeError <built-in method sin of type object at 0x00007FF9076478E0>: sin() takes 1 positional argument but 2 were given\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0112.html\n",
      "User code traceback:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_13088\\343837593.py\", line 7, in <module>\n",
      "    fn(torch.ones(3, 3))\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_13088\\343837593.py\", line 3, in fn\n",
      "    y = torch.sin(x, x)\n"
     ]
    }
   ],
   "source": [
    "@torch.compile\n",
    "def fn(x):\n",
    "    y = torch.sin(x, x)\n",
    "    return y\n",
    "\n",
    "try:\n",
    "    fn(torch.ones(3, 3))\n",
    "except Exception as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7c7a98",
   "metadata": {},
   "source": [
    "Dynamo makes a best-effort attempt to hint if a graph break is caused by your code.\n",
    "But it can still sometimes be difficult to tell from the logs if the graph break is caused by an error in your code,\n",
    "is a more complicated graph break, or is a `torch.compile` bug. In order to differentiate, we recommend trying to run your code without `torch.compile` to see if you still get the error reported by the graph break.\n",
    "\n",
    "## Data-dependent operations\n",
    "\n",
    "`torch.compile` graph breaks on data-dependent operations such as data-dependent control flow (if-statements, loops with tensors) and direct tensor data accesses (`.item`, `.data_ptr`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a6ad867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph break in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_13088\\3495555842.py:4\n",
      "Graph Break Reason: Data-dependent branching\n",
      "  Explanation: Detected data-dependent branching (e.g. `if my_tensor.sum() > 0:`). Dynamo does not support tracing dynamic control flow.\n",
      "  Hint: This graph break is fundamental - it is unlikely that Dynamo will ever be able to trace through your code. Consider finding a workaround.\n",
      "  Hint: Use `torch.cond` to express dynamic control flow.\n",
      "\n",
      "  Developer debug context: attempted to jump with TensorVariable()\n",
      "\n",
      "User code traceback:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_13088\\3495555842.py\", line 8, in <module>\n",
      "    print(fn(torch.ones(3, 3)))\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_13088\\3495555842.py\", line 4, in fn\n",
      "    if y > 0:\n",
      "Graph break from `Tensor.item()`, consider setting:\n",
      "    torch._dynamo.config.capture_scalar_outputs = True\n",
      "or:\n",
      "    env TORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS=1\n",
      "to include these operations in the captured graph.\n",
      "\n",
      "Graph break: from user code at:\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_13088\\3495555842.py\", line 5, in torch_dynamo_resume_in_fn_at_4\n",
      "    return x + y.item()\n",
      "Graph break in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_13088\\3495555842.py:5\n",
      "Graph Break Reason: Unsupported Tensor.item() call with capture_scalar_outputs=False\n",
      "  Explanation: Dynamo does not support tracing `Tensor.item()` with config.capture_scalar_outputs=False.\n",
      "  Hint: Set `torch._dynamo.config.capture_scalar_outputs = True` or `export TORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS=1` to include these operations in the captured graph.\n",
      "\n",
      "  Developer debug context: call_method TensorVariable() item () {}\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0124.html\n",
      "User code traceback:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_13088\\3495555842.py\", line 8, in <module>\n",
      "    print(fn(torch.ones(3, 3)))\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_13088\\3495555842.py\", line 5, in fn\n",
      "    return x + y.item()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph break from `Tensor.item()`, consider setting:\n",
      "    torch._dynamo.config.capture_scalar_outputs = True\n",
      "or:\n",
      "    env TORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS=1\n",
      "to include these operations in the captured graph.\n",
      "\n",
      "Graph break: from user code at:\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_13088\\3495555842.py\", line 5, in torch_dynamo_resume_in_fn_at_4\n",
      "    return x + y.item()\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph break in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_13088\\3495555842.py:5\n",
      "Graph Break Reason: Unsupported Tensor.item() call with capture_scalar_outputs=False\n",
      "  Explanation: Dynamo does not support tracing `Tensor.item()` with config.capture_scalar_outputs=False.\n",
      "  Hint: Set `torch._dynamo.config.capture_scalar_outputs = True` or `export TORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS=1` to include these operations in the captured graph.\n",
      "\n",
      "  Developer debug context: call_method TensorVariable() item () {}\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0124.html\n",
      "User code traceback:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_13088\\3495555842.py\", line 8, in <module>\n",
      "    print(fn(torch.ones(3, 3)))\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_13088\\3495555842.py\", line 5, in fn\n",
      "    return x + y.item()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10., 10., 10.],\n",
      "        [10., 10., 10.],\n",
      "        [10., 10., 10.]])\n"
     ]
    }
   ],
   "source": [
    "@torch.compile\n",
    "def fn(x):\n",
    "    y = x.sum()\n",
    "    if y > 0:\n",
    "        return x + y.item()\n",
    "    return x - y.item()\n",
    "\n",
    "print(fn(torch.ones(3, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f2b49a",
   "metadata": {},
   "source": [
    "The general workaround for these graph breaks is to avoid doing data-dependent operations. Some specific workarounds are:\n",
    "\n",
    "- If your control flow doesn't actually depend on data values, consider modifying your code to perform control flow on constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a7de478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph break in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_13088\\2410325100.py:5\n",
      "Graph Break Reason: Data-dependent branching\n",
      "  Explanation: Detected data-dependent branching (e.g. `if my_tensor.sum() > 0:`). Dynamo does not support tracing dynamic control flow.\n",
      "  Hint: This graph break is fundamental - it is unlikely that Dynamo will ever be able to trace through your code. Consider finding a workaround.\n",
      "  Hint: Use `torch.cond` to express dynamic control flow.\n",
      "\n",
      "  Developer debug context: attempted to jump with TensorVariable()\n",
      "\n",
      "User code traceback:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_13088\\2410325100.py\", line 10, in <module>\n",
      "    print(fn(torch.ones(3, 3)))\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_13088\\2410325100.py\", line 5, in fn\n",
      "    if x.sum() > 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.0617,  3.2001, -0.2806],\n",
      "        [ 0.9175,  2.3327, -0.1929],\n",
      "        [ 3.8927,  0.1718,  1.1279]])\n"
     ]
    }
   ],
   "source": [
    "# old\n",
    "x = torch.randn(3, 3)\n",
    "@torch.compile\n",
    "def fn(y):\n",
    "    if x.sum() > 0:\n",
    "        return y + x\n",
    "    else:\n",
    "        return y - x\n",
    "\n",
    "print(fn(torch.ones(3, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdaee025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4605,  2.4148,  0.7653],\n",
      "        [ 0.5703,  1.4693, -0.2955],\n",
      "        [ 1.5892,  0.9290,  1.1816]])\n"
     ]
    }
   ],
   "source": [
    "# new\n",
    "x = torch.randn(3, 3)\n",
    "cond = (x.sum() > 0).item()\n",
    "@torch.compile\n",
    "def fn(y):\n",
    "    if cond:\n",
    "        return y + x\n",
    "    else:\n",
    "        return y - x\n",
    "\n",
    "print(fn(torch.ones(3, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add3cf0e",
   "metadata": {},
   "source": [
    "- Use higher-order ops like {ref}`cond` in place of data-dependent control flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abc110a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph break in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_13088\\520574912.py:4\n",
      "Graph Break Reason: Data-dependent branching\n",
      "  Explanation: Detected data-dependent branching (e.g. `if my_tensor.sum() > 0:`). Dynamo does not support tracing dynamic control flow.\n",
      "  Hint: This graph break is fundamental - it is unlikely that Dynamo will ever be able to trace through your code. Consider finding a workaround.\n",
      "  Hint: Use `torch.cond` to express dynamic control flow.\n",
      "\n",
      "  Developer debug context: attempted to jump with TensorVariable()\n",
      "\n",
      "User code traceback:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_13088\\520574912.py\", line 8, in <module>\n",
      "    print(fn(torch.ones(3, 3)))\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_13088\\520574912.py\", line 4, in fn\n",
      "    if x.sum() > 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# old\n",
    "@torch.compile\n",
    "def fn(x):\n",
    "    if x.sum() > 0:\n",
    "        return x + 1\n",
    "    return x - 1\n",
    "\n",
    "print(fn(torch.ones(3, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a336ab0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# new\n",
    "@torch.compile\n",
    "def fn(x):\n",
    "    return torch.cond(\n",
    "        x.sum() > 0,\n",
    "        lambda x: x + 1,\n",
    "        lambda x: x - 1,\n",
    "        (x,),\n",
    "    )\n",
    "\n",
    "print(fn(torch.ones(3, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc8bb4f",
   "metadata": {},
   "source": [
    "- If you have a `.item()` call, try `torch._dynamo.config.capture_scalar_outputs = True`\n",
    "or `TORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS=1`.\n",
    "- Wrap problematic parts of the function in a custom operator\n",
    "\n",
    "## Printing and logging\n",
    "\n",
    "Printing/logging/issuing warnings will result in a graph break.\n",
    "You can try working around this by using `torch._dynamo.config.reorderable_logging_functions`.\n",
    "This config is used to reorder logging functions so that they are called at the end of the\n",
    "traced function, thus avoiding a graph break.\n",
    "However, the logged contents may differ if, for example, a mutation occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdac2ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log!\n",
      "tensor([[0.9093, 0.9093, 0.9093],\n",
      "        [0.9093, 0.9093, 0.9093],\n",
      "        [0.9093, 0.9093, 0.9093]])\n"
     ]
    }
   ],
   "source": [
    "torch._dynamo.config.reorderable_logging_functions.add(print)\n",
    "\n",
    "@torch.compile\n",
    "def fn(x):\n",
    "    x += 1\n",
    "    print(\"log!\")\n",
    "    return torch.sin(x)\n",
    "\n",
    "print(fn(torch.ones(3, 3)))"
   ]
  }
 ],
 "metadata": {
  "file_format": "mystnb",
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "mystnb": {
   "execution_show_tb": true,
   "execution_timeout": 30,
   "merge_streams": true
  },
  "source_map": [
   11,
   18,
   28,
   38,
   48,
   57,
   64,
   77,
   89,
   94,
   105,
   117,
   132
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}