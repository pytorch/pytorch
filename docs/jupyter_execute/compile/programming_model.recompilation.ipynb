{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8fdb5f7",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import header_code\n",
    "\n",
    "torch._logging.set_logs(recompiles=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fe24fa",
   "metadata": {},
   "source": [
    "# Dealing with Recompilations\n",
    "\n",
    "Recompilations are necessary for `torch.compile` soundness, but can result in significantly increased compile time.\n",
    "Thus, minimizing recompilations while preserving soundness is essential for reducing compile time.\n",
    "\n",
    "You can view recompilations and their reasons using tlparse or `TORCH_LOGS=recompiles`.\n",
    "\n",
    "## Is Dynamic Shapes Enabled?\n",
    "\n",
    "In the below example, we recompile due to mismatched shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23baf88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recompiling function fn in C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_4552\\2479206322.py:1\n",
      "    triggered by the following guard failure(s):\n",
      "    - 0/0: tensor 'x' size mismatch at index 0. expected 3, actual 4\n",
      "Error while creating guard:\n",
      "Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: ['SHAPE_ENV']\n",
      "    Code List: [\"2 <= L['x'].size()[0]\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 137, in check_compiler_exist_windows\n",
      "    subprocess.check_output([compiler, \"/help\"], stderr=subprocess.STDOUT)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 472, in check_output\n",
      "    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
      "           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "               **kwargs).stdout\n",
      "               ^^^^^^^^^\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 554, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1039, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        pass_fds, cwd, env,\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "                        gid, gids, uid, umask,\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        start_new_session, process_group)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1554, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "                             # no special security\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "                             cwd,\n",
      "                             ^^^^\n",
      "                             startupinfo)\n",
      "                             ^^^^^^^^^^^^\n",
      "FileNotFoundError: [WinError 2] The system cannot find the file specified\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_guards.py\", line 366, in create\n",
      "    return self.create_fn(builder, self)\n",
      "           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\guards.py\", line 2671, in SHAPE_ENV\n",
      "    clib = CppCodeCache.load(func_str)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 2839, in load\n",
      "    return cls.load_async(*args, **kwargs)()\n",
      "           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 2705, in load_async\n",
      "    \"vec_isa\": pick_vec_isa(),\n",
      "               ~~~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 497, in pick_vec_isa\n",
      "    _valid_vec_isa_list: list[VecISA] = valid_vec_isa_list()\n",
      "                                        ~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 484, in valid_vec_isa_list\n",
      "    isa_list.extend(\n",
      "    ~~~~~~~~~~~~~~~^\n",
      "        isa\n",
      "        ^^^\n",
      "        for isa in supported_vec_isa_list\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        if all(flag in _cpu_supported_x86_isa for flag in str(isa).split()) and isa\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 487, in <genexpr>\n",
      "    if all(flag in _cpu_supported_x86_isa for flag in str(isa).split()) and isa\n",
      "                                                                            ^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 143, in __bool__\n",
      "    return self.__bool__impl(config.cpp.vec_isa_ok)\n",
      "           ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 153, in __bool__impl\n",
      "    return self.check_build(VecISA._avx_code)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 103, in check_build\n",
      "    extra=_get_isa_dry_compile_fingerprint(self._arch_flags),\n",
      "          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 29, in _get_isa_dry_compile_fingerprint\n",
      "    compiler_info = get_compiler_version_info(get_cpp_compiler())\n",
      "                                              ~~~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 338, in get_cpp_compiler\n",
      "    check_compiler_exist_windows(compiler)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 139, in check_compiler_exist_windows\n",
      "    raise RuntimeError(f\"Compiler: {compiler} is not found.\") from exc\n",
      "RuntimeError: Compiler: cl is not found.\n",
      "Created at:\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 773, in trace_frame\n",
      "    tracer = InstructionTranslator(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3847, in __init__\n",
      "    output=OutputGraph(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 508, in __init__\n",
      "    self.init_ambient_guards()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 668, in init_ambient_guards\n",
      "    self.guards.add(ShapeEnvSource().make_guard(GuardBuilder.SHAPE_ENV))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while creating guard:\n",
      "Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: ['SHAPE_ENV']\n",
      "    Code List: [\"2 <= L['x'].size()[0]\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 137, in check_compiler_exist_windows\n",
      "    subprocess.check_output([compiler, \"/help\"], stderr=subprocess.STDOUT)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 472, in check_output\n",
      "    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
      "           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "               **kwargs).stdout\n",
      "               ^^^^^^^^^\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 554, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1039, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        pass_fds, cwd, env,\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "                        gid, gids, uid, umask,\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        start_new_session, process_group)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1554, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "                             # no special security\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "                             cwd,\n",
      "                             ^^^^\n",
      "                             startupinfo)\n",
      "                             ^^^^^^^^^^^^\n",
      "FileNotFoundError: [WinError 2] The system cannot find the file specified\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_guards.py\", line 366, in create\n",
      "    return self.create_fn(builder, self)\n",
      "           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\guards.py\", line 2671, in SHAPE_ENV\n",
      "    clib = CppCodeCache.load(func_str)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 2839, in load\n",
      "    return cls.load_async(*args, **kwargs)()\n",
      "           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 2705, in load_async\n",
      "    \"vec_isa\": pick_vec_isa(),\n",
      "               ~~~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 497, in pick_vec_isa\n",
      "    _valid_vec_isa_list: list[VecISA] = valid_vec_isa_list()\n",
      "                                        ~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 484, in valid_vec_isa_list\n",
      "    isa_list.extend(\n",
      "    ~~~~~~~~~~~~~~~^\n",
      "        isa\n",
      "        ^^^\n",
      "        for isa in supported_vec_isa_list\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        if all(flag in _cpu_supported_x86_isa for flag in str(isa).split()) and isa\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 487, in <genexpr>\n",
      "    if all(flag in _cpu_supported_x86_isa for flag in str(isa).split()) and isa\n",
      "                                                                            ^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 143, in __bool__\n",
      "    return self.__bool__impl(config.cpp.vec_isa_ok)\n",
      "           ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 153, in __bool__impl\n",
      "    return self.check_build(VecISA._avx_code)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 103, in check_build\n",
      "    extra=_get_isa_dry_compile_fingerprint(self._arch_flags),\n",
      "          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 29, in _get_isa_dry_compile_fingerprint\n",
      "    compiler_info = get_compiler_version_info(get_cpp_compiler())\n",
      "                                              ~~~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 338, in get_cpp_compiler\n",
      "    check_compiler_exist_windows(compiler)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 139, in check_compiler_exist_windows\n",
      "    raise RuntimeError(f\"Compiler: {compiler} is not found.\") from exc\n",
      "RuntimeError: Compiler: cl is not found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created at:\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 773, in trace_frame\n",
      "    tracer = InstructionTranslator(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3847, in __init__\n",
      "    output=OutputGraph(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 508, in __init__\n",
      "    self.init_ambient_guards()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 668, in init_ambient_guards\n",
      "    self.guards.add(ShapeEnvSource().make_guard(GuardBuilder.SHAPE_ENV))\n"
     ]
    },
    {
     "ename": "InternalTorchDynamoError",
     "evalue": "RuntimeError: Compiler: cl is not found.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalTorchDynamoError\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x + \u001b[32m1\u001b[39m\n\u001b[32m      4\u001b[39m fn(torch.ones(\u001b[32m3\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:832\u001b[39m, in \u001b[36m_TorchDynamoContext.__call__.<locals>.compile_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    829\u001b[39m _maybe_set_eval_frame(_callback_from_stance(callback))\n\u001b[32m    831\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m832\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    834\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config.verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1874\u001b[39m, in \u001b[36mCatchErrorsWrapper.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, frame_state)\u001b[39m\n\u001b[32m   1868\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(\n\u001b[32m   1869\u001b[39m                 frame, cache_entry, \u001b[38;5;28mself\u001b[39m.hooks, frame_state\n\u001b[32m   1870\u001b[39m             )\n\u001b[32m   1872\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock, _disable_current_modes():\n\u001b[32m   1873\u001b[39m     \u001b[38;5;66;03m# skip=1: skip this frame\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1874\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_backend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1876\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1877\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1624\u001b[39m, in \u001b[36mConvertFrame.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m   1622\u001b[39m counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtotal\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1623\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1624\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1626\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1627\u001b[39m     counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mok\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1628\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:688\u001b[39m, in \u001b[36mConvertFrameAssert.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m    685\u001b[39m     dynamo_tls.traced_frame_infos.append(info)\n\u001b[32m    687\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_context(CompileContext(compile_id)):\n\u001b[32m--> \u001b[39m\u001b[32m688\u001b[39m     result = \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_builtins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_one_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_package\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_frame_box\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_box\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.caching_precompile \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._package \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    710\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpackage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DynamoCache\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1494\u001b[39m, in \u001b[36m_compile\u001b[39m\u001b[34m(code, globals, locals, builtins, closure, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip, package, convert_frame_box)\u001b[39m\n\u001b[32m   1491\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m   1492\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1493\u001b[39m         \u001b[38;5;66;03m# Rewrap for clarity\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1494\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InternalTorchDynamoError(\n\u001b[32m   1495\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e).\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1496\u001b[39m         ).with_traceback(e.__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1498\u001b[39m     \u001b[38;5;66;03m# === WARNING WARNING WARNING ===\u001b[39;00m\n\u001b[32m   1499\u001b[39m     \u001b[38;5;66;03m# If you commit a bug here, it will suppress writing to\u001b[39;00m\n\u001b[32m   1500\u001b[39m     \u001b[38;5;66;03m# dynamo_compile table, and we will not have telemetry.\u001b[39;00m\n\u001b[32m   1501\u001b[39m     \u001b[38;5;66;03m# Be extra careful when making changes here!\u001b[39;00m\n\u001b[32m   1503\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._dynamo.config.run_gc_after_compile:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1433\u001b[39m, in \u001b[36m_compile\u001b[39m\u001b[34m(code, globals, locals, builtins, closure, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip, package, convert_frame_box)\u001b[39m\n\u001b[32m   1431\u001b[39m guarded_code = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1432\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1433\u001b[39m     guarded_code, tracer_output = \u001b[43mcompile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1435\u001b[39m     \u001b[38;5;66;03m# NB: We only put_code_state in success case.  Success case here\u001b[39;00m\n\u001b[32m   1436\u001b[39m     \u001b[38;5;66;03m# does include graph breaks; specifically, if a graph break still\u001b[39;00m\n\u001b[32m   1437\u001b[39m     \u001b[38;5;66;03m# resulted in a partially compiled graph, we WILL return here.  An\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1442\u001b[39m     \u001b[38;5;66;03m# to upload for graph break though, because this can prevent\u001b[39;00m\n\u001b[32m   1443\u001b[39m     \u001b[38;5;66;03m# extra graph break compilations.)\u001b[39;00m\n\u001b[32m   1444\u001b[39m     put_code_state()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_utils_internal.py:92\u001b[39m, in \u001b[36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# This is not needed but we have it here to avoid having profile_compile_time\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# in stack traces when profiling is not enabled.\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m StrobelightCompileTimeProfiler.enabled:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m StrobelightCompileTimeProfiler.profile_compile_time(\n\u001b[32m     95\u001b[39m     function, phase_name, *args, **kwargs\n\u001b[32m     96\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1117\u001b[39m, in \u001b[36m_compile.<locals>.compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks)\u001b[39m\n\u001b[32m   1111\u001b[39m     stack.enter_context(\n\u001b[32m   1112\u001b[39m         torch._dynamo.callback_handler.install_callbacks(\n\u001b[32m   1113\u001b[39m             CallbackTrigger.DYNAMO, \u001b[38;5;28mstr\u001b[39m(CompileContext.current_compile_id())\n\u001b[32m   1114\u001b[39m         )\n\u001b[32m   1115\u001b[39m     )\n\u001b[32m   1116\u001b[39m     stack.enter_context(CompileTimeInstructionCounter.record())\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m   1120\u001b[39m     ConvertFrameReturn(),\n\u001b[32m   1121\u001b[39m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1122\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1251\u001b[39m, in \u001b[36m_compile.<locals>._compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks)\u001b[39m\n\u001b[32m   1249\u001b[39m \u001b[38;5;28;01mnonlocal\u001b[39;00m cache_entry\n\u001b[32m   1250\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[33m\"\u001b[39m\u001b[33mbuild_guards\u001b[39m\u001b[33m\"\u001b[39m, log_pt2_compile_event=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m     check_fn = \u001b[43mdynamo_output\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_guards\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m package \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1259\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m check_fn.guards_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:856\u001b[39m, in \u001b[36mDynamoOutput.build_guards\u001b[39m\u001b[34m(self, code, hooks, save, cache_entry, strict_error)\u001b[39m\n\u001b[32m    847\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_guards\u001b[39m(\n\u001b[32m    848\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    849\u001b[39m     code: types.CodeType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    853\u001b[39m     strict_error: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    854\u001b[39m ) -> CheckFunctionManager:\n\u001b[32m    855\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tracer_output.output_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m856\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCheckFunctionManager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtracer_output\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mguard_fail_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mguard_filter_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_guards\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\guards.py:3383\u001b[39m, in \u001b[36mCheckFunctionManager.__init__\u001b[39m\u001b[34m(self, f_code, output_graph, cache_entry, guard_fail_fn, guard_filter_fn, shape_code_parts, runtime_global_scope, save_guards, strict_error)\u001b[39m\n\u001b[32m   3378\u001b[39m     sorted_guards = [\n\u001b[32m   3379\u001b[39m         guard \u001b[38;5;28;01mfor\u001b[39;00m i, guard \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sorted_guards) \u001b[38;5;28;01mif\u001b[39;00m filter_results[i]\n\u001b[32m   3380\u001b[39m     ]\n\u001b[32m   3382\u001b[39m \u001b[38;5;66;03m# Redo the guards because filtering relies on the results from the last guard builder.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3383\u001b[39m builder, guard_manager = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild_guards\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3384\u001b[39m \u001b[43m    \u001b[49m\u001b[43msorted_guards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexisting_diff_guard_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3387\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3388\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_guards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3389\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3391\u001b[39m \u001b[38;5;28mself\u001b[39m.guard_manager = guard_manager\n\u001b[32m   3392\u001b[39m \u001b[38;5;28mself\u001b[39m.compile_check_fn(builder, sorted_guards, guard_fail_fn)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\guards.py:3674\u001b[39m, in \u001b[36mCheckFunctionManager.build_guards\u001b[39m\u001b[34m(self, sorted_guards, existing_diff_guard_sources, f_code, output_graph, save_guards)\u001b[39m\n\u001b[32m   3663\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   3664\u001b[39m         \u001b[38;5;129;01mnot\u001b[39;00m guard_on_nn_modules\n\u001b[32m   3665\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m guard.is_specialized_nn_module()\n\u001b[32m   (...)\u001b[39m\u001b[32m   3670\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m (config.skip_nnmodule_hook_guards \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mhooks\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m guard.name)\n\u001b[32m   3671\u001b[39m     ):\n\u001b[32m   3672\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3674\u001b[39m     \u001b[43mguard\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3675\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m builder, guard_manager\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_guards.py:366\u001b[39m, in \u001b[36mGuard.create\u001b[39m\u001b[34m(self, builder)\u001b[39m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\u001b[38;5;28mself\u001b[39m, builder: GuardBuilderBase) -> Any:\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    367\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    368\u001b[39m         log.exception(\u001b[33m\"\u001b[39m\u001b[33mError while creating guard:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m).rstrip())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\guards.py:2671\u001b[39m, in \u001b[36mGuardBuilder.SHAPE_ENV\u001b[39m\u001b[34m(self, guard)\u001b[39m\n\u001b[32m   2646\u001b[39m func_str = textwrap.dedent(\n\u001b[32m   2647\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m   2648\u001b[39m \u001b[33m#include <algorithm>\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2664\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m   2665\u001b[39m )\n\u001b[32m   2666\u001b[39m guards_log.debug(\n\u001b[32m   2667\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mC++ shape guard function: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   2668\u001b[39m     func_str,\n\u001b[32m   2669\u001b[39m     verbose_code_parts.exprs,\n\u001b[32m   2670\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2671\u001b[39m clib = \u001b[43mCppCodeCache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2672\u001b[39m cguard = ctypes.cast(clib.guard, ctypes.c_void_p).value\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m cguard\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\codecache.py:2839\u001b[39m, in \u001b[36mCppCodeCache.load\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m   2837\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   2838\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mcls\u001b[39m, *args: Any, **kwargs: Any) -> Any:\n\u001b[32m-> \u001b[39m\u001b[32m2839\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\codecache.py:2705\u001b[39m, in \u001b[36mCppCodeCache.load_async\u001b[39m\u001b[34m(cls, main_code, device_type, submit_fn, extra_flags, optimized_code)\u001b[39m\n\u001b[32m   2689\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   2690\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_async\u001b[39m(\n\u001b[32m   2691\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2696\u001b[39m     optimized_code: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2697\u001b[39m ) -> Any:\n\u001b[32m   2698\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compile and load a C++ library.  Returns a callable that returns the loaded\u001b[39;00m\n\u001b[32m   2699\u001b[39m \u001b[33;03m    library.\"\"\"\u001b[39;00m\n\u001b[32m   2700\u001b[39m     compile_command = {\n\u001b[32m   2701\u001b[39m         **\u001b[38;5;28mcls\u001b[39m.cpp_compile_command_flags,\n\u001b[32m   2702\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdevice_type\u001b[39m\u001b[33m\"\u001b[39m: device_type,\n\u001b[32m   2703\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mextra_flags\u001b[39m\u001b[33m\"\u001b[39m: extra_flags,\n\u001b[32m   2704\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33muse_relative_path\u001b[39m\u001b[33m\"\u001b[39m: config.is_fbcode(),\n\u001b[32m-> \u001b[39m\u001b[32m2705\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mvec_isa\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mpick_vec_isa\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2706\u001b[39m     }\n\u001b[32m   2708\u001b[39m     _set_gpu_runtime_env()  \u001b[38;5;66;03m# cpp_extension consults the env\u001b[39;00m\n\u001b[32m   2710\u001b[39m     \u001b[38;5;66;03m# Note the distinction between the two booleans.  We do minimal optimization if\u001b[39;00m\n\u001b[32m   2711\u001b[39m     \u001b[38;5;66;03m# the optimized_code argument is present at all, since that's how the user of\u001b[39;00m\n\u001b[32m   2712\u001b[39m     \u001b[38;5;66;03m# this function opts in, but we do compilation and linking in one step if the\u001b[39;00m\n\u001b[32m   2713\u001b[39m     \u001b[38;5;66;03m# optimized_code argument is empty (as a micro-optimization).\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:497\u001b[39m, in \u001b[36mpick_vec_isa\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.is_fbcode() \u001b[38;5;129;01mand\u001b[39;00m (platform.machine() \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mx86_64\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAMD64\u001b[39m\u001b[33m\"\u001b[39m]):\n\u001b[32m    495\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m VecAVX2()\n\u001b[32m--> \u001b[39m\u001b[32m497\u001b[39m _valid_vec_isa_list: \u001b[38;5;28mlist\u001b[39m[VecISA] = \u001b[43mvalid_vec_isa_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _valid_vec_isa_list:\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_vec_isa\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:484\u001b[39m, in \u001b[36mvalid_vec_isa_list\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    480\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[33;03m    arch value is x86_64 on Linux, and the value is AMD64 on Windows.\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    483\u001b[39m     _cpu_supported_x86_isa = x86_isa_checker()\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m     \u001b[43misa_list\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43misa\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43misa\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msupported_vec_isa_list\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mflag\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_cpu_supported_x86_isa\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mflag\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43misa\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43misa\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m isa_list\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:487\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    480\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[33;03m    arch value is x86_64 on Linux, and the value is AMD64 on Windows.\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    483\u001b[39m     _cpu_supported_x86_isa = x86_isa_checker()\n\u001b[32m    484\u001b[39m     isa_list.extend(\n\u001b[32m    485\u001b[39m         isa\n\u001b[32m    486\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m isa \u001b[38;5;129;01min\u001b[39;00m supported_vec_isa_list\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(flag \u001b[38;5;129;01min\u001b[39;00m _cpu_supported_x86_isa \u001b[38;5;28;01mfor\u001b[39;00m flag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(isa).split()) \u001b[38;5;129;01mand\u001b[39;00m isa\n\u001b[32m    488\u001b[39m     )\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m isa_list\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:143\u001b[39m, in \u001b[36mVecISA.__bool__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__bool__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__bool__impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvec_isa_ok\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:153\u001b[39m, in \u001b[36mVecISA.__bool__impl\u001b[39m\u001b[34m(self, vec_isa_ok)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.is_fbcode():\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheck_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mVecISA\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_avx_code\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:103\u001b[39m, in \u001b[36mVecISA.check_build\u001b[39m\u001b[34m(self, code)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcodecache\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_lock_dir, LOCK_TIMEOUT, write\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcpp_builder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     95\u001b[39m     CppBuilder,\n\u001b[32m     96\u001b[39m     CppTorchOptions,\n\u001b[32m     97\u001b[39m     normalize_path_separator,\n\u001b[32m     98\u001b[39m )\n\u001b[32m    100\u001b[39m key, input_path = write(\n\u001b[32m    101\u001b[39m     code,\n\u001b[32m    102\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcpp\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     extra=\u001b[43m_get_isa_dry_compile_fingerprint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_arch_flags\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    104\u001b[39m )\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_filelock\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FileLock\n\u001b[32m    107\u001b[39m lock_dir = get_lock_dir()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:29\u001b[39m, in \u001b[36m_get_isa_dry_compile_fingerprint\u001b[39m\u001b[34m(isa_flags)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_isa_dry_compile_fingerprint\u001b[39m(isa_flags: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# ISA dry compile will cost about 1 sec time each startup time.\u001b[39;00m\n\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# Please check the issue: https://github.com/pytorch/pytorch/issues/100378\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     \u001b[38;5;66;03m# and generated them to output binary hash path.\u001b[39;00m\n\u001b[32m     26\u001b[39m     \u001b[38;5;66;03m# It would optimize and skip compile existing binary.\u001b[39;00m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcpp_builder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compiler_version_info, get_cpp_compiler\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     compiler_info = get_compiler_version_info(\u001b[43mget_cpp_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     30\u001b[39m     torch_version = torch.__version__\n\u001b[32m     31\u001b[39m     fingerprint = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompiler_info\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00misa_flags\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py:338\u001b[39m, in \u001b[36mget_cpp_compiler\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    336\u001b[39m     compiler = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mCXX\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    337\u001b[39m     compiler = normalize_path_separator(compiler)\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m     \u001b[43mcheck_compiler_exist_windows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompiler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m     check_msvc_cl_language_id(compiler)\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py:139\u001b[39m, in \u001b[36mcheck_compiler_exist_windows\u001b[39m\u001b[34m(compiler)\u001b[39m\n\u001b[32m    137\u001b[39m     subprocess.check_output([compiler, \u001b[33m\"\u001b[39m\u001b[33m/help\u001b[39m\u001b[33m\"\u001b[39m], stderr=subprocess.STDOUT)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCompiler: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompiler\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not found.\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess.SubprocessError:\n\u001b[32m    141\u001b[39m     \u001b[38;5;66;03m# Expected that some compiler(clang, clang++) is exist, but they not support `/help` args.\u001b[39;00m\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[31mInternalTorchDynamoError\u001b[39m: RuntimeError: Compiler: cl is not found.\n"
     ]
    }
   ],
   "source": [
    "@torch.compile\n",
    "def fn(x):\n",
    "    return x + 1\n",
    "fn(torch.ones(3))\n",
    "fn(torch.ones(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760cccdd",
   "metadata": {},
   "source": [
    "Make sure that the dynamic option of `torch.compile` is not set to `False`.\n",
    "The default option, `dynamic=None`, will only attempt dynamic shapes after the first compilation.\n",
    "You can set `dynamic=True` to upfront compile as dynamic as possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cec68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile(dynamic=True)\n",
    "def gn(x):\n",
    "    return x + 1\n",
    "gn(torch.ones(3))\n",
    "gn(torch.ones(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aea6a7",
   "metadata": {},
   "source": [
    "For more information on dynamic shapes, including dealing with errors/recompilations due to\n",
    "dynamic shapes, see [the dynamic shapes manual](https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit?tab=t.0#heading=h.fh8zzonyw8ng).\n",
    "\n",
    "## Wrapping Constants with Tensors\n",
    "By default, `int` / `float` variables are treated as constants and are guarded on their exact value.\n",
    "In the below example, we have a recompilation for each function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33904f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile\n",
    "def fn(x, c):\n",
    "    return x + c\n",
    "for i in range(5):\n",
    "    fn(torch.ones(i), 0.5 + i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06280d10",
   "metadata": {},
   "source": [
    "In particular, for LR schedulers, initializing with a constant can lead to recompilations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a92d683",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = torch.nn.Linear(3, 3)\n",
    "opt = torch.optim.Adam(mod.parameters(), lr=0.01)\n",
    "sched = torch.optim.lr_scheduler.ExponentialLR(opt, 0.9)\n",
    "@torch.compile\n",
    "def gn(inp):\n",
    "    opt.zero_grad(True)\n",
    "    out = mod(inp).sum()\n",
    "    out.backward()\n",
    "    opt.step()\n",
    "    sched.step()\n",
    "for i in range(5):\n",
    "    gn(torch.ones(3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7e0f28",
   "metadata": {},
   "source": [
    "In both examples, we can wrap `float` variables in tensors in order to prevent recompilations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f18fcf",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "torch._dynamo.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65566b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first example\n",
    "for i in range(5):\n",
    "    fn(torch.ones(i), torch.tensor(0.5 + i))\n",
    "# second example\n",
    "opt = torch.optim.Adam(mod.parameters(), lr=torch.tensor(0.01))\n",
    "sched = torch.optim.lr_scheduler.ExponentialLR(opt, torch.tensor(0.9))\n",
    "for i in range(5):\n",
    "    gn(torch.ones(3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec06a90a",
   "metadata": {},
   "source": [
    "(programming_model.recompilation.changing_cache_size_limit)=\n",
    "## Changing the Cache Size Limit\n",
    "\n",
    "There is a limit to how many times a function can be recompiled,\n",
    "determined by `torch._dynamo.config.cache_size_limit` and `torch._dynamo.config.accumulated_cache_size_limit`\n",
    "(The exact difference between these 2 values is detailed in [`torch/_dynamo/cache_size.py`](https://github.com/pytorch/pytorch/blob/4ce6e6ec8890a3f6ee604c9efb3ff153825ce575/torch/_dynamo/cache_size.py#L14)).\n",
    "If the Dynamo cache limit is hit, then all future compilation attempts **will result in the function being skipped (run eagerly)**.\n",
    "Dynamo will still attempt to use previously compiled bytecode for future function calls, if the guards pass.\n",
    "Note that in the case of a recompilation limit hit, **all nested function calls WILL be skipped**\n",
    "(Dynamo will try to use previously compiled bytecode for the nested functions).\n",
    "Dynamo will also issue a warning containing the affected function and which limit was hit.\n",
    "In the example below, each function call results in a recompile attempt.\n",
    "When we hit the cache size limit (by default, 8), we stop attempting to recompile.\n",
    "(Note that we set `dynamic=False` for demonstration purposes to force recompilation every time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02488b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile(dynamic=False)\n",
    "def fn(x):\n",
    "    return x + 1\n",
    "for i in range(1, 10):\n",
    "    # recompile every time due to dynamic=False\n",
    "    fn(torch.ones(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c756b1fa",
   "metadata": {},
   "source": [
    "If you know that the number of recompilations has a reasonable constant upper bound, you can raise the cache size limit.\n",
    "If the cost of recompilation outweighs the benefit of compilation, then you can consider lowering the cache size limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8243b398",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch._dynamo.config.cache_size_limit = 16\n",
    "@torch.compile(dynamic=False)\n",
    "def gn(x):\n",
    "    return x + 1\n",
    "for i in range(1, 10):\n",
    "    gn(torch.ones(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461b04cc",
   "metadata": {},
   "source": [
    "## Graph Breaking to Reduce Recompilation Costs\n",
    "If a large graph is recompiling and causing high compile time, you can intentionally introduce\n",
    "a graph break in order to reduce recompilation costs, at the expense of introducing a performance hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b2c854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def very_large_function(x):\n",
    "    return x + 1\n",
    "\n",
    "@torch.compile(dynamic=False)\n",
    "def fn(x, c):\n",
    "    y = very_large_function(x)  # recompiled every time\n",
    "    return y + c\n",
    "\n",
    "for i in range(1, 5):\n",
    "    fn(torch.ones(3), i)\n",
    "\n",
    "@torch.compile(dynamic=False)\n",
    "def gn(x, c):\n",
    "    y = very_large_function(x)  # compiled only once\n",
    "    torch._dynamo.graph_break()\n",
    "    return y + c  # recompiled every time\n",
    "\n",
    "for i in range(1, 5):\n",
    "    gn(torch.ones(3), i)"
   ]
  }
 ],
 "metadata": {
  "file_format": "mystnb",
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "mystnb": {
   "execution_show_tb": true,
   "execution_timeout": 30,
   "merge_streams": true
  },
  "source_map": [
   11,
   18,
   31,
   37,
   43,
   49,
   58,
   64,
   68,
   81,
   85,
   90,
   99,
   116,
   123,
   128,
   135,
   141
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}