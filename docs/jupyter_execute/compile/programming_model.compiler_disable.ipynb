{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0327b1ed",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import header_code\n",
    "\n",
    "torch._logging.set_logs(graph_breaks=True, graph_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10635b4f",
   "metadata": {},
   "source": [
    "# Disabling and Suppressing Errors\n",
    "For some model architectures, there are portions of the model which are particularly difficult to compile -\n",
    "either there are many graph breaks, or there are crashes.\n",
    "You may want to explicitly disable these portions of the model which are problematic so that you can apply\n",
    "`torch.compile` to the parts that work. You can do this by using the `@torch.compiler.disable` decorator.\n",
    "When `torch.compile` attempts to call a disabled function, it breaks the graph and skips tracing the disabled function,\n",
    "resuming tracing after the call. By default, all recursive calls made from a disabled function are also disabled.\n",
    "Use the `recursive=False` option to allow compilation for recursive calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee30d201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph break in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\1421264493.py:13\n",
      "Graph Break Reason: Skip calling `torch.compiler.disable()`d function\n",
      "  Explanation: Skip calling function `<function outer1 at 0x000002C3749D84A0>` since it was wrapped with `torch.compiler.disable` (reason: None)\n",
      "  Hint: Remove the `torch.compiler.disable` call\n",
      "\n",
      "  Developer debug context: <function outer1 at 0x000002C3749D84A0>\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0098.html\n",
      "User code traceback:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\1421264493.py\", line 16, in <module>\n",
      "    print(f(torch.ones(3)))\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\1421264493.py\", line 13, in f\n",
      "    x = outer1(x)\n",
      "TRACED GRAPH\n",
      " ===== __compiled_fn_4_80fd10a1_9ee4_4144_9391_bdc7cb4aac13 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_stack0_: \"f32[3][1]cpu\"):\n",
      "        l_stack0_ = L_stack0_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\1421264493.py:14 in torch_dynamo_resume_in_f_at_13, code: return x + 4  # traced\n",
      "        add: \"f32[3][1]cpu\" = l_stack0_ + 4;  l_stack0_ = None\n",
      "        return (add,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACED GRAPH\n",
      " ===== __compiled_fn_4_80fd10a1_9ee4_4144_9391_bdc7cb4aac13 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_stack0_: \"f32[3][1]cpu\"):\n",
      "        l_stack0_ = L_stack0_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\1421264493.py:14 in torch_dynamo_resume_in_f_at_13, code: return x + 4  # traced\n",
      "        add: \"f32[3][1]cpu\" = l_stack0_ + 4;  l_stack0_ = None\n",
      "        return (add,)\n",
      "        \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8., 8., 8.])\n"
     ]
    }
   ],
   "source": [
    "def inner1(x):\n",
    "    torch._dynamo.graph_break()  # not traced\n",
    "    return x + 1  # not traced\n",
    "\n",
    "@torch.compiler.disable\n",
    "def outer1(x):\n",
    "    x = x + 2  # not traced\n",
    "    torch._dynamo.graph_break()  # not traced\n",
    "    return inner1(x)\n",
    "\n",
    "@torch.compile\n",
    "def f(x):\n",
    "    x = outer1(x)\n",
    "    return x + 4  # traced\n",
    "\n",
    "print(f(torch.ones(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a81b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph break in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py:13\n",
      "Graph Break Reason: Skip inlining `torch.compiler.disable()`d function\n",
      "  Explanation: Skip inlining function <function outer2 at 0x000002C3787AFE20> since it was wrapped with `torch.compiler.disable` (reason: None)\n",
      "  Hint: Remove the `torch.compiler.disable` call\n",
      "\n",
      "  Developer debug context: <function outer2 at 0x000002C3787AFE20>\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0099.html\n",
      "User code traceback:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py\", line 16, in <module>\n",
      "    print(g(torch.ones(3)))\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py\", line 13, in g\n",
      "    x = outer2(x)\n",
      "Graph break in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py:8\n",
      "Graph Break Reason: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "User code traceback:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py\", line 16, in <module>\n",
      "    print(g(torch.ones(3)))\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py\", line 13, in g\n",
      "    x = outer2(x)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\external_utils.py\", line 196, in nonrecursive_disable_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py\", line 8, in outer2\n",
      "    torch._dynamo.graph_break()  # not traced\n",
      "TRACED GRAPH\n",
      " ===== __compiled_fn_10_9b6aaceb_bfaf_416e_b3f9_fa8d5fe267ef =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py:7 in outer2, code: x = x + 2  # not traced\n",
      "        x: \"f32[3][1]cpu\" = l_x_ + 2;  l_x_ = None\n",
      "        return (x,)\n",
      "Graph break in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py:2\n",
      "Graph Break Reason: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "User code traceback:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py\", line 16, in <module>\n",
      "    print(g(torch.ones(3)))\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py\", line 13, in g\n",
      "    x = outer2(x)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\external_utils.py\", line 196, in nonrecursive_disable_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py\", line 9, in outer2\n",
      "    return inner2(x)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py\", line 2, in inner2\n",
      "    torch._dynamo.graph_break()  # traced\n",
      "Graph break (user stack suppressed due to duplicate graph break) in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py:2\n",
      "Graph Break Reason: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "TRACED GRAPH\n",
      " ===== __compiled_fn_18_21aa0ac2_858a_4b75_b9b5_7e3b9ba8bff7 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py:3 in torch_dynamo_resume_in_inner2_at_2, code: return x + 1  # traced\n",
      "        add: \"f32[3][1]cpu\" = l_x_ + 1;  l_x_ = None\n",
      "        return (add,)\n",
      "TRACED GRAPH\n",
      " ===== __compiled_fn_20_03fb39dd_b270_47f2_963f_61e39076f0e5 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_stack0_: \"f32[3][1]cpu\"):\n",
      "        l_stack0_ = L_stack0_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py:14 in torch_dynamo_resume_in_g_at_13, code: return x + 4  # traced\n",
      "        add: \"f32[3][1]cpu\" = l_stack0_ + 4;  l_stack0_ = None\n",
      "        return (add,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph break in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py:8\n",
      "Graph Break Reason: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "User code traceback:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py\", line 16, in <module>\n",
      "    print(g(torch.ones(3)))\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py\", line 13, in g\n",
      "    x = outer2(x)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\external_utils.py\", line 196, in nonrecursive_disable_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py\", line 8, in outer2\n",
      "    torch._dynamo.graph_break()  # not traced\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACED GRAPH\n",
      " ===== __compiled_fn_10_9b6aaceb_bfaf_416e_b3f9_fa8d5fe267ef =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py:7 in outer2, code: x = x + 2  # not traced\n",
      "        x: \"f32[3][1]cpu\" = l_x_ + 2;  l_x_ = None\n",
      "        return (x,)\n",
      "        \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph break in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py:2\n",
      "Graph Break Reason: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "User code traceback:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py\", line 16, in <module>\n",
      "    print(g(torch.ones(3)))\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py\", line 13, in g\n",
      "    x = outer2(x)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\external_utils.py\", line 196, in nonrecursive_disable_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py\", line 9, in outer2\n",
      "    return inner2(x)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py\", line 2, in inner2\n",
      "    torch._dynamo.graph_break()  # traced\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph break (user stack suppressed due to duplicate graph break) in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py:2\n",
      "Graph Break Reason: Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACED GRAPH\n",
      " ===== __compiled_fn_18_21aa0ac2_858a_4b75_b9b5_7e3b9ba8bff7 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[3][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py:3 in torch_dynamo_resume_in_inner2_at_2, code: return x + 1  # traced\n",
      "        add: \"f32[3][1]cpu\" = l_x_ + 1;  l_x_ = None\n",
      "        return (add,)\n",
      "        \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACED GRAPH\n",
      " ===== __compiled_fn_20_03fb39dd_b270_47f2_963f_61e39076f0e5 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_stack0_: \"f32[3][1]cpu\"):\n",
      "        l_stack0_ = L_stack0_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_6152\\881423632.py:14 in torch_dynamo_resume_in_g_at_13, code: return x + 4  # traced\n",
      "        add: \"f32[3][1]cpu\" = l_stack0_ + 4;  l_stack0_ = None\n",
      "        return (add,)\n",
      "        \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8., 8., 8.])\n"
     ]
    }
   ],
   "source": [
    "def inner2(x):\n",
    "    torch._dynamo.graph_break()  # traced\n",
    "    return x + 1  # traced\n",
    "\n",
    "@torch.compiler.disable(recursive=False)\n",
    "def outer2(x):\n",
    "    x = x + 2  # not traced\n",
    "    torch._dynamo.graph_break()  # not traced\n",
    "    return inner2(x)\n",
    "\n",
    "@torch.compile\n",
    "def g(x):\n",
    "    x = outer2(x)\n",
    "    return x + 4  # traced\n",
    "\n",
    "print(g(torch.ones(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da37af8a",
   "metadata": {},
   "source": [
    "For example, one can use `torch.compiler.disable` to disable `torch.compile` on sparse architecture in\n",
    "recommendation models, as the sparse arch is difficult to compile.\n",
    "Preprocessing and logging functions are other examples of functions that typically cause\n",
    "a lot of graph breaks and do not get value from being compiled.\n",
    "\n",
    "If you are experiencing compiler crashes and you want to continue regardless,\n",
    "you can set `torch._dynamo.config.suppress_errors = True`.\n",
    "When the compiler crashes, we will just skip tracing the function and try again later.\n",
    "**This is not best practice** - it is better to eventually manually add `disable` annotations as necessary."
   ]
  }
 ],
 "metadata": {
  "file_format": "mystnb",
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "mystnb": {
   "execution_show_tb": true,
   "execution_timeout": 30,
   "merge_streams": true
  },
  "source_map": [
   11,
   18,
   29,
   48,
   65
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}