{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "961ce306",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import header_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac136c6",
   "metadata": {},
   "source": [
    "# Dynamo Core Concepts\n",
    "\n",
    "**Summary:**\n",
    "\n",
    "- Dynamo, `torch.compile`'s frontend, performs **tracing** to capture the semantics of a Python function\n",
    "  (and its nested function calls) into a linear sequence of operations (the \"(FX) graph\"),\n",
    "  residual bytecode, and \"guards\" (a list of conditions under which the graph and bytecode are valid).\n",
    "- Unsupported Python features lead to **graph breaks**, where Dynamo compiles a partial graph acquired from tracing,\n",
    "  then runs the unsupported code, then resumes tracing.\n",
    "- Graph breaks may lead to slowness in torch.compile and prevent backend optimization opportunities.\n",
    "  If you're not seeing the performance you expect, then check for graph breaks.\n",
    "\n",
    "## Dynamo Tracing\n",
    "`torch.compile`'s frontend (Dynamo) is a custom Python bytecode interpreter designed to allow graph compilation\n",
    "in PyTorch programs while retaining the full flexibility of Python. Given a function to be compiled, Dynamo\n",
    "interprets Python bytecode to extract sequences of PyTorch operations into 1 or more FX graphs that may be further optimized by a backend.\n",
    "\n",
    "![Summary diagram of Dynamo](_static/dynamo_summary_diagram.png)\n",
    "\n",
    "For example, for the function `f` in the above diagram, Dynamo produces:\n",
    "- a single **FX graph** that takes in the original input plus some additional inputs required by the function.\n",
    "- **Python bytecode** that can be used as a drop-in replacement for `f`. In our example, the bytecode retrieves\n",
    "  the additional inputs and passes it to the graph and also contains unoptimizable Python side effects (the list append)\n",
    "- **guards** that specify the conditions under which the graph and bytecode are valid. Unless otherwise specified,\n",
    "  the graph produced by Dynamo specializes on the shapes of input Tensors.\n",
    "\n",
    "(programming_model.dynamo_core_concepts.graph_breaks)=\n",
    "\n",
    "## Graph Breaks\n",
    "Dynamo traces your code and attempts to capture your PyTorch code into a single computation graph of PyTorch\n",
    "operators (FX graph). However, this is not always possible. When encountering code that can't be traced, a \"**graph break**\" occurs.\n",
    "In the default `torch.compile` settings, a graph break involves compiling the FX graph that has been determined so far,\n",
    "running the unsupported code in regular Python, then resuming tracing after the unsupported code with a new FX graph.\n",
    "\n",
    "Graph breaks are a feature that allows Dynamo to run over arbitrary Python code and carve out functional subgraphs that can each be individually optimized.\n",
    "\n",
    "However, it is possible for graph breaks to lead to unexpected slowness in `torch.compile`.\n",
    "If you're not getting the speedups you expect, we recommend checking for graph breaks and removing them.\n",
    "\n",
    "Graph breaks may occur on things like:\n",
    "\n",
    "- Data-dependent if-statements\n",
    "- Many Python built-in functions\n",
    "- C functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ada8966a",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "torch._logging.set_logs(graph_breaks=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4d8768",
   "metadata": {},
   "source": [
    "Below is an example of a graph break due to calling an unsupported operation `torch.save`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "569379d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph break in user code at C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_18408\\215272159.py:4\n",
      "Graph Break Reason: Attempted to call function marked as skipped\n",
      "  Explanation: Dynamo developers have intentionally marked that the function `save` in file `C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\serialization.py` should not be traced.\n",
      "  Hint: Avoid calling the function `save`.\n",
      "  Hint: Apply `@torch._dynamo.dont_skip_tracing` to the function `save` to force tracing into the function. More graph breaks may occur as a result of attempting to trace into the function.\n",
      "  Hint: Please file an issue to PyTorch.\n",
      "\n",
      "  Developer debug context: module: torch.serialization, qualname: save, skip reason: <missing reason>\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0007.html\n",
      "User code traceback:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2050, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_18408\\215272159.py\", line 9, in <module>\n",
      "    print(f(x))\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_18408\\215272159.py\", line 4, in f\n",
      "    torch.save(y, \"foo.pt\")  # torch.save is an unsupported operation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.6225e-02, 1.5628e+00, 4.5696e-05])\n"
     ]
    }
   ],
   "source": [
    "@torch.compile\n",
    "def f(x):\n",
    "   y = x ** 2  / 2\n",
    "   torch.save(y, \"foo.pt\")  # torch.save is an unsupported operation\n",
    "   z = y ** 3 / 6\n",
    "   return z\n",
    "\n",
    "x = torch.randn(3)\n",
    "print(f(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed05940b",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove(\"foo.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d91b2f",
   "metadata": {},
   "source": [
    "The semantics of `torch.compile(f)(x)` are roughly this:\n",
    "\n",
    "```python\n",
    "def compiled_f_semantics(x):\n",
    "   y = torch.compile(g, fullgraph=True)(x)\n",
    "   torch.save(y, \"foo.pt\")\n",
    "   z = torch.compile(h, fullgraph=True)(x)\n",
    "   return z\n",
    "\n",
    "def g(x):\n",
    "    return x ** 2  / 2\n",
    "\n",
    "def h(x):\n",
    "    return y ** 3 / 6\n",
    "```\n",
    "\n",
    "## Guards\n",
    "\n",
    "`torch.compile` makes some assumptions about runtime values as we trace through code. During tracing, we generate \"guards\",\n",
    "which are runtime checks for these assumptions. Guards are run in future calls to the compiled function to determine if we\n",
    "can reuse previously compiled code. Examples of runtime checks are constant values, types, and object IDs.\n",
    "\n",
    "Below is an example of generated guards. The `TENSOR_MATCH` guard checks for the input's type, device, dtype, shape, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ab3ae6c",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "torch._logging.set_logs(guards=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f022da9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GUARDS:\n",
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=0), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3, 3], stride=[3, 1])  # return x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_18408\\1068332425.py:3 in fn\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # return x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_18408\\1068332425.py:3 in fn\n",
      "Guard eval latency = 86.60 us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "TREE_GUARD_MANAGER:\n",
      "+- RootGuardManager\n",
      "| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo\\output_graph.py:688 in init_ambient_guards\n",
      "| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo\\output_graph.py:676 in init_ambient_guards\n",
      "| +- GLOBAL_STATE: ___check_global_state()\n",
      "| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n",
      "| +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=0), type=<class 'torch.Tensor'>, tag_safe=(True, False)\n",
      "| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3, 3], stride=[3, 1])  # return x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_18408\\1068332425.py:3 in fn\n",
      "| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # return x + 1  # sers\\Aditya\\AppData\\Local\\Temp\\ipykernel_18408\\1068332425.py:3 in fn\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Guard eval latency = 86.60 us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "@torch.compile\n",
    "def fn(x):\n",
    "    return x + 1\n",
    "\n",
    "print(fn(torch.ones(3, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2339c624",
   "metadata": {},
   "source": [
    "## Recompilations\n",
    "If the guards fail for every instance of previously compiled code, then `torch.compile` must \"recompile\" the function,\n",
    "requiring the original code to be traced again. In the example below, recompilation is necessary because the guard checking the tensor argument's shape failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09214056",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "torch._logging.set_logs(recompiles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "379e9ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recompiling function fn in C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_18408\\420870727.py:1\n",
      "    triggered by the following guard failure(s):\n",
      "    - 3/0: tensor 'x' size mismatch at index 0. expected 3, actual 4\n",
      "Error while creating guard:\n",
      "Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: ['SHAPE_ENV', 'SHAPE_ENV', 'SHAPE_ENV']\n",
      "    Code List: [\"L['x'].stride()[0] == L['x'].size()[1]\", \"2 <= L['x'].size()[0]\", \"2 <= L['x'].size()[1]\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 137, in check_compiler_exist_windows\n",
      "    subprocess.check_output([compiler, \"/help\"], stderr=subprocess.STDOUT)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 472, in check_output\n",
      "    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
      "           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "               **kwargs).stdout\n",
      "               ^^^^^^^^^\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 554, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1039, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        pass_fds, cwd, env,\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "                        gid, gids, uid, umask,\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        start_new_session, process_group)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1554, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "                             # no special security\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "                             cwd,\n",
      "                             ^^^^\n",
      "                             startupinfo)\n",
      "                             ^^^^^^^^^^^^\n",
      "FileNotFoundError: [WinError 2] The system cannot find the file specified\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_guards.py\", line 366, in create\n",
      "    return self.create_fn(builder, self)\n",
      "           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\guards.py\", line 2671, in SHAPE_ENV\n",
      "    clib = CppCodeCache.load(func_str)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 2839, in load\n",
      "    return cls.load_async(*args, **kwargs)()\n",
      "           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 2705, in load_async\n",
      "    \"vec_isa\": pick_vec_isa(),\n",
      "               ~~~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 497, in pick_vec_isa\n",
      "    _valid_vec_isa_list: list[VecISA] = valid_vec_isa_list()\n",
      "                                        ~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 484, in valid_vec_isa_list\n",
      "    isa_list.extend(\n",
      "    ~~~~~~~~~~~~~~~^\n",
      "        isa\n",
      "        ^^^\n",
      "        for isa in supported_vec_isa_list\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        if all(flag in _cpu_supported_x86_isa for flag in str(isa).split()) and isa\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 487, in <genexpr>\n",
      "    if all(flag in _cpu_supported_x86_isa for flag in str(isa).split()) and isa\n",
      "                                                                            ^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 143, in __bool__\n",
      "    return self.__bool__impl(config.cpp.vec_isa_ok)\n",
      "           ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 153, in __bool__impl\n",
      "    return self.check_build(VecISA._avx_code)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 103, in check_build\n",
      "    extra=_get_isa_dry_compile_fingerprint(self._arch_flags),\n",
      "          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 29, in _get_isa_dry_compile_fingerprint\n",
      "    compiler_info = get_compiler_version_info(get_cpp_compiler())\n",
      "                                              ~~~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 338, in get_cpp_compiler\n",
      "    check_compiler_exist_windows(compiler)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 139, in check_compiler_exist_windows\n",
      "    raise RuntimeError(f\"Compiler: {compiler} is not found.\") from exc\n",
      "RuntimeError: Compiler: cl is not found.\n",
      "Created at:\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 773, in trace_frame\n",
      "    tracer = InstructionTranslator(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3847, in __init__\n",
      "    output=OutputGraph(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 508, in __init__\n",
      "    self.init_ambient_guards()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 668, in init_ambient_guards\n",
      "    self.guards.add(ShapeEnvSource().make_guard(GuardBuilder.SHAPE_ENV))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while creating guard:\n",
      "Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: ['SHAPE_ENV', 'SHAPE_ENV', 'SHAPE_ENV']\n",
      "    Code List: [\"L['x'].stride()[0] == L['x'].size()[1]\", \"2 <= L['x'].size()[0]\", \"2 <= L['x'].size()[1]\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 137, in check_compiler_exist_windows\n",
      "    subprocess.check_output([compiler, \"/help\"], stderr=subprocess.STDOUT)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 472, in check_output\n",
      "    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
      "           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "               **kwargs).stdout\n",
      "               ^^^^^^^^^\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 554, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1039, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        pass_fds, cwd, env,\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "                        gid, gids, uid, umask,\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        start_new_session, process_group)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1554, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "                             # no special security\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "                             cwd,\n",
      "                             ^^^^\n",
      "                             startupinfo)\n",
      "                             ^^^^^^^^^^^^\n",
      "FileNotFoundError: [WinError 2] The system cannot find the file specified\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_guards.py\", line 366, in create\n",
      "    return self.create_fn(builder, self)\n",
      "           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\guards.py\", line 2671, in SHAPE_ENV\n",
      "    clib = CppCodeCache.load(func_str)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 2839, in load\n",
      "    return cls.load_async(*args, **kwargs)()\n",
      "           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 2705, in load_async\n",
      "    \"vec_isa\": pick_vec_isa(),\n",
      "               ~~~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 497, in pick_vec_isa\n",
      "    _valid_vec_isa_list: list[VecISA] = valid_vec_isa_list()\n",
      "                                        ~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 484, in valid_vec_isa_list\n",
      "    isa_list.extend(\n",
      "    ~~~~~~~~~~~~~~~^\n",
      "        isa\n",
      "        ^^^\n",
      "        for isa in supported_vec_isa_list\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        if all(flag in _cpu_supported_x86_isa for flag in str(isa).split()) and isa\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 487, in <genexpr>\n",
      "    if all(flag in _cpu_supported_x86_isa for flag in str(isa).split()) and isa\n",
      "                                                                            ^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 143, in __bool__\n",
      "    return self.__bool__impl(config.cpp.vec_isa_ok)\n",
      "           ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 153, in __bool__impl\n",
      "    return self.check_build(VecISA._avx_code)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 103, in check_build\n",
      "    extra=_get_isa_dry_compile_fingerprint(self._arch_flags),\n",
      "          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 29, in _get_isa_dry_compile_fingerprint\n",
      "    compiler_info = get_compiler_version_info(get_cpp_compiler())\n",
      "                                              ~~~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 338, in get_cpp_compiler\n",
      "    check_compiler_exist_windows(compiler)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 139, in check_compiler_exist_windows\n",
      "    raise RuntimeError(f\"Compiler: {compiler} is not found.\") from exc\n",
      "RuntimeError: Compiler: cl is not found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created at:\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 773, in trace_frame\n",
      "    tracer = InstructionTranslator(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3847, in __init__\n",
      "    output=OutputGraph(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 508, in __init__\n",
      "    self.init_ambient_guards()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 668, in init_ambient_guards\n",
      "    self.guards.add(ShapeEnvSource().make_guard(GuardBuilder.SHAPE_ENV))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    },
    {
     "ename": "InternalTorchDynamoError",
     "evalue": "RuntimeError: Compiler: cl is not found.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalTorchDynamoError\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x + \u001b[32m1\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(fn(torch.ones(\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m)))\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:832\u001b[39m, in \u001b[36m_TorchDynamoContext.__call__.<locals>.compile_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    829\u001b[39m _maybe_set_eval_frame(_callback_from_stance(callback))\n\u001b[32m    831\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m832\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    834\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config.verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1874\u001b[39m, in \u001b[36mCatchErrorsWrapper.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, frame_state)\u001b[39m\n\u001b[32m   1868\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(\n\u001b[32m   1869\u001b[39m                 frame, cache_entry, \u001b[38;5;28mself\u001b[39m.hooks, frame_state\n\u001b[32m   1870\u001b[39m             )\n\u001b[32m   1872\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock, _disable_current_modes():\n\u001b[32m   1873\u001b[39m     \u001b[38;5;66;03m# skip=1: skip this frame\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1874\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_backend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1876\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1877\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1624\u001b[39m, in \u001b[36mConvertFrame.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m   1622\u001b[39m counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtotal\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1623\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1624\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1626\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1627\u001b[39m     counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mok\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1628\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:688\u001b[39m, in \u001b[36mConvertFrameAssert.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m    685\u001b[39m     dynamo_tls.traced_frame_infos.append(info)\n\u001b[32m    687\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_context(CompileContext(compile_id)):\n\u001b[32m--> \u001b[39m\u001b[32m688\u001b[39m     result = \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_builtins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_one_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_package\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_frame_box\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_box\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.caching_precompile \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._package \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    710\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpackage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DynamoCache\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1494\u001b[39m, in \u001b[36m_compile\u001b[39m\u001b[34m(code, globals, locals, builtins, closure, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip, package, convert_frame_box)\u001b[39m\n\u001b[32m   1491\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m   1492\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1493\u001b[39m         \u001b[38;5;66;03m# Rewrap for clarity\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1494\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InternalTorchDynamoError(\n\u001b[32m   1495\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e).\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1496\u001b[39m         ).with_traceback(e.__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1498\u001b[39m     \u001b[38;5;66;03m# === WARNING WARNING WARNING ===\u001b[39;00m\n\u001b[32m   1499\u001b[39m     \u001b[38;5;66;03m# If you commit a bug here, it will suppress writing to\u001b[39;00m\n\u001b[32m   1500\u001b[39m     \u001b[38;5;66;03m# dynamo_compile table, and we will not have telemetry.\u001b[39;00m\n\u001b[32m   1501\u001b[39m     \u001b[38;5;66;03m# Be extra careful when making changes here!\u001b[39;00m\n\u001b[32m   1503\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._dynamo.config.run_gc_after_compile:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1433\u001b[39m, in \u001b[36m_compile\u001b[39m\u001b[34m(code, globals, locals, builtins, closure, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip, package, convert_frame_box)\u001b[39m\n\u001b[32m   1431\u001b[39m guarded_code = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1432\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1433\u001b[39m     guarded_code, tracer_output = \u001b[43mcompile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1435\u001b[39m     \u001b[38;5;66;03m# NB: We only put_code_state in success case.  Success case here\u001b[39;00m\n\u001b[32m   1436\u001b[39m     \u001b[38;5;66;03m# does include graph breaks; specifically, if a graph break still\u001b[39;00m\n\u001b[32m   1437\u001b[39m     \u001b[38;5;66;03m# resulted in a partially compiled graph, we WILL return here.  An\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1442\u001b[39m     \u001b[38;5;66;03m# to upload for graph break though, because this can prevent\u001b[39;00m\n\u001b[32m   1443\u001b[39m     \u001b[38;5;66;03m# extra graph break compilations.)\u001b[39;00m\n\u001b[32m   1444\u001b[39m     put_code_state()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_utils_internal.py:92\u001b[39m, in \u001b[36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# This is not needed but we have it here to avoid having profile_compile_time\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# in stack traces when profiling is not enabled.\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m StrobelightCompileTimeProfiler.enabled:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m StrobelightCompileTimeProfiler.profile_compile_time(\n\u001b[32m     95\u001b[39m     function, phase_name, *args, **kwargs\n\u001b[32m     96\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1117\u001b[39m, in \u001b[36m_compile.<locals>.compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks)\u001b[39m\n\u001b[32m   1111\u001b[39m     stack.enter_context(\n\u001b[32m   1112\u001b[39m         torch._dynamo.callback_handler.install_callbacks(\n\u001b[32m   1113\u001b[39m             CallbackTrigger.DYNAMO, \u001b[38;5;28mstr\u001b[39m(CompileContext.current_compile_id())\n\u001b[32m   1114\u001b[39m         )\n\u001b[32m   1115\u001b[39m     )\n\u001b[32m   1116\u001b[39m     stack.enter_context(CompileTimeInstructionCounter.record())\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m   1120\u001b[39m     ConvertFrameReturn(),\n\u001b[32m   1121\u001b[39m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1122\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1251\u001b[39m, in \u001b[36m_compile.<locals>._compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks)\u001b[39m\n\u001b[32m   1249\u001b[39m \u001b[38;5;28;01mnonlocal\u001b[39;00m cache_entry\n\u001b[32m   1250\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[33m\"\u001b[39m\u001b[33mbuild_guards\u001b[39m\u001b[33m\"\u001b[39m, log_pt2_compile_event=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m     check_fn = \u001b[43mdynamo_output\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_guards\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m package \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1259\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m check_fn.guards_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:856\u001b[39m, in \u001b[36mDynamoOutput.build_guards\u001b[39m\u001b[34m(self, code, hooks, save, cache_entry, strict_error)\u001b[39m\n\u001b[32m    847\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_guards\u001b[39m(\n\u001b[32m    848\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    849\u001b[39m     code: types.CodeType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    853\u001b[39m     strict_error: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    854\u001b[39m ) -> CheckFunctionManager:\n\u001b[32m    855\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tracer_output.output_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m856\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCheckFunctionManager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtracer_output\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mguard_fail_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mguard_filter_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_guards\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\guards.py:3383\u001b[39m, in \u001b[36mCheckFunctionManager.__init__\u001b[39m\u001b[34m(self, f_code, output_graph, cache_entry, guard_fail_fn, guard_filter_fn, shape_code_parts, runtime_global_scope, save_guards, strict_error)\u001b[39m\n\u001b[32m   3378\u001b[39m     sorted_guards = [\n\u001b[32m   3379\u001b[39m         guard \u001b[38;5;28;01mfor\u001b[39;00m i, guard \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sorted_guards) \u001b[38;5;28;01mif\u001b[39;00m filter_results[i]\n\u001b[32m   3380\u001b[39m     ]\n\u001b[32m   3382\u001b[39m \u001b[38;5;66;03m# Redo the guards because filtering relies on the results from the last guard builder.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3383\u001b[39m builder, guard_manager = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild_guards\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3384\u001b[39m \u001b[43m    \u001b[49m\u001b[43msorted_guards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexisting_diff_guard_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3387\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3388\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_guards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3389\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3391\u001b[39m \u001b[38;5;28mself\u001b[39m.guard_manager = guard_manager\n\u001b[32m   3392\u001b[39m \u001b[38;5;28mself\u001b[39m.compile_check_fn(builder, sorted_guards, guard_fail_fn)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\guards.py:3674\u001b[39m, in \u001b[36mCheckFunctionManager.build_guards\u001b[39m\u001b[34m(self, sorted_guards, existing_diff_guard_sources, f_code, output_graph, save_guards)\u001b[39m\n\u001b[32m   3663\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   3664\u001b[39m         \u001b[38;5;129;01mnot\u001b[39;00m guard_on_nn_modules\n\u001b[32m   3665\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m guard.is_specialized_nn_module()\n\u001b[32m   (...)\u001b[39m\u001b[32m   3670\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m (config.skip_nnmodule_hook_guards \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mhooks\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m guard.name)\n\u001b[32m   3671\u001b[39m     ):\n\u001b[32m   3672\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3674\u001b[39m     \u001b[43mguard\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3675\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m builder, guard_manager\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_guards.py:366\u001b[39m, in \u001b[36mGuard.create\u001b[39m\u001b[34m(self, builder)\u001b[39m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\u001b[38;5;28mself\u001b[39m, builder: GuardBuilderBase) -> Any:\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    367\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    368\u001b[39m         log.exception(\u001b[33m\"\u001b[39m\u001b[33mError while creating guard:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m).rstrip())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\guards.py:2671\u001b[39m, in \u001b[36mGuardBuilder.SHAPE_ENV\u001b[39m\u001b[34m(self, guard)\u001b[39m\n\u001b[32m   2646\u001b[39m func_str = textwrap.dedent(\n\u001b[32m   2647\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m   2648\u001b[39m \u001b[33m#include <algorithm>\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2664\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m   2665\u001b[39m )\n\u001b[32m   2666\u001b[39m guards_log.debug(\n\u001b[32m   2667\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mC++ shape guard function: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   2668\u001b[39m     func_str,\n\u001b[32m   2669\u001b[39m     verbose_code_parts.exprs,\n\u001b[32m   2670\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2671\u001b[39m clib = \u001b[43mCppCodeCache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2672\u001b[39m cguard = ctypes.cast(clib.guard, ctypes.c_void_p).value\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m cguard\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\codecache.py:2839\u001b[39m, in \u001b[36mCppCodeCache.load\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m   2837\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   2838\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mcls\u001b[39m, *args: Any, **kwargs: Any) -> Any:\n\u001b[32m-> \u001b[39m\u001b[32m2839\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\codecache.py:2705\u001b[39m, in \u001b[36mCppCodeCache.load_async\u001b[39m\u001b[34m(cls, main_code, device_type, submit_fn, extra_flags, optimized_code)\u001b[39m\n\u001b[32m   2689\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   2690\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_async\u001b[39m(\n\u001b[32m   2691\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2696\u001b[39m     optimized_code: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2697\u001b[39m ) -> Any:\n\u001b[32m   2698\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compile and load a C++ library.  Returns a callable that returns the loaded\u001b[39;00m\n\u001b[32m   2699\u001b[39m \u001b[33;03m    library.\"\"\"\u001b[39;00m\n\u001b[32m   2700\u001b[39m     compile_command = {\n\u001b[32m   2701\u001b[39m         **\u001b[38;5;28mcls\u001b[39m.cpp_compile_command_flags,\n\u001b[32m   2702\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdevice_type\u001b[39m\u001b[33m\"\u001b[39m: device_type,\n\u001b[32m   2703\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mextra_flags\u001b[39m\u001b[33m\"\u001b[39m: extra_flags,\n\u001b[32m   2704\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33muse_relative_path\u001b[39m\u001b[33m\"\u001b[39m: config.is_fbcode(),\n\u001b[32m-> \u001b[39m\u001b[32m2705\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mvec_isa\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mpick_vec_isa\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2706\u001b[39m     }\n\u001b[32m   2708\u001b[39m     _set_gpu_runtime_env()  \u001b[38;5;66;03m# cpp_extension consults the env\u001b[39;00m\n\u001b[32m   2710\u001b[39m     \u001b[38;5;66;03m# Note the distinction between the two booleans.  We do minimal optimization if\u001b[39;00m\n\u001b[32m   2711\u001b[39m     \u001b[38;5;66;03m# the optimized_code argument is present at all, since that's how the user of\u001b[39;00m\n\u001b[32m   2712\u001b[39m     \u001b[38;5;66;03m# this function opts in, but we do compilation and linking in one step if the\u001b[39;00m\n\u001b[32m   2713\u001b[39m     \u001b[38;5;66;03m# optimized_code argument is empty (as a micro-optimization).\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:497\u001b[39m, in \u001b[36mpick_vec_isa\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.is_fbcode() \u001b[38;5;129;01mand\u001b[39;00m (platform.machine() \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mx86_64\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAMD64\u001b[39m\u001b[33m\"\u001b[39m]):\n\u001b[32m    495\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m VecAVX2()\n\u001b[32m--> \u001b[39m\u001b[32m497\u001b[39m _valid_vec_isa_list: \u001b[38;5;28mlist\u001b[39m[VecISA] = \u001b[43mvalid_vec_isa_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _valid_vec_isa_list:\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_vec_isa\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:484\u001b[39m, in \u001b[36mvalid_vec_isa_list\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    480\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[33;03m    arch value is x86_64 on Linux, and the value is AMD64 on Windows.\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    483\u001b[39m     _cpu_supported_x86_isa = x86_isa_checker()\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m     \u001b[43misa_list\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43misa\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43misa\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msupported_vec_isa_list\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mflag\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_cpu_supported_x86_isa\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mflag\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43misa\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43misa\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m isa_list\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:487\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    480\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[33;03m    arch value is x86_64 on Linux, and the value is AMD64 on Windows.\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    483\u001b[39m     _cpu_supported_x86_isa = x86_isa_checker()\n\u001b[32m    484\u001b[39m     isa_list.extend(\n\u001b[32m    485\u001b[39m         isa\n\u001b[32m    486\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m isa \u001b[38;5;129;01min\u001b[39;00m supported_vec_isa_list\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(flag \u001b[38;5;129;01min\u001b[39;00m _cpu_supported_x86_isa \u001b[38;5;28;01mfor\u001b[39;00m flag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(isa).split()) \u001b[38;5;129;01mand\u001b[39;00m isa\n\u001b[32m    488\u001b[39m     )\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m isa_list\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:143\u001b[39m, in \u001b[36mVecISA.__bool__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__bool__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__bool__impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvec_isa_ok\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:153\u001b[39m, in \u001b[36mVecISA.__bool__impl\u001b[39m\u001b[34m(self, vec_isa_ok)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.is_fbcode():\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheck_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mVecISA\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_avx_code\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:103\u001b[39m, in \u001b[36mVecISA.check_build\u001b[39m\u001b[34m(self, code)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcodecache\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_lock_dir, LOCK_TIMEOUT, write\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcpp_builder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     95\u001b[39m     CppBuilder,\n\u001b[32m     96\u001b[39m     CppTorchOptions,\n\u001b[32m     97\u001b[39m     normalize_path_separator,\n\u001b[32m     98\u001b[39m )\n\u001b[32m    100\u001b[39m key, input_path = write(\n\u001b[32m    101\u001b[39m     code,\n\u001b[32m    102\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcpp\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     extra=\u001b[43m_get_isa_dry_compile_fingerprint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_arch_flags\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    104\u001b[39m )\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_filelock\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FileLock\n\u001b[32m    107\u001b[39m lock_dir = get_lock_dir()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:29\u001b[39m, in \u001b[36m_get_isa_dry_compile_fingerprint\u001b[39m\u001b[34m(isa_flags)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_isa_dry_compile_fingerprint\u001b[39m(isa_flags: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# ISA dry compile will cost about 1 sec time each startup time.\u001b[39;00m\n\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# Please check the issue: https://github.com/pytorch/pytorch/issues/100378\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     \u001b[38;5;66;03m# and generated them to output binary hash path.\u001b[39;00m\n\u001b[32m     26\u001b[39m     \u001b[38;5;66;03m# It would optimize and skip compile existing binary.\u001b[39;00m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcpp_builder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compiler_version_info, get_cpp_compiler\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     compiler_info = get_compiler_version_info(\u001b[43mget_cpp_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     30\u001b[39m     torch_version = torch.__version__\n\u001b[32m     31\u001b[39m     fingerprint = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompiler_info\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00misa_flags\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py:338\u001b[39m, in \u001b[36mget_cpp_compiler\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    336\u001b[39m     compiler = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mCXX\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    337\u001b[39m     compiler = normalize_path_separator(compiler)\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m     \u001b[43mcheck_compiler_exist_windows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompiler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m     check_msvc_cl_language_id(compiler)\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py:139\u001b[39m, in \u001b[36mcheck_compiler_exist_windows\u001b[39m\u001b[34m(compiler)\u001b[39m\n\u001b[32m    137\u001b[39m     subprocess.check_output([compiler, \u001b[33m\"\u001b[39m\u001b[33m/help\u001b[39m\u001b[33m\"\u001b[39m], stderr=subprocess.STDOUT)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCompiler: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompiler\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not found.\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess.SubprocessError:\n\u001b[32m    141\u001b[39m     \u001b[38;5;66;03m# Expected that some compiler(clang, clang++) is exist, but they not support `/help` args.\u001b[39;00m\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[31mInternalTorchDynamoError\u001b[39m: RuntimeError: Compiler: cl is not found.\n"
     ]
    }
   ],
   "source": [
    "@torch.compile\n",
    "def fn(x):\n",
    "    return x + 1\n",
    "\n",
    "print(fn(torch.ones(3, 3)))\n",
    "print(fn(torch.ones(4, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726e48c1",
   "metadata": {},
   "source": [
    "## Dynamic Shapes\n",
    "\n",
    "`torch.compile` initially assumes tensor shapes are static/constant and guards based on these assumptions. By using \"dynamic shapes,\"\n",
    "we can get `torch.compile` to produce compiled code that can accept tensor inputs with different shapes - we avoid recompiling every time shapes differ.\n",
    "By default, automatic dynamic shapes are enabled in `torch.compile(dynamic=None)` - if compilation fails due to shape mismatch,\n",
    "recompilation is attempted with dynamic shapes. Dynamic shapes can also be fully enabled (`dynamic=True`) or disabled (`dynamic=False`).\n",
    "\n",
    "Below, we enable dynamic shapes and note that we no longer need to recompile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db4fae8",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "torch._logging.set_logs(dynamic=logging.DEBUG, recompiles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465f297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile(dynamic=True)\n",
    "def fn(x):\n",
    "    return x + 1\n",
    "\n",
    "print(fn(torch.ones(3, 3)))\n",
    "print(fn(torch.ones(4, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bc851b",
   "metadata": {},
   "source": [
    "For more information on dynamic shapes, see [The dynamic shapes manual](https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit?tab=t.0#heading=h.fh8zzonyw8ng)."
   ]
  }
 ],
 "metadata": {
  "file_format": "mystnb",
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "mystnb": {
   "execution_show_tb": true,
   "execution_timeout": 30,
   "merge_streams": true
  },
  "source_map": [
   11,
   16,
   63,
   66,
   70,
   82,
   86,
   112,
   117,
   123,
   129,
   134,
   141,
   152,
   158,
   165
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}