{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2259548e",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import header_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6764421d",
   "metadata": {},
   "source": [
    "# Use `torch._dynamo.nonstrict_trace`\n",
    "\n",
    "**Summary:**\n",
    "- Use `nonstrict_trace` to trace a function with non-strict tracing inside of a `torch.compile`'d region.\n",
    "  You may wish to do this because the Dynamo graph breaks on something inside of the function\n",
    "  and you are sure that the function is non-strict traceable.\n",
    "\n",
    "Consider the following scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c16c683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call to `torch._dynamo.graph_break()`\n",
      "  Explanation: User-inserted graph break. Message: None\n",
      "  Hint: Remove the `torch._dynamo.graph_break()` call.\n",
      "\n",
      "  Developer debug context: Called `torch._dynamo.graph_break()` with args `[]`, kwargs `{}`\n",
      "\n",
      " For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0025.html\n",
      "\n",
      "from user code:\n",
      "   File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_19224\\2253748958.py\", line 9, in func\n",
      "    n = get_magic_num()\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_19224\\2253748958.py\", line 5, in get_magic_num\n",
      "    torch._dynamo.graph_break()\n",
      "\n",
      "Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"
     ]
    }
   ],
   "source": [
    "def get_magic_num():\n",
    "    # This explicit graph break call is meant to emulate any kind of Dynamo\n",
    "    # graph break, e.g., the function is implemented in C, or uses some python\n",
    "    # language feature Dynamo doesn't yet support.\n",
    "    torch._dynamo.graph_break()\n",
    "    return torch.tensor([42])\n",
    "@torch.compile(fullgraph=True)\n",
    "def func(x):\n",
    "    n = get_magic_num()\n",
    "    return x + n\n",
    "try:\n",
    "    func(torch.rand(10))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40c27d6",
   "metadata": {},
   "source": [
    "If we run the code above, we'll get an error from Dynamo, because it sees a graph break while the user specified `fullgraph=True`.\n",
    "\n",
    "In these situations, if a user still wants to keep `fullgraph=True`, they typically have several options:\n",
    "\n",
    "1. The graph break is due to a language feature Dynamo doesn't yet support.\n",
    "   In this case, the user either rewrites their code, or files an issue on GitHub.\n",
    "2. The graph break is due to a call to a function implemented in C.\n",
    "   In this case, the user can try to use a custom op.\n",
    "   The user could also try providing a polyfill (a reference implementation in Python)\n",
    "   so that Dynamo can trace through it.\n",
    "3. Worst case scenario -- an internal compiler error. In this case, the user likely has to file an issue on GitHub.\n",
    "\n",
    "In addition to all these options, PyTorch does provide an alternative `torch._dynamo.nonstrict_trace`, if the function call that induced the graph break satisfies certain requirements:\n",
    "\n",
    "- The requirements of [general non-strict tracing](programming_model.non_strict_tracing_model).\n",
    "- The inputs and outputs must contain either basic types (e.g., `int`, `float`, `list`, `dict`, `torch.Tensor`),\n",
    "  or user-defined types that are registered to `torch.utils._pytree`.\n",
    "- The function must be defined outside the `torch.compile`'d region.\n",
    "- Any non-input values read by the function will be treated as a constant\n",
    "  (e.g., a global tensor), and will not be guarded on.\n",
    "\n",
    "When tracing through a call to a `torch._dynamo.nonstrict_trace`'d function, `torch.compile` switches to [non-strict tracing](programming_model.non_strict_tracing_model),\n",
    "and the FX graph will eventually contain all the relevant tensor operations which happened inside that function.\n",
    "\n",
    "For the example above, we can use `torch._dynamo.nonstrict_trace to eliminate` the graph break:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38051b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([42.6698, 42.3129, 42.1239, 42.4041, 42.0318, 42.2082, 42.5521, 42.9130,\n",
      "        42.1376, 42.6910])\n"
     ]
    }
   ],
   "source": [
    "@torch._dynamo.nonstrict_trace\n",
    "def get_magic_num():\n",
    "    # This explicit graph break call is meant to emulate any kind of Dynamo\n",
    "    # graph break, e.g., the function is implemented in C, or uses some python\n",
    "    # language feature Dynamo doesn't yet support.\n",
    "    torch._dynamo.graph_break()\n",
    "    return torch.tensor([42])\n",
    "@torch.compile(fullgraph=True)\n",
    "def func(x):\n",
    "    n = get_magic_num()\n",
    "    return x + n\n",
    "print(func(torch.rand(10)))\n",
    "# No graph break and no error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7743825f",
   "metadata": {},
   "source": [
    "Note that one can use it inside a `torch.compile`'d region as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35803a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([42.3588, 42.7187, 42.9719, 42.5319, 42.4661, 42.3498, 42.7172, 42.8465,\n",
      "        42.0195, 42.7002])\n"
     ]
    }
   ],
   "source": [
    "def get_magic_num():\n",
    "    # This explicit graph break call is meant to emulate any kind of Dynamo\n",
    "    # graph break, e.g., the function is implemented in C, or uses some python\n",
    "    # language feature Dynamo doesn't yet support.\n",
    "    torch._dynamo.graph_break()\n",
    "    return torch.tensor([42])\n",
    "@torch.compile(fullgraph=True)\n",
    "def func(x):\n",
    "    n = torch._dynamo.nonstrict_trace(get_magic_num)()\n",
    "    return x + n\n",
    "print(func(torch.rand(10)))\n",
    "# No graph break and no error."
   ]
  }
 ],
 "metadata": {
  "file_format": "mystnb",
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "mystnb": {
   "execution_show_tb": true,
   "execution_timeout": 30,
   "merge_streams": true
  },
  "source_map": [
   11,
   16,
   27,
   42,
   70,
   84,
   88
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}