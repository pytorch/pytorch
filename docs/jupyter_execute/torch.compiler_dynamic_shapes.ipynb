{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c33daf7",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from compile import header_code\n",
    "\n",
    "torch._logging.set_logs(graph_breaks=True, graph_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c6d34a",
   "metadata": {},
   "source": [
    "(dynamic_shapes)=\n",
    "# Dynamic Shapes\n",
    "\n",
    "This section explains how to work with dynamic shapes in PyTorch, including how\n",
    "to debug and fix common errors, implement support for dynamic shapes in\n",
    "operators, and understand the underlying mechanisms.\n",
    "\n",
    "Dynamic shapes allow PyTorch models to handle inputs with varying dimensions\n",
    "without recompilation. This enables more flexible models that can process\n",
    "different batch sizes, sequence lengths, or image dimensions in a single\n",
    "compiled artifact. Dynamic shapes work by symbolically tracing tensor\n",
    "dimensions rather than using concrete values, creating a computation\n",
    "graph that adapts to different input shapes at runtime. By default,\n",
    "PyTorch assumes all input shapes to be static.\n",
    "\n",
    "Typically, deep learning compilers only support static shapes, requiring\n",
    "recompilation for input shape changes. While this approach covers many use cases,\n",
    "there are situations where this is insufficient:\n",
    "\n",
    "- **Variable Dimensions** - Batch sizes or sequence lengths vary, such as in\n",
    "adaptive batching.\n",
    "- **Data-Dependent Outputs** - Models produce outputs based on input data,\n",
    "like variable bounding boxes in detection models.\n",
    "- **Sparse Representations** - Processing depends on data-varying sparse structures,\n",
    "such as in sparse tensors, jagged tensors, and graph neural networks.\n",
    "\n",
    "Dynamic shapes do not support dynamic rank programs, programs which input tensors\n",
    "change in dimensionality, as this is uncommon and unnecessarily complex.\n",
    "\n",
    "\n",
    "## What does it mean for a size/integer to be dynamic?\n",
    "\n",
    "Dynamic shapes allow avoiding recompilations by making certain dimensions or integers\n",
    "dynamic. For example, if a function `f(x)` is compiled with a static size, it will need\n",
    "recompilation for different sizes:\n",
    "\n",
    "```{note}\n",
    "For simplicity, this example uses `@torch.compile(dynamic=True)`. Note, that\n",
    "this option is not recommended due to it being error prone.\n",
    "For a recommended way of enabling dynamic shapes, see {ref}`enable-dynamic-behavior`.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ede933a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACED GRAPH\n",
      " ===== __compiled_fn_1_475bc864_0792_46d5_8ad4_f5ad8d3a09b6 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[10][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_8960\\281359623.py:4 in f, code: return x* x.size()[0]\n",
      "        mul: \"f32[10][1]cpu\" = l_x_ * 10;  l_x_ = None\n",
      "        return (mul,)\n",
      "TRACED GRAPH\n",
      " ===== __compiled_fn_3_ec475164_0cce_461c_bbb2_758eaa00e145 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[20][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_8960\\281359623.py:4 in f, code: return x* x.size()[0]\n",
      "        mul: \"f32[20][1]cpu\" = l_x_ * 20;  l_x_ = None\n",
      "        return (mul,)\n",
      "TRACED GRAPH\n",
      " ===== __compiled_fn_5_3b1c5e1e_46be_4d59_99bf_4a4d14ea3b02 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[30][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_8960\\281359623.py:4 in f, code: return x* x.size()[0]\n",
      "        mul: \"f32[30][1]cpu\" = l_x_ * 30;  l_x_ = None\n",
      "        return (mul,)\n",
      "TRACED GRAPH\n",
      " ===== __compiled_fn_7_79b88145_850b_4164_8263_5b5a7a161f51 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[40][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_8960\\281359623.py:4 in f, code: return x* x.size()[0]\n",
      "        mul: \"f32[40][1]cpu\" = l_x_ * 40;  l_x_ = None\n",
      "        return (mul,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACED GRAPH\n",
      " ===== __compiled_fn_3_ec475164_0cce_461c_bbb2_758eaa00e145 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[20][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_8960\\281359623.py:4 in f, code: return x* x.size()[0]\n",
      "        mul: \"f32[20][1]cpu\" = l_x_ * 20;  l_x_ = None\n",
      "        return (mul,)\n",
      "        \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACED GRAPH\n",
      " ===== __compiled_fn_5_3b1c5e1e_46be_4d59_99bf_4a4d14ea3b02 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[30][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_8960\\281359623.py:4 in f, code: return x* x.size()[0]\n",
      "        mul: \"f32[30][1]cpu\" = l_x_ * 30;  l_x_ = None\n",
      "        return (mul,)\n",
      "        \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACED GRAPH\n",
      " ===== __compiled_fn_7_79b88145_850b_4164_8263_5b5a7a161f51 =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[40][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_8960\\281359623.py:4 in f, code: return x* x.size()[0]\n",
      "        mul: \"f32[40][1]cpu\" = l_x_ * 40;  l_x_ = None\n",
      "        return (mul,)\n",
      "        \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([34.7828, 33.7132, 39.0780,  3.9111,  9.0637, 25.8114, 28.4206,  0.8923,\n",
       "        11.9890, 25.3198,  6.9554, 36.9036, 20.4440,  4.1732, 35.1584, 11.9212,\n",
       "        21.3898, 15.7068,  8.5545, 11.1348, 16.1181, 21.9075,  9.3390,  6.4489,\n",
       "        13.9438, 23.5696, 15.8925,  8.6346, 19.9487,  8.4855, 11.8988, 24.0547,\n",
       "         6.8885, 21.6356, 24.3968, 28.4438, 38.9138, 35.7720, 25.5067,  2.4857])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "@torch.compile(dynamic=False)\n",
    "def f(x):\n",
    "     return x* x.size()[0]\n",
    "\n",
    "f(torch.rand(10))\n",
    "f(torch.rand(20))\n",
    "f(torch.rand(30))\n",
    "f(torch.rand(40))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb259d85",
   "metadata": {},
   "source": [
    "In the produced output, you can see that four graphs were generated.\n",
    "See the corresponding <a href=\"_static/img/dynamic_shapes/tlparse1_dynamic_shapes_false.png\" target=\"_blank\">tlparse output</a>\n",
    "\n",
    "By making the size dynamic, the function can handle various sizes without recompilation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8475ba0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRACED GRAPH\n",
      " ===== __compiled_fn_9_3aaefe1b_d6cd_4b43_9ae8_15927f0a7d9e =====\n",
      " C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\fx\\_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "    def forward(self, s77: \"Sym(s77)\", L_x_: \"f32[s77][1]cpu\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_8960\\1046103881.py:4 in f, code: return x* x.size()[0]\n",
      "        mul: \"f32[s77][1]cpu\" = l_x_ * s77;  l_x_ = s77 = None\n",
      "        return (mul,)\n",
      "Error while creating guard:\n",
      "Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: ['SHAPE_ENV']\n",
      "    Code List: [\"2 <= L['x'].size()[0]\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 137, in check_compiler_exist_windows\n",
      "    subprocess.check_output([compiler, \"/help\"], stderr=subprocess.STDOUT)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 472, in check_output\n",
      "    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
      "           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "               **kwargs).stdout\n",
      "               ^^^^^^^^^\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 554, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1039, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        pass_fds, cwd, env,\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "                        gid, gids, uid, umask,\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        start_new_session, process_group)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1554, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "                             # no special security\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "                             cwd,\n",
      "                             ^^^^\n",
      "                             startupinfo)\n",
      "                             ^^^^^^^^^^^^\n",
      "FileNotFoundError: [WinError 2] The system cannot find the file specified\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_guards.py\", line 366, in create\n",
      "    return self.create_fn(builder, self)\n",
      "           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\guards.py\", line 2671, in SHAPE_ENV\n",
      "    clib = CppCodeCache.load(func_str)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 2839, in load\n",
      "    return cls.load_async(*args, **kwargs)()\n",
      "           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 2705, in load_async\n",
      "    \"vec_isa\": pick_vec_isa(),\n",
      "               ~~~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 497, in pick_vec_isa\n",
      "    _valid_vec_isa_list: list[VecISA] = valid_vec_isa_list()\n",
      "                                        ~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 484, in valid_vec_isa_list\n",
      "    isa_list.extend(\n",
      "    ~~~~~~~~~~~~~~~^\n",
      "        isa\n",
      "        ^^^\n",
      "        for isa in supported_vec_isa_list\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        if all(flag in _cpu_supported_x86_isa for flag in str(isa).split()) and isa\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 487, in <genexpr>\n",
      "    if all(flag in _cpu_supported_x86_isa for flag in str(isa).split()) and isa\n",
      "                                                                            ^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 143, in __bool__\n",
      "    return self.__bool__impl(config.cpp.vec_isa_ok)\n",
      "           ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 153, in __bool__impl\n",
      "    return self.check_build(VecISA._avx_code)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 103, in check_build\n",
      "    extra=_get_isa_dry_compile_fingerprint(self._arch_flags),\n",
      "          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 29, in _get_isa_dry_compile_fingerprint\n",
      "    compiler_info = get_compiler_version_info(get_cpp_compiler())\n",
      "                                              ~~~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 338, in get_cpp_compiler\n",
      "    check_compiler_exist_windows(compiler)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 139, in check_compiler_exist_windows\n",
      "    raise RuntimeError(f\"Compiler: {compiler} is not found.\") from exc\n",
      "RuntimeError: Compiler: cl is not found.\n",
      "Created at:\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 773, in trace_frame\n",
      "    tracer = InstructionTranslator(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3847, in __init__\n",
      "    output=OutputGraph(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 508, in __init__\n",
      "    self.init_ambient_guards()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 668, in init_ambient_guards\n",
      "    self.guards.add(ShapeEnvSource().make_guard(GuardBuilder.SHAPE_ENV))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while creating guard:\n",
      "Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: ['SHAPE_ENV']\n",
      "    Code List: [\"2 <= L['x'].size()[0]\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 137, in check_compiler_exist_windows\n",
      "    subprocess.check_output([compiler, \"/help\"], stderr=subprocess.STDOUT)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 472, in check_output\n",
      "    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
      "           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "               **kwargs).stdout\n",
      "               ^^^^^^^^^\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 554, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1039, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        pass_fds, cwd, env,\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "                        gid, gids, uid, umask,\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        start_new_session, process_group)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1554, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "                             # no special security\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "                             cwd,\n",
      "                             ^^^^\n",
      "                             startupinfo)\n",
      "                             ^^^^^^^^^^^^\n",
      "FileNotFoundError: [WinError 2] The system cannot find the file specified\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_guards.py\", line 366, in create\n",
      "    return self.create_fn(builder, self)\n",
      "           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\guards.py\", line 2671, in SHAPE_ENV\n",
      "    clib = CppCodeCache.load(func_str)\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 2839, in load\n",
      "    return cls.load_async(*args, **kwargs)()\n",
      "           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 2705, in load_async\n",
      "    \"vec_isa\": pick_vec_isa(),\n",
      "               ~~~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 497, in pick_vec_isa\n",
      "    _valid_vec_isa_list: list[VecISA] = valid_vec_isa_list()\n",
      "                                        ~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 484, in valid_vec_isa_list\n",
      "    isa_list.extend(\n",
      "    ~~~~~~~~~~~~~~~^\n",
      "        isa\n",
      "        ^^^\n",
      "        for isa in supported_vec_isa_list\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        if all(flag in _cpu_supported_x86_isa for flag in str(isa).split()) and isa\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 487, in <genexpr>\n",
      "    if all(flag in _cpu_supported_x86_isa for flag in str(isa).split()) and isa\n",
      "                                                                            ^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 143, in __bool__\n",
      "    return self.__bool__impl(config.cpp.vec_isa_ok)\n",
      "           ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 153, in __bool__impl\n",
      "    return self.check_build(VecISA._avx_code)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 103, in check_build\n",
      "    extra=_get_isa_dry_compile_fingerprint(self._arch_flags),\n",
      "          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 29, in _get_isa_dry_compile_fingerprint\n",
      "    compiler_info = get_compiler_version_info(get_cpp_compiler())\n",
      "                                              ~~~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 338, in get_cpp_compiler\n",
      "    check_compiler_exist_windows(compiler)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 139, in check_compiler_exist_windows\n",
      "    raise RuntimeError(f\"Compiler: {compiler} is not found.\") from exc\n",
      "RuntimeError: Compiler: cl is not found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created at:\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 773, in trace_frame\n",
      "    tracer = InstructionTranslator(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3847, in __init__\n",
      "    output=OutputGraph(\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 508, in __init__\n",
      "    self.init_ambient_guards()\n",
      "  File \"C:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 668, in init_ambient_guards\n",
      "    self.guards.add(ShapeEnvSource().make_guard(GuardBuilder.SHAPE_ENV))\n"
     ]
    },
    {
     "ename": "InternalTorchDynamoError",
     "evalue": "RuntimeError: Compiler: cl is not found.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalTorchDynamoError\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;129m@torch\u001b[39m.compile(dynamic=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mf\u001b[39m(x):\n\u001b[32m      4\u001b[39m      \u001b[38;5;28;01mreturn\u001b[39;00m x* x.size()[\u001b[32m0\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m f(torch.rand(\u001b[32m20\u001b[39m))\n\u001b[32m      8\u001b[39m f(torch.rand(\u001b[32m30\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:832\u001b[39m, in \u001b[36m_TorchDynamoContext.__call__.<locals>.compile_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    829\u001b[39m _maybe_set_eval_frame(_callback_from_stance(callback))\n\u001b[32m    831\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m832\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    834\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config.verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1874\u001b[39m, in \u001b[36mCatchErrorsWrapper.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, frame_state)\u001b[39m\n\u001b[32m   1868\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(\n\u001b[32m   1869\u001b[39m                 frame, cache_entry, \u001b[38;5;28mself\u001b[39m.hooks, frame_state\n\u001b[32m   1870\u001b[39m             )\n\u001b[32m   1872\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock, _disable_current_modes():\n\u001b[32m   1873\u001b[39m     \u001b[38;5;66;03m# skip=1: skip this frame\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1874\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_backend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1876\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1877\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1624\u001b[39m, in \u001b[36mConvertFrame.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m   1622\u001b[39m counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtotal\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1623\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1624\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1626\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1627\u001b[39m     counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mok\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1628\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:688\u001b[39m, in \u001b[36mConvertFrameAssert.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m    685\u001b[39m     dynamo_tls.traced_frame_infos.append(info)\n\u001b[32m    687\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_context(CompileContext(compile_id)):\n\u001b[32m--> \u001b[39m\u001b[32m688\u001b[39m     result = \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_builtins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_one_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_package\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_frame_box\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_box\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.caching_precompile \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._package \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    710\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpackage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DynamoCache\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1494\u001b[39m, in \u001b[36m_compile\u001b[39m\u001b[34m(code, globals, locals, builtins, closure, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip, package, convert_frame_box)\u001b[39m\n\u001b[32m   1491\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m   1492\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1493\u001b[39m         \u001b[38;5;66;03m# Rewrap for clarity\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1494\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InternalTorchDynamoError(\n\u001b[32m   1495\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e).\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1496\u001b[39m         ).with_traceback(e.__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1498\u001b[39m     \u001b[38;5;66;03m# === WARNING WARNING WARNING ===\u001b[39;00m\n\u001b[32m   1499\u001b[39m     \u001b[38;5;66;03m# If you commit a bug here, it will suppress writing to\u001b[39;00m\n\u001b[32m   1500\u001b[39m     \u001b[38;5;66;03m# dynamo_compile table, and we will not have telemetry.\u001b[39;00m\n\u001b[32m   1501\u001b[39m     \u001b[38;5;66;03m# Be extra careful when making changes here!\u001b[39;00m\n\u001b[32m   1503\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._dynamo.config.run_gc_after_compile:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1433\u001b[39m, in \u001b[36m_compile\u001b[39m\u001b[34m(code, globals, locals, builtins, closure, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip, package, convert_frame_box)\u001b[39m\n\u001b[32m   1431\u001b[39m guarded_code = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1432\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1433\u001b[39m     guarded_code, tracer_output = \u001b[43mcompile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1435\u001b[39m     \u001b[38;5;66;03m# NB: We only put_code_state in success case.  Success case here\u001b[39;00m\n\u001b[32m   1436\u001b[39m     \u001b[38;5;66;03m# does include graph breaks; specifically, if a graph break still\u001b[39;00m\n\u001b[32m   1437\u001b[39m     \u001b[38;5;66;03m# resulted in a partially compiled graph, we WILL return here.  An\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1442\u001b[39m     \u001b[38;5;66;03m# to upload for graph break though, because this can prevent\u001b[39;00m\n\u001b[32m   1443\u001b[39m     \u001b[38;5;66;03m# extra graph break compilations.)\u001b[39;00m\n\u001b[32m   1444\u001b[39m     put_code_state()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_utils_internal.py:92\u001b[39m, in \u001b[36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# This is not needed but we have it here to avoid having profile_compile_time\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# in stack traces when profiling is not enabled.\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m StrobelightCompileTimeProfiler.enabled:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m StrobelightCompileTimeProfiler.profile_compile_time(\n\u001b[32m     95\u001b[39m     function, phase_name, *args, **kwargs\n\u001b[32m     96\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1117\u001b[39m, in \u001b[36m_compile.<locals>.compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks)\u001b[39m\n\u001b[32m   1111\u001b[39m     stack.enter_context(\n\u001b[32m   1112\u001b[39m         torch._dynamo.callback_handler.install_callbacks(\n\u001b[32m   1113\u001b[39m             CallbackTrigger.DYNAMO, \u001b[38;5;28mstr\u001b[39m(CompileContext.current_compile_id())\n\u001b[32m   1114\u001b[39m         )\n\u001b[32m   1115\u001b[39m     )\n\u001b[32m   1116\u001b[39m     stack.enter_context(CompileTimeInstructionCounter.record())\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m   1120\u001b[39m     ConvertFrameReturn(),\n\u001b[32m   1121\u001b[39m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1122\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1251\u001b[39m, in \u001b[36m_compile.<locals>._compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks)\u001b[39m\n\u001b[32m   1249\u001b[39m \u001b[38;5;28;01mnonlocal\u001b[39;00m cache_entry\n\u001b[32m   1250\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[33m\"\u001b[39m\u001b[33mbuild_guards\u001b[39m\u001b[33m\"\u001b[39m, log_pt2_compile_event=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m     check_fn = \u001b[43mdynamo_output\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_guards\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m package \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1259\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m check_fn.guards_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:856\u001b[39m, in \u001b[36mDynamoOutput.build_guards\u001b[39m\u001b[34m(self, code, hooks, save, cache_entry, strict_error)\u001b[39m\n\u001b[32m    847\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_guards\u001b[39m(\n\u001b[32m    848\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    849\u001b[39m     code: types.CodeType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    853\u001b[39m     strict_error: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    854\u001b[39m ) -> CheckFunctionManager:\n\u001b[32m    855\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tracer_output.output_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m856\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCheckFunctionManager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtracer_output\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mguard_fail_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mguard_filter_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_guards\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\guards.py:3383\u001b[39m, in \u001b[36mCheckFunctionManager.__init__\u001b[39m\u001b[34m(self, f_code, output_graph, cache_entry, guard_fail_fn, guard_filter_fn, shape_code_parts, runtime_global_scope, save_guards, strict_error)\u001b[39m\n\u001b[32m   3378\u001b[39m     sorted_guards = [\n\u001b[32m   3379\u001b[39m         guard \u001b[38;5;28;01mfor\u001b[39;00m i, guard \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sorted_guards) \u001b[38;5;28;01mif\u001b[39;00m filter_results[i]\n\u001b[32m   3380\u001b[39m     ]\n\u001b[32m   3382\u001b[39m \u001b[38;5;66;03m# Redo the guards because filtering relies on the results from the last guard builder.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3383\u001b[39m builder, guard_manager = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild_guards\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3384\u001b[39m \u001b[43m    \u001b[49m\u001b[43msorted_guards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexisting_diff_guard_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3387\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3388\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_guards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3389\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3391\u001b[39m \u001b[38;5;28mself\u001b[39m.guard_manager = guard_manager\n\u001b[32m   3392\u001b[39m \u001b[38;5;28mself\u001b[39m.compile_check_fn(builder, sorted_guards, guard_fail_fn)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\guards.py:3674\u001b[39m, in \u001b[36mCheckFunctionManager.build_guards\u001b[39m\u001b[34m(self, sorted_guards, existing_diff_guard_sources, f_code, output_graph, save_guards)\u001b[39m\n\u001b[32m   3663\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   3664\u001b[39m         \u001b[38;5;129;01mnot\u001b[39;00m guard_on_nn_modules\n\u001b[32m   3665\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m guard.is_specialized_nn_module()\n\u001b[32m   (...)\u001b[39m\u001b[32m   3670\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m (config.skip_nnmodule_hook_guards \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mhooks\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m guard.name)\n\u001b[32m   3671\u001b[39m     ):\n\u001b[32m   3672\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3674\u001b[39m     \u001b[43mguard\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3675\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m builder, guard_manager\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_guards.py:366\u001b[39m, in \u001b[36mGuard.create\u001b[39m\u001b[34m(self, builder)\u001b[39m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\u001b[38;5;28mself\u001b[39m, builder: GuardBuilderBase) -> Any:\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    367\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    368\u001b[39m         log.exception(\u001b[33m\"\u001b[39m\u001b[33mError while creating guard:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m).rstrip())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_dynamo\\guards.py:2671\u001b[39m, in \u001b[36mGuardBuilder.SHAPE_ENV\u001b[39m\u001b[34m(self, guard)\u001b[39m\n\u001b[32m   2646\u001b[39m func_str = textwrap.dedent(\n\u001b[32m   2647\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m   2648\u001b[39m \u001b[33m#include <algorithm>\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2664\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m   2665\u001b[39m )\n\u001b[32m   2666\u001b[39m guards_log.debug(\n\u001b[32m   2667\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mC++ shape guard function: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   2668\u001b[39m     func_str,\n\u001b[32m   2669\u001b[39m     verbose_code_parts.exprs,\n\u001b[32m   2670\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2671\u001b[39m clib = \u001b[43mCppCodeCache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2672\u001b[39m cguard = ctypes.cast(clib.guard, ctypes.c_void_p).value\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m cguard\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\codecache.py:2839\u001b[39m, in \u001b[36mCppCodeCache.load\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m   2837\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   2838\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mcls\u001b[39m, *args: Any, **kwargs: Any) -> Any:\n\u001b[32m-> \u001b[39m\u001b[32m2839\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\codecache.py:2705\u001b[39m, in \u001b[36mCppCodeCache.load_async\u001b[39m\u001b[34m(cls, main_code, device_type, submit_fn, extra_flags, optimized_code)\u001b[39m\n\u001b[32m   2689\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   2690\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_async\u001b[39m(\n\u001b[32m   2691\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2696\u001b[39m     optimized_code: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2697\u001b[39m ) -> Any:\n\u001b[32m   2698\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compile and load a C++ library.  Returns a callable that returns the loaded\u001b[39;00m\n\u001b[32m   2699\u001b[39m \u001b[33;03m    library.\"\"\"\u001b[39;00m\n\u001b[32m   2700\u001b[39m     compile_command = {\n\u001b[32m   2701\u001b[39m         **\u001b[38;5;28mcls\u001b[39m.cpp_compile_command_flags,\n\u001b[32m   2702\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdevice_type\u001b[39m\u001b[33m\"\u001b[39m: device_type,\n\u001b[32m   2703\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mextra_flags\u001b[39m\u001b[33m\"\u001b[39m: extra_flags,\n\u001b[32m   2704\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33muse_relative_path\u001b[39m\u001b[33m\"\u001b[39m: config.is_fbcode(),\n\u001b[32m-> \u001b[39m\u001b[32m2705\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mvec_isa\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mpick_vec_isa\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2706\u001b[39m     }\n\u001b[32m   2708\u001b[39m     _set_gpu_runtime_env()  \u001b[38;5;66;03m# cpp_extension consults the env\u001b[39;00m\n\u001b[32m   2710\u001b[39m     \u001b[38;5;66;03m# Note the distinction between the two booleans.  We do minimal optimization if\u001b[39;00m\n\u001b[32m   2711\u001b[39m     \u001b[38;5;66;03m# the optimized_code argument is present at all, since that's how the user of\u001b[39;00m\n\u001b[32m   2712\u001b[39m     \u001b[38;5;66;03m# this function opts in, but we do compilation and linking in one step if the\u001b[39;00m\n\u001b[32m   2713\u001b[39m     \u001b[38;5;66;03m# optimized_code argument is empty (as a micro-optimization).\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:497\u001b[39m, in \u001b[36mpick_vec_isa\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.is_fbcode() \u001b[38;5;129;01mand\u001b[39;00m (platform.machine() \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mx86_64\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAMD64\u001b[39m\u001b[33m\"\u001b[39m]):\n\u001b[32m    495\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m VecAVX2()\n\u001b[32m--> \u001b[39m\u001b[32m497\u001b[39m _valid_vec_isa_list: \u001b[38;5;28mlist\u001b[39m[VecISA] = \u001b[43mvalid_vec_isa_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _valid_vec_isa_list:\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_vec_isa\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:484\u001b[39m, in \u001b[36mvalid_vec_isa_list\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    480\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[33;03m    arch value is x86_64 on Linux, and the value is AMD64 on Windows.\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    483\u001b[39m     _cpu_supported_x86_isa = x86_isa_checker()\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m     \u001b[43misa_list\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43misa\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43misa\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msupported_vec_isa_list\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mflag\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_cpu_supported_x86_isa\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mflag\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43misa\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43misa\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m isa_list\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:487\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    480\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[33;03m    arch value is x86_64 on Linux, and the value is AMD64 on Windows.\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    483\u001b[39m     _cpu_supported_x86_isa = x86_isa_checker()\n\u001b[32m    484\u001b[39m     isa_list.extend(\n\u001b[32m    485\u001b[39m         isa\n\u001b[32m    486\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m isa \u001b[38;5;129;01min\u001b[39;00m supported_vec_isa_list\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(flag \u001b[38;5;129;01min\u001b[39;00m _cpu_supported_x86_isa \u001b[38;5;28;01mfor\u001b[39;00m flag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(isa).split()) \u001b[38;5;129;01mand\u001b[39;00m isa\n\u001b[32m    488\u001b[39m     )\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m isa_list\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:143\u001b[39m, in \u001b[36mVecISA.__bool__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__bool__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__bool__impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvec_isa_ok\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:153\u001b[39m, in \u001b[36mVecISA.__bool__impl\u001b[39m\u001b[34m(self, vec_isa_ok)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.is_fbcode():\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheck_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mVecISA\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_avx_code\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:103\u001b[39m, in \u001b[36mVecISA.check_build\u001b[39m\u001b[34m(self, code)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcodecache\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_lock_dir, LOCK_TIMEOUT, write\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcpp_builder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     95\u001b[39m     CppBuilder,\n\u001b[32m     96\u001b[39m     CppTorchOptions,\n\u001b[32m     97\u001b[39m     normalize_path_separator,\n\u001b[32m     98\u001b[39m )\n\u001b[32m    100\u001b[39m key, input_path = write(\n\u001b[32m    101\u001b[39m     code,\n\u001b[32m    102\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcpp\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     extra=\u001b[43m_get_isa_dry_compile_fingerprint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_arch_flags\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    104\u001b[39m )\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_filelock\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FileLock\n\u001b[32m    107\u001b[39m lock_dir = get_lock_dir()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:29\u001b[39m, in \u001b[36m_get_isa_dry_compile_fingerprint\u001b[39m\u001b[34m(isa_flags)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_isa_dry_compile_fingerprint\u001b[39m(isa_flags: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# ISA dry compile will cost about 1 sec time each startup time.\u001b[39;00m\n\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# Please check the issue: https://github.com/pytorch/pytorch/issues/100378\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     \u001b[38;5;66;03m# and generated them to output binary hash path.\u001b[39;00m\n\u001b[32m     26\u001b[39m     \u001b[38;5;66;03m# It would optimize and skip compile existing binary.\u001b[39;00m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcpp_builder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compiler_version_info, get_cpp_compiler\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     compiler_info = get_compiler_version_info(\u001b[43mget_cpp_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     30\u001b[39m     torch_version = torch.__version__\n\u001b[32m     31\u001b[39m     fingerprint = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompiler_info\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00misa_flags\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py:338\u001b[39m, in \u001b[36mget_cpp_compiler\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    336\u001b[39m     compiler = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mCXX\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    337\u001b[39m     compiler = normalize_path_separator(compiler)\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m     \u001b[43mcheck_compiler_exist_windows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompiler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m     check_msvc_cl_language_id(compiler)\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\dev\\pytorch\\venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py:139\u001b[39m, in \u001b[36mcheck_compiler_exist_windows\u001b[39m\u001b[34m(compiler)\u001b[39m\n\u001b[32m    137\u001b[39m     subprocess.check_output([compiler, \u001b[33m\"\u001b[39m\u001b[33m/help\u001b[39m\u001b[33m\"\u001b[39m], stderr=subprocess.STDOUT)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCompiler: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompiler\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not found.\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess.SubprocessError:\n\u001b[32m    141\u001b[39m     \u001b[38;5;66;03m# Expected that some compiler(clang, clang++) is exist, but they not support `/help` args.\u001b[39;00m\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[31mInternalTorchDynamoError\u001b[39m: RuntimeError: Compiler: cl is not found.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "@torch.compile(dynamic=True)\n",
    "def f(x):\n",
    "     return x* x.size()[0]\n",
    "\n",
    "f(torch.rand(10))\n",
    "f(torch.rand(20))\n",
    "f(torch.rand(30))\n",
    "f(torch.rand(40))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c3aa38",
   "metadata": {},
   "source": [
    "With dynamic shapes enabled, only one graph is created. See the\n",
    "corresponding <a href=\"_static/img/dynamic_shapes/tlparse2_dynamic_shapes_true.png\" target=\"_blank\">tlparse output</a>.\n",
    "\n",
    "While compilation time differences\n",
    "are minimal for this small example, more complex use cases would show significant\n",
    "performance improvements.\n",
    "\n",
    "(what_is_a_specialization)=\n",
    "## What is a specialization?\n",
    "\n",
    "**Specialization** refers to optimizing a computational graph for specific input shapes\n",
    "by examining shape conditions during control flow. If a branch is taken based on a\n",
    "shape condition, the graph is tailored for that condition. If a new input doesn't meet\n",
    "this condition, the system will recompile the graph.\n",
    "\n",
    "Specialization allows you to create optimized computational graphs for specific input\n",
    "shapes, which can significantly improve execution speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bb93ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "@torch.compile(dynamic=True)\n",
    "def f(x):\n",
    "    if x.size()[0] == 10:\n",
    "        return x * 10\n",
    "\n",
    "    if x.size()[0] <= 30:\n",
    "        return x*200\n",
    "\n",
    "    return x*x.size()[0]\n",
    "\n",
    "f(torch.rand(10))\n",
    "f(torch.rand(20))\n",
    "f(torch.rand(30))\n",
    "f(torch.rand(40))\n",
    "f(torch.rand(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a593599c",
   "metadata": {},
   "source": [
    "In the code above, we specialize that the graph requires an input size of 10, in which\n",
    "case it will return `x * 10`. If the input size is less than 30, it will return `x * 200`.\n",
    "In the output, you can see that this creates three graphs.\n",
    "\n",
    "See the corresponding <a href=\"_static/img/dynamic_shapes/tlparse3_specialization.png\" target=\"_blank\">tlparse output</a>\n",
    "\n",
    "\n",
    "This is how graphs created for the above function:\n",
    "\n",
    "```{image} _static/img/dynamic_shapes/dynamic_shapes_example_specialization.png\n",
    "```\n",
    "\n",
    "(enable-dynamic-behavior)=\n",
    "## Enabling Dynamic Behavior\n",
    "\n",
    "There are the following ways to make things dynamic:\n",
    "\n",
    "* {ref}`automatic_dynamic`\n",
    "* {ref}`user_annotations` (preferred)\n",
    "* {ref}`torch_compile_dynamic_true` (for testing only)\n",
    "* {ref}`dynamic_shapes_advanced_control_options` (for advanced use cases)\n",
    "\n",
    "Read below about each of this options.\n",
    "\n",
    "(automatic_dynamic)=\n",
    "### Automatic dynamic\n",
    "\n",
    "**Automatic dynamic** is the default behavior where {func}`torch.compile` performs\n",
    "the initial compilation assuming static shapes are used, while tracking the\n",
    "input sizes from that first compilation. When a recompile is triggered, it\n",
    "uses this information to identify which dimensions have changed and marks\n",
    "those as dynamic for the second compilation.\n",
    "\n",
    "(user_annotations)=\n",
    "### User Annotations\n",
    "\n",
    "Several APIs allow users to explicitly mark specific inputs\n",
    "by name or code as dynamic. This is useful for avoiding initial compilations that\n",
    "would eventually become dynamic with the previous tools. It is also used to mark\n",
    "elements that do not automatically get marked as dynamic, such as neural network\n",
    "module parameters, and so on. User annotations are the preferred way to enable\n",
    "dynamic shapes.\n",
    "\n",
    "#### `mark_dynamic(tensor, dim, min=min, max=max)`\n",
    "\n",
    "The {func}`torch._dynamo.mark_dynamic` function marks a tensor dimension as dynamic and will fail if it\n",
    "gets specialized. It does not work for integers. Use this function only if you know\n",
    "all graphs in the frame using this input converge to a single dynamic graph.\n",
    "Otherwise, you may encounter a misleading constraint violation error.\n",
    "In such cases, consider using {func}`torch._dynamo.maybe_mark_dynamic`. Currently,\n",
    "{func}`torch._dynamo.mark_dynamic`\n",
    "does not have precedence over `force_parameter_static_shapes = True` or `force_nn_module_property_static_shapes = True`.\n",
    "\n",
    "If you know in advance that a particular dimension will be dynamic, you\n",
    "can avoid the initial recompilation by using {func}`torch._dynamo.mark_dynamic(tensor, dim)`.\n",
    "Additionally, if you already know the minimum and maximum possible\n",
    "values for this dimension, you can specify them with\n",
    "{func}`torch._dynamo.mark_dynamic(tensor, dim, min=min, max=max)`.\n",
    "\n",
    "Here is a quick example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599bc350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "@torch.compile\n",
    "def f(x):\n",
    "    return x * x.size()[0]\n",
    "\n",
    "x = torch.randn(10)\n",
    "torch._dynamo.mark_dynamic(x, 0)\n",
    "\n",
    "# first invocation we give it is a tensor marked as dynamic\n",
    "f(x)\n",
    "# rest of these invocations will use dynamically compiled code\n",
    "f(torch.randn(20))\n",
    "f(torch.randn(30))\n",
    "f(torch.randn(40))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746add67",
   "metadata": {},
   "source": [
    "#### `maybe_mark_dynamic(tensor, dim)`\n",
    "\n",
    "The {func}`torch._dynamo.maybe_mark_dynamic` function shares all properties\n",
    "with  {func}`torch._dynamo.mark_dynamic`\n",
    "but does not fail if the size gets specialized. Use it for inputs shared by\n",
    "multiple graphs or if the number of graphs does not converge to one for a specific\n",
    "frame. For instance, in the example above, use {func}`torch._dynamo.maybe_mark_dynamic()` because graphs\n",
    "with sizes 0 and 1 will specialize. However, you can use {func}`torch._dynamo.mark_dynamic` to ensure\n",
    "you never specialize.\n",
    "\n",
    "#### `mark_unbacked(tensor, dim)`\n",
    "\n",
    "The {func}`torch._dynamo.decorators.mark_unbacked` function marks a tensor dimension as unbacked. It is unlikely\n",
    "to be the tool you need, but it could be useful if the specialization occurs inside\n",
    "a condition `guard_size_oblivious(x)`, and if using it removes the specialization.\n",
    "Ensure it fixes the specialization and does not introduce a data-dependent error\n",
    "that converts to a graph break at or before the specialization location\n",
    "you are trying to  avoid. It might be better to use the next option.\n",
    "\n",
    "(dynamic_sources_allow_list)=\n",
    "#### Dynamic Allow List (`DYNAMIC_SOURCES`)\n",
    "\n",
    "Use the evnironmental variable `TORCH_COMPILE_DYNAMIC_SOURCES` to pass a configuration\n",
    "list of source names to be marked as dynamic. For example:\n",
    "`TORCH_COMPILE_DYNAMIC_SOURCES=L[x],L[y]`\n",
    "It's easiest to find these dynamic source names using the PGO artifact in `tlparse`.\n",
    "You can copy and paste the dynamic source names from the PGO artifact. This method works\n",
    "for integers and tensor sizes and has the highest precedence over all other flags\n",
    "that force static shapes. It will not throw an error if what is marked dynamic\n",
    "gets specialized or if the provided input does not exist.\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b550df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "@torch.compile()\n",
    "def f(x):\n",
    "     return x * x.size()[0]\n",
    "\n",
    "with torch.compiler.config.patch(dynamic_sources=\"L['x']\"):\n",
    "    f(torch.rand(10))\n",
    "f(torch.rand(20))\n",
    "f(torch.rand(30))\n",
    "f(torch.rand(40))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d1ea99",
   "metadata": {},
   "source": [
    "(torch.compiler.set_stance_eager_then_compile)=\n",
    "#### `torch.compiler.set_stance (\"eager_then_compile\")`\n",
    "\n",
    "At times, identifying the appropriate inputs to mark as dynamic can\n",
    "be challenging. If you are willing to accept a performance cost for\n",
    "the first batch, another convenient option is to use the\n",
    "`eager_then_compile` stances, which automatically determine dynamic\n",
    "inputs for you. For more information, see {func}`torch.compiler.set_stance` and [Dynamic Compilation Control with torch.compiler.set_stance](https://docs.pytorch.org/tutorials/recipes/torch_compiler_set_stance_tutorial.html).\n",
    "\n",
    "(torch_compile_dynamic_true)=\n",
    "### `torch.compile (dynamic=true)` (Not recommended)\n",
    "\n",
    "This setting forces all sizes and integers to be dynamic, increasing the\n",
    "chance of encountering dynamic shape bugs. Setting this option is not\n",
    "recommended due to it  being error prone.\n",
    "It would make every input size dynamic which may result it performance\n",
    "regressions and ultimately increase compilation time.\n",
    "\n",
    "PyTorch also provides advanced control options for dynamic shapes, see:\n",
    "{ref}`dynamic_shapes_advanced_control_options`.\n",
    "\n",
    "## Where Do I Go From Here?\n",
    "\n",
    "If you encounter a framework code bug or an issue with specialization,\n",
    "file an issue so it can be reviewed and potentially improved. If the issue\n",
    "is within your user code, consider whether you are willing to rewrite your\n",
    "code to avoid it. Determine if it affects correctness or if it's a redundant\n",
    "check. If the issue involves a Triton custom kernel with a `constexpr`\n",
    "argument, evaluate whether you can rewrite it to address the problem.\n",
    "\n",
    "```{toctree}\n",
    ":maxdepth: 1\n",
    "compile/dynamic_shapes_core_concepts\n",
    "compile/dynamic_shapes_troubleshooting\n",
    "compile/dynamic_shapes_advanced_control_options\n",
    "compile/dynamic_shapes_beyond_the_basics\n",
    "```\n",
    "\n",
    "```{seealso}\n",
    "* [tlparse documentation](https://github.com/pytorch/tlparse)\n",
    "* [The dynamic shapes manual](https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit?tab=t.0#heading=h.fh8zzonyw8ng)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "file_format": "mystnb",
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "mystnb": {
   "execution_show_tb": true,
   "execution_timeout": 30,
   "merge_streams": true
  },
  "source_map": [
   11,
   17,
   61,
   71,
   78,
   88,
   109,
   126,
   189,
   205,
   240,
   252
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}