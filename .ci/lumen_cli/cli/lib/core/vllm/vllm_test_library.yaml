# VLLM Test Library Configuration
# This file defines the test plans for vllm CI development
# See https://github.com/vllm-project/vllm/blob/main/.buildkite/test-pipeline.yaml

vllm_basic_correctness_test:
  title: Basic Correctness Test
  id: vllm_basic_correctness_test
  env_vars:
    VLLM_WORKER_MULTIPROC_METHOD: spawn
  steps:
    - pytest -v -s basic_correctness/test_cumem.py
    - pytest -v -s basic_correctness/test_basic_correctness.py
    - pytest -v -s basic_correctness/test_cpu_offload.py

vllm_basic_models_test:
  title: Basic models test
  id: vllm_basic_models_test
  steps:
    - pytest -v -s models/test_transformers.py
    - pytest -v -s models/test_registry.py
    - pytest -v -s models/test_utils.py
    - pytest -v -s models/test_vision.py
    - pytest -v -s models/test_initialization.py

vllm_entrypoints_test:
  title: Entrypoints Test
  id: vllm_entrypoints_test
  env_vars:
    VLLM_WORKER_MULTIPROC_METHOD: spawn
  steps:
    - pytest -v -s entrypoints/llm --ignore=entrypoints/llm/test_generate.py --ignore=entrypoints/llm/test_collective_rpc.py
    - pytest -v -s entrypoints/llm/test_generate.py
    - pytest -v -s entrypoints/offline_mode

vllm_regression_test:
  title: Regression Test
  id: vllm_regression_test
  package_install:
    - modelscope
  steps:
    - pytest -v -s test_regression.py

vllm_lora_tp_test_distributed:
  title: LoRA TP Test (Distributed)
  id: vllm_lora_tp_test_distributed
  env_vars:
    VLLM_WORKER_MULTIPROC_METHOD: spawn
  num_gpus: 4
  steps:
    - pytest -v -s -x lora/test_chatglm3_tp.py
    - pytest -v -s -x lora/test_llama_tp.py
    - pytest -v -s -x lora/test_llm_with_multi_loras.py

vllm_distributed_test_28_failure_test:
  title: Distributed Tests (2 GPUs) pytorch 2.8 release failure
  id: vllm_distributed_test_28_failure_test
  env_vars:
    VLLM_WORKER_MULTIPROC_METHOD: spawn
  num_gpus: 4
  steps:
    - pytest -v -s distributed/test_sequence_parallel.py

vllm_lora_28_failure_test:
  title: LoRA pytorch 2.8 failure test
  id: vllm_lora_28_failure_test
  steps:
    - pytest -v lora/test_quant_model.py

vllm_multi_model_processor_test:
  title: Multi-Modal Processor Test
  id: vllm_multi_model_processor_test
  package_install:
    - git+https://github.com/TIGER-AI-Lab/Mantis.git
  steps:
    - pytest -v -s models/multimodal/processing --ignore models/multimodal/processing/test_tensor_schema.py

vllm_multi_model_test_28_failure_test:
  title: Multi-Model Test (Failed 2.8 release)
  id: vllm_multi_model_test_28_failure_test
  package_install:
    - git+https://github.com/TIGER-AI-Lab/Mantis.git
  steps:
    - pytest -v -s models/multimodal/generation/test_voxtral.py
    - pytest -v -s models/multimodal/pooling

vllm_pytorch_compilation_unit_tests:
  title: PyTorch Compilation Unit Tests
  id: vllm_pytorch_compilation_unit_tests
  steps:
    - pytest -v -s compile/test_pass_manager.py
    - pytest -v -s compile/test_fusion.py
    - pytest -v -s compile/test_fusion_attn.py
    - pytest -v -s compile/test_silu_mul_quant_fusion.py
    - pytest -v -s compile/distributed/test_sequence_parallelism.py
    - pytest -v -s compile/distributed/test_async_tp.py
    - pytest -v -s compile/distributed/test_fusion_all_reduce.py
    - pytest -v -s compile/test_decorator.py

vllm_language_model_test_extended_generation_28_failure_test:
  title: Language Models Test (Extended Generation) 2.8 release failure
  id: vllm_languagde_model_test_extended_generation_28_failure_test
  package_install:
    - --no-build-isolation
    - git+https://github.com/Dao-AILab/causal-conv1d@v1.5.0.post8
  steps:
    - pytest -v -s models/language/generation/test_mistral.py

vllm_distributed_test_2_gpu_28_failure_test:
  title: Distributed Tests (2 GPUs) pytorch 2.8 release failure
  id: vllm_distributed_test_2_gpu_28_failure_test
  env_vars:
    VLLM_WORKER_MULTIPROC_METHOD: spawn
  num_gpus: 4
  steps:
    - pytest -v -s distributed/test_sequence_parallel.py

# TODO(elainewy): need to add g6 with 4 gpus to run this test
vllm_lora_test:
  title: LoRA Test %N
  id: lora_test
  parallelism: 4
  steps:
    - "echo '[checking] list sharded lora tests:'"
    - pytest -q --collect-only lora --shard-id=$$BUILDKITE_PARALLEL_JOB --num-shards=$$BUILDKITE_PARALLEL_JOB_COUNT --ignore=lora/test_chatglm3_tp.py --ignore=lora/test_llama_tp.py --ignore=lora/test_llm_with_multi_loras.py --ignore=lora/test_olmoe_tp.py --ignore=lora/test_deepseekv2_tp.py --ignore=lora/test_gptoss_tp.py --ignore=lora/test_qwen3moe_tp.py
    - "echo '[checking] Done. list lora tests'"
    - pytest -v -s lora --shard-id=$$BUILDKITE_PARALLEL_JOB --num-shards=$$BUILDKITE_PARALLEL_JOB_COUNT --ignore=lora/test_chatglm3_tp.py --ignore=lora/test_llama_tp.py --ignore=lora/test_llm_with_multi_loras.py --ignore=lora/test_olmoe_tp.py --ignore=lora/test_deepseekv2_tp.py --ignore=lora/test_gptoss_tp.py --ignore=lora/test_qwen3moe_tp.py
