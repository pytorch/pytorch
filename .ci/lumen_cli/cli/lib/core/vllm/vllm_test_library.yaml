# VLLM Test Library Configuration
# This file defines the test plans for vllm CI development
# See https://github.com/vllm-project/vllm/blob/main/.buildkite/test-pipeline.yaml

vllm_basic_correctness_test:
  title: Basic Correctness Test
  id: vllm_basic_correctness_test
  env_vars:
    VLLM_WORKER_MULTIPROC_METHOD: spawn
  steps:
    - pytest -v -s basic_correctness/test_cumem.py
    - pytest -v -s basic_correctness/test_basic_correctness.py
    - pytest -v -s basic_correctness/test_cpu_offload.py

vllm_basic_models_test:
  title: Basic models test
  id: vllm_basic_models_test
  steps:
    - pytest -v -s models/test_transformers.py
    - pytest -v -s models/test_registry.py
    - pytest -v -s models/test_utils.py
    - pytest -v -s models/test_vision.py
    - pytest -v -s models/test_initialization.py

vllm_entrypoints_test:
  title: Entrypoints Test
  id: vllm_entrypoints_test
  env_vars:
    VLLM_WORKER_MULTIPROC_METHOD: spawn
  steps:
    - pytest -v -s entrypoints/llm --ignore=entrypoints/llm/test_generate.py --ignore=entrypoints/llm/test_collective_rpc.py
    - pytest -v -s entrypoints/llm/test_generate.py
    - pytest -v -s entrypoints/offline_mode

vllm_regression_test:
  title: Regression Test
  id: vllm_regression_test
  package_install:
    - modelscope
  steps:
    - pytest -v -s test_regression.py

vllm_lora_tp_test_distributed:
  title: LoRA TP Test (Distributed)
  id: vllm_lora_tp_test_distributed
  env_vars:
    VLLM_WORKER_MULTIPROC_METHOD: spawn
  num_gpus: 4
  steps:
    - pytest -v -s -x lora/test_chatglm3_tp.py
    - pytest -v -s -x lora/test_llama_tp.py
    - pytest -v -s -x lora/test_llm_with_multi_loras.py

vllm_distributed_test_28_failure_test:
  title: Distributed Tests (2 GPUs) pytorch 2.8 release failure
  id: vllm_distributed_test_28_failure_test
  env_vars:
    VLLM_WORKER_MULTIPROC_METHOD: spawn
  num_gpus: 4
  steps:
    - pytest -v -s distributed/test_sequence_parallel.py

vllm_lora_28_failure_test:
  title: LoRA pytorch 2.8 failure test
  id: vllm_lora_28_failure_test
  steps:
    - pytest -v lora/test_quant_model.py

vllm_multi_model_processor_test:
  title: Multi-Modal Processor Test
  id: vllm_multi_model_processor_test
  package_install:
    - git+https://github.com/TIGER-AI-Lab/Mantis.git
  steps:
    - pytest -v -s models/multimodal/processing --ignore models/multimodal/processing/test_tensor_schema.py

vllm_multi_model_test_28_failure_test:
  title: Multi-Model Test (Failed 2.8 release)
  id: vllm_multi_model_test_28_failure_test
  package_install:
    - git+https://github.com/TIGER-AI-Lab/Mantis.git
  steps:
    - pytest -v -s models/multimodal/generation/test_voxtral.py
    - pytest -v -s models/multimodal/pooling

vllm_pytorch_compilation_unit_tests:
  title: PyTorch Compilation Unit Tests
  id: vllm_pytorch_compilation_unit_tests
  steps:
    - "find compile/ -maxdepth 1 -name 'test_*.py' -print0 | xargs -0 -n1 -I{} pytest -s -v '{}'"

vllm_language_model_test_extended_generation_28_failure_test:
  title: Language Models Test (Extended Generation) 2.8 release failure
  id: vllm_languagde_model_test_extended_generation_28_failure_test
  package_install:
    - --no-build-isolation
    - git+https://github.com/Dao-AILab/causal-conv1d@v1.5.0.post8
  steps:
    - pytest -v -s models/language/generation/test_mistral.py

vllm_distributed_test_2_gpu_28_failure_test:
  title: Distributed Tests (2 GPUs) pytorch 2.8 release failure
  id: vllm_distributed_test_2_gpu_28_failure_test
  env_vars:
    VLLM_WORKER_MULTIPROC_METHOD: spawn
  num_gpus: 4
  steps:
    - pytest -v -s distributed/test_sequence_parallel.py
# V1 Test attention 100
vllm_test_attention:
  title: v1 Attention Test
  id: vllm_test_attention
  steps:
    - pytest -v -s v1/attention

# h100 tests
batch_invariance_test:
  title: Batch Invariance Tests H100
  id: batch_invariance_test
  env_vars:
    VLLM_WORKER_MULTIPROC_METHOD: spawn
  package_install:
    - pytest-timeout
    - pytest-forked
  steps:
    - pytest -v -s v1/determinism/test_batch_invariance.py
    - pytest -v -s v1/determinism/test_rms_norm_batch_invariant.py

pytorch_fullgraph_test:
  title: PyTorch Fullgraph Test
  id: pytorch_fullgraph_test
  steps:
    - pytest -v -s compile/fullgraph/test_full_graph.py -k 'not test_fp8_kv_scale_compile'
    - pytest -v -s compile/distributed/test_fusions_e2e.py -k 'TRITON and not +quant_fp8 and not Llama-4'

pytorch_fullgraph_smoke_test:
  title: PyTorch Fullgraph Smoke Test
  id: pytorch_fullgraph_smoke_test
  steps:
    - "find compile/fullgraph -maxdepth 1 -name 'test_*.py' -not -name 'test_full_graph.py' -print0 | xargs -0 -n1 -I{} pytest -s -v '{}'"


# TODO(elainewy): need to add g6 with 4 gpus to run this test
vllm_lora_test:
  title: LoRA Test %N
  id: lora_test
  parallelism: 4
  steps:
    - "echo '[checking] list sharded lora tests:'"
    - pytest -q --collect-only lora --shard-id=$$BUILDKITE_PARALLEL_JOB --num-shards=$$BUILDKITE_PARALLEL_JOB_COUNT --ignore=lora/test_chatglm3_tp.py --ignore=lora/test_llama_tp.py --ignore=lora/test_llm_with_multi_loras.py --ignore=lora/test_olmoe_tp.py --ignore=lora/test_deepseekv2_tp.py --ignore=lora/test_gptoss_tp.py --ignore=lora/test_qwen3moe_tp.py
    - "echo '[checking] Done. list lora tests'"
    - pytest -v -s lora --shard-id=$$BUILDKITE_PARALLEL_JOB --num-shards=$$BUILDKITE_PARALLEL_JOB_COUNT --ignore=lora/test_chatglm3_tp.py --ignore=lora/test_llama_tp.py --ignore=lora/test_llm_with_multi_loras.py --ignore=lora/test_olmoe_tp.py --ignore=lora/test_deepseekv2_tp.py --ignore=lora/test_gptoss_tp.py --ignore=lora/test_qwen3moe_tp.py
