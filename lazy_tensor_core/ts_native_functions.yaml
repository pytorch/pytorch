backend: Lazy
cpp_namespace: torch_lazy_tensors
full_codegen:
  - _log_softmax
  - _log_softmax_backward_data
  - _softmax
  - _softmax_backward_data
  - addcdiv
  - addcmul
  - addmm
  - bitwise_and.Tensor
  - baddbmm
  - bmm
  - cos
  - clamp
  - gelu
  - gelu_backward
  - log2
  - mean
  - mm
  - mv
  - native_layer_norm
  - native_layer_norm_backward
  - rsqrt
  - sigmoid
  - smooth_l1_loss
  - smooth_l1_loss_backward
  - softplus
  - softplus_backward
  - sum
  - sum.dim_IntList
  - topk
  - trace
  - add.Tensor
supported:
  - as_strided
  - as_strided_
  - bernoulli
  - bernoulli_.float
  - cat
  - constant_pad_nd
  - convolution_overrideable
  - convolution_backward_overrideable
  - _copy_from
  - _copy_from_and_resize
  - div.Tensor
  - div.Tensor_mode
  - div.Scalar
  - embedding_dense_backward
  - empty.memory_format
  - empty_strided
  - expand
  - fill_.Scalar
  - leaky_relu
  - leaky_relu_backward
  - mul.Tensor
  - mul.Scalar
  - native_batch_norm
  - native_batch_norm_backward
  - nll_loss_backward
  - nll_loss_forward
  - max_pool2d_with_indices
  - max_pool2d_with_indices_backward
  - max_pool3d_with_indices
  - max_pool3d_with_indices_backward
  - permute
  - random_
  - relu
  - relu_
  - repeat
  - select.int
  - slice.Tensor
  - sqrt
  - squeeze
  - squeeze.dim
  - squeeze_
  - squeeze_.dim
  - stack
  - t
  - t_
  - tanh
  - threshold
  - threshold_backward
  - transpose.int
  - transpose_
  - unsqueeze
  - unsqueeze_
  - sub.Tensor
  - sub.Scalar
  - view
  - ne.Scalar
  - ne.Tensor
  - eq.Scalar
  - eq.Tensor
  - ge.Scalar
  - ge.Tensor
  - le.Scalar
  - le.Tensor
  - gt.Scalar
  - gt.Tensor
  - lt.Scalar
  - lt.Tensor
  - index_select
  - alias
  - tanh_backward
  - zero_
autograd:
  - max_pool2d
  - max_pool3d
